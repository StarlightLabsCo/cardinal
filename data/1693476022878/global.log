[1693476022885] [Character] Creating Thomas's logger
[1693476022886] [Character] Creating George's logger
[1693476022886] [Character] Creating Will's logger
[1693476022887] [Character] Creating Lucy's logger
[1693476022887] [Character] Creating Eli's logger
[1693476022889] [Main] WebSocket server listening on port 8082
[1693476023132] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023133] [33m[OPENAI] Creating embedding...[39m
[1693476023133] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023133] [33m[OPENAI] Creating embedding...[39m
[1693476023133] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023134] [33m[OPENAI] Creating embedding...[39m
[1693476023134] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023134] [33m[OPENAI] Creating embedding...[39m
[1693476023134] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023134] [33m[OPENAI] Creating embedding...[39m
[1693476023134] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023134] [33m[OPENAI] Creating embedding...[39m
[1693476023134] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023134] [33m[OPENAI] Creating embedding...[39m
[1693476023134] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023134] [33m[OPENAI] Creating embedding...[39m
[1693476023134] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023134] [33m[OPENAI] Creating embedding...[39m
[1693476023134] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023134] [33m[OPENAI] Creating embedding...[39m
[1693476023134] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023134] [33m[OPENAI] Creating embedding...[39m
[1693476023134] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023134] [33m[OPENAI] Creating embedding...[39m
[1693476023134] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023135] [33m[OPENAI] Creating embedding...[39m
[1693476023135] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023135] [33m[OPENAI] Creating embedding...[39m
[1693476023135] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023135] [33m[OPENAI] Creating embedding...[39m
[1693476023224] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023224] [33m[OPENAI] Creating embedding...[39m
[1693476023225] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023225] [33m[OPENAI] Creating embedding...[39m
[1693476023225] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023225] [33m[OPENAI] Creating embedding...[39m
[1693476023225] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023225] [33m[OPENAI] Creating embedding...[39m
[1693476023225] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023225] [33m[OPENAI] Creating embedding...[39m
[1693476023225] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023225] [33m[OPENAI] Creating embedding...[39m
[1693476023225] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023225] [33m[OPENAI] Creating embedding...[39m
[1693476023225] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023225] [33m[OPENAI] Creating embedding...[39m
[1693476023225] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023225] [33m[OPENAI] Creating embedding...[39m
[1693476023225] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023225] [33m[OPENAI] Creating embedding...[39m
[1693476023225] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023225] [33m[OPENAI] Creating embedding...[39m
[1693476023225] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023225] [33m[OPENAI] Creating embedding...[39m
[1693476023225] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023225] [33m[OPENAI] Creating embedding...[39m
[1693476023225] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023225] [33m[OPENAI] Creating embedding...[39m
[1693476023225] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023225] [33m[OPENAI] Creating embedding...[39m
[1693476023225] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023225] [33m[OPENAI] Creating embedding...[39m
[1693476023278] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023278] [33m[OPENAI] Creating embedding...[39m
[1693476023278] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023278] [33m[OPENAI] Creating embedding...[39m
[1693476023278] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023278] [33m[OPENAI] Creating embedding...[39m
[1693476023278] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023278] [33m[OPENAI] Creating embedding...[39m
[1693476023278] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023278] [33m[OPENAI] Creating embedding...[39m
[1693476023278] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023278] [33m[OPENAI] Creating embedding...[39m
[1693476023278] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023278] [33m[OPENAI] Creating embedding...[39m
[1693476023278] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023278] [33m[OPENAI] Creating embedding...[39m
[1693476023279] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023279] [33m[OPENAI] Creating embedding...[39m
[1693476023279] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023279] [33m[OPENAI] Creating embedding...[39m
[1693476023279] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023279] [33m[OPENAI] Creating embedding...[39m
[1693476023279] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023279] [33m[OPENAI] Creating embedding...[39m
[1693476023279] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023279] [33m[OPENAI] Creating embedding...[39m
[1693476023279] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023279] [33m[OPENAI] Creating embedding...[39m
[1693476023279] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023279] [33m[OPENAI] Creating embedding...[39m
[1693476023320] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023320] [33m[OPENAI] Creating embedding...[39m
[1693476023320] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023320] [33m[OPENAI] Creating embedding...[39m
[1693476023320] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023320] [33m[OPENAI] Creating embedding...[39m
[1693476023320] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023320] [33m[OPENAI] Creating embedding...[39m
[1693476023320] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023320] [33m[OPENAI] Creating embedding...[39m
[1693476023320] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023320] [33m[OPENAI] Creating embedding...[39m
[1693476023320] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023320] [33m[OPENAI] Creating embedding...[39m
[1693476023320] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023320] [33m[OPENAI] Creating embedding...[39m
[1693476023320] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023320] [33m[OPENAI] Creating embedding...[39m
[1693476023321] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023321] [33m[OPENAI] Creating embedding...[39m
[1693476023321] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023321] [33m[OPENAI] Creating embedding...[39m
[1693476023321] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023321] [33m[OPENAI] Creating embedding...[39m
[1693476023321] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023321] [33m[OPENAI] Creating embedding...[39m
[1693476023321] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023321] [33m[OPENAI] Creating embedding...[39m
[1693476023321] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023321] [33m[OPENAI] Creating embedding...[39m
[1693476023330] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023330] [33m[OPENAI] Creating embedding...[39m
[1693476023330] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023330] [33m[OPENAI] Creating embedding...[39m
[1693476023330] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023330] [33m[OPENAI] Creating embedding...[39m
[1693476023330] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023330] [33m[OPENAI] Creating embedding...[39m
[1693476023330] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023330] [33m[OPENAI] Creating embedding...[39m
[1693476023330] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023330] [33m[OPENAI] Creating embedding...[39m
[1693476023330] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023330] [33m[OPENAI] Creating embedding...[39m
[1693476023330] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023330] [33m[OPENAI] Creating embedding...[39m
[1693476023330] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023330] [33m[OPENAI] Creating embedding...[39m
[1693476023330] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023330] [33m[OPENAI] Creating embedding...[39m
[1693476023330] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023330] [33m[OPENAI] Creating embedding...[39m
[1693476023330] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023330] [33m[OPENAI] Creating embedding...[39m
[1693476023330] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023330] [33m[OPENAI] Creating embedding...[39m
[1693476023330] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023330] [33m[OPENAI] Creating embedding...[39m
[1693476023330] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476023330] [33m[OPENAI] Creating embedding...[39m
[1693476023346] [32m[OPENAI] Embedding created successfully.[39m
[1693476023364] [32m[OPENAI] Embedding created successfully.[39m
[1693476023367] [32m[OPENAI] Embedding created successfully.[39m
[1693476023370] [32m[OPENAI] Embedding created successfully.[39m
[1693476023370] [32m[OPENAI] Embedding created successfully.[39m
[1693476023373] [32m[OPENAI] Embedding created successfully.[39m
[1693476023387] [32m[OPENAI] Embedding created successfully.[39m
[1693476023396] [32m[OPENAI] Embedding created successfully.[39m
[1693476023398] [32m[OPENAI] Embedding created successfully.[39m
[1693476023399] [32m[OPENAI] Embedding created successfully.[39m
[1693476023423] [32m[OPENAI] Embedding created successfully.[39m
[1693476023423] [32m[OPENAI] Embedding created successfully.[39m
[1693476023429] [32m[OPENAI] Embedding created successfully.[39m
[1693476023431] [32m[OPENAI] Embedding created successfully.[39m
[1693476023434] {
  "id": "chatcmpl-7tYlLIGM5mSw7FQdIzrmccZ7d2TPi",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693476023434] {
  "role": "assistant",
  "content": "3"
}
[1693476023434] [36m[OPENAI] Chat completion took 298.38499999046326ms[39m
[1693476023434] [36m[OPENAI] Tokens per second: 3.3513749016604764tps[39m
[1693476023434] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023435] {
  "id": "chatcmpl-7tYlLSUOKlWL9Kc9UHXOzjTl5qilT",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 96,
    "completion_tokens": 1,
    "total_tokens": 97
  }
}
[1693476023435] {
  "role": "assistant",
  "content": "3"
}
[1693476023435] [36m[OPENAI] Chat completion took 300.92870795726776ms[39m
[1693476023435] [36m[OPENAI] Tokens per second: 3.3230462018332965tps[39m
[1693476023435] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023441] {
  "id": "chatcmpl-7tYlLDVKWdHV498yyvetwXoXw1Phr",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693476023441] {
  "role": "assistant",
  "content": "5"
}
[1693476023441] [36m[OPENAI] Chat completion took 307.3975830078125ms[39m
[1693476023441] [36m[OPENAI] Tokens per second: 3.2531160141704336tps[39m
[1693476023441] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023443] {
  "id": "chatcmpl-7tYlLv3y8H24hEeBTiPMKzBY4rYvv",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693476023443] {
  "role": "assistant",
  "content": "7"
}
[1693476023443] [36m[OPENAI] Chat completion took 308.0905410051346ms[39m
[1693476023443] [36m[OPENAI] Tokens per second: 3.245799097685814tps[39m
[1693476023443] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023462] [32m[OPENAI] Embedding created successfully.[39m
[1693476023467] [32m[OPENAI] Embedding created successfully.[39m
[1693476023469] {
  "id": "chatcmpl-7tYlLHPcfmadIOgtcjcSFgEprPf96",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693476023469] {
  "role": "assistant",
  "content": "3"
}
[1693476023469] [36m[OPENAI] Chat completion took 334.86475002765656ms[39m
[1693476023469] [36m[OPENAI] Tokens per second: 2.9862802815686327tps[39m
[1693476023469] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023470] {
  "id": "chatcmpl-7tYlLI04Kpdq3XCbAnsqdvl7fhS8f",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693476023470] {
  "role": "assistant",
  "content": "4"
}
[1693476023470] [36m[OPENAI] Chat completion took 336.5288339853287ms[39m
[1693476023470] [36m[OPENAI] Tokens per second: 2.9715135792601832tps[39m
[1693476023470] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023471] [32m[OPENAI] Embedding created successfully.[39m
[1693476023473] [32m[OPENAI] Embedding created successfully.[39m
[1693476023473] {
  "id": "chatcmpl-7tYlLjXvKncqiVKijuWgzaCOGKRmo",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693476023473] {
  "role": "assistant",
  "content": "5"
}
[1693476023473] [36m[OPENAI] Chat completion took 339.6102080345154ms[39m
[1693476023473] [36m[OPENAI] Tokens per second: 2.944552243548485tps[39m
[1693476023473] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023475] [32m[OPENAI] Embedding created successfully.[39m
[1693476023476] [32m[OPENAI] Embedding created successfully.[39m
[1693476023476] [32m[OPENAI] Embedding created successfully.[39m
[1693476023476] [32m[OPENAI] Embedding created successfully.[39m
[1693476023478] [32m[OPENAI] Embedding created successfully.[39m
[1693476023483] [32m[OPENAI] Embedding created successfully.[39m
[1693476023489] [32m[OPENAI] Embedding created successfully.[39m
[1693476023491] [32m[OPENAI] Embedding created successfully.[39m
[1693476023493] {
  "id": "chatcmpl-7tYlL8V97myrGn54Z25kngmtUBjUA",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693476023493] {
  "role": "assistant",
  "content": "7"
}
[1693476023493] [36m[OPENAI] Chat completion took 268.07620906829834ms[39m
[1693476023493] [36m[OPENAI] Tokens per second: 3.7302825322527147tps[39m
[1693476023493] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023494] [32m[OPENAI] Embedding created successfully.[39m
[1693476023494] [32m[OPENAI] Embedding created successfully.[39m
[1693476023498] {
  "id": "chatcmpl-7tYlLqR6mwmqFNubxJwkQa92b3Fwo",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693476023498] {
  "role": "assistant",
  "content": "7"
}
[1693476023498] [36m[OPENAI] Chat completion took 363.9910420179367ms[39m
[1693476023498] [36m[OPENAI] Tokens per second: 2.7473203583694845tps[39m
[1693476023498] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023499] {
  "id": "chatcmpl-7tYlLUij5e2gQKQ2ZyjORc5qgfE9f",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693476023499] {
  "role": "assistant",
  "content": "4"
}
[1693476023499] [36m[OPENAI] Chat completion took 365.0670839548111ms[39m
[1693476023499] [36m[OPENAI] Tokens per second: 2.739222581140135tps[39m
[1693476023499] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023501] [32m[OPENAI] Embedding created successfully.[39m
[1693476023505] [32m[OPENAI] Embedding created successfully.[39m
[1693476023506] [32m[OPENAI] Embedding created successfully.[39m
[1693476023506] [32m[OPENAI] Embedding created successfully.[39m
[1693476023509] [32m[OPENAI] Embedding created successfully.[39m
[1693476023512] [32m[OPENAI] Embedding created successfully.[39m
[1693476023512] [32m[OPENAI] Embedding created successfully.[39m
[1693476023513] [32m[OPENAI] Embedding created successfully.[39m
[1693476023520] {
  "id": "chatcmpl-7tYlL8oEVWtlFewaOMbftDFk3dSfe",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 96,
    "completion_tokens": 1,
    "total_tokens": 97
  }
}
[1693476023520] {
  "role": "assistant",
  "content": "4"
}
[1693476023520] [36m[OPENAI] Chat completion took 384.93699991703033ms[39m
[1693476023520] [36m[OPENAI] Tokens per second: 2.5978276970401413tps[39m
[1693476023520] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023521] {
  "id": "chatcmpl-7tYlLMo84X7u173kXF0WunylzTzB7",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 114,
    "completion_tokens": 1,
    "total_tokens": 115
  }
}
[1693476023521] {
  "role": "assistant",
  "content": "3"
}
[1693476023521] [36m[OPENAI] Chat completion took 296.1440420150757ms[39m
[1693476023521] [36m[OPENAI] Tokens per second: 3.376735163049789tps[39m
[1693476023521] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023522] {
  "id": "chatcmpl-7tYlLhogj0pi3AaTHaglZS0BPTgu0",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693476023522] {
  "role": "assistant",
  "content": "2"
}
[1693476023522] [36m[OPENAI] Chat completion took 387.4956250190735ms[39m
[1693476023522] [36m[OPENAI] Tokens per second: 2.580674297808595tps[39m
[1693476023522] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023523] [32m[OPENAI] Embedding created successfully.[39m
[1693476023524] {
  "id": "chatcmpl-7tYlLJPqeAo0lnLbgVJWiNcpWgryN",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693476023524] {
  "role": "assistant",
  "content": "3"
}
[1693476023524] [36m[OPENAI] Chat completion took 298.8445829153061ms[39m
[1693476023524] [36m[OPENAI] Tokens per second: 3.346220936129214tps[39m
[1693476023524] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023524] [32m[OPENAI] Embedding created successfully.[39m
[1693476023528] {
  "id": "chatcmpl-7tYlL2auCPmJiOgxBSNsec3xgkIdI",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "8"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693476023528] {
  "role": "assistant",
  "content": "8"
}
[1693476023528] [36m[OPENAI] Chat completion took 302.8752090930939ms[39m
[1693476023528] [36m[OPENAI] Tokens per second: 3.301689837852107tps[39m
[1693476023528] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023532] {
  "id": "chatcmpl-7tYlLuUXXFUJ1fIrYd9PdYSF7gLZT",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693476023532] {
  "role": "assistant",
  "content": "7"
}
[1693476023532] [36m[OPENAI] Chat completion took 306.4381250143051ms[39m
[1693476023532] [36m[OPENAI] Tokens per second: 3.263301522789692tps[39m
[1693476023532] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023532] {
  "id": "chatcmpl-7tYlLlz1bugC2DPtmuf33jxbI8Ybp",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 90,
    "completion_tokens": 1,
    "total_tokens": 91
  }
}
[1693476023532] {
  "role": "assistant",
  "content": "2"
}
[1693476023532] [36m[OPENAI] Chat completion took 398.53395891189575ms[39m
[1693476023532] [36m[OPENAI] Tokens per second: 2.5091964627814085tps[39m
[1693476023532] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023533] {
  "id": "chatcmpl-7tYlLsJJGhgHG8iyfTQ1z9iOQ9YM9",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693476023533] {
  "role": "assistant",
  "content": "2"
}
[1693476023533] [36m[OPENAI] Chat completion took 398.40583300590515ms[39m
[1693476023533] [36m[OPENAI] Tokens per second: 2.5100034114841336tps[39m
[1693476023533] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023534] [32m[OPENAI] Embedding created successfully.[39m
[1693476023535] {
  "id": "chatcmpl-7tYlLUp1iIN52hzH1HsjWJUq1DSef",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693476023535] {
  "role": "assistant",
  "content": "6"
}
[1693476023535] [36m[OPENAI] Chat completion took 309.7916669845581ms[39m
[1693476023535] [36m[OPENAI] Tokens per second: 3.2279757868691994tps[39m
[1693476023535] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023539] {
  "id": "chatcmpl-7tYlLF4bH8TlpeEbGZw8Yc38hRdjQ",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693476023539] {
  "role": "assistant",
  "content": "5"
}
[1693476023539] [36m[OPENAI] Chat completion took 314.1333749294281ms[39m
[1693476023539] [36m[OPENAI] Tokens per second: 3.1833612083550684tps[39m
[1693476023539] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023543] [32m[OPENAI] Embedding created successfully.[39m
[1693476023543] [32m[OPENAI] Embedding created successfully.[39m
[1693476023543] [32m[OPENAI] Embedding created successfully.[39m
[1693476023548] [32m[OPENAI] Embedding created successfully.[39m
[1693476023548] [32m[OPENAI] Embedding created successfully.[39m
[1693476023548] [32m[OPENAI] Embedding created successfully.[39m
[1693476023550] {
  "id": "chatcmpl-7tYlLyTseWzP8teDBaAKtEU8snJHD",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693476023550] {
  "role": "assistant",
  "content": "5"
}
[1693476023550] [36m[OPENAI] Chat completion took 325.3124170303345ms[39m
[1693476023550] [36m[OPENAI] Tokens per second: 3.0739681231004248tps[39m
[1693476023550] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023550] {
  "id": "chatcmpl-7tYlLhgpupjci8E6g1ZAonPiYpvgV",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693476023550] {
  "role": "assistant",
  "content": "6"
}
[1693476023550] [36m[OPENAI] Chat completion took 417.7709159851074ms[39m
[1693476023550] [36m[OPENAI] Tokens per second: 2.3936563358940184tps[39m
[1693476023550] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023551] [32m[OPENAI] Embedding created successfully.[39m
[1693476023552] [32m[OPENAI] Embedding created successfully.[39m
[1693476023552] [32m[OPENAI] Embedding created successfully.[39m
[1693476023552] [32m[OPENAI] Embedding created successfully.[39m
[1693476023554] {
  "id": "chatcmpl-7tYlLkZsgUDPBjOp1UY8KyWDP2utM",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 2,
    "total_tokens": 102
  }
}
[1693476023554] {
  "role": "assistant",
  "content": "6."
}
[1693476023554] [36m[OPENAI] Chat completion took 329.5645419359207ms[39m
[1693476023554] [36m[OPENAI] Tokens per second: 6.068614020949112tps[39m
[1693476023554] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023554] {
  "id": "chatcmpl-7tYlL8Ha3w3h6slh8wa6n1W99UmbK",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693476023554] {
  "role": "assistant",
  "content": "2"
}
[1693476023554] [36m[OPENAI] Chat completion took 329.37395799160004ms[39m
[1693476023554] [36m[OPENAI] Tokens per second: 3.0360627357962007tps[39m
[1693476023555] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023556] {
  "id": "chatcmpl-7tYlLUZc1TbBWjpiV8mTHpn3a46pe",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693476023556] {
  "role": "assistant",
  "content": "6"
}
[1693476023556] [36m[OPENAI] Chat completion took 421.9834580421448ms[39m
[1693476023556] [36m[OPENAI] Tokens per second: 2.369761138599246tps[39m
[1693476023556] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023557] [32m[OPENAI] Embedding created successfully.[39m
[1693476023564] [32m[OPENAI] Embedding created successfully.[39m
[1693476023565] [32m[OPENAI] Embedding created successfully.[39m
[1693476023568] {
  "id": "chatcmpl-7tYlLIYvmOz03UFVPKZ4vCqev6Azx",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "8"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1693476023568] {
  "role": "assistant",
  "content": "8"
}
[1693476023568] [36m[OPENAI] Chat completion took 343.026624917984ms[39m
[1693476023568] [36m[OPENAI] Tokens per second: 2.9152256045404497tps[39m
[1693476023568] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023569] [32m[OPENAI] Embedding created successfully.[39m
[1693476023570] [32m[OPENAI] Embedding created successfully.[39m
[1693476023572] [32m[OPENAI] Embedding created successfully.[39m
[1693476023575] {
  "id": "chatcmpl-7tYlLXQo0J5IqT5nzv42AoJWvp6HY",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 86,
    "completion_tokens": 1,
    "total_tokens": 87
  }
}
[1693476023575] {
  "role": "assistant",
  "content": "1"
}
[1693476023575] [36m[OPENAI] Chat completion took 296.23745810985565ms[39m
[1693476023575] [36m[OPENAI] Tokens per second: 3.3756703368321626tps[39m
[1693476023575] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023577] [32m[OPENAI] Embedding created successfully.[39m
[1693476023579] {
  "id": "chatcmpl-7tYlLU81VKzRaEOJKitJNWsECgRsN",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693476023579] {
  "role": "assistant",
  "content": "6"
}
[1693476023579] [36m[OPENAI] Chat completion took 354.4765000343323ms[39m
[1693476023579] [36m[OPENAI] Tokens per second: 2.8210614805301524tps[39m
[1693476023579] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023580] [32m[OPENAI] Embedding created successfully.[39m
[1693476023581] {
  "id": "chatcmpl-7tYlLAnS2y9N4IQxFN1vcNCBcxQwu",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 92,
    "completion_tokens": 1,
    "total_tokens": 93
  }
}
[1693476023581] {
  "role": "assistant",
  "content": "1"
}
[1693476023581] [36m[OPENAI] Chat completion took 302.15091693401337ms[39m
[1693476023581] [36m[OPENAI] Tokens per second: 3.309604386268964tps[39m
[1693476023581] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023586] {
  "id": "chatcmpl-7tYlLg9sKHSMMzPvOJmNdyAem80HO",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 2,
    "total_tokens": 96
  }
}
[1693476023587] {
  "role": "assistant",
  "content": "3."
}
[1693476023587] [36m[OPENAI] Chat completion took 308.12804102897644ms[39m
[1693476023587] [36m[OPENAI] Tokens per second: 6.490808150147942tps[39m
[1693476023587] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023588] [32m[OPENAI] Embedding created successfully.[39m
[1693476023592] [32m[OPENAI] Embedding created successfully.[39m
[1693476023592] [32m[OPENAI] Embedding created successfully.[39m
[1693476023596] {
  "id": "chatcmpl-7tYlLbnK0TAo8kUs7be9S2FtUBKLo",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1693476023596] {
  "role": "assistant",
  "content": "4"
}
[1693476023596] [36m[OPENAI] Chat completion took 275.82762491703033ms[39m
[1693476023596] [36m[OPENAI] Tokens per second: 3.625452672845233tps[39m
[1693476023596] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023597] {
  "id": "chatcmpl-7tYlLw7TkipUHEcMbxBKM0Yg4OEUn",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693476023597] {
  "role": "assistant",
  "content": "7"
}
[1693476023597] [36m[OPENAI] Chat completion took 276.6218749284744ms[39m
[1693476023597] [36m[OPENAI] Tokens per second: 3.615043099026669tps[39m
[1693476023597] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023598] {
  "id": "chatcmpl-7tYlLs8JNNiwp86OBs5s7MM7AgBn4",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1693476023598] {
  "role": "assistant",
  "content": "4"
}
[1693476023598] [36m[OPENAI] Chat completion took 372.77416706085205ms[39m
[1693476023598] [36m[OPENAI] Tokens per second: 2.6825893217991124tps[39m
[1693476023598] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023601] [32m[OPENAI] Embedding created successfully.[39m
[1693476023602] [32m[OPENAI] Embedding created successfully.[39m
[1693476023602] [32m[OPENAI] Embedding created successfully.[39m
[1693476023606] {
  "id": "chatcmpl-7tYlLluM6nnFJ6zzjxv6W3cp7wwxd",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693476023606] {
  "role": "assistant",
  "content": "7"
}
[1693476023606] [36m[OPENAI] Chat completion took 286.30508399009705ms[39m
[1693476023606] [36m[OPENAI] Tokens per second: 3.4927776554418046tps[39m
[1693476023606] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023609] [32m[OPENAI] Embedding created successfully.[39m
[1693476023613] {
  "id": "chatcmpl-7tYlLnDJzlLW8pW4RooRjFmx8t1Jh",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693476023613] {
  "role": "assistant",
  "content": "2"
}
[1693476023613] [36m[OPENAI] Chat completion took 334.33570897579193ms[39m
[1693476023613] [36m[OPENAI] Tokens per second: 2.9910056663208726tps[39m
[1693476023613] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023614] [32m[OPENAI] Embedding created successfully.[39m
[1693476023617] {
  "id": "chatcmpl-7tYlL0LlFxjMfNCdSsftRD9EuRFaQ",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693476023617] {
  "role": "assistant",
  "content": "5"
}
[1693476023617] [36m[OPENAI] Chat completion took 286.3397080898285ms[39m
[1693476023617] [36m[OPENAI] Tokens per second: 3.492355309960318tps[39m
[1693476023617] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023618] {
  "id": "chatcmpl-7tYlL0VhrFsrUJViwJlxOwKFtmdlg",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1693476023618] {
  "role": "assistant",
  "content": "7"
}
[1693476023618] [36m[OPENAI] Chat completion took 296.79408299922943ms[39m
[1693476023618] [36m[OPENAI] Tokens per second: 3.3693394083014665tps[39m
[1693476023618] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023618] [32m[OPENAI] Embedding created successfully.[39m
[1693476023618] {
  "id": "chatcmpl-7tYlLWoYYF0Xxa6X2PtWLSA6FCZlO",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693476023618] {
  "role": "assistant",
  "content": "3"
}
[1693476023618] [36m[OPENAI] Chat completion took 339.55166697502136ms[39m
[1693476023618] [36m[OPENAI] Tokens per second: 2.9450599047524735tps[39m
[1693476023618] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023619] [32m[OPENAI] Embedding created successfully.[39m
[1693476023621] {
  "id": "chatcmpl-7tYlL3moULdA1w54JvOvJFQhPZwLP",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 90,
    "completion_tokens": 1,
    "total_tokens": 91
  }
}
[1693476023621] {
  "role": "assistant",
  "content": "4"
}
[1693476023621] [36m[OPENAI] Chat completion took 290.93545794487ms[39m
[1693476023621] [36m[OPENAI] Tokens per second: 3.4371884646301596tps[39m
[1693476023621] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023624] {
  "id": "chatcmpl-7tYlLs70Ci3NlwtNT3tpgsJ43FC4v",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "8"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693476023624] {
  "role": "assistant",
  "content": "8"
}
[1693476023624] [36m[OPENAI] Chat completion took 303.3813329935074ms[39m
[1693476023624] [36m[OPENAI] Tokens per second: 3.296181706807257tps[39m
[1693476023624] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023627] {
  "id": "chatcmpl-7tYlL0GFGdlNKUjblnWZMbCXAxqzl",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693476023627] {
  "role": "assistant",
  "content": "2"
}
[1693476023627] [36m[OPENAI] Chat completion took 305.6113749742508ms[39m
[1693476023627] [36m[OPENAI] Tokens per second: 3.2721295144339924tps[39m
[1693476023627] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023627] {
  "id": "chatcmpl-7tYlLRK2FxDzd8mhIIXLKGwM8KcYy",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693476023627] {
  "role": "assistant",
  "content": "2"
}
[1693476023627] [36m[OPENAI] Chat completion took 348.0341659784317ms[39m
[1693476023627] [36m[OPENAI] Tokens per second: 2.873281125112216tps[39m
[1693476023627] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023629] {
  "id": "chatcmpl-7tYlL8AmT8DVBYhzRKkmBFv13qh7Q",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693476023629] {
  "role": "assistant",
  "content": "3"
}
[1693476023629] [36m[OPENAI] Chat completion took 308.2011660337448ms[39m
[1693476023629] [36m[OPENAI] Tokens per second: 3.2446340579078483tps[39m
[1693476023629] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023629] {
  "id": "chatcmpl-7tYlLwfHZPj7oJ3s1zkjNyfKbBlxB",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 96,
    "completion_tokens": 1,
    "total_tokens": 97
  }
}
[1693476023629] {
  "role": "assistant",
  "content": "5"
}
[1693476023629] [36m[OPENAI] Chat completion took 299.0486670732498ms[39m
[1693476023629] [36m[OPENAI] Tokens per second: 3.3439373256094704tps[39m
[1693476023629] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023629] {
  "id": "chatcmpl-7tYlL7WwKmmDe76ruBgDfZyXEyZss",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693476023629] {
  "role": "assistant",
  "content": "4"
}
[1693476023629] [36m[OPENAI] Chat completion took 299.0766249895096ms[39m
[1693476023629] [36m[OPENAI] Tokens per second: 3.343624731739152tps[39m
[1693476023629] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023632] {
  "id": "chatcmpl-7tYlLwZROn8eyjVq8O9NTk3t9sPwQ",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693476023632] {
  "role": "assistant",
  "content": "7"
}
[1693476023632] [36m[OPENAI] Chat completion took 406.97183299064636ms[39m
[1693476023632] [36m[OPENAI] Tokens per second: 2.457172509093482tps[39m
[1693476023632] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023633] {
  "id": "chatcmpl-7tYlLe1jDXswftr3Tbw0f6mymt95r",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693476023633] {
  "role": "assistant",
  "content": "7"
}
[1693476023633] [36m[OPENAI] Chat completion took 407.9864579439163ms[39m
[1693476023633] [36m[OPENAI] Tokens per second: 2.4510617461167414tps[39m
[1693476023633] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023633] {
  "id": "chatcmpl-7tYlL16RONRb56a2ExjDoaoWRXkkE",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693476023633] {
  "role": "assistant",
  "content": "3"
}
[1693476023633] [36m[OPENAI] Chat completion took 354.4225000143051ms[39m
[1693476023633] [36m[OPENAI] Tokens per second: 2.8214912991123255tps[39m
[1693476023633] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023634] {
  "id": "chatcmpl-7tYlLL1gWQ5d0V99t7tRe33JJyAhp",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693476023634] {
  "role": "assistant",
  "content": "5"
}
[1693476023634] [36m[OPENAI] Chat completion took 313.7062499523163ms[39m
[1693476023634] [36m[OPENAI] Tokens per second: 3.1876954958723367tps[39m
[1693476023634] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023635] [32m[OPENAI] Embedding created successfully.[39m
[1693476023644] {
  "id": "chatcmpl-7tYlLYdcBjCEmMSWPvAEzbTgP5zfw",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693476023644] {
  "role": "assistant",
  "content": "2"
}
[1693476023644] [36m[OPENAI] Chat completion took 314.47233295440674ms[39m
[1693476023644] [36m[OPENAI] Tokens per second: 3.1799299817735744tps[39m
[1693476023644] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023645] {
  "id": "chatcmpl-7tYlL3pFfhccoVbqEkUZRgQPMFWTF",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693476023645] {
  "role": "assistant",
  "content": "2"
}
[1693476023645] [36m[OPENAI] Chat completion took 314.9640829563141ms[39m
[1693476023645] [36m[OPENAI] Tokens per second: 3.174965191630124tps[39m
[1693476023645] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023646] {
  "id": "chatcmpl-7tYlLsyvhRd3RV21uTWCJzZTzKVBS",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693476023646] {
  "role": "assistant",
  "content": "5"
}
[1693476023646] [36m[OPENAI] Chat completion took 367.7095420360565ms[39m
[1693476023646] [36m[OPENAI] Tokens per second: 2.7195378027528667tps[39m
[1693476023647] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023647] {
  "id": "chatcmpl-7tYlLNphNk7ZmkIosIgHQTWQNLVPi",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1693476023647] {
  "role": "assistant",
  "content": "1"
}
[1693476023647] [36m[OPENAI] Chat completion took 368.51608300209045ms[39m
[1693476023647] [36m[OPENAI] Tokens per second: 2.7135857731189645tps[39m
[1693476023647] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023652] [32m[OPENAI] Embedding created successfully.[39m
[1693476023653] {
  "id": "chatcmpl-7tYlL044tIddjYnnlZiVSpQsY5TV7",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693476023653] {
  "role": "assistant",
  "content": "3"
}
[1693476023653] [36m[OPENAI] Chat completion took 323.07912492752075ms[39m
[1693476023653] [36m[OPENAI] Tokens per second: 3.095217000554706tps[39m
[1693476023653] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023656] {
  "id": "chatcmpl-7tYlLGQChy0FGUDfcOO9MfbtMgOIs",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 2,
    "total_tokens": 96
  }
}
[1693476023656] {
  "role": "assistant",
  "content": "6."
}
[1693476023656] [36m[OPENAI] Chat completion took 335.11120796203613ms[39m
[1693476023656] [36m[OPENAI] Tokens per second: 5.968168036404723tps[39m
[1693476023656] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023659] {
  "id": "chatcmpl-7tYlLQ1k6wXM6IPOWqobMpK1D4aRC",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693476023659] {
  "role": "assistant",
  "content": "4"
}
[1693476023659] [36m[OPENAI] Chat completion took 329.5537919998169ms[39m
[1693476023659] [36m[OPENAI] Tokens per second: 3.0344059885694037tps[39m
[1693476023659] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023662] {
  "id": "chatcmpl-7tYlLTjIcTfWtz2u7n0a0IUD7TPkL",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "8"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1693476023662] {
  "role": "assistant",
  "content": "8"
}
[1693476023662] [36m[OPENAI] Chat completion took 340.64737498760223ms[39m
[1693476023662] [36m[OPENAI] Tokens per second: 2.935586983567376tps[39m
[1693476023662] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023664] {
  "id": "chatcmpl-7tYlLYOLgpORuUpyAmE6x0vmpa8H5",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693476023664] {
  "role": "assistant",
  "content": "2"
}
[1693476023664] [36m[OPENAI] Chat completion took 384.80716693401337ms[39m
[1693476023664] [36m[OPENAI] Tokens per second: 2.598704197657212tps[39m
[1693476023664] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023664] {
  "id": "chatcmpl-7tYlLjsNc9fTAFu53ZvFLzKn5Qew0",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 89,
    "completion_tokens": 1,
    "total_tokens": 90
  }
}
[1693476023664] {
  "role": "assistant",
  "content": "4"
}
[1693476023664] [36m[OPENAI] Chat completion took 386.0369589328766ms[39m
[1693476023664] [36m[OPENAI] Tokens per second: 2.590425545689469tps[39m
[1693476023665] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023667] {
  "id": "chatcmpl-7tYlL77LVa3strio3lCLrfXX66MXr",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693476023667] {
  "role": "assistant",
  "content": "5"
}
[1693476023667] [36m[OPENAI] Chat completion took 441.18795907497406ms[39m
[1693476023667] [36m[OPENAI] Tokens per second: 2.2666076429118123tps[39m
[1693476023667] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023667] [32m[OPENAI] Embedding created successfully.[39m
[1693476023668] [32m[OPENAI] Embedding created successfully.[39m
[1693476023670] {
  "id": "chatcmpl-7tYlLGg63YLBHXZOAWB9D7UnBWrQy",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693476023670] {
  "role": "assistant",
  "content": "2"
}
[1693476023670] [36m[OPENAI] Chat completion took 349.7285829782486ms[39m
[1693476023670] [36m[OPENAI] Tokens per second: 2.859360225818875tps[39m
[1693476023670] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023678] {
  "id": "chatcmpl-7tYlLXK60ELJYDT8cR0e0f2EfbJnw",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693476023678] {
  "role": "assistant",
  "content": "1"
}
[1693476023678] [36m[OPENAI] Chat completion took 399.1466670036316ms[39m
[1693476023678] [36m[OPENAI] Tokens per second: 2.5053447333205505tps[39m
[1693476023678] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023678] {
  "id": "chatcmpl-7tYlL5iw6o3AMQR4ulFHjyEvtm1rs",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 92,
    "completion_tokens": 2,
    "total_tokens": 94
  }
}
[1693476023678] {
  "role": "assistant",
  "content": "5."
}
[1693476023678] [36m[OPENAI] Chat completion took 348.40349996089935ms[39m
[1693476023678] [36m[OPENAI] Tokens per second: 5.740470460900812tps[39m
[1693476023678] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023684] {
  "id": "chatcmpl-7tYlLQV1pbSLSJ1DOltSR7FygHpGT",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693476023684] {
  "role": "assistant",
  "content": "6"
}
[1693476023684] [36m[OPENAI] Chat completion took 363.6377079486847ms[39m
[1693476023684] [36m[OPENAI] Tokens per second: 2.7499898336756554tps[39m
[1693476023684] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023690] [32m[OPENAI] Embedding created successfully.[39m
[1693476023695] {
  "id": "chatcmpl-7tYlLAWEBF37UYiDqVLxAY8rM3CjO",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693476023695] {
  "role": "assistant",
  "content": "2"
}
[1693476023695] [36m[OPENAI] Chat completion took 365.2259999513626ms[39m
[1693476023695] [36m[OPENAI] Tokens per second: 2.73803069916482tps[39m
[1693476023695] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023696] {
  "id": "chatcmpl-7tYlLubwexZ5u4SxWomj2rulAxZLy",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693476023696] {
  "role": "assistant",
  "content": "4"
}
[1693476023696] [36m[OPENAI] Chat completion took 375.2471250295639ms[39m
[1693476023696] [36m[OPENAI] Tokens per second: 2.6649104904433707tps[39m
[1693476023696] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023697] {
  "id": "chatcmpl-7tYlLojkk7wWjMhqB46F6b4Ez6U0Y",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693476023697] {
  "role": "assistant",
  "content": "5"
}
[1693476023697] [36m[OPENAI] Chat completion took 376.5198749303818ms[39m
[1693476023697] [36m[OPENAI] Tokens per second: 2.6559022951574582tps[39m
[1693476023697] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023698] [32m[OPENAI] Embedding created successfully.[39m
[1693476023700] [32m[OPENAI] Embedding created successfully.[39m
[1693476023704] [32m[OPENAI] Embedding created successfully.[39m
[1693476023704] [32m[OPENAI] Embedding created successfully.[39m
[1693476023713] {
  "id": "chatcmpl-7tYlLek8Lr0YbOP9ZYX0e6beyEIGO",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693476023713] {
  "role": "assistant",
  "content": "5"
}
[1693476023713] [36m[OPENAI] Chat completion took 382.9202079772949ms[39m
[1693476023713] [36m[OPENAI] Tokens per second: 2.6115101244781904tps[39m
[1693476023713] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023722] {
  "id": "chatcmpl-7tYlLCoQaokYGUPBKbgea0SWyaoGY",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 90,
    "completion_tokens": 1,
    "total_tokens": 91
  }
}
[1693476023722] {
  "role": "assistant",
  "content": "4"
}
[1693476023722] [36m[OPENAI] Chat completion took 392.6722090244293ms[39m
[1693476023722] [36m[OPENAI] Tokens per second: 2.546653358750395tps[39m
[1693476023722] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023749] {
  "id": "chatcmpl-7tYlLpMP8SpZRJkLVg8YTOVVB9tdq",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6.5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 3,
    "total_tokens": 94
  }
}
[1693476023750] {
  "role": "assistant",
  "content": "6.5"
}
[1693476023750] [36m[OPENAI] Chat completion took 471.21608304977417ms[39m
[1693476023750] [36m[OPENAI] Tokens per second: 6.366505957486838tps[39m
[1693476023750] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023790] {
  "id": "chatcmpl-7tYlLwqQ6SvOB3KtyyfsiERBIy7h4",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693476023790] {
  "role": "assistant",
  "content": "4"
}
[1693476023790] [36m[OPENAI] Chat completion took 459.84625005722046ms[39m
[1693476023790] [36m[OPENAI] Tokens per second: 2.1746398929545823tps[39m
[1693476023790] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023867] {
  "id": "chatcmpl-7tYlLMMGw4LnKtVwpyr50fPMdEyvN",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693476023867] {
  "role": "assistant",
  "content": "7"
}
[1693476023868] [36m[OPENAI] Chat completion took 589.0436669588089ms[39m
[1693476023868] [36m[OPENAI] Tokens per second: 1.6976670085647974tps[39m
[1693476023868] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023881] {
  "id": "chatcmpl-7tYlL8uDRoiAl8dIAiMHmit0fmhsK",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 92,
    "completion_tokens": 1,
    "total_tokens": 93
  }
}
[1693476023881] {
  "role": "assistant",
  "content": "4"
}
[1693476023881] [36m[OPENAI] Chat completion took 551.0141249895096ms[39m
[1693476023881] [36m[OPENAI] Tokens per second: 1.8148355090153783tps[39m
[1693476023881] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023903] {
  "id": "chatcmpl-7tYlLusVOBRXLuzI2KbCdvSQ8SG4I",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693476023903] {
  "role": "assistant",
  "content": "1"
}
[1693476023903] [36m[OPENAI] Chat completion took 625.056666970253ms[39m
[1693476023903] [36m[OPENAI] Tokens per second: 1.599854945707812tps[39m
[1693476023903] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023919] {
  "id": "chatcmpl-7tYlLeIAS5H10ezcAghFMddkf0Od5",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693476023919] {
  "role": "assistant",
  "content": "6"
}
[1693476023919] [36m[OPENAI] Chat completion took 589.4035830497742ms[39m
[1693476023919] [36m[OPENAI] Tokens per second: 1.6966303374432519tps[39m
[1693476023919] [32m[OPENAI] Chat completion created successfully.[39m
[1693476023921] {
  "id": "chatcmpl-7tYlLtciGGe94GBtXgjYxo8KifpbJ",
  "object": "chat.completion",
  "created": 1693476023,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693476023921] {
  "role": "assistant",
  "content": "5"
}
[1693476023921] [36m[OPENAI] Chat completion took 600.8326250314713ms[39m
[1693476023921] [36m[OPENAI] Tokens per second: 1.664357024466873tps[39m
[1693476023921] [32m[OPENAI] Chat completion created successfully.[39m
[1693476055621] [Main] WebSocket connection established
[1693476055652] [Character] Getting character: A5
[1693476055673] --- Observations received -- 
[1693476055673] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Small) at X: 41.33658, Y: 13.99647.",
  "time": 0
}
[1693476055673] [Character] Getting character: A5
[1693476055674] --- Observations received -- 
[1693476055674] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 42.12, Y: 5.77.",
  "time": 0
}
[1693476055674] [Character] Getting character: A5
[1693476055676] [Character] Getting character: A2
[1693476055676] --- Observations received -- 
[1693476055677] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Small) at X: 62.25, Y: 15.1.",
  "time": 0
}
[1693476055677] [Character] Getting character: A2
[1693476055677] --- Observations received -- 
[1693476055677] {
  "observerId": "A2",
  "observation": "George Brown sees Tree at X: 67.61, Y: 9.619999.",
  "time": 0
}
[1693476055677] [Character] Getting character: A2
[1693476055678] --- Observations received -- 
[1693476055678] {
  "observerId": "A2",
  "observation": "George Brown sees Iron Ore Deposit (Large) at X: 65.22, Y: 18.37.",
  "time": 0
}
[1693476055678] [Character] Getting character: A2
[1693476055679] [Character] Getting character: A4
[1693476055680] --- Observations received -- 
[1693476055680] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Diamond Ore Deposit (Small) at X: 58.32, Y: 22.87.",
  "time": 0
}
[1693476055680] [Character] Getting character: A4
[1693476055680] --- Observations received -- 
[1693476055680] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Diamond Ore Deposit (Large) at X: 60.38, Y: 24.68.",
  "time": 0
}
[1693476055680] [Character] Getting character: A4
[1693476055680] --- Observations received -- 
[1693476055680] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Diamond Ore Deposit (Large) at X: 61.07, Y: 27.32.",
  "time": 0
}
[1693476055680] [Character] Getting character: A4
[1693476055680] --- Observations received -- 
[1693476055680] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Large) at X: 55.12, Y: 28.15.",
  "time": 0
}
[1693476055680] [Character] Getting character: A4
[1693476055680] --- Observations received -- 
[1693476055680] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Small) at X: 57.1, Y: 24.45.",
  "time": 0
}
[1693476055680] [Character] Getting character: A4
[1693476055681] --- Observations received -- 
[1693476055681] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Medium) at X: 53.76, Y: 21.7.",
  "time": 0
}
[1693476055681] [Character] Getting character: A4
[1693476055681] --- Observations received -- 
[1693476055681] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Medium) at X: 52.01, Y: 23.05.",
  "time": 0
}
[1693476055681] [Character] Getting character: A4
[1693476055681] --- Observations received -- 
[1693476055681] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Medium) at X: 54.06, Y: 24.46.",
  "time": 0
}
[1693476055681] [Character] Getting character: A4
[1693476055682] --- Observations received -- 
[1693476055682] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Large) at X: 50.38, Y: 26.11.",
  "time": 0
}
[1693476055682] [Character] Getting character: A4
[1693476055682] --- Observations received -- 
[1693476055683] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Large) at X: 53.13, Y: 26.69.",
  "time": 0
}
[1693476055683] [Character] Getting character: A4
[1693476055683] --- Observations received -- 
[1693476055683] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Diamond Ore Deposit (Large) at X: 58.32, Y: 26.61.",
  "time": 0
}
[1693476055683] [Character] Getting character: A4
[1693476055686] [Character] Getting character: A3
[1693476055687] --- Observations received -- 
[1693476055687] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 38.75, Y: -9.01.",
  "time": 0
}
[1693476055687] [Character] Getting character: A3
[1693476055687] --- Observations received -- 
[1693476055687] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 41.03, Y: -11.7.",
  "time": 0
}
[1693476055687] [Character] Getting character: A3
[1693476055688] --- Observations received -- 
[1693476055688] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 42.72, Y: -12.97.",
  "time": 0
}
[1693476055688] [Character] Getting character: A3
[1693476055742] [33m[OPENAI] Creating embedding...[39m
[1693476055769] [33m[OPENAI] Creating embedding...[39m
[1693476055770] [33m[OPENAI] Creating embedding...[39m
[1693476055772] [33m[OPENAI] Creating embedding...[39m
[1693476055773] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476055773] [33m[OPENAI] Creating embedding...[39m
[1693476055774] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476055774] [33m[OPENAI] Creating embedding...[39m
[1693476055797] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476055797] [33m[OPENAI] Creating embedding...[39m
[1693476055798] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476055798] [33m[OPENAI] Creating embedding...[39m
[1693476055802] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476055802] [33m[OPENAI] Creating embedding...[39m
[1693476055803] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476055803] [33m[OPENAI] Creating embedding...[39m
[1693476055806] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476055806] [33m[OPENAI] Creating embedding...[39m
[1693476055807] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476055807] [33m[OPENAI] Creating embedding...[39m
[1693476055808] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476055808] [33m[OPENAI] Creating embedding...[39m
[1693476055809] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476055809] [33m[OPENAI] Creating embedding...[39m
[1693476055814] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476055814] [33m[OPENAI] Creating embedding...[39m
[1693476055815] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476055816] [33m[OPENAI] Creating embedding...[39m
[1693476055817] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476055817] [33m[OPENAI] Creating embedding...[39m
[1693476055818] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476055818] [33m[OPENAI] Creating embedding...[39m
[1693476055823] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476055823] [33m[OPENAI] Creating embedding...[39m
[1693476055824] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476055824] [33m[OPENAI] Creating embedding...[39m
[1693476055825] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476055825] [33m[OPENAI] Creating embedding...[39m
[1693476055831] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476055831] [33m[OPENAI] Creating embedding...[39m
[1693476055831] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476055831] [33m[OPENAI] Creating embedding...[39m
[1693476055966] [32m[OPENAI] Embedding created successfully.[39m
[1693476055977] [32m[OPENAI] Embedding created successfully.[39m
[1693476055988] [32m[OPENAI] Embedding created successfully.[39m
[1693476056015] [32m[OPENAI] Embedding created successfully.[39m
[1693476056017] [32m[OPENAI] Embedding created successfully.[39m
[1693476056039] [32m[OPENAI] Embedding created successfully.[39m
[1693476056063] [32m[OPENAI] Embedding created successfully.[39m
[1693476056066] [32m[OPENAI] Embedding created successfully.[39m
[1693476056075] {
  "id": "chatcmpl-7tYlrxd55h8PxrtzM20t9MAfn5zkG",
  "object": "chat.completion",
  "created": 1693476055,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476056075] {
  "role": "assistant",
  "content": "2"
}
[1693476056075] [36m[OPENAI] Chat completion took 301.9434999227524ms[39m
[1693476056075] [36m[OPENAI] Tokens per second: 3.3118778852859383tps[39m
[1693476056075] [32m[OPENAI] Chat completion created successfully.[39m
[1693476056084] {
  "id": "chatcmpl-7tYlrBf7b1YRCxtlHC5EK8FNTHE0s",
  "object": "chat.completion",
  "created": 1693476055,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693476056084] {
  "role": "assistant",
  "content": "2"
}
[1693476056084] [36m[OPENAI] Chat completion took 286.2055000066757ms[39m
[1693476056084] [36m[OPENAI] Tokens per second: 3.4939929525347173tps[39m
[1693476056084] [32m[OPENAI] Chat completion created successfully.[39m
[1693476056085] [32m[OPENAI] Embedding created successfully.[39m
[1693476056094] [32m[OPENAI] Embedding created successfully.[39m
[1693476056094] [32m[OPENAI] Embedding created successfully.[39m
[1693476056101] [32m[OPENAI] Embedding created successfully.[39m
[1693476056105] [32m[OPENAI] Embedding created successfully.[39m
[1693476056105] [32m[OPENAI] Embedding created successfully.[39m
[1693476056105] [32m[OPENAI] Embedding created successfully.[39m
[1693476056112] [32m[OPENAI] Embedding created successfully.[39m
[1693476056117] [32m[OPENAI] Embedding created successfully.[39m
[1693476056118] [32m[OPENAI] Embedding created successfully.[39m
[1693476056118] [32m[OPENAI] Embedding created successfully.[39m
[1693476056124] [32m[OPENAI] Embedding created successfully.[39m
[1693476056124] {
  "id": "chatcmpl-7tYlrp7V0pXbgHkiA3hiFYtdJCQ98",
  "object": "chat.completion",
  "created": 1693476055,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693476056124] {
  "role": "assistant",
  "content": "1"
}
[1693476056124] [36m[OPENAI] Chat completion took 326.458624958992ms[39m
[1693476056124] [36m[OPENAI] Tokens per second: 3.0631753108854594tps[39m
[1693476056124] [32m[OPENAI] Chat completion created successfully.[39m
[1693476056125] {
  "id": "chatcmpl-7tYlrWI9HES1p2DzxMR44oG9Fg50F",
  "object": "chat.completion",
  "created": 1693476055,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476056125] {
  "role": "assistant",
  "content": "4"
}
[1693476056125] [36m[OPENAI] Chat completion took 350.9840830564499ms[39m
[1693476056125] [36m[OPENAI] Tokens per second: 2.849132049783485tps[39m
[1693476056125] [32m[OPENAI] Chat completion created successfully.[39m
[1693476056149] [32m[OPENAI] Embedding created successfully.[39m
[1693476056208] {
  "id": "chatcmpl-7tYlsqIeRHgQgcZRQJzrNA2x4Sogi",
  "object": "chat.completion",
  "created": 1693476056,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476056209] {
  "role": "assistant",
  "content": "2"
}
[1693476056209] [36m[OPENAI] Chat completion took 402.36441600322723ms[39m
[1693476056209] [36m[OPENAI] Tokens per second: 2.4853092376637482tps[39m
[1693476056209] [32m[OPENAI] Chat completion created successfully.[39m
[1693476056211] {
  "id": "chatcmpl-7tYlsvcLa9RZRZksyanC7jGSYW1WX",
  "object": "chat.completion",
  "created": 1693476056,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476056211] {
  "role": "assistant",
  "content": "1"
}
[1693476056211] [36m[OPENAI] Chat completion took 379.9103339910507ms[39m
[1693476056211] [36m[OPENAI] Tokens per second: 2.6322000496663414tps[39m
[1693476056211] [32m[OPENAI] Chat completion created successfully.[39m
[1693476056212] {
  "id": "chatcmpl-7tYlsLETb8MFp9Yq9AJTcTY7PKOBL",
  "object": "chat.completion",
  "created": 1693476056,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476056212] {
  "role": "assistant",
  "content": "2"
}
[1693476056212] [36m[OPENAI] Chat completion took 404.49699997901917ms[39m
[1693476056212] [36m[OPENAI] Tokens per second: 2.472206221682408tps[39m
[1693476056212] [32m[OPENAI] Chat completion created successfully.[39m
[1693476056213] {
  "id": "chatcmpl-7tYls2Xyn4bLugPVk28OZN4hAtb4t",
  "object": "chat.completion",
  "created": 1693476056,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476056213] {
  "role": "assistant",
  "content": "1"
}
[1693476056213] [36m[OPENAI] Chat completion took 409.46604204177856ms[39m
[1693476056213] [36m[OPENAI] Tokens per second: 2.4422049628671485tps[39m
[1693476056213] [32m[OPENAI] Chat completion created successfully.[39m
[1693476056214] {
  "id": "chatcmpl-7tYlsGweRdPJpXB74kCbEOBCQGfXl",
  "object": "chat.completion",
  "created": 1693476056,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476056214] {
  "role": "assistant",
  "content": "3"
}
[1693476056214] [36m[OPENAI] Chat completion took 404.31291604042053ms[39m
[1693476056214] [36m[OPENAI] Tokens per second: 2.473331818813393tps[39m
[1693476056214] [32m[OPENAI] Chat completion created successfully.[39m
[1693476056214] {
  "id": "chatcmpl-7tYlsLflmsCOee75XNHCaqtjeDBvQ",
  "object": "chat.completion",
  "created": 1693476056,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476056214] {
  "role": "assistant",
  "content": "3"
}
[1693476056214] [36m[OPENAI] Chat completion took 406.2237499952316ms[39m
[1693476056214] [36m[OPENAI] Tokens per second: 2.461697525099747tps[39m
[1693476056214] [32m[OPENAI] Chat completion created successfully.[39m
[1693476056215] {
  "id": "chatcmpl-7tYlsyPTyIOx9e9BPqz2jBAGdXiyP",
  "object": "chat.completion",
  "created": 1693476056,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693476056215] {
  "role": "assistant",
  "content": "2"
}
[1693476056215] [36m[OPENAI] Chat completion took 384.5983330011368ms[39m
[1693476056215] [36m[OPENAI] Tokens per second: 2.6001152740228965tps[39m
[1693476056215] [32m[OPENAI] Chat completion created successfully.[39m
[1693476056217] [32m[OPENAI] Embedding created successfully.[39m
[1693476056218] {
  "id": "chatcmpl-7tYlstFSh1PA7g1pVESJoGTDK1ZbY",
  "object": "chat.completion",
  "created": 1693476056,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693476056218] {
  "role": "assistant",
  "content": "2"
}
[1693476056218] [36m[OPENAI] Chat completion took 395.20670795440674ms[39m
[1693476056218] [36m[OPENAI] Tokens per second: 2.530321423884753tps[39m
[1693476056218] [32m[OPENAI] Chat completion created successfully.[39m
[1693476056219] {
  "id": "chatcmpl-7tYlsgJI39e4rpLO22WQKxs356ivG",
  "object": "chat.completion",
  "created": 1693476056,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 2,
    "total_tokens": 108
  }
}
[1693476056219] {
  "role": "assistant",
  "content": "4."
}
[1693476056219] [36m[OPENAI] Chat completion took 405.76691699028015ms[39m
[1693476056219] [36m[OPENAI] Tokens per second: 4.928938058417188tps[39m
[1693476056219] [32m[OPENAI] Chat completion created successfully.[39m
[1693476056251] {
  "id": "chatcmpl-7tYlrWB4oQF4WscgsHnBAs2zqMrQX",
  "object": "chat.completion",
  "created": 1693476055,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476056251] {
  "role": "assistant",
  "content": "2"
}
[1693476056251] [36m[OPENAI] Chat completion took 448.46629190444946ms[39m
[1693476056251] [36m[OPENAI] Tokens per second: 2.2298219911989743tps[39m
[1693476056251] [32m[OPENAI] Chat completion created successfully.[39m
[1693476056278] {
  "id": "chatcmpl-7tYlsSu8UafhqxqtCOjNJkL6bHFIo",
  "object": "chat.completion",
  "created": 1693476056,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476056279] {
  "role": "assistant",
  "content": "2"
}
[1693476056279] [36m[OPENAI] Chat completion took 461.5772910118103ms[39m
[1693476056279] [36m[OPENAI] Tokens per second: 2.166484399195482tps[39m
[1693476056279] [32m[OPENAI] Chat completion created successfully.[39m
[1693476056279] {
  "id": "chatcmpl-7tYls0FrVWPoX2t3ThBABLLGZtS7r",
  "object": "chat.completion",
  "created": 1693476056,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476056279] {
  "role": "assistant",
  "content": "1"
}
[1693476056279] [36m[OPENAI] Chat completion took 460.78712499141693ms[39m
[1693476056279] [36m[OPENAI] Tokens per second: 2.170199525472043tps[39m
[1693476056279] [32m[OPENAI] Chat completion created successfully.[39m
[1693476056298] {
  "id": "chatcmpl-7tYlsIgQrDmEwC5lZJ1kWExX4WdJ5",
  "object": "chat.completion",
  "created": 1693476056,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476056298] {
  "role": "assistant",
  "content": "2"
}
[1693476056298] [36m[OPENAI] Chat completion took 482.19258296489716ms[39m
[1693476056298] [36m[OPENAI] Tokens per second: 2.073860186424308tps[39m
[1693476056298] [32m[OPENAI] Chat completion created successfully.[39m
[1693476056412] {
  "id": "chatcmpl-7tYlsCfYylBLj9AWWkV6toMztwUZl",
  "object": "chat.completion",
  "created": 1693476056,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693476056412] {
  "role": "assistant",
  "content": "3"
}
[1693476056413] [36m[OPENAI] Chat completion took 587.9132920503616ms[39m
[1693476056413] [36m[OPENAI] Tokens per second: 1.7009310956594912tps[39m
[1693476056413] [32m[OPENAI] Chat completion created successfully.[39m
[1693476056428] [32m[OPENAI] Embedding created successfully.[39m
[1693476056469] [33m[OPENAI] Creating embedding...[39m
[1693476056596] [33m[OPENAI] Creating embedding...[39m
[1693476056620] [32m[OPENAI] Embedding created successfully.[39m
[1693476056698] [33m[OPENAI] Creating embedding...[39m
[1693476056795] [32m[OPENAI] Embedding created successfully.[39m
[1693476056844] [33m[OPENAI] Creating embedding...[39m
[1693476056909] [32m[OPENAI] Embedding created successfully.[39m
[1693476056992] [33m[OPENAI] Creating embedding...[39m
[1693476057105] [33m[OPENAI] Creating embedding...[39m
[1693476057136] [32m[OPENAI] Embedding created successfully.[39m
[1693476057152] [32m[OPENAI] Embedding created successfully.[39m
[1693476057377] [33m[OPENAI] Creating embedding...[39m
[1693476057481] [33m[OPENAI] Creating embedding...[39m
[1693476057526] [32m[OPENAI] Embedding created successfully.[39m
[1693476057549] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476057633] [32m[OPENAI] Embedding created successfully.[39m
[1693476057880] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476057963] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476058386] [32m[OPENAI] Embedding created successfully.[39m
[1693476058829] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476074800] {
  "id": "chatcmpl-7tYluv5WrnqfqhRCeeBM4tmRQMEC3",
  "object": "chat.completion",
  "created": 1693476058,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "[\n  {\n    \"task\": \"Eat the berries to combat hunger\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Start collecting wood for the villagers\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Make use of the pickaxe and collect some copper ore\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Explore surrounding areas for potential food sources\",\n    \"priority\": 4\n  }, \n  {\n    \"task\": \"Engage in conversation with villagers\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Do some physical exercise to maintain health\",\n    \"priority\": 6\n  }\n]"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 1286,
    "completion_tokens": 148,
    "total_tokens": 1434
  }
}
[1693476074801] {
  "role": "assistant",
  "content": "[\n  {\n    \"task\": \"Eat the berries to combat hunger\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Start collecting wood for the villagers\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Make use of the pickaxe and collect some copper ore\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Explore surrounding areas for potential food sources\",\n    \"priority\": 4\n  }, \n  {\n    \"task\": \"Engage in conversation with villagers\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Do some physical exercise to maintain health\",\n    \"priority\": 6\n  }\n]"
}
[1693476074801] [36m[OPENAI] Chat completion took 15969.147166967392ms[39m
[1693476074801] [36m[OPENAI] Tokens per second: 9.26787125527542tps[39m
[1693476074801] [32m[OPENAI] Chat completion created successfully.[39m
[1693476074802] [Character] Getting character: A4
[1693476074865] [33m[OPENAI] Creating embedding...[39m
[1693476075017] [32m[OPENAI] Embedding created successfully.[39m
[1693476075504] [33m[OPENAI] Creating embedding...[39m
[1693476075718] [32m[OPENAI] Embedding created successfully.[39m
[1693476076128] [33m[OPENAI] Creating embedding...[39m
[1693476076343] [32m[OPENAI] Embedding created successfully.[39m
[1693476076770] [33m[OPENAI] Creating embedding...[39m
[1693476076869] {
  "id": "chatcmpl-7tYluJ4g1yOO2j3bxVvBd8znLmUvO",
  "object": "chat.completion",
  "created": 1693476058,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "[\n  {\n    \"task\": \"Eat some food\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Gather coal from small deposit\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Chop tree for wood\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Mine iron from large deposit\", \n    \"priority\": 4\n  },\n  {\n    \"task\": \"Carry out your daily duties\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Catch up with other villagers\",\n    \"priority\": 6\n  },\n  {\n    \"task\": \"Maintain a healthy lifestyle\",\n    \"priority\": 7\n  }\n]"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 947,
    "completion_tokens": 157,
    "total_tokens": 1104
  }
}
[1693476076869] {
  "role": "assistant",
  "content": "[\n  {\n    \"task\": \"Eat some food\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Gather coal from small deposit\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Chop tree for wood\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Mine iron from large deposit\", \n    \"priority\": 4\n  },\n  {\n    \"task\": \"Carry out your daily duties\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Catch up with other villagers\",\n    \"priority\": 6\n  },\n  {\n    \"task\": \"Maintain a healthy lifestyle\",\n    \"priority\": 7\n  }\n]"
}
[1693476076869] [36m[OPENAI] Chat completion took 18904.772249937057ms[39m
[1693476076869] [36m[OPENAI] Tokens per second: 8.304781349615187tps[39m
[1693476076869] [32m[OPENAI] Chat completion created successfully.[39m
[1693476076871] [Character] Getting character: A2
[1693476076904] [33m[OPENAI] Creating embedding...[39m
[1693476076931] [32m[OPENAI] Embedding created successfully.[39m
[1693476077072] [32m[OPENAI] Embedding created successfully.[39m
[1693476077296] [33m[OPENAI] Creating embedding...[39m
[1693476077496] [32m[OPENAI] Embedding created successfully.[39m
[1693476077501] [33m[OPENAI] Creating embedding...[39m
[1693476077759] [32m[OPENAI] Embedding created successfully.[39m
[1693476077876] [33m[OPENAI] Creating embedding...[39m
[1693476078126] [33m[OPENAI] Creating embedding...[39m
[1693476078183] [32m[OPENAI] Embedding created successfully.[39m
[1693476078265] [32m[OPENAI] Embedding created successfully.[39m
[1693476078561] [33m[OPENAI] Creating embedding...[39m
[1693476078615] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476078771] [32m[OPENAI] Embedding created successfully.[39m
[1693476079101] [33m[OPENAI] Creating embedding...[39m
[1693476079232] {
  "id": "chatcmpl-7tYlukO5t6CH0BZ572Jqno8ZzTgmm",
  "object": "chat.completion",
  "created": 1693476058,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "[\n  {\n    \"task\": \"Eat Berries\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Chop trees for wood\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Mine stones from the deposits\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Explore new places near the stone ore deposits\",\n    \"priority\": 4\n  },\n  {\n    \"task\": \"Maintain a healthy lifestyle\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Catch up with other villagers\",\n    \"priority\": 6\n  },\n  {\n    \"task\": \"Find more food\",\n    \"priority\": 7\n  },\n  {\n    \"task\": \"Listen to the forest\",\n    \"priority\": 8,\n    \"note\": \"As per Lucy's advice\"\n  }\n]"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 960,
    "completion_tokens": 187,
    "total_tokens": 1147
  }
}
[1693476079234] {
  "role": "assistant",
  "content": "[\n  {\n    \"task\": \"Eat Berries\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Chop trees for wood\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Mine stones from the deposits\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Explore new places near the stone ore deposits\",\n    \"priority\": 4\n  },\n  {\n    \"task\": \"Maintain a healthy lifestyle\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Catch up with other villagers\",\n    \"priority\": 6\n  },\n  {\n    \"task\": \"Find more food\",\n    \"priority\": 7\n  },\n  {\n    \"task\": \"Listen to the forest\",\n    \"priority\": 8,\n    \"note\": \"As per Lucy's advice\"\n  }\n]"
}
[1693476079235] [36m[OPENAI] Chat completion took 21351.864333987236ms[39m
[1693476079235] [36m[OPENAI] Tokens per second: 8.758017429997398tps[39m
[1693476079235] [32m[OPENAI] Chat completion created successfully.[39m
[1693476079235] [Character] Getting character: A5
[1693476079242] [32m[OPENAI] Embedding created successfully.[39m
[1693476079265] [33m[OPENAI] Creating embedding...[39m
[1693476079368] [32m[OPENAI] Embedding created successfully.[39m
[1693476079571] [33m[OPENAI] Creating embedding...[39m
[1693476079690] [33m[OPENAI] Creating embedding...[39m
[1693476079910] [32m[OPENAI] Embedding created successfully.[39m
[1693476080266] [33m[OPENAI] Creating embedding...[39m
[1693476080459] [32m[OPENAI] Embedding created successfully.[39m
[1693476080527] [32m[OPENAI] Embedding created successfully.[39m
[1693476080772] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476080891] [33m[OPENAI] Creating embedding...[39m
[1693476081037] [32m[OPENAI] Embedding created successfully.[39m
[1693476081369] [33m[OPENAI] Creating embedding...[39m
[1693476081535] [32m[OPENAI] Embedding created successfully.[39m
[1693476081906] [33m[OPENAI] Creating embedding...[39m
[1693476082247] [32m[OPENAI] Embedding created successfully.[39m
[1693476082318] {
  "id": "chatcmpl-7tYmFRXbZYRrqSQD72zLwmSocrbM1",
  "object": "chat.completion",
  "created": 1693476079,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "eat",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"foodId\": \"berries\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1661,
    "completion_tokens": 25,
    "total_tokens": 1686
  }
}
[1693476082319] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "eat",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"foodId\": \"berries\"\n}"
  }
}
[1693476082319] [36m[OPENAI] Chat completion took 3702.883208990097ms[39m
[1693476082319] [36m[OPENAI] Tokens per second: 6.751495682959537tps[39m
[1693476082319] [32m[OPENAI] Chat completion created successfully.[39m
[1693476082394] [Character] Getting character: A4
[1693476082456] [33m[OPENAI] Creating embedding...[39m
[1693476082564] [33m[OPENAI] Creating embedding...[39m
[1693476082695] [32m[OPENAI] Embedding created successfully.[39m
[1693476082719] [32m[OPENAI] Embedding created successfully.[39m
[1693476083064] [33m[OPENAI] Creating embedding...[39m
[1693476083067] [33m[OPENAI] Creating embedding...[39m
[1693476083241] [32m[OPENAI] Embedding created successfully.[39m
[1693476083247] [32m[OPENAI] Embedding created successfully.[39m
[1693476083585] [33m[OPENAI] Creating embedding...[39m
[1693476083609] [33m[OPENAI] Creating embedding...[39m
[1693476083741] [32m[OPENAI] Embedding created successfully.[39m
[1693476083781] [32m[OPENAI] Embedding created successfully.[39m
[1693476084061] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476084172] [33m[OPENAI] Creating embedding...[39m
[1693476084750] [32m[OPENAI] Embedding created successfully.[39m
[1693476085142] [33m[OPENAI] Creating embedding...[39m
[1693476085351] [32m[OPENAI] Embedding created successfully.[39m
[1693476085671] {
  "id": "chatcmpl-7tYmIg9FVqwmXRvWvg5hIrnpuUNHJ",
  "object": "chat.completion",
  "created": 1693476082,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "eat",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"foodId\": \"berries\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1327,
    "completion_tokens": 25,
    "total_tokens": 1352
  }
}
[1693476085671] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "eat",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"foodId\": \"berries\"\n}"
  }
}
[1693476085671] [36m[OPENAI] Chat completion took 4898.41883289814ms[39m
[1693476085671] [36m[OPENAI] Tokens per second: 5.10368771083807tps[39m
[1693476085671] [32m[OPENAI] Chat completion created successfully.[39m
[1693476085693] [Character] Getting character: A2
[1693476085729] [33m[OPENAI] Creating embedding...[39m
[1693476085786] [33m[OPENAI] Creating embedding...[39m
[1693476085893] [32m[OPENAI] Embedding created successfully.[39m
[1693476085962] [32m[OPENAI] Embedding created successfully.[39m
[1693476086348] [33m[OPENAI] Creating embedding...[39m
[1693476086407] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476086749] [32m[OPENAI] Embedding created successfully.[39m
[1693476087164] [33m[OPENAI] Creating embedding...[39m
[1693476087379] {
  "id": "chatcmpl-7tYmKEgtA5skZF8kl8m2PAoZnGh5c",
  "object": "chat.completion",
  "created": 1693476084,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "eat",
          "arguments": "{\n  \"characterId\": \"A5\",\n  \"foodId\": \"berries\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1345,
    "completion_tokens": 25,
    "total_tokens": 1370
  }
}
[1693476087379] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "eat",
    "arguments": "{\n  \"characterId\": \"A5\",\n  \"foodId\": \"berries\"\n}"
  }
}
[1693476087379] [36m[OPENAI] Chat completion took 3318.1633330583572ms[39m
[1693476087379] [36m[OPENAI] Tokens per second: 7.534288547802575tps[39m
[1693476087379] [32m[OPENAI] Chat completion created successfully.[39m
[1693476087396] [Character] Getting character: A5
[1693476087408] [32m[OPENAI] Embedding created successfully.[39m
[1693476087427] [33m[OPENAI] Creating embedding...[39m
[1693476087587] [32m[OPENAI] Embedding created successfully.[39m
[1693476087770] [33m[OPENAI] Creating embedding...[39m
[1693476087938] [33m[OPENAI] Creating embedding...[39m
[1693476087979] [32m[OPENAI] Embedding created successfully.[39m
[1693476088070] [32m[OPENAI] Embedding created successfully.[39m
[1693476088326] [33m[OPENAI] Creating embedding...[39m
[1693476088408] [33m[OPENAI] Creating embedding...[39m
[1693476088535] [32m[OPENAI] Embedding created successfully.[39m
[1693476088737] [32m[OPENAI] Embedding created successfully.[39m
[1693476088863] [33m[OPENAI] Creating embedding...[39m
[1693476088996] [33m[OPENAI] Creating embedding...[39m
[1693476089165] [32m[OPENAI] Embedding created successfully.[39m
[1693476089247] [32m[OPENAI] Embedding created successfully.[39m
[1693476089371] {
  "id": "chatcmpl-7tYltL76izGMV4XEKVtdnEwE19QRB",
  "object": "chat.completion",
  "created": 1693476057,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "[\n  {\n    \"task\": \"Eat some food\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Carry out your daily duties\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Catch up with other villagers\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Collect resources from nearby trees\",\n    \"priority\": 4\n  },\n  {\n    \"task\": \"Maintain a healthy lifestyle\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Learn more about the different routes in the mine\",\n    \"priority\": 6\n  },\n  {\n    \"task\": \"Exchange stories with older miners\",\n    \"priority\": 7\n  },\n  {\n    \"task\": \"Tell family about the day's journey\",\n    \"priority\": 8\n  },\n  {\n    \"task\": \"Show gratitude to the village for their support\",\n    \"priority\": 9\n  },\n  {\n    \"task\": \"Conquer fear of mine's depth and darkness\",\n    \"priority\": 10\n  },\n  {\n    \"task\": \"Express appreciation to George and Thomas\",\n    \"priority\": 11\n  },\n  {\n    \"task\": \"Remember to wear helmet on the next trip to mines\",\n    \"priority\": 12\n  }\n]"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 1175,
    "completion_tokens": 284,
    "total_tokens": 1459
  }
}
[1693476089373] {
  "role": "assistant",
  "content": "[\n  {\n    \"task\": \"Eat some food\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Carry out your daily duties\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Catch up with other villagers\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Collect resources from nearby trees\",\n    \"priority\": 4\n  },\n  {\n    \"task\": \"Maintain a healthy lifestyle\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Learn more about the different routes in the mine\",\n    \"priority\": 6\n  },\n  {\n    \"task\": \"Exchange stories with older miners\",\n    \"priority\": 7\n  },\n  {\n    \"task\": \"Tell family about the day's journey\",\n    \"priority\": 8\n  },\n  {\n    \"task\": \"Show gratitude to the village for their support\",\n    \"priority\": 9\n  },\n  {\n    \"task\": \"Conquer fear of mine's depth and darkness\",\n    \"priority\": 10\n  },\n  {\n    \"task\": \"Express appreciation to George and Thomas\",\n    \"priority\": 11\n  },\n  {\n    \"task\": \"Remember to wear helmet on the next trip to mines\",\n    \"priority\": 12\n  }\n]"
}
[1693476089373] [36m[OPENAI] Chat completion took 31822.032375097275ms[39m
[1693476089374] [36m[OPENAI] Tokens per second: 8.924634248761802tps[39m
[1693476089374] [32m[OPENAI] Chat completion created successfully.[39m
[1693476089375] [Character] Getting character: A3
[1693476089419] [33m[OPENAI] Creating embedding...[39m
[1693476089498] [33m[OPENAI] Creating embedding...[39m
[1693476089603] [33m[OPENAI] Creating embedding...[39m
[1693476089642] [32m[OPENAI] Embedding created successfully.[39m
[1693476089670] [32m[OPENAI] Embedding created successfully.[39m
[1693476089760] [32m[OPENAI] Embedding created successfully.[39m
[1693476089970] [33m[OPENAI] Creating embedding...[39m
[1693476090010] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476090133] [33m[OPENAI] Creating embedding...[39m
[1693476090259] [32m[OPENAI] Embedding created successfully.[39m
[1693476090273] [32m[OPENAI] Embedding created successfully.[39m
[1693476090544] [33m[OPENAI] Creating embedding...[39m
[1693476090616] [33m[OPENAI] Creating embedding...[39m
[1693476090788] [32m[OPENAI] Embedding created successfully.[39m
[1693476090797] [32m[OPENAI] Embedding created successfully.[39m
[1693476091065] [33m[OPENAI] Creating embedding...[39m
[1693476091123] [33m[OPENAI] Creating embedding...[39m
[1693476091315] [32m[OPENAI] Embedding created successfully.[39m
[1693476091376] [32m[OPENAI] Embedding created successfully.[39m
[1693476091651] [33m[OPENAI] Creating embedding...[39m
[1693476091677] {
  "id": "chatcmpl-7tYmMhO4I6PCFZtyGXsLo7b3h5mOw",
  "object": "chat.completion",
  "created": 1693476086,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 54.06,\n  \"y\": 24.46\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1573,
    "completion_tokens": 35,
    "total_tokens": 1608
  }
}
[1693476091677] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 54.06,\n  \"y\": 24.46\n}"
  }
}
[1693476091677] [36m[OPENAI] Chat completion took 5269.321874976158ms[39m
[1693476091677] [36m[OPENAI] Tokens per second: 6.642220921484013tps[39m
[1693476091677] [32m[OPENAI] Chat completion created successfully.[39m
[1693476091695] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476091706] --- Observations received -- 
[1693476091707] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 54.06, Y: 24.46.",
  "time": 35.5875168
}
[1693476091707] [Character] Getting character: A4
[1693476091771] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476091774] [33m[OPENAI] Creating embedding...[39m
[1693476091788] --- Observations received -- 
[1693476091788] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees DiamondOreLarge (1) at X: 61.07, Y: 27.32",
  "time": 35.6819038
}
[1693476091788] [Character] Getting character: A4
[1693476091858] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476091859] [33m[OPENAI] Creating embedding...[39m
[1693476091903] [32m[OPENAI] Embedding created successfully.[39m
[1693476092023] [32m[OPENAI] Embedding created successfully.[39m
[1693476092037] {
  "id": "chatcmpl-7tYmRVd7tskibd4jyZGUZisRgmtuo",
  "object": "chat.completion",
  "created": 1693476091,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693476092038] {
  "role": "assistant",
  "content": "1"
}
[1693476092038] [36m[OPENAI] Chat completion took 266.0404999256134ms[39m
[1693476092038] [36m[OPENAI] Tokens per second: 3.758826194807205tps[39m
[1693476092038] [32m[OPENAI] Chat completion created successfully.[39m
[1693476092068] [32m[OPENAI] Embedding created successfully.[39m
[1693476092188] {
  "id": "chatcmpl-7tYmSDQtGXW7vNTUXrImfsO4AAUdJ",
  "object": "chat.completion",
  "created": 1693476092,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "8"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693476092188] {
  "role": "assistant",
  "content": "8"
}
[1693476092188] [36m[OPENAI] Chat completion took 329.4652919769287ms[39m
[1693476092188] [36m[OPENAI] Tokens per second: 3.0352210820131744tps[39m
[1693476092188] [32m[OPENAI] Chat completion created successfully.[39m
[1693476092218] [33m[OPENAI] Creating embedding...[39m
[1693476092290] --- Observations received -- 
[1693476092290] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees DiamondOreLarge (2) at X: 60.38, Y: 24.68",
  "time": 36.1867561
}
[1693476092290] [Character] Getting character: A4
[1693476092390] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476092390] [33m[OPENAI] Creating embedding...[39m
[1693476092401] [32m[OPENAI] Embedding created successfully.[39m
[1693476092548] --- Observations received -- 
[1693476092549] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Small) at X: 49.03, Y: 23.52.",
  "time": 36.4400368
}
[1693476092549] [Character] Getting character: A4
[1693476092569] [32m[OPENAI] Embedding created successfully.[39m
[1693476092615] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476092615] [33m[OPENAI] Creating embedding...[39m
[1693476092668] --- Observations received -- 
[1693476092668] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 54.06, Y: 24.46.",
  "time": 36.5599861
}
[1693476092668] [Character] Getting character: A4
[1693476092671] [Character] Getting character: A4
[1693476092706] [33m[OPENAI] Creating embedding...[39m
[1693476092707] [33m[OPENAI] Creating embedding...[39m
[1693476092738] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476092739] [33m[OPENAI] Creating embedding...[39m
[1693476092804] [32m[OPENAI] Embedding created successfully.[39m
[1693476092882] {
  "id": "chatcmpl-7tYmS8yDtWX8foUyuevuEKDpe3fF6",
  "object": "chat.completion",
  "created": 1693476092,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476092882] {
  "role": "assistant",
  "content": "1"
}
[1693476092882] [36m[OPENAI] Chat completion took 267.4832500219345ms[39m
[1693476092882] [36m[OPENAI] Tokens per second: 3.738551852940312tps[39m
[1693476092882] [32m[OPENAI] Chat completion created successfully.[39m
[1693476092884] [32m[OPENAI] Embedding created successfully.[39m
[1693476092899] [32m[OPENAI] Embedding created successfully.[39m
[1693476092961] {
  "id": "chatcmpl-7tYmSQJRRc02RsjnxidnDGxtnsAdx",
  "object": "chat.completion",
  "created": 1693476092,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693476092962] {
  "role": "assistant",
  "content": "1"
}
[1693476092962] [36m[OPENAI] Chat completion took 571.0375829935074ms[39m
[1693476092962] [36m[OPENAI] Tokens per second: 1.7511982219414968tps[39m
[1693476092962] [32m[OPENAI] Chat completion created successfully.[39m
[1693476093028] [32m[OPENAI] Embedding created successfully.[39m
[1693476093049] {
  "id": "chatcmpl-7tYmS81gGj2xllwwnWZxY8sn8EUIP",
  "object": "chat.completion",
  "created": 1693476092,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693476093049] {
  "role": "assistant",
  "content": "2"
}
[1693476093049] [36m[OPENAI] Chat completion took 310.3168749809265ms[39m
[1693476093049] [36m[OPENAI] Tokens per second: 3.2225124723283725tps[39m
[1693476093049] [32m[OPENAI] Chat completion created successfully.[39m
[1693476093226] [33m[OPENAI] Creating embedding...[39m
[1693476093271] [33m[OPENAI] Creating embedding...[39m
[1693476093385] [32m[OPENAI] Embedding created successfully.[39m
[1693476093426] [32m[OPENAI] Embedding created successfully.[39m
[1693476093698] [33m[OPENAI] Creating embedding...[39m
[1693476093787] [33m[OPENAI] Creating embedding...[39m
[1693476093869] [32m[OPENAI] Embedding created successfully.[39m
[1693476093981] [32m[OPENAI] Embedding created successfully.[39m
[1693476094190] [33m[OPENAI] Creating embedding...[39m
[1693476094335] [33m[OPENAI] Creating embedding...[39m
[1693476094413] [32m[OPENAI] Embedding created successfully.[39m
[1693476094493] [32m[OPENAI] Embedding created successfully.[39m
[1693476094692] [33m[OPENAI] Creating embedding...[39m
[1693476094844] [33m[OPENAI] Creating embedding...[39m
[1693476094890] [32m[OPENAI] Embedding created successfully.[39m
[1693476095073] [32m[OPENAI] Embedding created successfully.[39m
[1693476095168] [33m[OPENAI] Creating embedding...[39m
[1693476095327] {
  "id": "chatcmpl-7tYmQUg7VE7VrjKhmwd2UDKqrYGFX",
  "object": "chat.completion",
  "created": 1693476090,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 62.25,\n  \"y\": 15.1\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1239,
    "completion_tokens": 35,
    "total_tokens": 1274
  }
}
[1693476095327] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 62.25,\n  \"y\": 15.1\n}"
  }
}
[1693476095327] [36m[OPENAI] Chat completion took 5316.664374947548ms[39m
[1693476095327] [36m[OPENAI] Tokens per second: 6.583074937910727tps[39m
[1693476095327] [32m[OPENAI] Chat completion created successfully.[39m
[1693476095329] [32m[OPENAI] Embedding created successfully.[39m
[1693476095333] --- Observations received -- 
[1693476095334] {
  "observerId": "A2",
  "observation": "George Brown has started walking to 62.25, Y: 15.1.",
  "time": 39.23087
}
[1693476095334] [Character] Getting character: A2
[1693476095422] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476095423] [33m[OPENAI] Creating embedding...[39m
[1693476095495] [33m[OPENAI] Creating embedding...[39m
[1693476095525] --- Observations received -- 
[1693476095525] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Medium) at X: 61.66, Y: 18.02.",
  "time": 39.42116
}
[1693476095525] [Character] Getting character: A2
[1693476095588] [32m[OPENAI] Embedding created successfully.[39m
[1693476095589] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476095590] [33m[OPENAI] Creating embedding...[39m
[1693476095647] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476095693] {
  "id": "chatcmpl-7tYmVQDaDV32xy5Pnx87i8SX7NWU9",
  "object": "chat.completion",
  "created": 1693476095,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693476095694] {
  "role": "assistant",
  "content": "1"
}
[1693476095694] [36m[OPENAI] Chat completion took 271.0986250638962ms[39m
[1693476095694] [36m[OPENAI] Tokens per second: 3.68869447332795tps[39m
[1693476095694] [32m[OPENAI] Chat completion created successfully.[39m
[1693476095740] [32m[OPENAI] Embedding created successfully.[39m
[1693476095754] [32m[OPENAI] Embedding created successfully.[39m
[1693476095785] --- Observations received -- 
[1693476095785] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Medium) at X: 59.9, Y: 16.03.",
  "time": 39.68179
}
[1693476095785] [Character] Getting character: A2
[1693476095848] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476095848] [33m[OPENAI] Creating embedding...[39m
[1693476095938] {
  "id": "chatcmpl-7tYmV7DxiUds9wDlCUFLyOlDnXrEs",
  "object": "chat.completion",
  "created": 1693476095,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476095938] {
  "role": "assistant",
  "content": "2"
}
[1693476095938] [36m[OPENAI] Chat completion took 348.8902499675751ms[39m
[1693476095938] [36m[OPENAI] Tokens per second: 2.8662308565313515tps[39m
[1693476095938] [32m[OPENAI] Chat completion created successfully.[39m
[1693476096019] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476096030] [32m[OPENAI] Embedding created successfully.[39m
[1693476096098] {
  "id": "chatcmpl-7tYmVWWMSC6nyw2D7PBGzw84HytID",
  "object": "chat.completion",
  "created": 1693476095,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476096099] {
  "role": "assistant",
  "content": "2"
}
[1693476096099] [36m[OPENAI] Chat completion took 249.83816695213318ms[39m
[1693476096099] [36m[OPENAI] Tokens per second: 4.002591006007466tps[39m
[1693476096099] [32m[OPENAI] Chat completion created successfully.[39m
[1693476096183] --- Observations received -- 
[1693476096187] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Small) at X: 59.32, Y: 14.11.",
  "time": 40.0801659
}
[1693476096187] [Character] Getting character: A2
[1693476096249] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476096253] [33m[OPENAI] Creating embedding...[39m
[1693476096304] --- Observations received -- 
[1693476096304] {
  "observerId": "A2",
  "observation": "George Brown no longer sees Tree (1056) at X: 67.61, Y: 9.619999",
  "time": 40.2001
}
[1693476096304] [Character] Getting character: A2
[1693476096369] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476096373] [33m[OPENAI] Creating embedding...[39m
[1693476096455] [32m[OPENAI] Embedding created successfully.[39m
[1693476096558] {
  "id": "chatcmpl-7tYmWBggNCHWtFDXaKVoEk4K7fCMA",
  "object": "chat.completion",
  "created": 1693476096,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476096558] {
  "role": "assistant",
  "content": "3"
}
[1693476096558] [36m[OPENAI] Chat completion took 305.00387489795685ms[39m
[1693476096558] [36m[OPENAI] Tokens per second: 3.2786468707473424tps[39m
[1693476096558] [32m[OPENAI] Chat completion created successfully.[39m
[1693476096583] --- Observations received -- 
[1693476096583] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Small) at X: 62.95, Y: 20.13.",
  "time": 40.4802361
}
[1693476096583] [Character] Getting character: A2
[1693476096629] {
  "id": "chatcmpl-7tYmWIpYIpslXQuUt7nfCJgsUJLSA",
  "object": "chat.completion",
  "created": 1693476096,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 107,
    "completion_tokens": 1,
    "total_tokens": 108
  }
}
[1693476096629] {
  "role": "assistant",
  "content": "2"
}
[1693476096629] [36m[OPENAI] Chat completion took 254.8029589653015ms[39m
[1693476096629] [36m[OPENAI] Tokens per second: 3.9246012058132247tps[39m
[1693476096629] [32m[OPENAI] Chat completion created successfully.[39m
[1693476096640] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476096640] [33m[OPENAI] Creating embedding...[39m
[1693476096723] [32m[OPENAI] Embedding created successfully.[39m
[1693476096804] [32m[OPENAI] Embedding created successfully.[39m
[1693476096887] {
  "id": "chatcmpl-7tYmWlCcieZacPmTK9X4VotpQbE5M",
  "object": "chat.completion",
  "created": 1693476096,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476096887] {
  "role": "assistant",
  "content": "2"
}
[1693476096887] [36m[OPENAI] Chat completion took 246.55895900726318ms[39m
[1693476096887] [36m[OPENAI] Tokens per second: 4.0558250409004275tps[39m
[1693476096887] [32m[OPENAI] Chat completion created successfully.[39m
[1693476097084] {
  "id": "chatcmpl-7tYmSkegeLiox3oOxNLeBKPuLTXDG",
  "object": "chat.completion",
  "created": 1693476092,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 42.12,\n  \"y\": 5.77\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1257,
    "completion_tokens": 35,
    "total_tokens": 1292
  }
}
[1693476097084] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 42.12,\n  \"y\": 5.77\n}"
  }
}
[1693476097084] [36m[OPENAI] Chat completion took 5388.488499999046ms[39m
[1693476097084] [36m[OPENAI] Tokens per second: 6.495327956996882tps[39m
[1693476097084] [32m[OPENAI] Chat completion created successfully.[39m
[1693476097091] --- Observations received -- 
[1693476097092] {
  "observerId": "A5",
  "observation": "Eli Green has started walking to 42.12, Y: 5.77.",
  "time": 40.9875565
}
[1693476097092] [Character] Getting character: A5
[1693476097152] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476097152] [33m[OPENAI] Creating embedding...[39m
[1693476097223] {
  "status": 503,
  "headers": {
    "access-control-allow-origin": "*",
    "alt-svc": "h3=\":443\"; ma=86400",
    "cf-cache-status": "DYNAMIC",
    "cf-ray": "7ff46ee6e993238f-SJC",
    "connection": "keep-alive",
    "content-length": "176",
    "content-type": "application/json",
    "date": "Thu, 31 Aug 2023 10:01:37 GMT",
    "nel": "{\"success_fraction\":0,\"report_to\":\"cf-nel\",\"max_age\":604800}",
    "openai-model": "gpt-4-0613",
    "openai-organization": "ember-ai",
    "openai-processing-ms": "53",
    "openai-version": "2020-10-01",
    "report-to": "{\"endpoints\":[{\"url\":\"https:\\/\\/a.nel.cloudflare.com\\/report\\/v3?s=R3fn%2Bt7H%2Fqg4KJI9O3rsHoaHWHrsnY4CT2mWE8BraRUiRiM30c0D%2Flzazb27pGpEKKz0UOAVD00y75PX%2BOdf1vySpTQsdt6mTLE9W3LSVJ2EAYcvgGt1xg7J5eKWzTOWd8pxzctjnBZZpAYhZo1AlPs%3D\"}],\"group\":\"cf-nel\",\"max_age\":604800}",
    "server": "cloudflare",
    "strict-transport-security": "max-age=15724800; includeSubDomains",
    "vary": "Accept-Encoding",
    "x-ratelimit-limit-requests": "200",
    "x-ratelimit-limit-tokens": "40000",
    "x-ratelimit-remaining-requests": "199",
    "x-ratelimit-remaining-tokens": "37131",
    "x-ratelimit-reset-requests": "300ms",
    "x-ratelimit-reset-tokens": "4.302s",
    "x-request-id": "38c1587ebc33151515f6c13017dd9bd2"
  },
  "error": {
    "message": "The server had an error while processing your request. Sorry about that!",
    "type": "server_error",
    "param": null,
    "code": null
  },
  "code": null,
  "param": null,
  "type": "server_error"
}
[1693476097223] [31mInternalServerError: The server had an error while processing your request. Sorry about that![39m
[31m    at APIError.generate (file:///Users/harris/src/starlightshire-server/node_modules/openai/error.mjs:52:14)[39m
[31m    at OpenAI.makeStatusError (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:176:21)[39m
[31m    at OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:212:24)[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:70:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:397:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:72:13) {[39m
[31m  status: 503,[39m
[31m  headers: {[39m
[31m    'access-control-allow-origin': '*',[39m
[31m    'alt-svc': 'h3=":443"; ma=86400',[39m
[31m    'cf-cache-status': 'DYNAMIC',[39m
[31m    'cf-ray': '7ff46ee6e993238f-SJC',[39m
[31m    connection: 'keep-alive',[39m
[31m    'content-length': '176',[39m
[31m    'content-type': 'application/json',[39m
[31m    date: 'Thu, 31 Aug 2023 10:01:37 GMT',[39m
[31m    nel: '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}',[39m
[31m    'openai-model': 'gpt-4-0613',[39m
[31m    'openai-organization': 'ember-ai',[39m
[31m    'openai-processing-ms': '53',[39m
[31m    'openai-version': '2020-10-01',[39m
[31m    'report-to': '{"endpoints":[{"url":"https:\\/\\/a.nel.cloudflare.com\\/report\\/v3?s=R3fn%2Bt7H%2Fqg4KJI9O3rsHoaHWHrsnY4CT2mWE8BraRUiRiM30c0D%2Flzazb27pGpEKKz0UOAVD00y75PX%2BOdf1vySpTQsdt6mTLE9W3LSVJ2EAYcvgGt1xg7J5eKWzTOWd8pxzctjnBZZpAYhZo1AlPs%3D"}],"group":"cf-nel","max_age":604800}',[39m
[31m    server: 'cloudflare',[39m
[31m    'strict-transport-security': 'max-age=15724800; includeSubDomains',[39m
[31m    vary: 'Accept-Encoding',[39m
[31m    'x-ratelimit-limit-requests': '200',[39m
[31m    'x-ratelimit-limit-tokens': '40000',[39m
[31m    'x-ratelimit-remaining-requests': '199',[39m
[31m    'x-ratelimit-remaining-tokens': '37131',[39m
[31m    'x-ratelimit-reset-requests': '300ms',[39m
[31m    'x-ratelimit-reset-tokens': '4.302s',[39m
[31m    'x-request-id': '38c1587ebc33151515f6c13017dd9bd2'[39m
[31m  },[39m
[31m  error: {[39m
[31m    message: 'The server had an error while processing your request. Sorry about that!',[39m
[31m    type: 'server_error',[39m
[31m    param: null,[39m
[31m    code: null[39m
[31m  },[39m
[31m  code: null,[39m
[31m  param: null,[39m
[31m  type: 'server_error'[39m
[31m}[39m
[1693476097223] [31mFailed to create chat completion. Retrying...[39m
[1693476097301] [32m[OPENAI] Embedding created successfully.[39m
[1693476097307] --- Observations received -- 
[1693476097307] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Large) at X: 58.91, Y: 19.37.",
  "time": 41.2032051
}
[1693476097307] [Character] Getting character: A2
[1693476097374] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476097375] [33m[OPENAI] Creating embedding...[39m
[1693476097385] --- Observations received -- 
[1693476097386] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 45.24001, Y: 10.2.",
  "time": 41.28187
}
[1693476097386] [Character] Getting character: A5
[1693476097447] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476097447] [33m[OPENAI] Creating embedding...[39m
[1693476097456] {
  "id": "chatcmpl-7tYmXaVh3574xmj8GNQVRjQTmufYq",
  "object": "chat.completion",
  "created": 1693476097,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693476097456] {
  "role": "assistant",
  "content": "3"
}
[1693476097456] [36m[OPENAI] Chat completion took 303.359041929245ms[39m
[1693476097456] [36m[OPENAI] Tokens per second: 3.296423912867046tps[39m
[1693476097456] [32m[OPENAI] Chat completion created successfully.[39m
[1693476097543] --- Observations received -- 
[1693476097544] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Medium) at X: 57.27, Y: 17.32.",
  "time": 41.44025
}
[1693476097544] [Character] Getting character: A2
[1693476097604] [32m[OPENAI] Embedding created successfully.[39m
[1693476097611] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476097612] [33m[OPENAI] Creating embedding...[39m
[1693476097653] {
  "id": "chatcmpl-7tYmXCn7Amele4ScYFPYgugf9YduF",
  "object": "chat.completion",
  "created": 1693476097,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476097654] {
  "role": "assistant",
  "content": "2"
}
[1693476097654] [36m[OPENAI] Chat completion took 278.2997090816498ms[39m
[1693476097654] [36m[OPENAI] Tokens per second: 3.593248456133355tps[39m
[1693476097654] [32m[OPENAI] Chat completion created successfully.[39m
[1693476097723] {
  "id": "chatcmpl-7tYmXymuXPH9pi9XszZWIDWvVJH59",
  "object": "chat.completion",
  "created": 1693476097,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 2,
    "total_tokens": 104
  }
}
[1693476097723] {
  "role": "assistant",
  "content": "3."
}
[1693476097724] [36m[OPENAI] Chat completion took 275.9962500333786ms[39m
[1693476097724] [36m[OPENAI] Tokens per second: 7.246475268262243tps[39m
[1693476097724] [32m[OPENAI] Chat completion created successfully.[39m
[1693476097730] --- Observations received -- 
[1693476097730] {
  "observerId": "A2",
  "observation": "George Brown finished walking to 62.25, Y: 15.1.",
  "time": 41.6199837
}
[1693476097730] [Character] Getting character: A2
[1693476097730] [Character] Getting character: A2
[1693476097733] [32m[OPENAI] Embedding created successfully.[39m
[1693476097749] [32m[OPENAI] Embedding created successfully.[39m
[1693476097793] [33m[OPENAI] Creating embedding...[39m
[1693476097828] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476097829] [33m[OPENAI] Creating embedding...[39m
[1693476097846] {
  "id": "chatcmpl-7tYmXabovPqMM0RsjVhOrFhhcEmru",
  "object": "chat.completion",
  "created": 1693476097,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476097846] {
  "role": "assistant",
  "content": "2"
}
[1693476097846] [36m[OPENAI] Chat completion took 232.0625410079956ms[39m
[1693476097846] [36m[OPENAI] Tokens per second: 4.309183186809737tps[39m
[1693476097846] [32m[OPENAI] Chat completion created successfully.[39m
[1693476098067] [32m[OPENAI] Embedding created successfully.[39m
[1693476098117] {
  "id": "chatcmpl-7tYmXjjb0idA8eVUPx61PlIsLCWA3",
  "object": "chat.completion",
  "created": 1693476097,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693476098117] {
  "role": "assistant",
  "content": "2"
}
[1693476098117] [36m[OPENAI] Chat completion took 288.9502090215683ms[39m
[1693476098117] [36m[OPENAI] Tokens per second: 3.4608038643964307tps[39m
[1693476098117] [32m[OPENAI] Chat completion created successfully.[39m
[1693476098254] [32m[OPENAI] Embedding created successfully.[39m
[1693476098566] --- Observations received -- 
[1693476098566] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees StoneOreSmall (3) at X: 41.33658, Y: 13.99647",
  "time": 42.46199
}
[1693476098566] [Character] Getting character: A5
[1693476098630] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476098630] [33m[OPENAI] Creating embedding...[39m
[1693476098639] [33m[OPENAI] Creating embedding...[39m
[1693476098815] [32m[OPENAI] Embedding created successfully.[39m
[1693476098826] [32m[OPENAI] Embedding created successfully.[39m
[1693476098862] --- Observations received -- 
[1693476098862] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 45.84, Y: 5.299999.",
  "time": 42.74268
}
[1693476098862] [Character] Getting character: A5
[1693476098893] {
  "id": "chatcmpl-7tYmYKchedSriCJZaormDpNURsINJ",
  "object": "chat.completion",
  "created": 1693476098,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 110,
    "completion_tokens": 1,
    "total_tokens": 111
  }
}
[1693476098893] {
  "role": "assistant",
  "content": "3"
}
[1693476098893] [36m[OPENAI] Chat completion took 262.73595798015594ms[39m
[1693476098893] [36m[OPENAI] Tokens per second: 3.8061025513513025tps[39m
[1693476098893] [32m[OPENAI] Chat completion created successfully.[39m
[1693476098927] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476098927] [33m[OPENAI] Creating embedding...[39m
[1693476099088] [32m[OPENAI] Embedding created successfully.[39m
[1693476099189] {
  "id": "chatcmpl-7tYmZvd7FrHdtTFTW2jpn5IG1Mgim",
  "object": "chat.completion",
  "created": 1693476099,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693476099189] {
  "role": "assistant",
  "content": "5"
}
[1693476099189] [36m[OPENAI] Chat completion took 261.8982080221176ms[39m
[1693476099189] [36m[OPENAI] Tokens per second: 3.818277366432186tps[39m
[1693476099190] [32m[OPENAI] Chat completion created successfully.[39m
[1693476099218] [33m[OPENAI] Creating embedding...[39m
[1693476099347] [32m[OPENAI] Embedding created successfully.[39m
[1693476099425] --- Observations received -- 
[1693476099425] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 42.32, Y: 1.859999.",
  "time": 43.32154
}
[1693476099425] [Character] Getting character: A5
[1693476099512] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476099513] [33m[OPENAI] Creating embedding...[39m
[1693476099524] --- Observations received -- 
[1693476099524] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 44.99, Y: 2.73.",
  "time": 43.4214668
}
[1693476099524] [Character] Getting character: A5
[1693476099579] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476099579] [33m[OPENAI] Creating embedding...[39m
[1693476099671] [32m[OPENAI] Embedding created successfully.[39m
[1693476099694] [33m[OPENAI] Creating embedding...[39m
[1693476099738] {
  "id": "chatcmpl-7tYmZxwnifheGkySlF2VuL8wXeEtV",
  "object": "chat.completion",
  "created": 1693476099,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693476099738] {
  "role": "assistant",
  "content": "2"
}
[1693476099738] [36m[OPENAI] Chat completion took 225.19058394432068ms[39m
[1693476099738] [36m[OPENAI] Tokens per second: 4.4406830094070635tps[39m
[1693476099738] [32m[OPENAI] Chat completion created successfully.[39m
[1693476099897] {
  "id": "chatcmpl-7tYmZmeakXKdZNJvlkWNdzWGray0I",
  "object": "chat.completion",
  "created": 1693476099,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693476099897] {
  "role": "assistant",
  "content": "2"
}
[1693476099897] [36m[OPENAI] Chat completion took 318.3904159069061ms[39m
[1693476099897] [36m[OPENAI] Tokens per second: 3.1407980581060864tps[39m
[1693476099897] [32m[OPENAI] Chat completion created successfully.[39m
[1693476099905] [32m[OPENAI] Embedding created successfully.[39m
[1693476099921] [32m[OPENAI] Embedding created successfully.[39m
[1693476099926] {
  "id": "chatcmpl-7tYmV86TIaTYE3VsJv41AkdbVRVr9",
  "object": "chat.completion",
  "created": 1693476095,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "eat",
          "arguments": "{\n  \"characterId\": \"A3\",\n  \"foodId\": \"berries\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1668,
    "completion_tokens": 25,
    "total_tokens": 1693
  }
}
[1693476099926] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "eat",
    "arguments": "{\n  \"characterId\": \"A3\",\n  \"foodId\": \"berries\"\n}"
  }
}
[1693476099926] [36m[OPENAI] Chat completion took 4278.721291065216ms[39m
[1693476099926] [36m[OPENAI] Tokens per second: 5.842867132338054tps[39m
[1693476099926] [32m[OPENAI] Chat completion created successfully.[39m
[1693476099957] [Character] Getting character: A3
[1693476099987] [33m[OPENAI] Creating embedding...[39m
[1693476100067] --- Observations received -- 
[1693476100067] {
  "observerId": "A5",
  "observation": "Eli Green finished walking to 42.12, Y: 5.77.",
  "time": 43.9599838
}
[1693476100067] [Character] Getting character: A5
[1693476100068] [Character] Getting character: A5
[1693476100099] [33m[OPENAI] Creating embedding...[39m
[1693476100126] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476100127] [33m[OPENAI] Creating embedding...[39m
[1693476100170] [32m[OPENAI] Embedding created successfully.[39m
[1693476100260] [33m[OPENAI] Creating embedding...[39m
[1693476100346] [32m[OPENAI] Embedding created successfully.[39m
[1693476100371] [32m[OPENAI] Embedding created successfully.[39m
[1693476100378] {
  "id": "chatcmpl-7tYmaT0wnoWzb7o0sscf5UY4GyHcM",
  "object": "chat.completion",
  "created": 1693476100,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693476100378] {
  "role": "assistant",
  "content": "4"
}
[1693476100378] [36m[OPENAI] Chat completion took 251.50354099273682ms[39m
[1693476100378] [36m[OPENAI] Tokens per second: 3.976087159857837tps[39m
[1693476100378] [32m[OPENAI] Chat completion created successfully.[39m
[1693476100417] {
  "id": "chatcmpl-7tYmXuJUCOjln0FFYWW5HDQKNY6ud",
  "object": "chat.completion",
  "created": 1693476097,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_pickaxe",
          "arguments": "{\n  \"characterId\": \"A4\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1798,
    "completion_tokens": 18,
    "total_tokens": 1816
  }
}
[1693476100417] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_pickaxe",
    "arguments": "{\n  \"characterId\": \"A4\"\n}"
  }
}
[1693476100417] [36m[OPENAI] Chat completion took 3193.058000087738ms[39m
[1693476100417] [36m[OPENAI] Tokens per second: 5.637229264080202tps[39m
[1693476100417] [32m[OPENAI] Chat completion created successfully.[39m
[1693476100510] [32m[OPENAI] Embedding created successfully.[39m
[1693476100540] [33m[OPENAI] Creating embedding...[39m
[1693476100739] [33m[OPENAI] Creating embedding...[39m
[1693476100896] [33m[OPENAI] Creating embedding...[39m
[1693476100970] [32m[OPENAI] Embedding created successfully.[39m
[1693476101058] [32m[OPENAI] Embedding created successfully.[39m
[1693476101248] [33m[OPENAI] Creating embedding...[39m
[1693476101384] [33m[OPENAI] Creating embedding...[39m
[1693476101412] [32m[OPENAI] Embedding created successfully.[39m
[1693476101430] [Character] Getting character: A4
[1693476101468] [33m[OPENAI] Creating embedding...[39m
[1693476101597] [32m[OPENAI] Embedding created successfully.[39m
[1693476101625] [32m[OPENAI] Embedding created successfully.[39m
[1693476101821] [33m[OPENAI] Creating embedding...[39m
[1693476101993] [33m[OPENAI] Creating embedding...[39m
[1693476102022] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476102024] [32m[OPENAI] Embedding created successfully.[39m
[1693476102368] [33m[OPENAI] Creating embedding...[39m
[1693476102608] [32m[OPENAI] Embedding created successfully.[39m
[1693476102716] [32m[OPENAI] Embedding created successfully.[39m
[1693476103049] [33m[OPENAI] Creating embedding...[39m
[1693476103117] [33m[OPENAI] Creating embedding...[39m
[1693476103199] [32m[OPENAI] Embedding created successfully.[39m
[1693476103296] [32m[OPENAI] Embedding created successfully.[39m
[1693476103459] [32m[OPENAI] Embedding created successfully.[39m
[1693476103648] [33m[OPENAI] Creating embedding...[39m
[1693476103717] [33m[OPENAI] Creating embedding...[39m
[1693476103806] [32m[OPENAI] Embedding created successfully.[39m
[1693476103825] [33m[OPENAI] Creating embedding...[39m
[1693476103884] [32m[OPENAI] Embedding created successfully.[39m
[1693476104012] [32m[OPENAI] Embedding created successfully.[39m
[1693476104176] [33m[OPENAI] Creating embedding...[39m
[1693476104320] [33m[OPENAI] Creating embedding...[39m
[1693476104477] [33m[OPENAI] Creating embedding...[39m
[1693476104571] [32m[OPENAI] Embedding created successfully.[39m
[1693476104585] [32m[OPENAI] Embedding created successfully.[39m
[1693476104773] [32m[OPENAI] Embedding created successfully.[39m
[1693476104947] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476104960] [33m[OPENAI] Creating embedding...[39m
[1693476105105] [33m[OPENAI] Creating embedding...[39m
[1693476105119] {
  "id": "chatcmpl-7tYmcKuzQstTEfIq6K2ZuFzSTRige",
  "object": "chat.completion",
  "created": 1693476102,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_pickaxe",
          "arguments": "{\n  \"characterId\": \"A2\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1712,
    "completion_tokens": 18,
    "total_tokens": 1730
  }
}
[1693476105119] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_pickaxe",
    "arguments": "{\n  \"characterId\": \"A2\"\n}"
  }
}
[1693476105119] [36m[OPENAI] Chat completion took 3096.585958003998ms[39m
[1693476105119] [36m[OPENAI] Tokens per second: 5.812853330770275tps[39m
[1693476105119] [32m[OPENAI] Chat completion created successfully.[39m
[1693476105259] [32m[OPENAI] Embedding created successfully.[39m
[1693476105356] [32m[OPENAI] Embedding created successfully.[39m
[1693476105517] [33m[OPENAI] Creating embedding...[39m
[1693476105666] [32m[OPENAI] Embedding created successfully.[39m
[1693476105673] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476105749] --- Observations received -- 
[1693476105750] {
  "observerId": "A2",
  "observation": "George Brown picked up Coal at X: 62.6383, Y: 15.4435",
  "time": 49.6457443
}
[1693476105750] [Character] Getting character: A2
[1693476105808] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476105809] [33m[OPENAI] Creating embedding...[39m
[1693476105958] [32m[OPENAI] Embedding created successfully.[39m
[1693476105986] [33m[OPENAI] Creating embedding...[39m
[1693476106135] [Character] Getting character: A2
[1693476106171] [33m[OPENAI] Creating embedding...[39m
[1693476106201] [32m[OPENAI] Embedding created successfully.[39m
[1693476106342] {
  "id": "chatcmpl-7tYmgzS9aM0apyAa6xNMGmsBzO7u0",
  "object": "chat.completion",
  "created": 1693476106,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693476106344] {
  "role": "assistant",
  "content": "3"
}
[1693476106344] [36m[OPENAI] Chat completion took 533.0955830812454ms[39m
[1693476106344] [36m[OPENAI] Tokens per second: 1.8758362134986906tps[39m
[1693476106344] [32m[OPENAI] Chat completion created successfully.[39m
[1693476106350] [32m[OPENAI] Embedding created successfully.[39m
[1693476106505] [33m[OPENAI] Creating embedding...[39m
[1693476106688] [32m[OPENAI] Embedding created successfully.[39m
[1693476106767] [33m[OPENAI] Creating embedding...[39m
[1693476106962] [32m[OPENAI] Embedding created successfully.[39m
[1693476107036] [33m[OPENAI] Creating embedding...[39m
[1693476107173] [32m[OPENAI] Embedding created successfully.[39m
[1693476107307] [33m[OPENAI] Creating embedding...[39m
[1693476107443] [33m[OPENAI] Creating embedding...[39m
[1693476107586] [32m[OPENAI] Embedding created successfully.[39m
[1693476107913] [33m[OPENAI] Creating embedding...[39m
[1693476107985] [32m[OPENAI] Embedding created successfully.[39m
[1693476108140] [32m[OPENAI] Embedding created successfully.[39m
[1693476108281] [33m[OPENAI] Creating embedding...[39m
[1693476108463] [32m[OPENAI] Embedding created successfully.[39m
[1693476108471] [33m[OPENAI] Creating embedding...[39m
[1693476108847] [33m[OPENAI] Creating embedding...[39m
[1693476109039] {
  "id": "chatcmpl-7tYmfwuzp2nAlW87DQ0586YAhkMED",
  "object": "chat.completion",
  "created": 1693476105,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_pickaxe",
          "arguments": "{\n  \"characterId\": \"A4\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1840,
    "completion_tokens": 18,
    "total_tokens": 1858
  }
}
[1693476109039] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_pickaxe",
    "arguments": "{\n  \"characterId\": \"A4\"\n}"
  }
}
[1693476109039] [36m[OPENAI] Chat completion took 3365.9584159851074ms[39m
[1693476109040] [36m[OPENAI] Tokens per second: 5.347659648591345tps[39m
[1693476109040] [32m[OPENAI] Chat completion created successfully.[39m
[1693476109164] [32m[OPENAI] Embedding created successfully.[39m
[1693476109531] {
  "id": "chatcmpl-7tYmfgjn3OA4GHbuo2B4n6R4eKCm0",
  "object": "chat.completion",
  "created": 1693476105,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_axe",
          "arguments": "{\n  \"characterId\": \"A5\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1535,
    "completion_tokens": 18,
    "total_tokens": 1553
  }
}
[1693476109531] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_axe",
    "arguments": "{\n  \"characterId\": \"A5\"\n}"
  }
}
[1693476109531] [36m[OPENAI] Chat completion took 4583.691624999046ms[39m
[1693476109531] [36m[OPENAI] Tokens per second: 3.9269657456513003tps[39m
[1693476109531] [32m[OPENAI] Chat completion created successfully.[39m
[1693476109580] [33m[OPENAI] Creating embedding...[39m
[1693476109663] --- Observations received -- 
[1693476109664] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Small) at X: 54.06, Y: 24.46.",
  "time": 53.56018
}
[1693476109664] [Character] Getting character: A4
[1693476109664] --- Observations received -- 
[1693476109664] {
  "observerId": "A4",
  "observation": "Lucy Wilde picked up Copper at X: 54.15919, Y: 25.0994",
  "time": 53.56018
}
[1693476109664] [Character] Getting character: A4
[1693476109763] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476109763] [33m[OPENAI] Creating embedding...[39m
[1693476109763] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476109763] [33m[OPENAI] Creating embedding...[39m
[1693476109773] [32m[OPENAI] Embedding created successfully.[39m
[1693476109885] [32m[OPENAI] Embedding created successfully.[39m
[1693476109953] [32m[OPENAI] Embedding created successfully.[39m
[1693476110008] [32m[OPENAI] Embedding created successfully.[39m
[1693476110017] {
  "id": "chatcmpl-7tYmjWsbZQ2aUFVh7bVb0irpLqFht",
  "object": "chat.completion",
  "created": 1693476109,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476110018] {
  "role": "assistant",
  "content": "2"
}
[1693476110018] [36m[OPENAI] Chat completion took 254.38304197788239ms[39m
[1693476110018] [36m[OPENAI] Tokens per second: 3.9310796514767135tps[39m
[1693476110018] [32m[OPENAI] Chat completion created successfully.[39m
[1693476110053] [Character] Getting character: A4
[1693476110096] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476110097] [33m[OPENAI] Creating embedding...[39m
[1693476110097] {
  "id": "chatcmpl-7tYmjcpyQ8HcBqF7gxvAH2e7MjSp0",
  "object": "chat.completion",
  "created": 1693476109,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693476110097] {
  "role": "assistant",
  "content": "2"
}
[1693476110097] [36m[OPENAI] Chat completion took 334.10837495326996ms[39m
[1693476110097] [36m[OPENAI] Tokens per second: 2.99304080641458tps[39m
[1693476110098] [32m[OPENAI] Chat completion created successfully.[39m
[1693476110272] [33m[OPENAI] Creating embedding...[39m
[1693476110340] [32m[OPENAI] Embedding created successfully.[39m
[1693476110437] [32m[OPENAI] Embedding created successfully.[39m
[1693476110552] [Character] Getting character: A5
[1693476110598] [33m[OPENAI] Creating embedding...[39m
[1693476110769] [32m[OPENAI] Embedding created successfully.[39m
[1693476110785] [33m[OPENAI] Creating embedding...[39m
[1693476110838] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476111031] [32m[OPENAI] Embedding created successfully.[39m
[1693476111109] [33m[OPENAI] Creating embedding...[39m
[1693476111359] [33m[OPENAI] Creating embedding...[39m
[1693476111378] [32m[OPENAI] Embedding created successfully.[39m
[1693476111505] [32m[OPENAI] Embedding created successfully.[39m
[1693476111722] [33m[OPENAI] Creating embedding...[39m
[1693476111889] [33m[OPENAI] Creating embedding...[39m
[1693476112011] [32m[OPENAI] Embedding created successfully.[39m
[1693476112118] [32m[OPENAI] Embedding created successfully.[39m
[1693476112348] [33m[OPENAI] Creating embedding...[39m
[1693476112544] [33m[OPENAI] Creating embedding...[39m
[1693476112632] [32m[OPENAI] Embedding created successfully.[39m
[1693476112734] [32m[OPENAI] Embedding created successfully.[39m
[1693476112871] --- Observations received -- 
[1693476112872] {
  "observerId": "A2",
  "observation": "George Brown sees Thomas Smith at X: 58.09618, Y: 18.46836.",
  "time": 56.76089
}
[1693476112872] [Character] Getting character: A2
[1693476112906] [33m[OPENAI] Creating embedding...[39m
[1693476112936] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476112936] [33m[OPENAI] Creating embedding...[39m
[1693476113059] [33m[OPENAI] Creating embedding...[39m
[1693476113072] [32m[OPENAI] Embedding created successfully.[39m
[1693476113103] [32m[OPENAI] Embedding created successfully.[39m
[1693476113189] {
  "id": "chatcmpl-7tYmnzphK7mJ7PIuErs0k4sqsKT8V",
  "object": "chat.completion",
  "created": 1693476113,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1693476113189] {
  "role": "assistant",
  "content": "3"
}
[1693476113189] [36m[OPENAI] Chat completion took 252.77912497520447ms[39m
[1693476113189] [36m[OPENAI] Tokens per second: 3.9560228721342856tps[39m
[1693476113189] [32m[OPENAI] Chat completion created successfully.[39m
[1693476113266] [32m[OPENAI] Embedding created successfully.[39m
[1693476113456] [33m[OPENAI] Creating embedding...[39m
[1693476113616] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476113644] [32m[OPENAI] Embedding created successfully.[39m
[1693476113942] [33m[OPENAI] Creating embedding...[39m
[1693476114119] [32m[OPENAI] Embedding created successfully.[39m
[1693476114441] [33m[OPENAI] Creating embedding...[39m
[1693476114618] [32m[OPENAI] Embedding created successfully.[39m
[1693476114879] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476115160] {
  "id": "chatcmpl-7tYmkz9c5xlzDW1Y4cVg1RuuaGrn7",
  "object": "chat.completion",
  "created": 1693476110,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A3\",\n  \"x\": 41.03,\n  \"y\": -11.7\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1580,
    "completion_tokens": 35,
    "total_tokens": 1615
  }
}
[1693476115161] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A3\",\n  \"x\": 41.03,\n  \"y\": -11.7\n}"
  }
}
[1693476115161] [36m[OPENAI] Chat completion took 5064.016499996185ms[39m
[1693476115161] [36m[OPENAI] Tokens per second: 6.911509865741229tps[39m
[1693476115161] [32m[OPENAI] Chat completion created successfully.[39m
[1693476115168] --- Observations received -- 
[1693476115168] {
  "observerId": "A3",
  "observation": "Will Turner has started walking to 41.03, Y: -11.7.",
  "time": 59.0625534
}
[1693476115168] [Character] Getting character: A3
[1693476115204] --- Observations received -- 
[1693476115204] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 38.63, Y: -11.64.",
  "time": 59.1005745
}
[1693476115204] [Character] Getting character: A3
[1693476115230] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476115231] [33m[OPENAI] Creating embedding...[39m
[1693476115278] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476115278] [33m[OPENAI] Creating embedding...[39m
[1693476115392] [32m[OPENAI] Embedding created successfully.[39m
[1693476115485] {
  "id": "chatcmpl-7tYmpMUBFrtWoGI9hhWpGsps419Qx",
  "object": "chat.completion",
  "created": 1693476115,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693476115485] {
  "role": "assistant",
  "content": "2"
}
[1693476115486] [36m[OPENAI] Chat completion took 254.9357498884201ms[39m
[1693476115486] [36m[OPENAI] Tokens per second: 3.922556959695447tps[39m
[1693476115486] [32m[OPENAI] Chat completion created successfully.[39m
[1693476115494] [32m[OPENAI] Embedding created successfully.[39m
[1693476115625] {
  "id": "chatcmpl-7tYmpQN8dCDDKHepQUJja2z3q2nfs",
  "object": "chat.completion",
  "created": 1693476115,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 2,
    "total_tokens": 103
  }
}
[1693476115625] {
  "role": "assistant",
  "content": "3."
}
[1693476115625] [36m[OPENAI] Chat completion took 346.8235000371933ms[39m
[1693476115625] [36m[OPENAI] Tokens per second: 5.766621926673135tps[39m
[1693476115625] [32m[OPENAI] Chat completion created successfully.[39m
[1693476115760] --- Observations received -- 
[1693476115760] {
  "observerId": "A2",
  "observation": "Thomas Smith started a conversation with me.",
  "time": 59.6547775
}
[1693476115760] [Character] Getting character: A2
[1693476115823] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476115823] [33m[OPENAI] Creating embedding...[39m
[1693476115864] --- Observations received -- 
[1693476115864] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 44.48, Y: -14.04.",
  "time": 59.7611237
}
[1693476115864] [Character] Getting character: A3
[1693476115904] --- Observations received -- 
[1693476115904] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 40.96, Y: -14.27.",
  "time": 59.8009224
}
[1693476115904] [Character] Getting character: A3
[1693476115930] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476115930] [33m[OPENAI] Creating embedding...[39m
[1693476115967] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476115968] [33m[OPENAI] Creating embedding...[39m
[1693476116035] {
  "id": "chatcmpl-7tYmptjwwx44GTp1dXIvTfiU13inH",
  "object": "chat.completion",
  "created": 1693476115,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 90,
    "completion_tokens": 1,
    "total_tokens": 91
  }
}
[1693476116035] {
  "role": "assistant",
  "content": "2"
}
[1693476116036] [36m[OPENAI] Chat completion took 212.23824989795685ms[39m
[1693476116036] [36m[OPENAI] Tokens per second: 4.711686043777666tps[39m
[1693476116036] [32m[OPENAI] Chat completion created successfully.[39m
[1693476116070] [32m[OPENAI] Embedding created successfully.[39m
[1693476116078] [32m[OPENAI] Embedding created successfully.[39m
[1693476116167] --- Observations received -- 
[1693476116167] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 36.64, Y: -10.67.",
  "time": 60.06156
}
[1693476116167] [Character] Getting character: A3
[1693476116178] [32m[OPENAI] Embedding created successfully.[39m
[1693476116194] {
  "id": "chatcmpl-7tYmq3VsqfzR74dCvbzfwp1cJOsHR",
  "object": "chat.completion",
  "created": 1693476116,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693476116195] {
  "role": "assistant",
  "content": "1"
}
[1693476116195] [36m[OPENAI] Chat completion took 264.41245794296265ms[39m
[1693476116195] [36m[OPENAI] Tokens per second: 3.7819700621508296tps[39m
[1693476116195] [32m[OPENAI] Chat completion created successfully.[39m
[1693476116236] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476116236] [33m[OPENAI] Creating embedding...[39m
[1693476116249] {
  "id": "chatcmpl-7tYmqp74Ec4orVAOcWA8XphyZSM2d",
  "object": "chat.completion",
  "created": 1693476116,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693476116249] {
  "role": "assistant",
  "content": "3"
}
[1693476116249] [36m[OPENAI] Chat completion took 281.6058750152588ms[39m
[1693476116249] [36m[OPENAI] Tokens per second: 3.5510622778939362tps[39m
[1693476116249] [32m[OPENAI] Chat completion created successfully.[39m
[1693476116285] {
  "id": "chatcmpl-7tYmlxDeQRI24tmw4YvGHbFje7wq7",
  "object": "chat.completion",
  "created": 1693476111,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 61.66,\n  \"y\": 18.02\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1643,
    "completion_tokens": 35,
    "total_tokens": 1678
  }
}
[1693476116285] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 61.66,\n  \"y\": 18.02\n}"
  }
}
[1693476116285] [36m[OPENAI] Chat completion took 5446.039625048637ms[39m
[1693476116285] [36m[OPENAI] Tokens per second: 6.426688457979668tps[39m
[1693476116285] [32m[OPENAI] Chat completion created successfully.[39m
[1693476116449] [32m[OPENAI] Embedding created successfully.[39m
[1693476116528] {
  "id": "chatcmpl-7tYmql2eYM05ZOWWDQFXk1pCJvAqX",
  "object": "chat.completion",
  "created": 1693476116,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693476116528] {
  "role": "assistant",
  "content": "2"
}
[1693476116528] [36m[OPENAI] Chat completion took 291.80545806884766ms[39m
[1693476116528] [36m[OPENAI] Tokens per second: 3.4269406974699668tps[39m
[1693476116528] [32m[OPENAI] Chat completion created successfully.[39m
[1693476116588] --- Observations received -- 
[1693476116589] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 36.7, Y: -12.62.",
  "time": 60.484726
}
[1693476116589] [Character] Getting character: A3
[1693476116625] --- Observations received -- 
[1693476116625] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 38.39, Y: -14.58.",
  "time": 60.5213737
}
[1693476116626] [Character] Getting character: A3
[1693476116655] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476116656] [33m[OPENAI] Creating embedding...[39m
[1693476116690] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476116691] [33m[OPENAI] Creating embedding...[39m
[1693476116855] [32m[OPENAI] Embedding created successfully.[39m
[1693476116860] [32m[OPENAI] Embedding created successfully.[39m
[1693476116911] {
  "id": "chatcmpl-7tYmq6Ppf4NIegejAiuOSy8VfbeuG",
  "object": "chat.completion",
  "created": 1693476116,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693476116911] {
  "role": "assistant",
  "content": "3"
}
[1693476116911] [36m[OPENAI] Chat completion took 255.04537498950958ms[39m
[1693476116911] [36m[OPENAI] Tokens per second: 3.920870943223854tps[39m
[1693476116911] [32m[OPENAI] Chat completion created successfully.[39m
[1693476116927] {
  "id": "chatcmpl-7tYmq0wTlwexsozJIUfN8IeaNyWne",
  "object": "chat.completion",
  "created": 1693476116,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693476116927] {
  "role": "assistant",
  "content": "2"
}
[1693476116927] [36m[OPENAI] Chat completion took 236.30604100227356ms[39m
[1693476116927] [36m[OPENAI] Tokens per second: 4.231800404926503tps[39m
[1693476116927] [32m[OPENAI] Chat completion created successfully.[39m
[1693476116963] --- Observations received -- 
[1693476116963] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 41.43, Y: -16.",
  "time": 60.8600845
}
[1693476116963] [Character] Getting character: A3
[1693476117039] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476117039] [33m[OPENAI] Creating embedding...[39m
[1693476117203] [32m[OPENAI] Embedding created successfully.[39m
[1693476117243] --- Observations received -- 
[1693476117244] {
  "observerId": "A3",
  "observation": "Will Turner finished walking to 41.03, Y: -11.7.",
  "time": 61.1399765
}
[1693476117244] [Character] Getting character: A3
[1693476117246] [Character] Getting character: A3
[1693476117277] [33m[OPENAI] Creating embedding...[39m
[1693476117306] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476117306] [33m[OPENAI] Creating embedding...[39m
[1693476117366] {
  "id": "chatcmpl-7tYmrLEYhtFUlz0d1q0A4I4Kb4CbS",
  "object": "chat.completion",
  "created": 1693476117,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693476117366] {
  "role": "assistant",
  "content": "3"
}
[1693476117366] [36m[OPENAI] Chat completion took 326.92025005817413ms[39m
[1693476117366] [36m[OPENAI] Tokens per second: 3.0588499789231594tps[39m
[1693476117366] [32m[OPENAI] Chat completion created successfully.[39m
[1693476117472] [32m[OPENAI] Embedding created successfully.[39m
[1693476117482] [32m[OPENAI] Embedding created successfully.[39m
[1693476117652] {
  "id": "chatcmpl-7tYmrrfPaHAxBeyDaBksWt3mS4C8u",
  "object": "chat.completion",
  "created": 1693476117,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693476117653] {
  "role": "assistant",
  "content": "4"
}
[1693476117653] [36m[OPENAI] Chat completion took 346.3874999284744ms[39m
[1693476117653] [36m[OPENAI] Tokens per second: 2.8869402048471438tps[39m
[1693476117653] [32m[OPENAI] Chat completion created successfully.[39m
[1693476117864] [33m[OPENAI] Creating embedding...[39m
[1693476118108] [32m[OPENAI] Embedding created successfully.[39m
[1693476118324] {
  "id": "chatcmpl-7tYmnk53jZOj2YVgNxMqsYoWgOGOA",
  "object": "chat.completion",
  "created": 1693476113,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.13,\n  \"y\": 26.69\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1913,
    "completion_tokens": 35,
    "total_tokens": 1948
  }
}
[1693476118324] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.13,\n  \"y\": 26.69\n}"
  }
}
[1693476118324] [36m[OPENAI] Chat completion took 4707.147374987602ms[39m
[1693476118324] [36m[OPENAI] Tokens per second: 7.4355012094968tps[39m
[1693476118324] [32m[OPENAI] Chat completion created successfully.[39m
[1693476118332] --- Observations received -- 
[1693476118333] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 53.13, Y: 26.69.",
  "time": 62.2273941
}
[1693476118333] [Character] Getting character: A4
[1693476118384] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476118384] [33m[OPENAI] Creating embedding...[39m
[1693476118484] --- Observations received -- 
[1693476118485] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Large) at X: 49.04, Y: 28.68.",
  "time": 62.3812943
}
[1693476118485] [Character] Getting character: A4
[1693476118517] [33m[OPENAI] Creating embedding...[39m
[1693476118555] [32m[OPENAI] Embedding created successfully.[39m
[1693476118558] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476118558] [33m[OPENAI] Creating embedding...[39m
[1693476118667] {
  "id": "chatcmpl-7tYmseFnBkw9no8JRs5GHuq8gE7Ra",
  "object": "chat.completion",
  "created": 1693476118,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693476118667] {
  "role": "assistant",
  "content": "1"
}
[1693476118667] [36m[OPENAI] Chat completion took 282.8018749952316ms[39m
[1693476118667] [36m[OPENAI] Tokens per second: 3.5360444481383344tps[39m
[1693476118667] [32m[OPENAI] Chat completion created successfully.[39m
[1693476118747] [32m[OPENAI] Embedding created successfully.[39m
[1693476118747] [32m[OPENAI] Embedding created successfully.[39m
[1693476118815] {
  "id": "chatcmpl-7tYmsr1xdDzupttWCbs9f2NLjZnJT",
  "object": "chat.completion",
  "created": 1693476118,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476118816] {
  "role": "assistant",
  "content": "1"
}
[1693476118816] [36m[OPENAI] Chat completion took 256.78400003910065ms[39m
[1693476118816] [36m[OPENAI] Tokens per second: 3.8943236332782787tps[39m
[1693476118816] [32m[OPENAI] Chat completion created successfully.[39m
[1693476118836] {
  "id": "chatcmpl-7tYmpGEwK4BhCWnASiDRDYrjrt7xp",
  "object": "chat.completion",
  "created": 1693476115,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 45.84,\n  \"y\": 5.299999\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1574,
    "completion_tokens": 36,
    "total_tokens": 1610
  }
}
[1693476118840] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 45.84,\n  \"y\": 5.299999\n}"
  }
}
[1693476118840] [36m[OPENAI] Chat completion took 3956.4562079906464ms[39m
[1693476118840] [36m[OPENAI] Tokens per second: 9.099051804817831tps[39m
[1693476118840] [32m[OPENAI] Chat completion created successfully.[39m
[1693476118848] --- Observations received -- 
[1693476118848] {
  "observerId": "A5",
  "observation": "Eli Green has started walking to 45.84, Y: 5.299999.",
  "time": 62.7456322
}
[1693476118848] [Character] Getting character: A5
[1693476118914] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476118914] [33m[OPENAI] Creating embedding...[39m
[1693476119064] --- Observations received -- 
[1693476119064] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees DiamondOreSmall at X: 58.32, Y: 22.87",
  "time": 62.9611053
}
[1693476119064] [Character] Getting character: A4
[1693476119085] --- Observations received -- 
[1693476119085] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 53.13, Y: 26.69.",
  "time": 62.9799767
}
[1693476119085] [Character] Getting character: A4
[1693476119088] [Character] Getting character: A4
[1693476119115] [33m[OPENAI] Creating embedding...[39m
[1693476119127] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476119127] [33m[OPENAI] Creating embedding...[39m
[1693476119140] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476119141] [33m[OPENAI] Creating embedding...[39m
[1693476119146] [33m[OPENAI] Creating embedding...[39m
[1693476119177] {
  "id": "chatcmpl-7tYmtCiI2CVpi1oPdSnCsfYSK9E1r",
  "object": "chat.completion",
  "created": 1693476119,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693476119177] {
  "role": "assistant",
  "content": "3"
}
[1693476119177] [36m[OPENAI] Chat completion took 262.4189999103546ms[39m
[1693476119177] [36m[OPENAI] Tokens per second: 3.810699683870496tps[39m
[1693476119177] [32m[OPENAI] Chat completion created successfully.[39m
[1693476119279] [32m[OPENAI] Embedding created successfully.[39m
[1693476119285] [32m[OPENAI] Embedding created successfully.[39m
[1693476119293] [32m[OPENAI] Embedding created successfully.[39m
[1693476119314] [32m[OPENAI] Embedding created successfully.[39m
[1693476119333] [32m[OPENAI] Embedding created successfully.[39m
[1693476119403] --- Observations received -- 
[1693476119408] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 48.47, Y: 5.46.",
  "time": 63.3000259
}
[1693476119408] [Character] Getting character: A5
[1693476119471] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476119471] [33m[OPENAI] Creating embedding...[39m
[1693476119478] {
  "id": "chatcmpl-7tYmtITVBJfazPqM8XJJO75UVrNZA",
  "object": "chat.completion",
  "created": 1693476119,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 2,
    "total_tokens": 107
  }
}
[1693476119478] {
  "role": "assistant",
  "content": "2."
}
[1693476119481] [36m[OPENAI] Chat completion took 350.7222911119461ms[39m
[1693476119481] [36m[OPENAI] Tokens per second: 5.702517492284588tps[39m
[1693476119481] [32m[OPENAI] Chat completion created successfully.[39m
[1693476119626] --- Observations received -- 
[1693476119626] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 47.72001, Y: 10.21.",
  "time": 63.5206223
}
[1693476119626] [Character] Getting character: A5
[1693476119650] {
  "id": "chatcmpl-7tYmt1og4iLArxU2OR6AVzNc3AC1X",
  "object": "chat.completion",
  "created": 1693476119,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693476119651] {
  "role": "assistant",
  "content": "4"
}
[1693476119651] [36m[OPENAI] Chat completion took 502.9670000076294ms[39m
[1693476119651] [36m[OPENAI] Tokens per second: 1.988202009246792tps[39m
[1693476119651] [32m[OPENAI] Chat completion created successfully.[39m
[1693476119693] [32m[OPENAI] Embedding created successfully.[39m
[1693476119693] [33m[OPENAI] Creating embedding...[39m
[1693476119709] [33m[OPENAI] Creating embedding...[39m
[1693476119716] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476119716] [33m[OPENAI] Creating embedding...[39m
[1693476119751] {
  "id": "chatcmpl-7tYmty9AK1fPJquJAty8t9puiMRiG",
  "object": "chat.completion",
  "created": 1693476119,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693476119751] {
  "role": "assistant",
  "content": "3"
}
[1693476119751] [36m[OPENAI] Chat completion took 279.15004205703735ms[39m
[1693476119751] [36m[OPENAI] Tokens per second: 3.582302881386186tps[39m
[1693476119751] [32m[OPENAI] Chat completion created successfully.[39m
[1693476119785] --- Observations received -- 
[1693476119786] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 48.39, Y: 3.48.",
  "time": 63.6819077
}
[1693476119786] [Character] Getting character: A5
[1693476119850] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476119850] [33m[OPENAI] Creating embedding...[39m
[1693476119884] --- Observations received -- 
[1693476119885] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 47.44, Y: 2.209999.",
  "time": 63.781414
}
[1693476119885] [Character] Getting character: A5
[1693476119943] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476119943] [33m[OPENAI] Creating embedding...[39m
[1693476119976] [32m[OPENAI] Embedding created successfully.[39m
[1693476119984] [32m[OPENAI] Embedding created successfully.[39m
[1693476119993] [32m[OPENAI] Embedding created successfully.[39m
[1693476120004] {
  "id": "chatcmpl-7tYmtSHV7eTP1htI7Em2iyhlHdPQ7",
  "object": "chat.completion",
  "created": 1693476119,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693476120004] {
  "role": "assistant",
  "content": "2"
}
[1693476120004] [36m[OPENAI] Chat completion took 287.98708295822144ms[39m
[1693476120004] [36m[OPENAI] Tokens per second: 3.472377961288878tps[39m
[1693476120004] [32m[OPENAI] Chat completion created successfully.[39m
[1693476120030] [32m[OPENAI] Embedding created successfully.[39m
[1693476120101] [32m[OPENAI] Embedding created successfully.[39m
[1693476120115] {
  "id": "chatcmpl-7tYmt1bSsQZeGlXAsef6Gnx2oqmyl",
  "object": "chat.completion",
  "created": 1693476119,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693476120115] {
  "role": "assistant",
  "content": "2"
}
[1693476120115] [36m[OPENAI] Chat completion took 265.09500002861023ms[39m
[1693476120115] [36m[OPENAI] Tokens per second: 3.7722325954547444tps[39m
[1693476120115] [32m[OPENAI] Chat completion created successfully.[39m
[1693476120181] {
  "id": "chatcmpl-7tYmuom1BjXnsqocRBXJT49jCc7py",
  "object": "chat.completion",
  "created": 1693476120,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693476120183] {
  "role": "assistant",
  "content": "1"
}
[1693476120183] [36m[OPENAI] Chat completion took 237.2416250705719ms[39m
[1693476120183] [36m[OPENAI] Tokens per second: 4.215111912601895tps[39m
[1693476120183] [32m[OPENAI] Chat completion created successfully.[39m
[1693476120285] --- Observations received -- 
[1693476120285] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 45.86, Y: 0.8400002.",
  "time": 64.18179
}
[1693476120285] [Character] Getting character: A5
[1693476120328] [33m[OPENAI] Creating embedding...[39m
[1693476120342] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476120342] [33m[OPENAI] Creating embedding...[39m
[1693476120380] [33m[OPENAI] Creating embedding...[39m
[1693476120404] --- Observations received -- 
[1693476120404] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 50.12, Y: 6.280001.",
  "time": 64.30062
}
[1693476120404] [Character] Getting character: A5
[1693476120462] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476120462] [33m[OPENAI] Creating embedding...[39m
[1693476120517] [32m[OPENAI] Embedding created successfully.[39m
[1693476120544] [32m[OPENAI] Embedding created successfully.[39m
[1693476120575] [32m[OPENAI] Embedding created successfully.[39m
[1693476120594] {
  "id": "chatcmpl-7tYmu7q3jzSYY8no40yL0UWyJ9AaU",
  "object": "chat.completion",
  "created": 1693476120,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693476120594] {
  "role": "assistant",
  "content": "4"
}
[1693476120595] [36m[OPENAI] Chat completion took 252.5963329076767ms[39m
[1693476120595] [36m[OPENAI] Tokens per second: 3.958885659537652tps[39m
[1693476120595] [32m[OPENAI] Chat completion created successfully.[39m
[1693476120631] [32m[OPENAI] Embedding created successfully.[39m
[1693476120803] {
  "id": "chatcmpl-7tYmuIaTtsvg2D2Us0OtKVT2peZsZ",
  "object": "chat.completion",
  "created": 1693476120,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693476120803] {
  "role": "assistant",
  "content": "1"
}
[1693476120803] [36m[OPENAI] Chat completion took 340.39479100704193ms[39m
[1693476120803] [36m[OPENAI] Tokens per second: 2.937765284367446tps[39m
[1693476120803] [32m[OPENAI] Chat completion created successfully.[39m
[1693476120869] [33m[OPENAI] Creating embedding...[39m
[1693476120963] --- Observations received -- 
[1693476120964] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 50.98, Y: 4.519997.",
  "time": 64.8607254
}
[1693476120964] [Character] Getting character: A5
[1693476120984] --- Observations received -- 
[1693476120985] {
  "observerId": "A5",
  "observation": "Eli Green finished walking to 45.84, Y: 5.299999.",
  "time": 64.8799744
}
[1693476120985] [Character] Getting character: A5
[1693476120986] [Character] Getting character: A5
[1693476121025] [33m[OPENAI] Creating embedding...[39m
[1693476121035] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476121035] [33m[OPENAI] Creating embedding...[39m
[1693476121049] [32m[OPENAI] Embedding created successfully.[39m
[1693476121053] [33m[OPENAI] Creating embedding...[39m
[1693476121064] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476121064] [33m[OPENAI] Creating embedding...[39m
[1693476121178] [32m[OPENAI] Embedding created successfully.[39m
[1693476121212] [32m[OPENAI] Embedding created successfully.[39m
[1693476121215] [32m[OPENAI] Embedding created successfully.[39m
[1693476121231] [32m[OPENAI] Embedding created successfully.[39m
[1693476121294] {
  "id": "chatcmpl-7tYmvlI0OGBZwS7kArbX96GVRNfBG",
  "object": "chat.completion",
  "created": 1693476121,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693476121294] {
  "role": "assistant",
  "content": "5"
}
[1693476121294] [36m[OPENAI] Chat completion took 259.22183299064636ms[39m
[1693476121295] [36m[OPENAI] Tokens per second: 3.857699748755667tps[39m
[1693476121295] [32m[OPENAI] Chat completion created successfully.[39m
[1693476121389] {
  "id": "chatcmpl-7tYmv767WMcS5ZucGTlaNQgXnUBRf",
  "object": "chat.completion",
  "created": 1693476121,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693476121389] {
  "role": "assistant",
  "content": "2"
}
[1693476121389] [36m[OPENAI] Chat completion took 324.8428750038147ms[39m
[1693476121389] [36m[OPENAI] Tokens per second: 3.0784113703840874tps[39m
[1693476121389] [32m[OPENAI] Chat completion created successfully.[39m
[1693476121468] [33m[OPENAI] Creating embedding...[39m
[1693476121566] [33m[OPENAI] Creating embedding...[39m
[1693476121634] [32m[OPENAI] Embedding created successfully.[39m
[1693476121635] [33m[OPENAI] Creating embedding...[39m
[1693476121742] [32m[OPENAI] Embedding created successfully.[39m
[1693476121801] [32m[OPENAI] Embedding created successfully.[39m
[1693476122043] [33m[OPENAI] Creating embedding...[39m
[1693476122174] [33m[OPENAI] Creating embedding...[39m
[1693476122208] [33m[OPENAI] Creating embedding...[39m
[1693476122310] [32m[OPENAI] Embedding created successfully.[39m
[1693476122341] [32m[OPENAI] Embedding created successfully.[39m
[1693476122394] [32m[OPENAI] Embedding created successfully.[39m
[1693476122641] [33m[OPENAI] Creating embedding...[39m
[1693476122718] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476122792] [33m[OPENAI] Creating embedding...[39m
[1693476122832] [32m[OPENAI] Embedding created successfully.[39m
[1693476122960] [32m[OPENAI] Embedding created successfully.[39m
[1693476123203] [33m[OPENAI] Creating embedding...[39m
[1693476123379] [33m[OPENAI] Creating embedding...[39m
[1693476123389] [32m[OPENAI] Embedding created successfully.[39m
[1693476123672] [33m[OPENAI] Creating embedding...[39m
[1693476123925] [32m[OPENAI] Embedding created successfully.[39m
[1693476123952] [32m[OPENAI] Embedding created successfully.[39m
[1693476124218] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476124365] [33m[OPENAI] Creating embedding...[39m
[1693476124534] [32m[OPENAI] Embedding created successfully.[39m
[1693476124915] [33m[OPENAI] Creating embedding...[39m
[1693476125074] [32m[OPENAI] Embedding created successfully.[39m
[1693476125437] [33m[OPENAI] Creating embedding...[39m
[1693476125725] [32m[OPENAI] Embedding created successfully.[39m
[1693476126032] {
  "id": "chatcmpl-7tYmwgbYtuCx0zb1NXxa8JG96Zb1x",
  "object": "chat.completion",
  "created": 1693476122,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_pickaxe",
          "arguments": "{\n  \"characterId\": \"A4\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1940,
    "completion_tokens": 18,
    "total_tokens": 1958
  }
}
[1693476126032] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_pickaxe",
    "arguments": "{\n  \"characterId\": \"A4\"\n}"
  }
}
[1693476126034] [36m[OPENAI] Chat completion took 3313.161917090416ms[39m
[1693476126034] [36m[OPENAI] Tokens per second: 5.432876644859968tps[39m
[1693476126034] [32m[OPENAI] Chat completion created successfully.[39m
[1693476126074] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476126334] {
  "status": 503,
  "headers": {
    "access-control-allow-origin": "*",
    "alt-svc": "h3=\":443\"; ma=86400",
    "cf-cache-status": "DYNAMIC",
    "cf-ray": "7ff46f9ad9ac17ea-SJC",
    "connection": "keep-alive",
    "content-length": "176",
    "content-type": "application/json",
    "date": "Thu, 31 Aug 2023 10:02:06 GMT",
    "nel": "{\"success_fraction\":0,\"report_to\":\"cf-nel\",\"max_age\":604800}",
    "openai-model": "gpt-4-0613",
    "openai-organization": "ember-ai",
    "openai-processing-ms": "174",
    "openai-version": "2020-10-01",
    "report-to": "{\"endpoints\":[{\"url\":\"https:\\/\\/a.nel.cloudflare.com\\/report\\/v3?s=KSD9O7Q2eeJqbMMpSVKnxAxuIFvQalq025TZAhP6H9CBiqtV4FXS2UjAik%2BGn1NsNomS4zHnZ7RJIu%2B3tkk0INV5rQED7Xyd0WBR10kbgMvokgmm2iGSi3%2BTpO9KhoINBXX1iZRlIojItlgsbpBFn3k%3D\"}],\"group\":\"cf-nel\",\"max_age\":604800}",
    "server": "cloudflare",
    "strict-transport-security": "max-age=15724800; includeSubDomains",
    "vary": "Accept-Encoding",
    "x-ratelimit-limit-requests": "200",
    "x-ratelimit-limit-tokens": "40000",
    "x-ratelimit-remaining-requests": "199",
    "x-ratelimit-remaining-tokens": "37849",
    "x-ratelimit-reset-requests": "300ms",
    "x-ratelimit-reset-tokens": "3.225s",
    "x-request-id": "9582439e3af85869d30af2fcb589d7b4"
  },
  "error": {
    "message": "The server had an error while processing your request. Sorry about that!",
    "type": "server_error",
    "param": null,
    "code": null
  },
  "code": null,
  "param": null,
  "type": "server_error"
}
[1693476126335] [31mInternalServerError: The server had an error while processing your request. Sorry about that![39m
[31m    at APIError.generate (file:///Users/harris/src/starlightshire-server/node_modules/openai/error.mjs:52:14)[39m
[31m    at OpenAI.makeStatusError (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:176:21)[39m
[31m    at OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:212:24)[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:70:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:397:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:72:13) {[39m
[31m  status: 503,[39m
[31m  headers: {[39m
[31m    'access-control-allow-origin': '*',[39m
[31m    'alt-svc': 'h3=":443"; ma=86400',[39m
[31m    'cf-cache-status': 'DYNAMIC',[39m
[31m    'cf-ray': '7ff46f9ad9ac17ea-SJC',[39m
[31m    connection: 'keep-alive',[39m
[31m    'content-length': '176',[39m
[31m    'content-type': 'application/json',[39m
[31m    date: 'Thu, 31 Aug 2023 10:02:06 GMT',[39m
[31m    nel: '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}',[39m
[31m    'openai-model': 'gpt-4-0613',[39m
[31m    'openai-organization': 'ember-ai',[39m
[31m    'openai-processing-ms': '174',[39m
[31m    'openai-version': '2020-10-01',[39m
[31m    'report-to': '{"endpoints":[{"url":"https:\\/\\/a.nel.cloudflare.com\\/report\\/v3?s=KSD9O7Q2eeJqbMMpSVKnxAxuIFvQalq025TZAhP6H9CBiqtV4FXS2UjAik%2BGn1NsNomS4zHnZ7RJIu%2B3tkk0INV5rQED7Xyd0WBR10kbgMvokgmm2iGSi3%2BTpO9KhoINBXX1iZRlIojItlgsbpBFn3k%3D"}],"group":"cf-nel","max_age":604800}',[39m
[31m    server: 'cloudflare',[39m
[31m    'strict-transport-security': 'max-age=15724800; includeSubDomains',[39m
[31m    vary: 'Accept-Encoding',[39m
[31m    'x-ratelimit-limit-requests': '200',[39m
[31m    'x-ratelimit-limit-tokens': '40000',[39m
[31m    'x-ratelimit-remaining-requests': '199',[39m
[31m    'x-ratelimit-remaining-tokens': '37849',[39m
[31m    'x-ratelimit-reset-requests': '300ms',[39m
[31m    'x-ratelimit-reset-tokens': '3.225s',[39m
[31m    'x-request-id': '9582439e3af85869d30af2fcb589d7b4'[39m
[31m  },[39m
[31m  error: {[39m
[31m    message: 'The server had an error while processing your request. Sorry about that!',[39m
[31m    type: 'server_error',[39m
[31m    param: null,[39m
[31m    code: null[39m
[31m  },[39m
[31m  code: null,[39m
[31m  param: null,[39m
[31m  type: 'server_error'[39m
[31m}[39m
[1693476126335] [31mFailed to create chat completion. Retrying...[39m
[1693476127052] [Character] Getting character: A4
[1693476127089] [33m[OPENAI] Creating embedding...[39m
[1693476127282] [32m[OPENAI] Embedding created successfully.[39m
[1693476127667] [33m[OPENAI] Creating embedding...[39m
[1693476127872] [32m[OPENAI] Embedding created successfully.[39m
[1693476128310] [33m[OPENAI] Creating embedding...[39m
[1693476128455] [32m[OPENAI] Embedding created successfully.[39m
[1693476128687] {
  "id": "chatcmpl-7tYn0SS5LLIuAAoTMiepPgyh1WEDa",
  "object": "chat.completion",
  "created": 1693476126,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_axe",
          "arguments": "{\n  \"characterId\": \"A5\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1771,
    "completion_tokens": 18,
    "total_tokens": 1789
  }
}
[1693476128688] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_axe",
    "arguments": "{\n  \"characterId\": \"A5\"\n}"
  }
}
[1693476128688] [36m[OPENAI] Chat completion took 2612.773290991783ms[39m
[1693476128688] [36m[OPENAI] Tokens per second: 6.8892314775490435tps[39m
[1693476128688] [32m[OPENAI] Chat completion created successfully.[39m
[1693476128863] [33m[OPENAI] Creating embedding...[39m
[1693476129074] [32m[OPENAI] Embedding created successfully.[39m
[1693476129479] [33m[OPENAI] Creating embedding...[39m
[1693476129581] {
  "id": "chatcmpl-7tYn09XDWtP8ypGHafNa7Q1X2MR1e",
  "object": "chat.completion",
  "created": 1693476126,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_axe",
          "arguments": "{\n\"characterId\": \"A3\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2052,
    "completion_tokens": 17,
    "total_tokens": 2069
  }
}
[1693476129581] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_axe",
    "arguments": "{\n\"characterId\": \"A3\"\n}"
  }
}
[1693476129581] [36m[OPENAI] Chat completion took 3244.7921249866486ms[39m
[1693476129581] [36m[OPENAI] Tokens per second: 5.2391645890320175tps[39m
[1693476129581] [32m[OPENAI] Chat completion created successfully.[39m
[1693476129672] [32m[OPENAI] Embedding created successfully.[39m
[1693476129700] [Character] Getting character: A5
[1693476129733] [33m[OPENAI] Creating embedding...[39m
[1693476130006] [32m[OPENAI] Embedding created successfully.[39m
[1693476130052] [33m[OPENAI] Creating embedding...[39m
[1693476130220] [32m[OPENAI] Embedding created successfully.[39m
[1693476130339] [33m[OPENAI] Creating embedding...[39m
[1693476130487] [32m[OPENAI] Embedding created successfully.[39m
[1693476130595] [Character] Getting character: A3
[1693476130623] [33m[OPENAI] Creating embedding...[39m
[1693476130659] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476130763] [33m[OPENAI] Creating embedding...[39m
[1693476130789] [32m[OPENAI] Embedding created successfully.[39m
[1693476130928] [32m[OPENAI] Embedding created successfully.[39m
[1693476131147] [33m[OPENAI] Creating embedding...[39m
[1693476131283] [32m[OPENAI] Embedding created successfully.[39m
[1693476131294] [33m[OPENAI] Creating embedding...[39m
[1693476131515] [32m[OPENAI] Embedding created successfully.[39m
[1693476131564] [33m[OPENAI] Creating embedding...[39m
[1693476131825] [33m[OPENAI] Creating embedding...[39m
[1693476131945] [32m[OPENAI] Embedding created successfully.[39m
[1693476132194] [33m[OPENAI] Creating embedding...[39m
[1693476132364] [32m[OPENAI] Embedding created successfully.[39m
[1693476132447] [32m[OPENAI] Embedding created successfully.[39m
[1693476132703] [33m[OPENAI] Creating embedding...[39m
[1693476132862] [33m[OPENAI] Creating embedding...[39m
[1693476132921] [32m[OPENAI] Embedding created successfully.[39m
[1693476133014] [32m[OPENAI] Embedding created successfully.[39m
[1693476133272] [33m[OPENAI] Creating embedding...[39m
[1693476133410] [32m[OPENAI] Embedding created successfully.[39m
[1693476133421] [33m[OPENAI] Creating embedding...[39m
[1693476133589] [32m[OPENAI] Embedding created successfully.[39m
[1693476133676] {
  "id": "chatcmpl-7tYn4JieGgxu83YggE3eZJJZKeTVm",
  "object": "chat.completion",
  "created": 1693476130,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_pickaxe",
          "arguments": "{\n  \"characterId\": \"A4\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1982,
    "completion_tokens": 18,
    "total_tokens": 2000
  }
}
[1693476133679] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_pickaxe",
    "arguments": "{\n  \"characterId\": \"A4\"\n}"
  }
}
[1693476133679] [36m[OPENAI] Chat completion took 3014.530292034149ms[39m
[1693476133679] [36m[OPENAI] Tokens per second: 5.97107949041505tps[39m
[1693476133679] [32m[OPENAI] Chat completion created successfully.[39m
[1693476133712] [33m[OPENAI] Creating embedding...[39m
[1693476133869] [33m[OPENAI] Creating embedding...[39m
[1693476133873] [32m[OPENAI] Embedding created successfully.[39m
[1693476134098] [32m[OPENAI] Embedding created successfully.[39m
[1693476134153] [33m[OPENAI] Creating embedding...[39m
[1693476134345] [32m[OPENAI] Embedding created successfully.[39m
[1693476134507] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476134594] [33m[OPENAI] Creating embedding...[39m
[1693476134697] [Character] Getting character: A4
[1693476134730] [33m[OPENAI] Creating embedding...[39m
[1693476134750] [32m[OPENAI] Embedding created successfully.[39m
[1693476134981] [32m[OPENAI] Embedding created successfully.[39m
[1693476134989] [33m[OPENAI] Creating embedding...[39m
[1693476135145] [32m[OPENAI] Embedding created successfully.[39m
[1693476135292] [33m[OPENAI] Creating embedding...[39m
[1693476135430] [32m[OPENAI] Embedding created successfully.[39m
[1693476135528] [33m[OPENAI] Creating embedding...[39m
[1693476135847] [32m[OPENAI] Embedding created successfully.[39m
[1693476135858] [33m[OPENAI] Creating embedding...[39m
[1693476136029] [32m[OPENAI] Embedding created successfully.[39m
[1693476136167] [33m[OPENAI] Creating embedding...[39m
[1693476136357] [32m[OPENAI] Embedding created successfully.[39m
[1693476136419] [33m[OPENAI] Creating embedding...[39m
[1693476136556] [32m[OPENAI] Embedding created successfully.[39m
[1693476136664] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476136975] [33m[OPENAI] Creating embedding...[39m
[1693476137142] [32m[OPENAI] Embedding created successfully.[39m
[1693476137514] [33m[OPENAI] Creating embedding...[39m
[1693476137690] [32m[OPENAI] Embedding created successfully.[39m
[1693476138091] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476140138] {
  "id": "chatcmpl-7tYn8svcP7isR4ajN9GlLF5PAZnf1",
  "object": "chat.completion",
  "created": 1693476134,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 44.99,\n  \"y\": 2.73\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1810,
    "completion_tokens": 35,
    "total_tokens": 1845
  }
}
[1693476140138] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 44.99,\n  \"y\": 2.73\n}"
  }
}
[1693476140138] [36m[OPENAI] Chat completion took 5630.84429204464ms[39m
[1693476140138] [36m[OPENAI] Tokens per second: 6.21576413495373tps[39m
[1693476140138] [32m[OPENAI] Chat completion created successfully.[39m
[1693476140147] --- Observations received -- 
[1693476140147] {
  "observerId": "A5",
  "observation": "Eli Green has started walking to 44.99, Y: 2.73.",
  "time": 84.04203
}
[1693476140147] [Character] Getting character: A5
[1693476140184] --- Observations received -- 
[1693476140184] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees Tree (534) at X: 50.98, Y: 4.519997",
  "time": 84.0808945
}
[1693476140184] [Character] Getting character: A5
[1693476140238] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476140238] [33m[OPENAI] Creating embedding...[39m
[1693476140278] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476140278] [33m[OPENAI] Creating embedding...[39m
[1693476140426] [32m[OPENAI] Embedding created successfully.[39m
[1693476140491] [32m[OPENAI] Embedding created successfully.[39m
[1693476140501] {
  "id": "chatcmpl-7tYnEuyEZJ2GFY4V6QrXLByZZk1Ei",
  "object": "chat.completion",
  "created": 1693476140,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693476140502] {
  "role": "assistant",
  "content": "4"
}
[1693476140502] [36m[OPENAI] Chat completion took 260.0173749923706ms[39m
[1693476140502] [36m[OPENAI] Tokens per second: 3.845896836814624tps[39m
[1693476140502] [32m[OPENAI] Chat completion created successfully.[39m
[1693476140663] --- Observations received -- 
[1693476140663] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees Tree (481) at X: 47.72001, Y: 10.21",
  "time": 84.56029
}
[1693476140663] [Character] Getting character: A5
[1693476140689] {
  "id": "chatcmpl-7tYnEQQlMpCCZZo8Wsfvyy2Gpegx2",
  "object": "chat.completion",
  "created": 1693476140,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5.5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 3,
    "total_tokens": 109
  }
}
[1693476140690] {
  "role": "assistant",
  "content": "5.5"
}
[1693476140690] [36m[OPENAI] Chat completion took 411.22787499427795ms[39m
[1693476140690] [36m[OPENAI] Tokens per second: 7.295225305535875tps[39m
[1693476140690] [32m[OPENAI] Chat completion created successfully.[39m
[1693476140726] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476140726] [33m[OPENAI] Creating embedding...[39m
[1693476140873] [32m[OPENAI] Embedding created successfully.[39m
[1693476140964] --- Observations received -- 
[1693476140965] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees Tree (479) at X: 45.24001, Y: 10.2",
  "time": 84.8614
}
[1693476140965] [Character] Getting character: A5
[1693476140989] --- Observations received -- 
[1693476140989] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 49.68, Y: 1.630001.",
  "time": 84.88112
}
[1693476140989] [Character] Getting character: A5
[1693476141029] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476141030] [33m[OPENAI] Creating embedding...[39m
[1693476141058] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476141058] [33m[OPENAI] Creating embedding...[39m
[1693476141063] --- Observations received -- 
[1693476141063] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 42, Y: -0.3199997.",
  "time": 84.96079
}
[1693476141063] [Character] Getting character: A5
[1693476141107] {
  "id": "chatcmpl-7tYnAwTEBjM4xHkmZdLqVcRMSiJx2",
  "object": "chat.completion",
  "created": 1693476136,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A3\",\n  \"x\": 42.72,\n  \"y\": -12.97\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2085,
    "completion_tokens": 35,
    "total_tokens": 2120
  }
}
[1693476141107] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A3\",\n  \"x\": 42.72,\n  \"y\": -12.97\n}"
  }
}
[1693476141107] [36m[OPENAI] Chat completion took 4443.166082978249ms[39m
[1693476141107] [36m[OPENAI] Tokens per second: 7.877265748423147tps[39m
[1693476141107] [32m[OPENAI] Chat completion created successfully.[39m
[1693476141111] --- Observations received -- 
[1693476141111] {
  "observerId": "A3",
  "observation": "Will Turner has started walking to 42.72, Y: -12.97.",
  "time": 85.00811
}
[1693476141111] [Character] Getting character: A3
[1693476141128] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476141129] [33m[OPENAI] Creating embedding...[39m
[1693476141143] --- Observations received -- 
[1693476141144] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 43.22001, Y: -16.37.",
  "time": 85.04062
}
[1693476141144] [Character] Getting character: A3
[1693476141166] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476141166] [33m[OPENAI] Creating embedding...[39m
[1693476141192] [32m[OPENAI] Embedding created successfully.[39m
[1693476141198] {
  "id": "chatcmpl-7tYnEtTI0psLJJZWi4hVDK0HlqX1F",
  "object": "chat.completion",
  "created": 1693476140,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476141198] {
  "role": "assistant",
  "content": "1"
}
[1693476141198] [36m[OPENAI] Chat completion took 471.958624958992ms[39m
[1693476141198] [36m[OPENAI] Tokens per second: 2.11882980226686tps[39m
[1693476141198] [32m[OPENAI] Chat completion created successfully.[39m
[1693476141206] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476141206] [33m[OPENAI] Creating embedding...[39m
[1693476141271] [32m[OPENAI] Embedding created successfully.[39m
[1693476141284] --- Observations received -- 
[1693476141285] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 47.63, Y: -0.7000008.",
  "time": 85.18127
}
[1693476141285] [Character] Getting character: A5
[1693476141296] {
  "id": "chatcmpl-7tYnFtNocyh6f54t0hz6XDqMs19lG",
  "object": "chat.completion",
  "created": 1693476141,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476141297] {
  "role": "assistant",
  "content": "2"
}
[1693476141297] [36m[OPENAI] Chat completion took 267.1613749265671ms[39m
[1693476141297] [36m[OPENAI] Tokens per second: 3.7430560472106555tps[39m
[1693476141297] [32m[OPENAI] Chat completion created successfully.[39m
[1693476141356] [32m[OPENAI] Embedding created successfully.[39m
[1693476141363] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476141364] [33m[OPENAI] Creating embedding...[39m
[1693476141383] [32m[OPENAI] Embedding created successfully.[39m
[1693476141387] {
  "id": "chatcmpl-7tYnF1ABPBJ0ZceD4U1pkGu1796EH",
  "object": "chat.completion",
  "created": 1693476141,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693476141387] {
  "role": "assistant",
  "content": "2"
}
[1693476141387] [36m[OPENAI] Chat completion took 329.059916973114ms[39m
[1693476141387] [36m[OPENAI] Tokens per second: 3.038960227057085tps[39m
[1693476141387] [32m[OPENAI] Chat completion created successfully.[39m
[1693476141405] {
  "id": "chatcmpl-7tYnF5jQJw3leh3q9ZXFVmwi7G9df",
  "object": "chat.completion",
  "created": 1693476141,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693476141405] {
  "role": "assistant",
  "content": "4"
}
[1693476141405] [36m[OPENAI] Chat completion took 276.4268330335617ms[39m
[1693476141405] [36m[OPENAI] Tokens per second: 3.6175938096378197tps[39m
[1693476141405] [32m[OPENAI] Chat completion created successfully.[39m
[1693476141421] [32m[OPENAI] Embedding created successfully.[39m
[1693476141483] {
  "id": "chatcmpl-7tYnFmSxe8OGecZYJhhK3IbOUXUgi",
  "object": "chat.completion",
  "created": 1693476141,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693476141483] {
  "role": "assistant",
  "content": "2"
}
[1693476141484] [36m[OPENAI] Chat completion took 317.0339159965515ms[39m
[1693476141484] [36m[OPENAI] Tokens per second: 3.154236659054728tps[39m
[1693476141484] [32m[OPENAI] Chat completion created successfully.[39m
[1693476141540] [32m[OPENAI] Embedding created successfully.[39m
[1693476141549] --- Observations received -- 
[1693476141549] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 45.66, Y: -15.94.",
  "time": 85.44083
}
[1693476141549] [Character] Getting character: A3
[1693476141549] {
  "id": "chatcmpl-7tYnFkK1LAPQ6hNOcrCPg3DcT0rQY",
  "object": "chat.completion",
  "created": 1693476141,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693476141549] {
  "role": "assistant",
  "content": "4"
}
[1693476141549] [36m[OPENAI] Chat completion took 343.332083940506ms[39m
[1693476141549] [36m[OPENAI] Tokens per second: 2.912631958314983tps[39m
[1693476141549] [32m[OPENAI] Chat completion created successfully.[39m
[1693476141565] --- Observations received -- 
[1693476141565] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees Tree (533) at X: 50.12, Y: 6.280001",
  "time": 85.46157
}
[1693476141565] [Character] Getting character: A5
[1693476141602] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476141602] [33m[OPENAI] Creating embedding...[39m
[1693476141605] {
  "id": "chatcmpl-7tYnFpybHcpea41XVCmqrDWzTZJek",
  "object": "chat.completion",
  "created": 1693476141,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693476141605] {
  "role": "assistant",
  "content": "2"
}
[1693476141605] [36m[OPENAI] Chat completion took 241.29670906066895ms[39m
[1693476141605] [36m[OPENAI] Tokens per second: 4.144275335924997tps[39m
[1693476141605] [32m[OPENAI] Chat completion created successfully.[39m
[1693476141623] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476141623] [33m[OPENAI] Creating embedding...[39m
[1693476141723] --- Observations received -- 
[1693476141723] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 44.56, Y: -1.91.",
  "time": 85.6204
}
[1693476141723] [Character] Getting character: A5
[1693476141747] --- Observations received -- 
[1693476141747] {
  "observerId": "A5",
  "observation": "Eli Green finished walking to 44.99, Y: 2.73.",
  "time": 85.63997
}
[1693476141747] [Character] Getting character: A5
[1693476141748] [Character] Getting character: A5
[1693476141779] [33m[OPENAI] Creating embedding...[39m
[1693476141789] --- Observations received -- 
[1693476141789] {
  "observerId": "A3",
  "observation": "Will Turner no longer sees Tree (217) at X: 36.64, Y: -10.67",
  "time": 85.6800156
}
[1693476141789] [Character] Getting character: A3
[1693476141797] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476141798] [33m[OPENAI] Creating embedding...[39m
[1693476141802] [32m[OPENAI] Embedding created successfully.[39m
[1693476141807] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476141807] [33m[OPENAI] Creating embedding...[39m
[1693476141827] --- Observations received -- 
[1693476141827] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 38.96, Y: -16.52.",
  "time": 85.7216644
}
[1693476141828] [Character] Getting character: A3
[1693476141849] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476141849] [33m[OPENAI] Creating embedding...[39m
[1693476141886] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476141886] [33m[OPENAI] Creating embedding...[39m
[1693476141904] {
  "id": "chatcmpl-7tYnFFrkznRpodXoD00JcUDOkwT0m",
  "object": "chat.completion",
  "created": 1693476141,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476141904] {
  "role": "assistant",
  "content": "1"
}
[1693476141904] [36m[OPENAI] Chat completion took 281.0972499847412ms[39m
[1693476141904] [36m[OPENAI] Tokens per second: 3.5574876668280564tps[39m
[1693476141904] [32m[OPENAI] Chat completion created successfully.[39m
[1693476141905] --- Observations received -- 
[1693476141905] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree Stump at X: 40.39, Y: -17.62.",
  "time": 85.80182
}
[1693476141905] [Character] Getting character: A3
[1693476141927] --- Observations received -- 
[1693476141928] {
  "observerId": "A3",
  "observation": "Will Turner no longer sees Tree (90) at X: 36.7, Y: -12.62",
  "time": 85.82148
}
[1693476141928] [Character] Getting character: A3
[1693476141961] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476141963] [33m[OPENAI] Creating embedding...[39m
[1693476141965] {
  "id": "chatcmpl-7tYnFL8Eyl9qlfE9niF3rqkZv260o",
  "object": "chat.completion",
  "created": 1693476141,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693476141965] {
  "role": "assistant",
  "content": "3"
}
[1693476141965] [36m[OPENAI] Chat completion took 362.7210839986801ms[39m
[1693476141965] [36m[OPENAI] Tokens per second: 2.756939268530745tps[39m
[1693476141965] [32m[OPENAI] Chat completion created successfully.[39m
[1693476141986] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476141986] [33m[OPENAI] Creating embedding...[39m
[1693476142019] [32m[OPENAI] Embedding created successfully.[39m
[1693476142030] {
  "id": "chatcmpl-7tYnFjDOwbLeEsMlvTZzr9ghSXzOj",
  "object": "chat.completion",
  "created": 1693476141,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693476142030] {
  "role": "assistant",
  "content": "4"
}
[1693476142030] [36m[OPENAI] Chat completion took 222.51170802116394ms[39m
[1693476142030] [36m[OPENAI] Tokens per second: 4.494145539096245tps[39m
[1693476142030] [32m[OPENAI] Chat completion created successfully.[39m
[1693476142034] [32m[OPENAI] Embedding created successfully.[39m
[1693476142036] [32m[OPENAI] Embedding created successfully.[39m
[1693476142061] [32m[OPENAI] Embedding created successfully.[39m
[1693476142071] {
  "id": "chatcmpl-7tYnFbVz9JZkklNekAJOY9OYhe6l9",
  "object": "chat.completion",
  "created": 1693476141,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693476142072] {
  "role": "assistant",
  "content": "3"
}
[1693476142072] [36m[OPENAI] Chat completion took 273.8909579515457ms[39m
[1693476142072] [36m[OPENAI] Tokens per second: 3.65108803692932tps[39m
[1693476142072] [32m[OPENAI] Chat completion created successfully.[39m
[1693476142105] {
  "id": "chatcmpl-7tYnFjlr0CDMk8JMOtXXh9dcLjRJp",
  "object": "chat.completion",
  "created": 1693476141,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693476142105] {
  "role": "assistant",
  "content": "2"
}
[1693476142105] [36m[OPENAI] Chat completion took 255.8877500295639ms[39m
[1693476142105] [36m[OPENAI] Tokens per second: 3.9079635499724605tps[39m
[1693476142105] [32m[OPENAI] Chat completion created successfully.[39m
[1693476142140] [32m[OPENAI] Embedding created successfully.[39m
[1693476142187] [32m[OPENAI] Embedding created successfully.[39m
[1693476142206] [32m[OPENAI] Embedding created successfully.[39m
[1693476142227] {
  "id": "chatcmpl-7tYnG6RttAzDDWHeakijBELLJJo1Q",
  "object": "chat.completion",
  "created": 1693476142,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693476142227] {
  "role": "assistant",
  "content": "5"
}
[1693476142227] [36m[OPENAI] Chat completion took 340.06787502765656ms[39m
[1693476142227] [36m[OPENAI] Tokens per second: 2.940589433561384tps[39m
[1693476142227] [32m[OPENAI] Chat completion created successfully.[39m
[1693476142238] {
  "id": "chatcmpl-7tYnG1sqjkDJMdHYBJ03lKNiOsJxx",
  "object": "chat.completion",
  "created": 1693476142,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693476142238] {
  "role": "assistant",
  "content": "2"
}
[1693476142238] [36m[OPENAI] Chat completion took 277.65141701698303ms[39m
[1693476142239] [36m[OPENAI] Tokens per second: 3.60163838075724tps[39m
[1693476142239] [32m[OPENAI] Chat completion created successfully.[39m
[1693476142267] --- Observations received -- 
[1693476142268] {
  "observerId": "A3",
  "observation": "Will Turner finished walking to 42.72, Y: -12.97.",
  "time": 86.15997
}
[1693476142268] [Character] Getting character: A3
[1693476142268] [Character] Getting character: A3
[1693476142272] {
  "id": "chatcmpl-7tYnG9kRxvjLAu0VFrT3n4gpRzRwR",
  "object": "chat.completion",
  "created": 1693476142,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693476142272] {
  "role": "assistant",
  "content": "3"
}
[1693476142272] [36m[OPENAI] Chat completion took 285.4447920322418ms[39m
[1693476142272] [36m[OPENAI] Tokens per second: 3.50330441442087tps[39m
[1693476142272] [32m[OPENAI] Chat completion created successfully.[39m
[1693476142282] [32m[OPENAI] Embedding created successfully.[39m
[1693476142339] [33m[OPENAI] Creating embedding...[39m
[1693476142380] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476142380] [33m[OPENAI] Creating embedding...[39m
[1693476142480] [32m[OPENAI] Embedding created successfully.[39m
[1693476142613] [33m[OPENAI] Creating embedding...[39m
[1693476142666] {
  "id": "chatcmpl-7tYnGqXhdkyYybOpHP89JXtYTBwSF",
  "object": "chat.completion",
  "created": 1693476142,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693476142666] {
  "role": "assistant",
  "content": "1"
}
[1693476142666] [36m[OPENAI] Chat completion took 285.28249990940094ms[39m
[1693476142666] [36m[OPENAI] Tokens per second: 3.5052973817797324tps[39m
[1693476142666] [32m[OPENAI] Chat completion created successfully.[39m
[1693476142773] [32m[OPENAI] Embedding created successfully.[39m
[1693476142921] [33m[OPENAI] Creating embedding...[39m
[1693476142927] [32m[OPENAI] Embedding created successfully.[39m
[1693476143152] [33m[OPENAI] Creating embedding...[39m
[1693476143190] [32m[OPENAI] Embedding created successfully.[39m
[1693476143412] {
  "id": "chatcmpl-7tYnD24143rGSg4yNRgJqrWIt19Ho",
  "object": "chat.completion",
  "created": 1693476139,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 54.06,\n  \"y\": 24.46\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2024,
    "completion_tokens": 35,
    "total_tokens": 2059
  }
}
[1693476143413] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 54.06,\n  \"y\": 24.46\n}"
  }
}
[1693476143413] [36m[OPENAI] Chat completion took 5321.234749913216ms[39m
[1693476143413] [36m[OPENAI] Tokens per second: 6.577420776366015tps[39m
[1693476143413] [32m[OPENAI] Chat completion created successfully.[39m
[1693476143414] [32m[OPENAI] Embedding created successfully.[39m
[1693476143417] --- Observations received -- 
[1693476143417] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 54.06, Y: 24.46.",
  "time": 87.31479
}
[1693476143417] [Character] Getting character: A4
[1693476143445] --- Observations received -- 
[1693476143445] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Diamond Ore Deposit (Small) at X: 58.32, Y: 22.87.",
  "time": 87.34108
}
[1693476143445] [Character] Getting character: A4
[1693476143473] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476143476] [33m[OPENAI] Creating embedding...[39m
[1693476143521] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476143521] [33m[OPENAI] Creating embedding...[39m
[1693476143579] [33m[OPENAI] Creating embedding...[39m
[1693476143658] [32m[OPENAI] Embedding created successfully.[39m
[1693476143722] [32m[OPENAI] Embedding created successfully.[39m
[1693476143731] [32m[OPENAI] Embedding created successfully.[39m
[1693476143813] [33m[OPENAI] Creating embedding...[39m
[1693476143977] {
  "id": "chatcmpl-7tYnHttbOzDpkSVWrcjH6O6v4DZwB",
  "object": "chat.completion",
  "created": 1693476143,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 2,
    "total_tokens": 102
  }
}
[1693476143977] {
  "role": "assistant",
  "content": "2."
}
[1693476143978] [36m[OPENAI] Chat completion took 503.4609580039978ms[39m
[1693476143979] [36m[OPENAI] Tokens per second: 3.9725026701755066tps[39m
[1693476143979] [32m[OPENAI] Chat completion created successfully.[39m
[1693476144006] {
  "id": "chatcmpl-7tYnHu3nbBHmEt8UqLo6ePKhIyHni",
  "object": "chat.completion",
  "created": 1693476143,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476144006] {
  "role": "assistant",
  "content": "2"
}
[1693476144006] [36m[OPENAI] Chat completion took 484.9157500267029ms[39m
[1693476144006] [36m[OPENAI] Tokens per second: 2.062213899929901tps[39m
[1693476144006] [32m[OPENAI] Chat completion created successfully.[39m
[1693476144008] [32m[OPENAI] Embedding created successfully.[39m
[1693476144043] --- Observations received -- 
[1693476144043] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees CopperOreLarge (1) at X: 49.04, Y: 28.68",
  "time": 87.94014
}
[1693476144044] [Character] Getting character: A4
[1693476144063] --- Observations received -- 
[1693476144063] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 54.06, Y: 24.46.",
  "time": 87.95997
}
[1693476144063] [Character] Getting character: A4
[1693476144065] [Character] Getting character: A4
[1693476144094] [33m[OPENAI] Creating embedding...[39m
[1693476144113] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476144113] [33m[OPENAI] Creating embedding...[39m
[1693476144125] [33m[OPENAI] Creating embedding...[39m
[1693476144129] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476144129] [33m[OPENAI] Creating embedding...[39m
[1693476144306] [32m[OPENAI] Embedding created successfully.[39m
[1693476144318] [32m[OPENAI] Embedding created successfully.[39m
[1693476144336] [32m[OPENAI] Embedding created successfully.[39m
[1693476144337] [32m[OPENAI] Embedding created successfully.[39m
[1693476144368] {
  "id": "chatcmpl-7tYnIumBDHfnhLE4BdQDGXuQZtzXX",
  "object": "chat.completion",
  "created": 1693476144,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693476144368] {
  "role": "assistant",
  "content": "2"
}
[1693476144368] [36m[OPENAI] Chat completion took 254.2638750076294ms[39m
[1693476144368] [36m[OPENAI] Tokens per second: 3.9329220478921525tps[39m
[1693476144368] [32m[OPENAI] Chat completion created successfully.[39m
[1693476144495] {
  "id": "chatcmpl-7tYnIjyAvdYSjhEuDDPBDhYnm680B",
  "object": "chat.completion",
  "created": 1693476144,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693476144495] {
  "role": "assistant",
  "content": "2"
}
[1693476144495] [36m[OPENAI] Chat completion took 364.939041018486ms[39m
[1693476144495] [36m[OPENAI] Tokens per second: 2.7401836679604386tps[39m
[1693476144495] [32m[OPENAI] Chat completion created successfully.[39m
[1693476144768] [33m[OPENAI] Creating embedding...[39m
[1693476144800] [33m[OPENAI] Creating embedding...[39m
[1693476144846] [33m[OPENAI] Creating embedding...[39m
[1693476145036] [32m[OPENAI] Embedding created successfully.[39m
[1693476145045] [32m[OPENAI] Embedding created successfully.[39m
[1693476145063] [32m[OPENAI] Embedding created successfully.[39m
[1693476145448] [33m[OPENAI] Creating embedding...[39m
[1693476145470] [33m[OPENAI] Creating embedding...[39m
[1693476145540] [33m[OPENAI] Creating embedding...[39m
[1693476145618] [32m[OPENAI] Embedding created successfully.[39m
[1693476145687] [32m[OPENAI] Embedding created successfully.[39m
[1693476145774] [32m[OPENAI] Embedding created successfully.[39m
[1693476146028] [33m[OPENAI] Creating embedding...[39m
[1693476146227] [33m[OPENAI] Creating embedding...[39m
[1693476146253] [32m[OPENAI] Embedding created successfully.[39m
[1693476146346] [33m[OPENAI] Creating embedding...[39m
[1693476146519] [32m[OPENAI] Embedding created successfully.[39m
[1693476146635] [33m[OPENAI] Creating embedding...[39m
[1693476146856] [32m[OPENAI] Embedding created successfully.[39m
[1693476146918] [33m[OPENAI] Creating embedding...[39m
[1693476147009] [32m[OPENAI] Embedding created successfully.[39m
[1693476147130] [32m[OPENAI] Embedding created successfully.[39m
[1693476147255] [33m[OPENAI] Creating embedding...[39m
[1693476147357] [33m[OPENAI] Creating embedding...[39m
[1693476147358] [33m[CONVERSATION] Starting conversation as player ...[39m
[1693476147358] [33m[CONVERSATION] Starting conversation...[39m
[1693476147358] [33m[CONVERSATION] Player: A1[39m
[1693476147358] [33m[CONVERSATION] Character: A2[39m
[1693476147399] [32m[OPENAI] Embedding created successfully.[39m
[1693476147421] [33m[OPENAI] Creating embedding...[39m
[1693476147493] [33m[OPENAI] Creating embedding...[39m
[1693476147519] [32m[OPENAI] Embedding created successfully.[39m
[1693476147577] [32m[OPENAI] Embedding created successfully.[39m
[1693476147795] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476147913] [32m[OPENAI] Embedding created successfully.[39m
[1693476147952] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476148182] [33m[OPENAI] Creating embedding...[39m
[1693476148309] [32m[OPENAI] Embedding created successfully.[39m
[1693476148583] [33m[OPENAI] Creating embedding...[39m
[1693476148796] [32m[OPENAI] Embedding created successfully.[39m
[1693476149067] [33m[OPENAI] Creating embedding...[39m
[1693476149236] [32m[OPENAI] Embedding created successfully.[39m
[1693476149434] {
  "status": 503,
  "headers": {
    "access-control-allow-origin": "*",
    "alt-svc": "h3=\":443\"; ma=86400",
    "cf-cache-status": "DYNAMIC",
    "cf-ray": "7ff4702cbd85253c-SJC",
    "connection": "keep-alive",
    "content-length": "176",
    "content-type": "application/json",
    "date": "Thu, 31 Aug 2023 10:02:29 GMT",
    "nel": "{\"success_fraction\":0,\"report_to\":\"cf-nel\",\"max_age\":604800}",
    "openai-model": "gpt-4-0613",
    "openai-organization": "ember-ai",
    "openai-processing-ms": "90",
    "openai-version": "2020-10-01",
    "report-to": "{\"endpoints\":[{\"url\":\"https:\\/\\/a.nel.cloudflare.com\\/report\\/v3?s=L95wkwEJ983%2Fy9Di03mfDqQ0OVxvfq5qU8wjDPykAmuY%2FpuiQuLf2zaioO60h61W23DMIU%2BVH%2B7LDuGG91xY6Lwy8SZQCIRE98zKxscg96TBsCpz6YMmJ7uKyla1ydQ6uCseyo3PT4YGo9tYbHopawM%3D\"}],\"group\":\"cf-nel\",\"max_age\":604800}",
    "server": "cloudflare",
    "strict-transport-security": "max-age=15724800; includeSubDomains",
    "vary": "Accept-Encoding",
    "x-ratelimit-limit-requests": "200",
    "x-ratelimit-limit-tokens": "40000",
    "x-ratelimit-remaining-requests": "199",
    "x-ratelimit-remaining-tokens": "35859",
    "x-ratelimit-reset-requests": "300ms",
    "x-ratelimit-reset-tokens": "6.21s",
    "x-request-id": "71cfb9067968c39bcad9f7e97f501639"
  },
  "error": {
    "message": "The server had an error while processing your request. Sorry about that!",
    "type": "server_error",
    "param": null,
    "code": null
  },
  "code": null,
  "param": null,
  "type": "server_error"
}
[1693476149435] [31mInternalServerError: The server had an error while processing your request. Sorry about that![39m
[31m    at APIError.generate (file:///Users/harris/src/starlightshire-server/node_modules/openai/error.mjs:52:14)[39m
[31m    at OpenAI.makeStatusError (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:176:21)[39m
[31m    at OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:212:24)[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:70:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:397:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:72:13) {[39m
[31m  status: 503,[39m
[31m  headers: {[39m
[31m    'access-control-allow-origin': '*',[39m
[31m    'alt-svc': 'h3=":443"; ma=86400',[39m
[31m    'cf-cache-status': 'DYNAMIC',[39m
[31m    'cf-ray': '7ff4702cbd85253c-SJC',[39m
[31m    connection: 'keep-alive',[39m
[31m    'content-length': '176',[39m
[31m    'content-type': 'application/json',[39m
[31m    date: 'Thu, 31 Aug 2023 10:02:29 GMT',[39m
[31m    nel: '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}',[39m
[31m    'openai-model': 'gpt-4-0613',[39m
[31m    'openai-organization': 'ember-ai',[39m
[31m    'openai-processing-ms': '90',[39m
[31m    'openai-version': '2020-10-01',[39m
[31m    'report-to': '{"endpoints":[{"url":"https:\\/\\/a.nel.cloudflare.com\\/report\\/v3?s=L95wkwEJ983%2Fy9Di03mfDqQ0OVxvfq5qU8wjDPykAmuY%2FpuiQuLf2zaioO60h61W23DMIU%2BVH%2B7LDuGG91xY6Lwy8SZQCIRE98zKxscg96TBsCpz6YMmJ7uKyla1ydQ6uCseyo3PT4YGo9tYbHopawM%3D"}],"group":"cf-nel","max_age":604800}',[39m
[31m    server: 'cloudflare',[39m
[31m    'strict-transport-security': 'max-age=15724800; includeSubDomains',[39m
[31m    vary: 'Accept-Encoding',[39m
[31m    'x-ratelimit-limit-requests': '200',[39m
[31m    'x-ratelimit-limit-tokens': '40000',[39m
[31m    'x-ratelimit-remaining-requests': '199',[39m
[31m    'x-ratelimit-remaining-tokens': '35859',[39m
[31m    'x-ratelimit-reset-requests': '300ms',[39m
[31m    'x-ratelimit-reset-tokens': '6.21s',[39m
[31m    'x-request-id': '71cfb9067968c39bcad9f7e97f501639'[39m
[31m  },[39m
[31m  error: {[39m
[31m    message: 'The server had an error while processing your request. Sorry about that!',[39m
[31m    type: 'server_error',[39m
[31m    param: null,[39m
[31m    code: null[39m
[31m  },[39m
[31m  code: null,[39m
[31m  param: null,[39m
[31m  type: 'server_error'[39m
[31m}[39m
[1693476149435] [31mFailed to create chat completion. Retrying...[39m
[1693476149501] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476150513] {
  "id": "chatcmpl-7tYnLH9X3WiHalC3B1VzJ9OChBLA9",
  "object": "chat.completion",
  "created": 1693476147,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_axe",
          "arguments": "{\n  \"characterId\": \"A5\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1944,
    "completion_tokens": 18,
    "total_tokens": 1962
  }
}
[1693476150513] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_axe",
    "arguments": "{\n  \"characterId\": \"A5\"\n}"
  }
}
[1693476150513] [36m[OPENAI] Chat completion took 2717.1369169950485ms[39m
[1693476150513] [36m[OPENAI] Tokens per second: 6.6246201608075985tps[39m
[1693476150513] [32m[OPENAI] Chat completion created successfully.[39m
[1693476151528] [Character] Getting character: A5
[1693476151593] [33m[OPENAI] Creating embedding...[39m
[1693476151802] [32m[OPENAI] Embedding created successfully.[39m
[1693476152261] [33m[OPENAI] Creating embedding...[39m
[1693476152567] [32m[OPENAI] Embedding created successfully.[39m
[1693476153026] [33m[OPENAI] Creating embedding...[39m
[1693476153202] [32m[OPENAI] Embedding created successfully.[39m
[1693476153350] {
  "id": "chatcmpl-7tYnNWi58GjU6VZPAy2dhIYQ2Um2J",
  "object": "chat.completion",
  "created": 1693476149,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_axe",
          "arguments": "{\n  \"characterId\": \"A3\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2122,
    "completion_tokens": 18,
    "total_tokens": 2140
  }
}
[1693476153351] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_axe",
    "arguments": "{\n  \"characterId\": \"A3\"\n}"
  }
}
[1693476153351] [36m[OPENAI] Chat completion took 3849.3300420045853ms[39m
[1693476153351] [36m[OPENAI] Tokens per second: 4.676138393845356tps[39m
[1693476153351] [32m[OPENAI] Chat completion created successfully.[39m
[1693476153693] [33m[OPENAI] Creating embedding...[39m
[1693476153860] [32m[OPENAI] Embedding created successfully.[39m
[1693476154286] [33m[OPENAI] Creating embedding...[39m
[1693476154365] [Character] Getting character: A3
[1693476154401] [33m[OPENAI] Creating embedding...[39m
[1693476154446] [32m[OPENAI] Embedding created successfully.[39m
[1693476154587] [32m[OPENAI] Embedding created successfully.[39m
[1693476154834] [33m[OPENAI] Creating embedding...[39m
[1693476154947] {
  "id": "chatcmpl-7tYnNifDoLRNJYIsV29nlOlxBGtqq",
  "object": "chat.completion",
  "created": 1693476149,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 52.01,\n  \"y\": 23.05\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2007,
    "completion_tokens": 35,
    "total_tokens": 2042
  }
}
[1693476154947] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 52.01,\n  \"y\": 23.05\n}"
  }
}
[1693476154947] [36m[OPENAI] Chat completion took 5511.56274998188ms[39m
[1693476154947] [36m[OPENAI] Tokens per second: 6.350286041851754tps[39m
[1693476154947] [32m[OPENAI] Chat completion created successfully.[39m
[1693476154954] --- Observations received -- 
[1693476154955] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 52.01, Y: 23.05.",
  "time": 98.85188
}
[1693476154955] [Character] Getting character: A4
[1693476154984] --- Observations received -- 
[1693476154984] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Large) at X: 49.04, Y: 28.68.",
  "time": 98.8812943
}
[1693476154984] [Character] Getting character: A4
[1693476155002] [33m[OPENAI] Creating embedding...[39m
[1693476155013] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476155014] [33m[OPENAI] Creating embedding...[39m
[1693476155033] [32m[OPENAI] Embedding created successfully.[39m
[1693476155036] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476155036] [33m[OPENAI] Creating embedding...[39m
[1693476155188] [32m[OPENAI] Embedding created successfully.[39m
[1693476155208] [32m[OPENAI] Embedding created successfully.[39m
[1693476155216] [32m[OPENAI] Embedding created successfully.[39m
[1693476155225] --- Observations received -- 
[1693476155225] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Small) at X: 50.43, Y: 20.71.",
  "time": 99.12127
}
[1693476155225] [Character] Getting character: A4
[1693476155261] {
  "id": "chatcmpl-7tYnTscbjnEQyGqDQEBOodT8Zoqhy",
  "object": "chat.completion",
  "created": 1693476155,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476155261] {
  "role": "assistant",
  "content": "2"
}
[1693476155261] [36m[OPENAI] Chat completion took 225.18145895004272ms[39m
[1693476155261] [36m[OPENAI] Tokens per second: 4.440862958534492tps[39m
[1693476155261] [32m[OPENAI] Chat completion created successfully.[39m
[1693476155282] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476155283] [33m[OPENAI] Creating embedding...[39m
[1693476155439] [33m[OPENAI] Creating embedding...[39m
[1693476155474] [32m[OPENAI] Embedding created successfully.[39m
[1693476155483] --- Observations received -- 
[1693476155484] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Small) at X: 53.88, Y: 19.83.",
  "time": 99.38063
}
[1693476155484] [Character] Getting character: A4
[1693476155534] {
  "id": "chatcmpl-7tYnThk1FPzRMLlGyILQ0XzLkILds",
  "object": "chat.completion",
  "created": 1693476155,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693476155534] {
  "role": "assistant",
  "content": "1"
}
[1693476155535] [36m[OPENAI] Chat completion took 520.5623339414597ms[39m
[1693476155535] [36m[OPENAI] Tokens per second: 1.9209995322336477tps[39m
[1693476155535] [32m[OPENAI] Chat completion created successfully.[39m
[1693476155542] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476155543] [33m[OPENAI] Creating embedding...[39m
[1693476155553] {
  "id": "chatcmpl-7tYnTvdp2AP7koOSFjoI3Deyz1PTo",
  "object": "chat.completion",
  "created": 1693476155,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476155553] {
  "role": "assistant",
  "content": "2"
}
[1693476155553] [36m[OPENAI] Chat completion took 269.97637498378754ms[39m
[1693476155553] [36m[OPENAI] Tokens per second: 3.704027806359173tps[39m
[1693476155553] [32m[OPENAI] Chat completion created successfully.[39m
[1693476155582] [33m[OPENAI] Creating embedding...[39m
[1693476155584] --- Observations received -- 
[1693476155584] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Large) at X: 47.23, Y: 25.46.",
  "time": 99.48159
}
[1693476155584] [Character] Getting character: A4
[1693476155600] [32m[OPENAI] Embedding created successfully.[39m
[1693476155656] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476155657] [33m[OPENAI] Creating embedding...[39m
[1693476155723] --- Observations received -- 
[1693476155723] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees DiamondOreSmall at X: 58.32, Y: 22.87",
  "time": 99.61998
}
[1693476155723] [Character] Getting character: A4
[1693476155748] [32m[OPENAI] Embedding created successfully.[39m
[1693476155781] [32m[OPENAI] Embedding created successfully.[39m
[1693476155794] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476155794] [33m[OPENAI] Creating embedding...[39m
[1693476155804] --- Observations received -- 
[1693476155804] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees DiamondOreLarge (3) at X: 58.32, Y: 26.61",
  "time": 99.70082
}
[1693476155804] [Character] Getting character: A4
[1693476155832] [32m[OPENAI] Embedding created successfully.[39m
[1693476155861] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476155861] [33m[OPENAI] Creating embedding...[39m
[1693476155861] {
  "id": "chatcmpl-7tYnTtxNF7lQGmNy7stoAEpMvrBTb",
  "object": "chat.completion",
  "created": 1693476155,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476155861] {
  "role": "assistant",
  "content": "2"
}
[1693476155861] [36m[OPENAI] Chat completion took 318.8332920074463ms[39m
[1693476155861] [36m[OPENAI] Tokens per second: 3.1364353255074917tps[39m
[1693476155861] [32m[OPENAI] Chat completion created successfully.[39m
[1693476155911] {
  "id": "chatcmpl-7tYnTRAyduKpjNFyrz8zl7APMtoLy",
  "object": "chat.completion",
  "created": 1693476155,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476155911] {
  "role": "assistant",
  "content": "1"
}
[1693476155911] [36m[OPENAI] Chat completion took 254.50804197788239ms[39m
[1693476155911] [36m[OPENAI] Tokens per second: 3.9291489268024913tps[39m
[1693476155912] [32m[OPENAI] Chat completion created successfully.[39m
[1693476155934] [32m[OPENAI] Embedding created successfully.[39m
[1693476155939] [33m[OPENAI] Creating embedding...[39m
[1693476156001] [32m[OPENAI] Embedding created successfully.[39m
[1693476156122] {
  "id": "chatcmpl-7tYnTGb1FtgMU2UUeID3EH1lzvkAB",
  "object": "chat.completion",
  "created": 1693476155,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693476156122] {
  "role": "assistant",
  "content": "4"
}
[1693476156123] [36m[OPENAI] Chat completion took 261.29266703128815ms[39m
[1693476156123] [36m[OPENAI] Tokens per second: 3.8271261545975808tps[39m
[1693476156123] [32m[OPENAI] Chat completion created successfully.[39m
[1693476156126] [33m[OPENAI] Creating embedding...[39m
[1693476156139] [32m[OPENAI] Embedding created successfully.[39m
[1693476156285] --- Observations received -- 
[1693476156285] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 52.01, Y: 23.05.",
  "time": 100.179962
}
[1693476156285] [Character] Getting character: A4
[1693476156290] [Character] Getting character: A4
[1693476156291] {
  "id": "chatcmpl-7tYnUrjCIDum6v5vdNDbTdM103tyn",
  "object": "chat.completion",
  "created": 1693476156,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693476156291] {
  "role": "assistant",
  "content": "3"
}
[1693476156291] [36m[OPENAI] Chat completion took 497.37883400917053ms[39m
[1693476156291] [36m[OPENAI] Tokens per second: 2.0105399177110184tps[39m
[1693476156291] [32m[OPENAI] Chat completion created successfully.[39m
[1693476156318] [33m[OPENAI] Creating embedding...[39m
[1693476156344] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476156344] [33m[OPENAI] Creating embedding...[39m
[1693476156389] [32m[OPENAI] Embedding created successfully.[39m
[1693476156455] [32m[OPENAI] Embedding created successfully.[39m
[1693476156608] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476156724] [33m[OPENAI] Creating embedding...[39m
[1693476156780] [32m[OPENAI] Embedding created successfully.[39m
[1693476156859] [33m[OPENAI] Creating embedding...[39m
[1693476156994] [32m[OPENAI] Embedding created successfully.[39m
[1693476157085] [32m[OPENAI] Embedding created successfully.[39m
[1693476157339] {
  "id": "chatcmpl-7tYnVlnDApnmBPBEbgnqSilvCc2ZR",
  "object": "chat.completion",
  "created": 1693476157,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693476157339] {
  "role": "assistant",
  "content": "5"
}
[1693476157339] [36m[OPENAI] Chat completion took 995.2304170131683ms[39m
[1693476157339] [36m[OPENAI] Tokens per second: 1.0047924409315643tps[39m
[1693476157339] [32m[OPENAI] Chat completion created successfully.[39m
[1693476157382] [33m[OPENAI] Creating embedding...[39m
[1693476157507] [33m[OPENAI] Creating embedding...[39m
[1693476157576] [32m[OPENAI] Embedding created successfully.[39m
[1693476157695] [32m[OPENAI] Embedding created successfully.[39m
[1693476158016] [33m[OPENAI] Creating embedding...[39m
[1693476158178] [32m[OPENAI] Embedding created successfully.[39m
[1693476158209] [33m[OPENAI] Creating embedding...[39m
[1693476158419] [32m[OPENAI] Embedding created successfully.[39m
[1693476158464] [33m[OPENAI] Creating embedding...[39m
[1693476158706] [32m[OPENAI] Embedding created successfully.[39m
[1693476158865] [33m[OPENAI] Creating embedding...[39m
[1693476159005] [32m[OPENAI] Embedding created successfully.[39m
[1693476159104] [33m[OPENAI] Creating embedding...[39m
[1693476159269] [32m[OPENAI] Embedding created successfully.[39m
[1693476159480] [33m[OPENAI] Creating embedding...[39m
[1693476159543] [33m[OPENAI] Creating embedding...[39m
[1693476159729] [32m[OPENAI] Embedding created successfully.[39m
[1693476159763] [32m[OPENAI] Embedding created successfully.[39m
[1693476160107] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476160200] [33m[OPENAI] Creating embedding...[39m
[1693476160343] [32m[OPENAI] Embedding created successfully.[39m
[1693476160628] [33m[OPENAI] Creating embedding...[39m
[1693476161559] [32m[OPENAI] Embedding created successfully.[39m
[1693476161667] {
  "status": 503,
  "headers": {
    "access-control-allow-origin": "*",
    "alt-svc": "h3=\":443\"; ma=86400",
    "cf-cache-status": "DYNAMIC",
    "cf-ray": "7ff4707999e7253c-SJC",
    "connection": "keep-alive",
    "content-length": "176",
    "content-type": "application/json",
    "date": "Thu, 31 Aug 2023 10:02:41 GMT",
    "nel": "{\"success_fraction\":0,\"report_to\":\"cf-nel\",\"max_age\":604800}",
    "openai-model": "gpt-4-0613",
    "openai-organization": "ember-ai",
    "openai-processing-ms": "67",
    "openai-version": "2020-10-01",
    "report-to": "{\"endpoints\":[{\"url\":\"https:\\/\\/a.nel.cloudflare.com\\/report\\/v3?s=IXLpqJbcAZ%2F3MGKZ6j5nTMy1bznWkZNK0QqciqlF2%2BaBrGUem%2FBk7mAyVI8FIqIkJ%2Fm6trmeSbdjzDeJuzcQxoVbDZRKvfJrnk9zjfoj9W9nzJeCLm27XOBvHeZnsA86pTvYDpa3kmYNmFjZlFSDlbw%3D\"}],\"group\":\"cf-nel\",\"max_age\":604800}",
    "server": "cloudflare",
    "strict-transport-security": "max-age=15724800; includeSubDomains",
    "vary": "Accept-Encoding",
    "x-ratelimit-limit-requests": "200",
    "x-ratelimit-limit-tokens": "40000",
    "x-ratelimit-remaining-requests": "199",
    "x-ratelimit-remaining-tokens": "33258",
    "x-ratelimit-reset-requests": "300ms",
    "x-ratelimit-reset-tokens": "10.112s",
    "x-request-id": "3266cb45a98787cb730ab24d56eb65f3"
  },
  "error": {
    "message": "The server had an error while processing your request. Sorry about that!",
    "type": "server_error",
    "param": null,
    "code": null
  },
  "code": null,
  "param": null,
  "type": "server_error"
}
[1693476161668] [31mInternalServerError: The server had an error while processing your request. Sorry about that![39m
[31m    at APIError.generate (file:///Users/harris/src/starlightshire-server/node_modules/openai/error.mjs:52:14)[39m
[31m    at OpenAI.makeStatusError (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:176:21)[39m
[31m    at OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:212:24)[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:70:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:397:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:72:13) {[39m
[31m  status: 503,[39m
[31m  headers: {[39m
[31m    'access-control-allow-origin': '*',[39m
[31m    'alt-svc': 'h3=":443"; ma=86400',[39m
[31m    'cf-cache-status': 'DYNAMIC',[39m
[31m    'cf-ray': '7ff4707999e7253c-SJC',[39m
[31m    connection: 'keep-alive',[39m
[31m    'content-length': '176',[39m
[31m    'content-type': 'application/json',[39m
[31m    date: 'Thu, 31 Aug 2023 10:02:41 GMT',[39m
[31m    nel: '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}',[39m
[31m    'openai-model': 'gpt-4-0613',[39m
[31m    'openai-organization': 'ember-ai',[39m
[31m    'openai-processing-ms': '67',[39m
[31m    'openai-version': '2020-10-01',[39m
[31m    'report-to': '{"endpoints":[{"url":"https:\\/\\/a.nel.cloudflare.com\\/report\\/v3?s=IXLpqJbcAZ%2F3MGKZ6j5nTMy1bznWkZNK0QqciqlF2%2BaBrGUem%2FBk7mAyVI8FIqIkJ%2Fm6trmeSbdjzDeJuzcQxoVbDZRKvfJrnk9zjfoj9W9nzJeCLm27XOBvHeZnsA86pTvYDpa3kmYNmFjZlFSDlbw%3D"}],"group":"cf-nel","max_age":604800}',[39m
[31m    server: 'cloudflare',[39m
[31m    'strict-transport-security': 'max-age=15724800; includeSubDomains',[39m
[31m    vary: 'Accept-Encoding',[39m
[31m    'x-ratelimit-limit-requests': '200',[39m
[31m    'x-ratelimit-limit-tokens': '40000',[39m
[31m    'x-ratelimit-remaining-requests': '199',[39m
[31m    'x-ratelimit-remaining-tokens': '33258',[39m
[31m    'x-ratelimit-reset-requests': '300ms',[39m
[31m    'x-ratelimit-reset-tokens': '10.112s',[39m
[31m    'x-request-id': '3266cb45a98787cb730ab24d56eb65f3'[39m
[31m  },[39m
[31m  error: {[39m
[31m    message: 'The server had an error while processing your request. Sorry about that!',[39m
[31m    type: 'server_error',[39m
[31m    param: null,[39m
[31m    code: null[39m
[31m  },[39m
[31m  code: null,[39m
[31m  param: null,[39m
[31m  type: 'server_error'[39m
[31m}[39m
[1693476161668] [31mFailed to create chat completion. Retrying...[39m
[1693476161944] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476162118] {
  "id": "chatcmpl-7tYnVYcJvEYKqyGBsWCacrajPGQCf",
  "object": "chat.completion",
  "created": 1693476157,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 45.84,\n  \"y\": 5.299999\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1983,
    "completion_tokens": 36,
    "total_tokens": 2019
  }
}
[1693476162118] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 45.84,\n  \"y\": 5.299999\n}"
  }
}
[1693476162118] [36m[OPENAI] Chat completion took 5509.645334005356ms[39m
[1693476162118] [36m[OPENAI] Tokens per second: 6.533995895853613tps[39m
[1693476162118] [32m[OPENAI] Chat completion created successfully.[39m
[1693476162127] --- Observations received -- 
[1693476162127] {
  "observerId": "A5",
  "observation": "Eli Green has started walking to 45.84, Y: 5.299999.",
  "time": 106.024582
}
[1693476162127] [Character] Getting character: A5
[1693476162164] --- Observations received -- 
[1693476162164] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees Tree (201) at X: 44.56, Y: -1.91",
  "time": 106.061195
}
[1693476162165] [Character] Getting character: A5
[1693476162193] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476162193] [33m[OPENAI] Creating embedding...[39m
[1693476162226] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476162227] [33m[OPENAI] Creating embedding...[39m
[1693476162423] --- Observations received -- 
[1693476162423] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 50.12, Y: 6.280001.",
  "time": 106.320091
}
[1693476162423] [Character] Getting character: A5
[1693476162459] [32m[OPENAI] Embedding created successfully.[39m
[1693476162468] [32m[OPENAI] Embedding created successfully.[39m
[1693476162486] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476162486] [33m[OPENAI] Creating embedding...[39m
[1693476162498] {
  "id": "chatcmpl-7tYnaJWBNYiZioHqfL5ApJkeQEtFv",
  "object": "chat.completion",
  "created": 1693476162,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693476162498] {
  "role": "assistant",
  "content": "4"
}
[1693476162498] [36m[OPENAI] Chat completion took 270.76895904541016ms[39m
[1693476162498] [36m[OPENAI] Tokens per second: 3.6931855243875717tps[39m
[1693476162498] [32m[OPENAI] Chat completion created successfully.[39m
[1693476162506] {
  "id": "chatcmpl-7tYna5NJeyFvDSO2eM7ersPh2LWPA",
  "object": "chat.completion",
  "created": 1693476162,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693476162506] {
  "role": "assistant",
  "content": "2"
}
[1693476162506] [36m[OPENAI] Chat completion took 312.5129590034485ms[39m
[1693476162506] [36m[OPENAI] Tokens per second: 3.1998673053073787tps[39m
[1693476162506] [32m[OPENAI] Chat completion created successfully.[39m
[1693476162605] --- Observations received -- 
[1693476162605] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees Tree (519) at X: 47.63, Y: -0.7000008",
  "time": 106.501419
}
[1693476162605] [Character] Getting character: A5
[1693476162677] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476162678] [33m[OPENAI] Creating embedding...[39m
[1693476162737] [32m[OPENAI] Embedding created successfully.[39m
[1693476162753] {
  "id": "chatcmpl-7tYnaRxubvZXMTLrAH2MtQkTeqjYu",
  "object": "chat.completion",
  "created": 1693476162,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693476162753] {
  "role": "assistant",
  "content": "2"
}
[1693476162754] [36m[OPENAI] Chat completion took 266.246749997139ms[39m
[1693476162754] [36m[OPENAI] Tokens per second: 3.755914391483636tps[39m
[1693476162754] [32m[OPENAI] Chat completion created successfully.[39m
[1693476162823] --- Observations received -- 
[1693476162823] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees Tree (213) at X: 42, Y: -0.3199997",
  "time": 106.72049
}
[1693476162823] [Character] Getting character: A5
[1693476162897] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476162898] [33m[OPENAI] Creating embedding...[39m
[1693476162905] --- Observations received -- 
[1693476162905] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees Tree (472) at X: 49.68, Y: 1.630001",
  "time": 106.800468
}
[1693476162905] [Character] Getting character: A5
[1693476162909] [32m[OPENAI] Embedding created successfully.[39m
[1693476162923] --- Observations received -- 
[1693476162923] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 45.24001, Y: 10.2.",
  "time": 106.820625
}
[1693476162923] [Character] Getting character: A5
[1693476162973] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476162974] [33m[OPENAI] Creating embedding...[39m
[1693476162990] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476162993] [33m[OPENAI] Creating embedding...[39m
[1693476163033] {
  "id": "chatcmpl-7tYnaoJLw0etpOGXtZYvDcMxGP4C8",
  "object": "chat.completion",
  "created": 1693476162,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 107,
    "completion_tokens": 1,
    "total_tokens": 108
  }
}
[1693476163033] {
  "role": "assistant",
  "content": "3"
}
[1693476163033] [36m[OPENAI] Chat completion took 354.75854110717773ms[39m
[1693476163033] [36m[OPENAI] Tokens per second: 2.8188186727768882tps[39m
[1693476163033] [32m[OPENAI] Chat completion created successfully.[39m
[1693476163040] [32m[OPENAI] Embedding created successfully.[39m
[1693476163189] {
  "id": "chatcmpl-7tYnbJlfxcu38thNsmr4WlsshWxwj",
  "object": "chat.completion",
  "created": 1693476163,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693476163189] {
  "role": "assistant",
  "content": "3"
}
[1693476163189] [36m[OPENAI] Chat completion took 291.4872500896454ms[39m
[1693476163189] [36m[OPENAI] Tokens per second: 3.4306817869133392tps[39m
[1693476163189] [32m[OPENAI] Chat completion created successfully.[39m
[1693476163203] [32m[OPENAI] Embedding created successfully.[39m
[1693476163203] [32m[OPENAI] Embedding created successfully.[39m
[1693476163245] --- Observations received -- 
[1693476163245] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 47.72001, Y: 10.21.",
  "time": 107.141159
}
[1693476163245] [Character] Getting character: A5
[1693476163262] {
  "id": "chatcmpl-7tYnb6PsIDGqSlabepnaK0WbpuRsi",
  "object": "chat.completion",
  "created": 1693476163,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693476163262] {
  "role": "assistant",
  "content": "1"
}
[1693476163262] [36m[OPENAI] Chat completion took 268.56791603565216ms[39m
[1693476163262] [36m[OPENAI] Tokens per second: 3.723452952836149tps[39m
[1693476163262] [32m[OPENAI] Chat completion created successfully.[39m
[1693476163306] {
  "id": "chatcmpl-7tYnbqYZAtxStc66WoJOl2f7WvRui",
  "object": "chat.completion",
  "created": 1693476163,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476163307] {
  "role": "assistant",
  "content": "2"
}
[1693476163307] [36m[OPENAI] Chat completion took 332.8975409269333ms[39m
[1693476163307] [36m[OPENAI] Tokens per second: 3.0039272660758014tps[39m
[1693476163307] [32m[OPENAI] Chat completion created successfully.[39m
[1693476163312] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476163314] [33m[OPENAI] Creating embedding...[39m
[1693476163540] [32m[OPENAI] Embedding created successfully.[39m
[1693476163671] --- Observations received -- 
[1693476163671] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 50.98, Y: 4.519997.",
  "time": 107.5613
}
[1693476163671] [Character] Getting character: A5
[1693476163705] --- Observations received -- 
[1693476163705] {
  "observerId": "A5",
  "observation": "Eli Green finished walking to 45.84, Y: 5.299999.",
  "time": 107.59996
}
[1693476163705] [Character] Getting character: A5
[1693476163706] [Character] Getting character: A5
[1693476163729] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476163730] [33m[OPENAI] Creating embedding...[39m
[1693476163740] [33m[OPENAI] Creating embedding...[39m
[1693476163781] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476163781] [33m[OPENAI] Creating embedding...[39m
[1693476163945] [32m[OPENAI] Embedding created successfully.[39m
[1693476163953] [32m[OPENAI] Embedding created successfully.[39m
[1693476163982] [32m[OPENAI] Embedding created successfully.[39m
[1693476164040] {
  "id": "chatcmpl-7tYnb9qcWlLi6ZKotMJzztMYQJcme",
  "object": "chat.completion",
  "created": 1693476163,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693476164040] {
  "role": "assistant",
  "content": "2"
}
[1693476164040] [36m[OPENAI] Chat completion took 309.93504106998444ms[39m
[1693476164040] [36m[OPENAI] Tokens per second: 3.2264825446897323tps[39m
[1693476164040] [32m[OPENAI] Chat completion created successfully.[39m
[1693476164050] {
  "id": "chatcmpl-7tYnbOsxnMMUZmslvn4hWVi2U6LEl",
  "object": "chat.completion",
  "created": 1693476163,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693476164050] {
  "role": "assistant",
  "content": "1"
}
[1693476164050] [36m[OPENAI] Chat completion took 268.3843330144882ms[39m
[1693476164050] [36m[OPENAI] Tokens per second: 3.725999907550553tps[39m
[1693476164050] [32m[OPENAI] Chat completion created successfully.[39m
[1693476164548] {
  "id": "chatcmpl-7tYnbrZWgrabxhiynz0n0it8Jo86g",
  "object": "chat.completion",
  "created": 1693476163,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693476164548] {
  "role": "assistant",
  "content": "2"
}
[1693476164548] [36m[OPENAI] Chat completion took 1235.5147500038147ms[39m
[1693476164548] [36m[OPENAI] Tokens per second: 0.8093792486062287tps[39m
[1693476164548] [32m[OPENAI] Chat completion created successfully.[39m
[1693476164650] [33m[OPENAI] Creating embedding...[39m
[1693476164874] [32m[OPENAI] Embedding created successfully.[39m
[1693476165208] {
  "id": "chatcmpl-7tYnZPhkDVj9vV6TUsX4os7acAofz",
  "object": "chat.completion",
  "created": 1693476161,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_pickaxe",
          "arguments": "{\n  \"characterId\": \"A4\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2211,
    "completion_tokens": 18,
    "total_tokens": 2229
  }
}
[1693476165208] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_pickaxe",
    "arguments": "{\n  \"characterId\": \"A4\"\n}"
  }
}
[1693476165208] [36m[OPENAI] Chat completion took 3539.207000017166ms[39m
[1693476165208] [36m[OPENAI] Tokens per second: 5.085885058407913tps[39m
[1693476165208] [32m[OPENAI] Chat completion created successfully.[39m
[1693476165308] [33m[OPENAI] Creating embedding...[39m
[1693476165624] [32m[OPENAI] Embedding created successfully.[39m
[1693476166098] [33m[OPENAI] Creating embedding...[39m
[1693476166219] [Character] Getting character: A4
[1693476166254] [33m[OPENAI] Creating embedding...[39m
[1693476166266] [32m[OPENAI] Embedding created successfully.[39m
[1693476166447] [32m[OPENAI] Embedding created successfully.[39m
[1693476166793] [33m[OPENAI] Creating embedding...[39m
[1693476166890] [33m[OPENAI] Creating embedding...[39m
[1693476167005] [32m[OPENAI] Embedding created successfully.[39m
[1693476167040] [32m[OPENAI] Embedding created successfully.[39m
[1693476167517] [33m[OPENAI] Creating embedding...[39m
[1693476167539] {
  "id": "chatcmpl-7tYna5ickrFMJKSj0Vuj7osofirQu",
  "object": "chat.completion",
  "created": 1693476162,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A3\",\n  \"x\": 41.03,\n  \"y\": -11.7\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2161,
    "completion_tokens": 35,
    "total_tokens": 2196
  }
}
[1693476167539] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A3\",\n  \"x\": 41.03,\n  \"y\": -11.7\n}"
  }
}
[1693476167539] [36m[OPENAI] Chat completion took 5594.310292005539ms[39m
[1693476167539] [36m[OPENAI] Tokens per second: 6.256356578936317tps[39m
[1693476167539] [32m[OPENAI] Chat completion created successfully.[39m
[1693476167542] --- Observations received -- 
[1693476167542] {
  "observerId": "A3",
  "observation": "Will Turner has started walking to 41.03, Y: -11.7.",
  "time": 111.439
}
[1693476167542] [Character] Getting character: A3
[1693476167544] [33m[OPENAI] Creating embedding...[39m
[1693476167607] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476167608] [33m[OPENAI] Creating embedding...[39m
[1693476167762] [32m[OPENAI] Embedding created successfully.[39m
[1693476167831] [32m[OPENAI] Embedding created successfully.[39m
[1693476167843] [32m[OPENAI] Embedding created successfully.[39m
[1693476167865] --- Observations received -- 
[1693476167866] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 36.7, Y: -12.62.",
  "time": 111.761627
}
[1693476167866] [Character] Getting character: A3
[1693476167915] {
  "id": "chatcmpl-7tYnftIDlmmK67VwhNiINvIrymkH3",
  "object": "chat.completion",
  "created": 1693476167,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693476167915] {
  "role": "assistant",
  "content": "2"
}
[1693476167915] [36m[OPENAI] Chat completion took 307.188707947731ms[39m
[1693476167915] [36m[OPENAI] Tokens per second: 3.2553279926231946tps[39m
[1693476167915] [32m[OPENAI] Chat completion created successfully.[39m
[1693476167926] --- Observations received -- 
[1693476167926] {
  "observerId": "A3",
  "observation": "Will Turner no longer sees Stump (17) at X: 40.39, Y: -17.62",
  "time": 111.822128
}
[1693476167926] [Character] Getting character: A3
[1693476167938] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476167938] [33m[OPENAI] Creating embedding...[39m
[1693476167984] --- Observations received -- 
[1693476167984] {
  "observerId": "A3",
  "observation": "Will Turner no longer sees Tree (169) at X: 38.96, Y: -16.52",
  "time": 111.880486
}
[1693476167984] [Character] Getting character: A3
[1693476167989] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476167989] [33m[OPENAI] Creating embedding...[39m
[1693476168078] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476168078] [33m[OPENAI] Creating embedding...[39m
[1693476168130] [32m[OPENAI] Embedding created successfully.[39m
[1693476168134] [32m[OPENAI] Embedding created successfully.[39m
[1693476168165] --- Observations received -- 
[1693476168165] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 36.64, Y: -10.67.",
  "time": 112.061691
}
[1693476168165] [Character] Getting character: A3
[1693476168174] {
  "id": "chatcmpl-7tYngttsIFbQOfRASMV7EkZOg7z8j",
  "object": "chat.completion",
  "created": 1693476168,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693476168174] {
  "role": "assistant",
  "content": "4"
}
[1693476168174] [36m[OPENAI] Chat completion took 236.15495800971985ms[39m
[1693476168174] [36m[OPENAI] Tokens per second: 4.23450775045274tps[39m
[1693476168174] [32m[OPENAI] Chat completion created successfully.[39m
[1693476168221] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476168221] [33m[OPENAI] Creating embedding...[39m
[1693476168272] [32m[OPENAI] Embedding created successfully.[39m
[1693476168322] [33m[OPENAI] Creating embedding...[39m
[1693476168331] --- Observations received -- 
[1693476168331] {
  "observerId": "A3",
  "observation": "Will Turner no longer sees Tree (272) at X: 45.66, Y: -15.94",
  "time": 112.221848
}
[1693476168333] [Character] Getting character: A3
[1693476168334] [33m[OPENAI] Creating embedding...[39m
[1693476168374] {
  "id": "chatcmpl-7tYnguZsWKNxht1E8Aq0H4C183MI9",
  "object": "chat.completion",
  "created": 1693476168,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693476168374] {
  "role": "assistant",
  "content": "3"
}
[1693476168374] [36m[OPENAI] Chat completion took 385.0000829696655ms[39m
[1693476168374] [36m[OPENAI] Tokens per second: 2.5974020376478486tps[39m
[1693476168374] [32m[OPENAI] Chat completion created successfully.[39m
[1693476168391] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476168391] [33m[OPENAI] Creating embedding...[39m
[1693476168419] {
  "id": "chatcmpl-7tYngySo2qN7dZrtoHxcI1UwFUYAm",
  "object": "chat.completion",
  "created": 1693476168,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693476168419] {
  "role": "assistant",
  "content": "3"
}
[1693476168419] [36m[OPENAI] Chat completion took 340.5645000934601ms[39m
[1693476168419] [36m[OPENAI] Tokens per second: 2.9363013459288125tps[39m
[1693476168419] [32m[OPENAI] Chat completion created successfully.[39m
[1693476168430] [32m[OPENAI] Embedding created successfully.[39m
[1693476168461] [32m[OPENAI] Embedding created successfully.[39m
[1693476168465] [32m[OPENAI] Embedding created successfully.[39m
[1693476168586] {
  "id": "chatcmpl-7tYnga5gm9i6WQOKXIYj9NO5H8ch3",
  "object": "chat.completion",
  "created": 1693476168,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 2,
    "total_tokens": 103
  }
}
[1693476168586] {
  "role": "assistant",
  "content": "2."
}
[1693476168586] [36m[OPENAI] Chat completion took 365.1313329935074ms[39m
[1693476168586] [36m[OPENAI] Tokens per second: 5.477481167127236tps[39m
[1693476168587] [32m[OPENAI] Chat completion created successfully.[39m
[1693476168604] --- Observations received -- 
[1693476168604] {
  "observerId": "A3",
  "observation": "Will Turner finished walking to 41.03, Y: -11.7.",
  "time": 112.499962
}
[1693476168604] [Character] Getting character: A3
[1693476168607] [Character] Getting character: A3
[1693476168679] [33m[OPENAI] Creating embedding...[39m
[1693476168695] {
  "id": "chatcmpl-7tYngNEpBJ8efplgLBthS58a969Ya",
  "object": "chat.completion",
  "created": 1693476168,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693476168695] {
  "role": "assistant",
  "content": "1"
}
[1693476168695] [36m[OPENAI] Chat completion took 303.36966598033905ms[39m
[1693476168695] [36m[OPENAI] Tokens per second: 3.2963084716083926tps[39m
[1693476168695] [32m[OPENAI] Chat completion created successfully.[39m
[1693476168703] [32m[OPENAI] Embedding created successfully.[39m
[1693476168708] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693476168708] [33m[OPENAI] Creating embedding...[39m
[1693476168841] [32m[OPENAI] Embedding created successfully.[39m
[1693476168851] [33m[OPENAI] Creating embedding...[39m
[1693476168889] [33m[OPENAI] Creating embedding...[39m
[1693476169016] {
  "id": "chatcmpl-7tYngBtUTCHGhmELfYKw92rSx3pS6",
  "object": "chat.completion",
  "created": 1693476168,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693476169016] {
  "role": "assistant",
  "content": "4"
}
[1693476169016] [36m[OPENAI] Chat completion took 308.2977920770645ms[39m
[1693476169016] [36m[OPENAI] Tokens per second: 3.2436171315493305tps[39m
[1693476169016] [32m[OPENAI] Chat completion created successfully.[39m
[1693476169034] [32m[OPENAI] Embedding created successfully.[39m
[1693476169035] [32m[OPENAI] Embedding created successfully.[39m
[1693476169046] [32m[OPENAI] Embedding created successfully.[39m
[1693476169197] [33m[OPENAI] Creating embedding...[39m
[1693476169360] [32m[OPENAI] Embedding created successfully.[39m
[1693476169471] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476169507] [33m[OPENAI] Creating embedding...[39m
[1693476169712] [32m[OPENAI] Embedding created successfully.[39m
[1693476169724] [33m[OPENAI] Creating embedding...[39m
[1693476169894] [32m[OPENAI] Embedding created successfully.[39m
[1693476170087] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693476170226] [33m[OPENAI] Creating embedding...[39m
[1693476170318] [33m[CONVERSATION] Continuing conversation as player...[39m
[1693476170319] [33m[CONVERSATION] Continuing conversation...[39m
[1693476170319] [33m[CONVERSATION] Player: A1[39m
[1693476170319] [33m[CONVERSATION] Character: A2[39m
[1693476170371] [32m[OPENAI] Embedding created successfully.[39m
[1693476170710] [33m[OPENAI] Creating embedding...[39m
[1693476170901] [32m[OPENAI] Embedding created successfully.[39m
[1693476171212] [33m[OPENAI] Creating embedding...[39m
[1693476171362] [32m[OPENAI] Embedding created successfully.[39m
[1693476171635] [33m[OPENAI] Creating embedding...[39m
[1693476171809] [32m[OPENAI] Embedding created successfully.[39m
[1693476172084] [33m[OPENAI] Creating embedding...[39m
[1693476172281] [32m[OPENAI] Embedding created successfully.[39m
[1693476172574] [33m[OPENAI] Creating embedding...[39m
[1693476172808] [32m[OPENAI] Embedding created successfully.[39m
[1693476173101] [33m[OPENAI] Creating embedding...[39m
[1693476173431] [32m[OPENAI] Embedding created successfully.[39m
[1693476173735] [33m[OPENAI] Creating embedding...[39m
[1693476173873] [32m[OPENAI] Embedding created successfully.[39m
[1693476174153] [33m[OPENAI] Creating embedding...[39m
[1693476174288] [32m[OPENAI] Embedding created successfully.[39m
