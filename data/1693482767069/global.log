[1693482767077] [Character] Creating Thomas's logger
[1693482767078] [Character] Creating George's logger
[1693482767078] [Character] Creating Will's logger
[1693482767079] [Character] Creating Lucy's logger
[1693482767079] [Character] Creating Eli's logger
[1693482767082] [Main] WebSocket server listening on port 8082
[1693482767348] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767350] [33m[OPENAI] Creating embedding...[39m
[1693482767350] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767351] [33m[OPENAI] Creating embedding...[39m
[1693482767351] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767351] [33m[OPENAI] Creating embedding...[39m
[1693482767351] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767351] [33m[OPENAI] Creating embedding...[39m
[1693482767351] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767351] [33m[OPENAI] Creating embedding...[39m
[1693482767351] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767351] [33m[OPENAI] Creating embedding...[39m
[1693482767351] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767351] [33m[OPENAI] Creating embedding...[39m
[1693482767352] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767352] [33m[OPENAI] Creating embedding...[39m
[1693482767352] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767352] [33m[OPENAI] Creating embedding...[39m
[1693482767352] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767352] [33m[OPENAI] Creating embedding...[39m
[1693482767352] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767352] [33m[OPENAI] Creating embedding...[39m
[1693482767352] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767352] [33m[OPENAI] Creating embedding...[39m
[1693482767352] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767352] [33m[OPENAI] Creating embedding...[39m
[1693482767352] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767352] [33m[OPENAI] Creating embedding...[39m
[1693482767352] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767352] [33m[OPENAI] Creating embedding...[39m
[1693482767448] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767448] [33m[OPENAI] Creating embedding...[39m
[1693482767448] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767448] [33m[OPENAI] Creating embedding...[39m
[1693482767448] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767448] [33m[OPENAI] Creating embedding...[39m
[1693482767448] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767448] [33m[OPENAI] Creating embedding...[39m
[1693482767448] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767448] [33m[OPENAI] Creating embedding...[39m
[1693482767448] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767448] [33m[OPENAI] Creating embedding...[39m
[1693482767448] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767448] [33m[OPENAI] Creating embedding...[39m
[1693482767448] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767448] [33m[OPENAI] Creating embedding...[39m
[1693482767448] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767448] [33m[OPENAI] Creating embedding...[39m
[1693482767448] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767448] [33m[OPENAI] Creating embedding...[39m
[1693482767449] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767449] [33m[OPENAI] Creating embedding...[39m
[1693482767449] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767449] [33m[OPENAI] Creating embedding...[39m
[1693482767449] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767449] [33m[OPENAI] Creating embedding...[39m
[1693482767449] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767449] [33m[OPENAI] Creating embedding...[39m
[1693482767449] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767449] [33m[OPENAI] Creating embedding...[39m
[1693482767481] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767481] [33m[OPENAI] Creating embedding...[39m
[1693482767481] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767481] [33m[OPENAI] Creating embedding...[39m
[1693482767481] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767481] [33m[OPENAI] Creating embedding...[39m
[1693482767482] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767482] [33m[OPENAI] Creating embedding...[39m
[1693482767482] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767482] [33m[OPENAI] Creating embedding...[39m
[1693482767482] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767482] [33m[OPENAI] Creating embedding...[39m
[1693482767482] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767482] [33m[OPENAI] Creating embedding...[39m
[1693482767482] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767482] [33m[OPENAI] Creating embedding...[39m
[1693482767482] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767482] [33m[OPENAI] Creating embedding...[39m
[1693482767482] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767482] [33m[OPENAI] Creating embedding...[39m
[1693482767482] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767482] [33m[OPENAI] Creating embedding...[39m
[1693482767482] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767482] [33m[OPENAI] Creating embedding...[39m
[1693482767482] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767482] [33m[OPENAI] Creating embedding...[39m
[1693482767482] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767482] [33m[OPENAI] Creating embedding...[39m
[1693482767482] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767482] [33m[OPENAI] Creating embedding...[39m
[1693482767491] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767491] [33m[OPENAI] Creating embedding...[39m
[1693482767491] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767491] [33m[OPENAI] Creating embedding...[39m
[1693482767491] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767491] [33m[OPENAI] Creating embedding...[39m
[1693482767491] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767491] [33m[OPENAI] Creating embedding...[39m
[1693482767491] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767491] [33m[OPENAI] Creating embedding...[39m
[1693482767491] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767491] [33m[OPENAI] Creating embedding...[39m
[1693482767491] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767491] [33m[OPENAI] Creating embedding...[39m
[1693482767491] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767491] [33m[OPENAI] Creating embedding...[39m
[1693482767491] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767491] [33m[OPENAI] Creating embedding...[39m
[1693482767491] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767491] [33m[OPENAI] Creating embedding...[39m
[1693482767491] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767492] [33m[OPENAI] Creating embedding...[39m
[1693482767492] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767492] [33m[OPENAI] Creating embedding...[39m
[1693482767492] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767492] [33m[OPENAI] Creating embedding...[39m
[1693482767492] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767492] [33m[OPENAI] Creating embedding...[39m
[1693482767492] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767492] [33m[OPENAI] Creating embedding...[39m
[1693482767492] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767492] [33m[OPENAI] Creating embedding...[39m
[1693482767524] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767524] [33m[OPENAI] Creating embedding...[39m
[1693482767524] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767524] [33m[OPENAI] Creating embedding...[39m
[1693482767524] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767524] [33m[OPENAI] Creating embedding...[39m
[1693482767524] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767524] [33m[OPENAI] Creating embedding...[39m
[1693482767524] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767524] [33m[OPENAI] Creating embedding...[39m
[1693482767524] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767524] [33m[OPENAI] Creating embedding...[39m
[1693482767524] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767524] [33m[OPENAI] Creating embedding...[39m
[1693482767524] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767524] [33m[OPENAI] Creating embedding...[39m
[1693482767524] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767524] [33m[OPENAI] Creating embedding...[39m
[1693482767524] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767525] [33m[OPENAI] Creating embedding...[39m
[1693482767525] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767525] [33m[OPENAI] Creating embedding...[39m
[1693482767525] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767525] [33m[OPENAI] Creating embedding...[39m
[1693482767525] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767525] [33m[OPENAI] Creating embedding...[39m
[1693482767525] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767525] [33m[OPENAI] Creating embedding...[39m
[1693482767525] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482767525] [33m[OPENAI] Creating embedding...[39m
[1693482767595] [32m[OPENAI] Embedding created successfully.[39m
[1693482767595] [32m[OPENAI] Embedding created successfully.[39m
[1693482767595] [32m[OPENAI] Embedding created successfully.[39m
[1693482767595] [32m[OPENAI] Embedding created successfully.[39m
[1693482767596] [32m[OPENAI] Embedding created successfully.[39m
[1693482767596] [32m[OPENAI] Embedding created successfully.[39m
[1693482767596] [32m[OPENAI] Embedding created successfully.[39m
[1693482767596] [32m[OPENAI] Embedding created successfully.[39m
[1693482767600] [32m[OPENAI] Embedding created successfully.[39m
[1693482767631] [32m[OPENAI] Embedding created successfully.[39m
[1693482767631] [32m[OPENAI] Embedding created successfully.[39m
[1693482767633] [32m[OPENAI] Embedding created successfully.[39m
[1693482767633] [32m[OPENAI] Embedding created successfully.[39m
[1693482767634] [32m[OPENAI] Embedding created successfully.[39m
[1693482767641] [32m[OPENAI] Embedding created successfully.[39m
[1693482767642] [32m[OPENAI] Embedding created successfully.[39m
[1693482767646] [32m[OPENAI] Embedding created successfully.[39m
[1693482767646] [32m[OPENAI] Embedding created successfully.[39m
[1693482767654] {
  "id": "chatcmpl-7taW7CSUN55qh9ovJ3VqQOt3w1aBS",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 90,
    "completion_tokens": 1,
    "total_tokens": 91
  }
}
[1693482767654] {
  "role": "assistant",
  "content": "4"
}
[1693482767654] [36m[OPENAI] Chat completion took 302.73391699790955ms[39m
[1693482767654] [36m[OPENAI] Tokens per second: 3.303230803857717tps[39m
[1693482767654] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767659] {
  "id": "chatcmpl-7taW7KeB813q6hbWkCSYwxAQk5G2R",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 90,
    "completion_tokens": 1,
    "total_tokens": 91
  }
}
[1693482767659] {
  "role": "assistant",
  "content": "3"
}
[1693482767659] [36m[OPENAI] Chat completion took 306.9127080440521ms[39m
[1693482767659] [36m[OPENAI] Tokens per second: 3.258255438078722tps[39m
[1693482767659] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767662] [32m[OPENAI] Embedding created successfully.[39m
[1693482767670] [32m[OPENAI] Embedding created successfully.[39m
[1693482767678] {
  "id": "chatcmpl-7taW7FzzlNmtJovidpyjp552hxGjO",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 96,
    "completion_tokens": 1,
    "total_tokens": 97
  }
}
[1693482767678] {
  "role": "assistant",
  "content": "3"
}
[1693482767678] [36m[OPENAI] Chat completion took 325.7016251087189ms[39m
[1693482767678] [36m[OPENAI] Tokens per second: 3.070294781815108tps[39m
[1693482767678] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767679] {
  "id": "chatcmpl-7taW7QT9rtV3q46gSCZuCnxLBBZ9f",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693482767679] {
  "role": "assistant",
  "content": "3"
}
[1693482767679] [36m[OPENAI] Chat completion took 328.13008296489716ms[39m
[1693482767680] [36m[OPENAI] Tokens per second: 3.047571837864614tps[39m
[1693482767680] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767681] [32m[OPENAI] Embedding created successfully.[39m
[1693482767683] [32m[OPENAI] Embedding created successfully.[39m
[1693482767684] [32m[OPENAI] Embedding created successfully.[39m
[1693482767685] [32m[OPENAI] Embedding created successfully.[39m
[1693482767686] {
  "id": "chatcmpl-7taW70RzVh634MIk5WiWEJtxILb9r",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693482767686] {
  "role": "assistant",
  "content": "3"
}
[1693482767686] [36m[OPENAI] Chat completion took 334.02970802783966ms[39m
[1693482767686] [36m[OPENAI] Tokens per second: 2.9937456937712112tps[39m
[1693482767686] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767691] [32m[OPENAI] Embedding created successfully.[39m
[1693482767691] [32m[OPENAI] Embedding created successfully.[39m
[1693482767693] {
  "id": "chatcmpl-7taW7ktoT3gfgaBjOjDBsu7YyflAT",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693482767693] {
  "role": "assistant",
  "content": "2"
}
[1693482767693] [36m[OPENAI] Chat completion took 341.0248749256134ms[39m
[1693482767693] [36m[OPENAI] Tokens per second: 2.9323374144426464tps[39m
[1693482767693] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767694] [32m[OPENAI] Embedding created successfully.[39m
[1693482767699] [32m[OPENAI] Embedding created successfully.[39m
[1693482767703] {
  "id": "chatcmpl-7taW79vBdTDkZF8sX31eAvZZPjE7z",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693482767703] {
  "role": "assistant",
  "content": "2"
}
[1693482767703] [36m[OPENAI] Chat completion took 350.3009170293808ms[39m
[1693482767703] [36m[OPENAI] Tokens per second: 2.854688501760693tps[39m
[1693482767703] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767703] {
  "id": "chatcmpl-7taW7VUWyfJqgSxUrJDsBNoRHOopk",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693482767703] {
  "role": "assistant",
  "content": "4"
}
[1693482767703] [36m[OPENAI] Chat completion took 351.82270789146423ms[39m
[1693482767703] [36m[OPENAI] Tokens per second: 2.8423406948152294tps[39m
[1693482767703] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767704] [32m[OPENAI] Embedding created successfully.[39m
[1693482767706] [32m[OPENAI] Embedding created successfully.[39m
[1693482767706] [32m[OPENAI] Embedding created successfully.[39m
[1693482767709] [32m[OPENAI] Embedding created successfully.[39m
[1693482767709] [32m[OPENAI] Embedding created successfully.[39m
[1693482767710] [32m[OPENAI] Embedding created successfully.[39m
[1693482767713] [32m[OPENAI] Embedding created successfully.[39m
[1693482767714] [32m[OPENAI] Embedding created successfully.[39m
[1693482767715] [32m[OPENAI] Embedding created successfully.[39m
[1693482767715] [32m[OPENAI] Embedding created successfully.[39m
[1693482767717] [32m[OPENAI] Embedding created successfully.[39m
[1693482767724] [32m[OPENAI] Embedding created successfully.[39m
[1693482767727] {
  "id": "chatcmpl-7taW7TmtLmNEREZjnexvb46OyL6ro",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 2,
    "total_tokens": 95
  }
}
[1693482767727] {
  "role": "assistant",
  "content": "4."
}
[1693482767727] [36m[OPENAI] Chat completion took 376.0966659784317ms[39m
[1693482767727] [36m[OPENAI] Tokens per second: 5.317781785693084tps[39m
[1693482767727] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767728] [32m[OPENAI] Embedding created successfully.[39m
[1693482767728] [32m[OPENAI] Embedding created successfully.[39m
[1693482767729] {
  "id": "chatcmpl-7taW7ThckOnPSerUSh9MaXvXPvluZ",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693482767729] {
  "role": "assistant",
  "content": "4"
}
[1693482767729] [36m[OPENAI] Chat completion took 281.0870410203934ms[39m
[1693482767729] [36m[OPENAI] Tokens per second: 3.5576168732995703tps[39m
[1693482767729] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767730] [32m[OPENAI] Embedding created successfully.[39m
[1693482767735] {
  "id": "chatcmpl-7taW7N9o0hJ7hsX2Oh1VYHpFosrp0",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693482767735] {
  "role": "assistant",
  "content": "6"
}
[1693482767735] [36m[OPENAI] Chat completion took 286.2037500143051ms[39m
[1693482767735] [36m[OPENAI] Tokens per second: 3.4940143165490243tps[39m
[1693482767735] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767737] {
  "id": "chatcmpl-7taW7hDszqFVDcQCSV50OYjDUEnPR",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 96,
    "completion_tokens": 1,
    "total_tokens": 97
  }
}
[1693482767737] {
  "role": "assistant",
  "content": "1"
}
[1693482767737] [36m[OPENAI] Chat completion took 288.82333397865295ms[39m
[1693482767737] [36m[OPENAI] Tokens per second: 3.4623241350503573tps[39m
[1693482767737] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767738] {
  "id": "chatcmpl-7taW7nCfwnVCSPnACMT42dXLyh69y",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693482767738] {
  "role": "assistant",
  "content": "5"
}
[1693482767738] [36m[OPENAI] Chat completion took 289.5669159889221ms[39m
[1693482767738] [36m[OPENAI] Tokens per second: 3.4534331955182913tps[39m
[1693482767738] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767739] [32m[OPENAI] Embedding created successfully.[39m
[1693482767740] [32m[OPENAI] Embedding created successfully.[39m
[1693482767740] [32m[OPENAI] Embedding created successfully.[39m
[1693482767740] [32m[OPENAI] Embedding created successfully.[39m
[1693482767742] [32m[OPENAI] Embedding created successfully.[39m
[1693482767744] [32m[OPENAI] Embedding created successfully.[39m
[1693482767744] [32m[OPENAI] Embedding created successfully.[39m
[1693482767746] [32m[OPENAI] Embedding created successfully.[39m
[1693482767746] {
  "id": "chatcmpl-7taW7lIIQEX7PWPX5aKWukK2CBgfn",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693482767747] {
  "role": "assistant",
  "content": "2"
}
[1693482767747] [36m[OPENAI] Chat completion took 297.6287080049515ms[39m
[1693482767747] [36m[OPENAI] Tokens per second: 3.359890941647213tps[39m
[1693482767747] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767747] [32m[OPENAI] Embedding created successfully.[39m
[1693482767748] [32m[OPENAI] Embedding created successfully.[39m
[1693482767749] [32m[OPENAI] Embedding created successfully.[39m
[1693482767758] {
  "id": "chatcmpl-7taW7487pBWjJpvRBCM4LzCYDUAhy",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 90,
    "completion_tokens": 1,
    "total_tokens": 91
  }
}
[1693482767758] {
  "role": "assistant",
  "content": "4"
}
[1693482767758] [36m[OPENAI] Chat completion took 310.024209022522ms[39m
[1693482767759] [36m[OPENAI] Tokens per second: 3.225554556377738tps[39m
[1693482767759] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767759] {
  "id": "chatcmpl-7taW7Ha7BFyYGWJT1f4KzeLqGkQoi",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693482767759] {
  "role": "assistant",
  "content": "5"
}
[1693482767759] [36m[OPENAI] Chat completion took 310.3805420398712ms[39m
[1693482767759] [36m[OPENAI] Tokens per second: 3.2218514518591856tps[39m
[1693482767759] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767760] {
  "id": "chatcmpl-7taW7ER5S1AK7YbthqRnleOZLiPr9",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693482767760] {
  "role": "assistant",
  "content": "5"
}
[1693482767760] [36m[OPENAI] Chat completion took 408.2367089986801ms[39m
[1693482767760] [36m[OPENAI] Tokens per second: 2.4495592335456364tps[39m
[1693482767760] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767765] {
  "id": "chatcmpl-7taW7VJEqBSgFGalOVVWDBBJyimPt",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 92,
    "completion_tokens": 1,
    "total_tokens": 93
  }
}
[1693482767766] {
  "role": "assistant",
  "content": "4"
}
[1693482767766] [36m[OPENAI] Chat completion took 414.3557080030441ms[39m
[1693482767766] [36m[OPENAI] Tokens per second: 2.413385361141576tps[39m
[1693482767766] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767767] [32m[OPENAI] Embedding created successfully.[39m
[1693482767770] {
  "id": "chatcmpl-7taW7PT92dOifQrdAghoLCeFKvPmP",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 92,
    "completion_tokens": 1,
    "total_tokens": 93
  }
}
[1693482767770] {
  "role": "assistant",
  "content": "5"
}
[1693482767770] [36m[OPENAI] Chat completion took 418.2091660499573ms[39m
[1693482767770] [36m[OPENAI] Tokens per second: 2.3911479737403574tps[39m
[1693482767770] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767771] {
  "id": "chatcmpl-7taW7ytllpss7UVOsJjXWeGpdr0tk",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693482767771] {
  "role": "assistant",
  "content": "3"
}
[1693482767771] [36m[OPENAI] Chat completion took 421.7624160051346ms[39m
[1693482767771] [36m[OPENAI] Tokens per second: 2.3710031099305584tps[39m
[1693482767771] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767772] {
  "id": "chatcmpl-7taW7SlPwlczEVxpe33MUMCLFbb8y",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693482767772] {
  "role": "assistant",
  "content": "5"
}
[1693482767772] [36m[OPENAI] Chat completion took 323.8298330307007ms[39m
[1693482767772] [36m[OPENAI] Tokens per second: 3.0880416132172575tps[39m
[1693482767772] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767773] {
  "id": "chatcmpl-7taW77KeywJRkY31xAJ8T5IezbUCP",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693482767773] {
  "role": "assistant",
  "content": "2"
}
[1693482767773] [36m[OPENAI] Chat completion took 324.89970898628235ms[39m
[1693482767773] [36m[OPENAI] Tokens per second: 3.077872870739386tps[39m
[1693482767773] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767780] [32m[OPENAI] Embedding created successfully.[39m
[1693482767781] [32m[OPENAI] Embedding created successfully.[39m
[1693482767783] {
  "id": "chatcmpl-7taW7a1W0xxolKrtaM5Cp1G4TedrF",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693482767783] {
  "role": "assistant",
  "content": "2"
}
[1693482767783] [36m[OPENAI] Chat completion took 431.42083299160004ms[39m
[1693482767783] [36m[OPENAI] Tokens per second: 2.3179223707527132tps[39m
[1693482767783] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767784] {
  "id": "chatcmpl-7taW7tVsxOB9z4v82TS1NdzWjvUal",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 2,
    "total_tokens": 96
  }
}
[1693482767784] {
  "role": "assistant",
  "content": "2."
}
[1693482767784] [36m[OPENAI] Chat completion took 335.1857498884201ms[39m
[1693482767784] [36m[OPENAI] Tokens per second: 5.966840776094388tps[39m
[1693482767784] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767788] {
  "id": "chatcmpl-7taW7oniWH7Byi6BDedgNrlNfZkch",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693482767788] {
  "role": "assistant",
  "content": "3"
}
[1693482767788] [36m[OPENAI] Chat completion took 340.0427500009537ms[39m
[1693482767788] [36m[OPENAI] Tokens per second: 2.9408067073836905tps[39m
[1693482767788] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767789] {
  "id": "chatcmpl-7taW7CxX9N9AfXzcvdrzil8OvdFbc",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1693482767789] {
  "role": "assistant",
  "content": "1"
}
[1693482767789] [36m[OPENAI] Chat completion took 306.4748330116272ms[39m
[1693482767789] [36m[OPENAI] Tokens per second: 3.262910661124535tps[39m
[1693482767789] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767790] {
  "id": "chatcmpl-7taW7Q66LQ3fAF0gPwrVqeQ1EvBNF",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693482767790] {
  "role": "assistant",
  "content": "5"
}
[1693482767790] [36m[OPENAI] Chat completion took 341.7482500076294ms[39m
[1693482767790] [36m[OPENAI] Tokens per second: 2.9261305653435694tps[39m
[1693482767790] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767791] {
  "id": "chatcmpl-7taW7Nu98V2O0oBRSsPoyL5nmgSB6",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693482767791] {
  "role": "assistant",
  "content": "4"
}
[1693482767791] [36m[OPENAI] Chat completion took 299.98562502861023ms[39m
[1693482767791] [36m[OPENAI] Tokens per second: 3.3334930628913573tps[39m
[1693482767791] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767797] {
  "id": "chatcmpl-7taW7JWAWjbnDGFEsC0sDV2inhHb0",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693482767797] {
  "role": "assistant",
  "content": "7"
}
[1693482767797] [36m[OPENAI] Chat completion took 315.8294999599457ms[39m
[1693482767797] [36m[OPENAI] Tokens per second: 3.1662653429360543tps[39m
[1693482767797] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767798] {
  "id": "chatcmpl-7taW74RPT1J4TzYgcI3IB5wI8mNQ0",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693482767798] {
  "role": "assistant",
  "content": "4"
}
[1693482767798] [36m[OPENAI] Chat completion took 316.64950001239777ms[39m
[1693482767798] [36m[OPENAI] Tokens per second: 3.1580659371350563tps[39m
[1693482767798] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767799] {
  "id": "chatcmpl-7taW7IUCqbw9dNlNfTBNf1k0cuDd3",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1693482767799] {
  "role": "assistant",
  "content": "3"
}
[1693482767799] [36m[OPENAI] Chat completion took 307.5900419950485ms[39m
[1693482767799] [36m[OPENAI] Tokens per second: 3.2510805405595598tps[39m
[1693482767799] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767799] {
  "id": "chatcmpl-7taW7NU4dzV7wRYFyJzRPKJNYNHbV",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 114,
    "completion_tokens": 1,
    "total_tokens": 115
  }
}
[1693482767799] {
  "role": "assistant",
  "content": "4"
}
[1693482767799] [36m[OPENAI] Chat completion took 308.21116602420807ms[39m
[1693482767799] [36m[OPENAI] Tokens per second: 3.2445287849222706tps[39m
[1693482767799] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767801] {
  "id": "chatcmpl-7taW7g0KbnvZxfKTHg7pnXDzoz3er",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693482767801] {
  "role": "assistant",
  "content": "6"
}
[1693482767801] [36m[OPENAI] Chat completion took 318.28250002861023ms[39m
[1693482767801] [36m[OPENAI] Tokens per second: 3.1418629673642458tps[39m
[1693482767801] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767801] {
  "id": "chatcmpl-7taW74j7FbQqEGg137Z6bpZBxc5gZ",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "8"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693482767801] {
  "role": "assistant",
  "content": "8"
}
[1693482767801] [36m[OPENAI] Chat completion took 309.5532499551773ms[39m
[1693482767801] [36m[OPENAI] Tokens per second: 3.230461964604791tps[39m
[1693482767801] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767802] {
  "id": "chatcmpl-7taW7NJ32c5n65JBBjB5kYHwCTA9D",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693482767802] {
  "role": "assistant",
  "content": "2"
}
[1693482767802] [36m[OPENAI] Chat completion took 450.40516698360443ms[39m
[1693482767802] [36m[OPENAI] Tokens per second: 2.2202231974758893tps[39m
[1693482767802] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767804] {
  "id": "chatcmpl-7taW7cht7GDq6gg6unw5CH88W9fF1",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "8"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1693482767804] {
  "role": "assistant",
  "content": "8"
}
[1693482767804] [36m[OPENAI] Chat completion took 312.4583330154419ms[39m
[1693482767804] [36m[OPENAI] Tokens per second: 3.2004267268192184tps[39m
[1693482767804] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767805] [32m[OPENAI] Embedding created successfully.[39m
[1693482767808] {
  "id": "chatcmpl-7taW7zttOeGdsa50bJHbZ9Cxq98cs",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693482767808] {
  "role": "assistant",
  "content": "4"
}
[1693482767808] [36m[OPENAI] Chat completion took 326.1550840139389ms[39m
[1693482767808] [36m[OPENAI] Tokens per second: 3.0660260992812334tps[39m
[1693482767808] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767809] {
  "id": "chatcmpl-7taW74BPh0i8gehscNWcgAFmlyov2",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693482767809] {
  "role": "assistant",
  "content": "7"
}
[1693482767809] [36m[OPENAI] Chat completion took 317.1785839796066ms[39m
[1693482767809] [36m[OPENAI] Tokens per second: 3.1527979835621442tps[39m
[1693482767809] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767809] {
  "id": "chatcmpl-7taW7oWA3I0CoNTOOAFhWpexzcuie",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693482767809] {
  "role": "assistant",
  "content": "7"
}
[1693482767809] [36m[OPENAI] Chat completion took 317.2266249656677ms[39m
[1693482767809] [36m[OPENAI] Tokens per second: 3.152320521987164tps[39m
[1693482767809] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767810] {
  "id": "chatcmpl-7taW73N5Lb9Gk0ZZxhDswgQrsEvus",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693482767810] {
  "role": "assistant",
  "content": "2"
}
[1693482767810] [36m[OPENAI] Chat completion took 360.9462500810623ms[39m
[1693482767810] [36m[OPENAI] Tokens per second: 2.7704956064106976tps[39m
[1693482767810] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767811] {
  "id": "chatcmpl-7taW7N2FtHfmUudpg9uB8qwlois6D",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693482767811] {
  "role": "assistant",
  "content": "5"
}
[1693482767811] [36m[OPENAI] Chat completion took 286.2196249961853ms[39m
[1693482767811] [36m[OPENAI] Tokens per second: 3.4938205233597377tps[39m
[1693482767811] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767812] {
  "id": "chatcmpl-7taW7PFYzyXfTIUcYZuzsgxUP3hsM",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693482767812] {
  "role": "assistant",
  "content": "1"
}
[1693482767812] [36m[OPENAI] Chat completion took 329.3907079696655ms[39m
[1693482767812] [36m[OPENAI] Tokens per second: 3.0359083477609596tps[39m
[1693482767812] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767812] {
  "id": "chatcmpl-7taW77NZ6trEENrFciLNPN4qZEWV0",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693482767812] {
  "role": "assistant",
  "content": "5"
}
[1693482767812] [36m[OPENAI] Chat completion took 320.75537502765656ms[39m
[1693482767812] [36m[OPENAI] Tokens per second: 3.1176406628065916tps[39m
[1693482767812] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767816] {
  "id": "chatcmpl-7taW7l4NUgfwwYHgl1CAyhjJrzw20",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693482767816] {
  "role": "assistant",
  "content": "4"
}
[1693482767816] [36m[OPENAI] Chat completion took 333.7592499256134ms[39m
[1693482767816] [36m[OPENAI] Tokens per second: 2.9961716423526092tps[39m
[1693482767816] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767817] {
  "id": "chatcmpl-7taW7K0TDacENYpvv6VEyZ7evVhfN",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 2,
    "total_tokens": 96
  }
}
[1693482767817] {
  "role": "assistant",
  "content": "4."
}
[1693482767817] [36m[OPENAI] Chat completion took 335.56204199790955ms[39m
[1693482767817] [36m[OPENAI] Tokens per second: 5.960149688242925tps[39m
[1693482767817] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767818] {
  "id": "chatcmpl-7taW71ZIGKU3xhiajiykmEf8Fs8Xl",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693482767818] {
  "role": "assistant",
  "content": "5"
}
[1693482767818] [36m[OPENAI] Chat completion took 326.6470000743866ms[39m
[1693482767818] [36m[OPENAI] Tokens per second: 3.0614087984040026tps[39m
[1693482767818] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767819] {
  "id": "chatcmpl-7taW72DVFBFZzGl5PspkShLfagW5v",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693482767819] {
  "role": "assistant",
  "content": "7"
}
[1693482767819] [36m[OPENAI] Chat completion took 294.58525002002716ms[39m
[1693482767819] [36m[OPENAI] Tokens per second: 3.3946030900461435tps[39m
[1693482767819] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767825] {
  "id": "chatcmpl-7taW7XQE7H6VCJiIla2eft9egDsbU",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "8"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693482767825] {
  "role": "assistant",
  "content": "8"
}
[1693482767825] [36m[OPENAI] Chat completion took 333.82304191589355ms[39m
[1693482767825] [36m[OPENAI] Tokens per second: 2.9955990882497234tps[39m
[1693482767825] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767826] {
  "id": "chatcmpl-7taW7R8qKtqumG9LFA2qkyPMXVBBT",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 92,
    "completion_tokens": 1,
    "total_tokens": 93
  }
}
[1693482767826] {
  "role": "assistant",
  "content": "1"
}
[1693482767826] [36m[OPENAI] Chat completion took 344.23945796489716ms[39m
[1693482767826] [36m[OPENAI] Tokens per second: 2.904954608957037tps[39m
[1693482767826] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767827] {
  "id": "chatcmpl-7taW7JDxAGYWNa2QPXFPDgtTi1lT6",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 86,
    "completion_tokens": 1,
    "total_tokens": 87
  }
}
[1693482767827] {
  "role": "assistant",
  "content": "1"
}
[1693482767827] [36m[OPENAI] Chat completion took 345.5703330039978ms[39m
[1693482767827] [36m[OPENAI] Tokens per second: 2.893766925265634tps[39m
[1693482767827] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767832] {
  "id": "chatcmpl-7taW7NzXtsJ9xQpKYcJauqoBNuqWZ",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693482767832] {
  "role": "assistant",
  "content": "2"
}
[1693482767832] [36m[OPENAI] Chat completion took 350.6125409603119ms[39m
[1693482767832] [36m[OPENAI] Tokens per second: 2.852151258654483tps[39m
[1693482767832] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767836] {
  "id": "chatcmpl-7taW70Kg2BPEXfZwH6Bfk0XLPcG41",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 96,
    "completion_tokens": 1,
    "total_tokens": 97
  }
}
[1693482767836] {
  "role": "assistant",
  "content": "2"
}
[1693482767836] [36m[OPENAI] Chat completion took 387.2089170217514ms[39m
[1693482767836] [36m[OPENAI] Tokens per second: 2.582585152458731tps[39m
[1693482767836] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767837] [32m[OPENAI] Embedding created successfully.[39m
[1693482767842] {
  "id": "chatcmpl-7taW79Jqzyc3GNEdE5tXUOqQRRC1f",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693482767842] {
  "role": "assistant",
  "content": "7"
}
[1693482767842] [36m[OPENAI] Chat completion took 318.48366701602936ms[39m
[1693482767842] [36m[OPENAI] Tokens per second: 3.139878441394829tps[39m
[1693482767842] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767842] {
  "id": "chatcmpl-7taW7tPLo9K4YcLm2rhXl9Y1bn1SZ",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693482767842] {
  "role": "assistant",
  "content": "6"
}
[1693482767842] [36m[OPENAI] Chat completion took 318.425125002861ms[39m
[1693482767842] [36m[OPENAI] Tokens per second: 3.1404557036478047tps[39m
[1693482767842] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767852] {
  "id": "chatcmpl-7taW7yQyafZNPveaiQ4Es7dLkYqf9",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6.5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 3,
    "total_tokens": 97
  }
}
[1693482767852] {
  "role": "assistant",
  "content": "6.5"
}
[1693482767852] [36m[OPENAI] Chat completion took 369.24845790863037ms[39m
[1693482767852] [36m[OPENAI] Tokens per second: 8.124610775605033tps[39m
[1693482767852] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767852] {
  "id": "chatcmpl-7taW7BRJIANHEWYyJxwSmdQOytga8",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693482767852] {
  "role": "assistant",
  "content": "1"
}
[1693482767852] [36m[OPENAI] Chat completion took 370.590499997139ms[39m
[1693482767852] [36m[OPENAI] Tokens per second: 2.69839620823448tps[39m
[1693482767852] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767852] {
  "id": "chatcmpl-7taW7Fr3hZ1LW5nLbBHgPiCxhCpLA",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 2,
    "total_tokens": 103
  }
}
[1693482767852] {
  "role": "assistant",
  "content": "7."
}
[1693482767852] [36m[OPENAI] Chat completion took 361.2600419521332ms[39m
[1693482767852] [36m[OPENAI] Tokens per second: 5.536178286401792tps[39m
[1693482767852] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767858] {
  "id": "chatcmpl-7taW7bVSE3LCoHj3rbtOJzBkcbZzf",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 2,
    "total_tokens": 101
  }
}
[1693482767858] {
  "role": "assistant",
  "content": "2."
}
[1693482767858] [36m[OPENAI] Chat completion took 366.76295804977417ms[39m
[1693482767858] [36m[OPENAI] Tokens per second: 5.453113396823939tps[39m
[1693482767858] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767861] {
  "id": "chatcmpl-7taW7myzsxmnnhlu0lN9Qir1TkCFL",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 89,
    "completion_tokens": 1,
    "total_tokens": 90
  }
}
[1693482767861] {
  "role": "assistant",
  "content": "5"
}
[1693482767861] [36m[OPENAI] Chat completion took 379.31066703796387ms[39m
[1693482767861] [36m[OPENAI] Tokens per second: 2.6363613968702695tps[39m
[1693482767861] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767862] {
  "id": "chatcmpl-7taW7eRFZvBZN1KFoNFnn0q8i76LQ",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1693482767862] {
  "role": "assistant",
  "content": "7"
}
[1693482767862] [36m[OPENAI] Chat completion took 337.3454999923706ms[39m
[1693482767862] [36m[OPENAI] Tokens per second: 2.964319962835182tps[39m
[1693482767862] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767868] {
  "id": "chatcmpl-7taW7XIbiD06almkGhFQrpVKk2CeN",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693482767868] {
  "role": "assistant",
  "content": "6"
}
[1693482767868] [36m[OPENAI] Chat completion took 343.6707088947296ms[39m
[1693482767868] [36m[OPENAI] Tokens per second: 2.909762089460792tps[39m
[1693482767868] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767877] {
  "id": "chatcmpl-7taW7K3CKb1Z2pbWzkEnUYlMiEQRC",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693482767877] {
  "role": "assistant",
  "content": "7"
}
[1693482767877] [36m[OPENAI] Chat completion took 395.298082947731ms[39m
[1693482767877] [36m[OPENAI] Tokens per second: 2.5297365283004085tps[39m
[1693482767877] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767884] {
  "id": "chatcmpl-7taW7VBQ50n6qNAcT7mosk6WLhVB4",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1693482767884] {
  "role": "assistant",
  "content": "4"
}
[1693482767884] [36m[OPENAI] Chat completion took 359.81695902347565ms[39m
[1693482767884] [36m[OPENAI] Tokens per second: 2.7791908494639816tps[39m
[1693482767884] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767885] {
  "id": "chatcmpl-7taW7hveDnhPXYLbLPQqYzBJu4ARg",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693482767885] {
  "role": "assistant",
  "content": "5"
}
[1693482767885] [36m[OPENAI] Chat completion took 393.06787490844727ms[39m
[1693482767885] [36m[OPENAI] Tokens per second: 2.544089873111402tps[39m
[1693482767885] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767885] [32m[OPENAI] Embedding created successfully.[39m
[1693482767887] {
  "id": "chatcmpl-7taW7uPYKg2790hxW9toCPpJg4jOk",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693482767887] {
  "role": "assistant",
  "content": "4"
}
[1693482767887] [36m[OPENAI] Chat completion took 438.5055420398712ms[39m
[1693482767887] [36m[OPENAI] Tokens per second: 2.2804728883200176tps[39m
[1693482767887] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767894] [32m[OPENAI] Embedding created successfully.[39m
[1693482767899] {
  "id": "chatcmpl-7taW7eryQEDAz1fjkEEQtawZLVvvc",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693482767899] {
  "role": "assistant",
  "content": "6"
}
[1693482767899] [36m[OPENAI] Chat completion took 374.83083403110504ms[39m
[1693482767899] [36m[OPENAI] Tokens per second: 2.667870167578091tps[39m
[1693482767899] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767900] [32m[OPENAI] Embedding created successfully.[39m
[1693482767900] {
  "id": "chatcmpl-7taW7sXm4LqsWkJ2sbDlgt4KrogLL",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693482767900] {
  "role": "assistant",
  "content": "3"
}
[1693482767900] [36m[OPENAI] Chat completion took 408.80662500858307ms[39m
[1693482767900] [36m[OPENAI] Tokens per second: 2.4461443108437995tps[39m
[1693482767900] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767901] [32m[OPENAI] Embedding created successfully.[39m
[1693482767903] {
  "id": "chatcmpl-7taW7lVeVfUlWNr2wnylq0YrrqD4B",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693482767904] {
  "role": "assistant",
  "content": "5"
}
[1693482767904] [36m[OPENAI] Chat completion took 378.67841696739197ms[39m
[1693482767904] [36m[OPENAI] Tokens per second: 2.640763125631504tps[39m
[1693482767904] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767907] [32m[OPENAI] Embedding created successfully.[39m
[1693482767914] {
  "id": "chatcmpl-7taW7D6V0RH4jXMX54p1qEdB1AV9f",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693482767914] {
  "role": "assistant",
  "content": "5"
}
[1693482767914] [36m[OPENAI] Chat completion took 389.7515000104904ms[39m
[1693482767914] [36m[OPENAI] Tokens per second: 2.565737399273856tps[39m
[1693482767914] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767919] {
  "id": "chatcmpl-7taW7Rvp0NF9OEp8y1i6GPA9OuFLi",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693482767919] {
  "role": "assistant",
  "content": "2"
}
[1693482767919] [36m[OPENAI] Chat completion took 394.7456669807434ms[39m
[1693482767919] [36m[OPENAI] Tokens per second: 2.5332766985097326tps[39m
[1693482767919] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767920] {
  "id": "chatcmpl-7taW79n7oqRaJUHM29o24z4tSyYEK",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482767920] {
  "role": "assistant",
  "content": "6"
}
[1693482767920] [36m[OPENAI] Chat completion took 428.32741594314575ms[39m
[1693482767920] [36m[OPENAI] Tokens per second: 2.3346626033686704tps[39m
[1693482767920] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767923] [32m[OPENAI] Embedding created successfully.[39m
[1693482767926] [32m[OPENAI] Embedding created successfully.[39m
[1693482767933] {
  "id": "chatcmpl-7taW7WbSczHrnqECTaVqprlV2CQ8N",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693482767933] {
  "role": "assistant",
  "content": "5"
}
[1693482767933] [36m[OPENAI] Chat completion took 408.72520792484283ms[39m
[1693482767933] [36m[OPENAI] Tokens per second: 2.4466315769392963tps[39m
[1693482767933] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767973] {
  "id": "chatcmpl-7taW7CvlQeTkpHVSk9pruyIt8vRzv",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693482767974] {
  "role": "assistant",
  "content": "7"
}
[1693482767974] [36m[OPENAI] Chat completion took 482.30741691589355ms[39m
[1693482767974] [36m[OPENAI] Tokens per second: 2.0733664151268556tps[39m
[1693482767974] [32m[OPENAI] Chat completion created successfully.[39m
[1693482767979] {
  "id": "chatcmpl-7taW7mwLz4IKgmVppRwUL5WADK9Lu",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "8."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 2,
    "total_tokens": 106
  }
}
[1693482767979] {
  "role": "assistant",
  "content": "8."
}
[1693482767979] [36m[OPENAI] Chat completion took 454.3943330049515ms[39m
[1693482767979] [36m[OPENAI] Tokens per second: 4.401463343025905tps[39m
[1693482767979] [32m[OPENAI] Chat completion created successfully.[39m
[1693482768006] [32m[OPENAI] Embedding created successfully.[39m
[1693482768013] {
  "id": "chatcmpl-7taW7eztYNdVvqRRcjqo2JndakWRB",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693482768013] {
  "role": "assistant",
  "content": "5"
}
[1693482768013] [36m[OPENAI] Chat completion took 488.8759580850601ms[39m
[1693482768013] [36m[OPENAI] Tokens per second: 2.045508647872614tps[39m
[1693482768013] [32m[OPENAI] Chat completion created successfully.[39m
[1693482768054] {
  "id": "chatcmpl-7taW76Hbik95ZsSgrjVNhToWPmFUH",
  "object": "chat.completion",
  "created": 1693482767,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693482768055] {
  "role": "assistant",
  "content": "4"
}
[1693482768055] [36m[OPENAI] Chat completion took 529.6480840444565ms[39m
[1693482768055] [36m[OPENAI] Tokens per second: 1.8880461010335006tps[39m
[1693482768055] [32m[OPENAI] Chat completion created successfully.[39m
[1693482768292] [32m[OPENAI] Embedding created successfully.[39m
[1693482768308] [32m[OPENAI] Embedding created successfully.[39m
[1693482768312] [32m[OPENAI] Embedding created successfully.[39m
[1693482768324] [32m[OPENAI] Embedding created successfully.[39m
[1693482768348] [32m[OPENAI] Embedding created successfully.[39m
[1693482768357] [32m[OPENAI] Embedding created successfully.[39m
[1693482768361] [32m[OPENAI] Embedding created successfully.[39m
[1693482768367] [32m[OPENAI] Embedding created successfully.[39m
[1693482773998] [32m[OPENAI] Embedding created successfully.[39m
[1693482846353] [Main] WebSocket connection established
[1693482847178] [Character] Getting character: A5
[1693482847194] --- Observations received -- 
[1693482847194] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Small) at X: 41.33658, Y: 13.99647.",
  "time": 0.0199999921
}
[1693482847194] [Character] Getting character: A5
[1693482847196] --- Observations received -- 
[1693482847197] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 42.12, Y: 5.77.",
  "time": 0.0199999921
}
[1693482847197] [Character] Getting character: A5
[1693482847201] [Character] Getting character: A2
[1693482847201] --- Observations received -- 
[1693482847201] {
  "observerId": "A2",
  "observation": "George Brown sees Copper Ore Deposit (Small) at X: 50.43, Y: 20.71.",
  "time": 0.0199999921
}
[1693482847201] [Character] Getting character: A2
[1693482847201] --- Observations received -- 
[1693482847201] {
  "observerId": "A2",
  "observation": "George Brown sees Copper Ore Deposit (Medium) at X: 53.76, Y: 21.7.",
  "time": 0.0199999921
}
[1693482847201] [Character] Getting character: A2
[1693482847201] --- Observations received -- 
[1693482847201] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Medium) at X: 57.27, Y: 17.32.",
  "time": 0.0199999921
}
[1693482847201] [Character] Getting character: A2
[1693482847201] --- Observations received -- 
[1693482847201] {
  "observerId": "A2",
  "observation": "George Brown sees Stone Ore Deposit (Small) at X: 47.58, Y: 19.17.",
  "time": 0.0199999921
}
[1693482847201] [Character] Getting character: A2
[1693482847201] --- Observations received -- 
[1693482847201] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Small) at X: 54.64, Y: 16.97.",
  "time": 0.0199999921
}
[1693482847201] [Character] Getting character: A2
[1693482847201] --- Observations received -- 
[1693482847201] {
  "observerId": "A2",
  "observation": "George Brown sees Chest at X: 50.52, Y: 14.5.",
  "time": 0.0199999921
}
[1693482847201] [Character] Getting character: A2
[1693482847202] --- Observations received -- 
[1693482847202] {
  "observerId": "A2",
  "observation": "George Brown sees Copper Ore Deposit (Small) at X: 53.88, Y: 19.83.",
  "time": 0.0199999921
}
[1693482847202] [Character] Getting character: A2
[1693482847202] --- Observations received -- 
[1693482847202] {
  "observerId": "A2",
  "observation": "George Brown sees Thomas Smith at X: 48.72, Y: 13.43.",
  "time": 0.0199999921
}
[1693482847202] [Character] Getting character: A2
[1693482847202] --- Observations received -- 
[1693482847202] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Small) at X: 56.74, Y: 14.81.",
  "time": 0.0199999921
}
[1693482847202] [Character] Getting character: A2
[1693482847202] [Character] Getting character: A4
[1693482847202] --- Observations received -- 
[1693482847202] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Coal Ore Deposit (Small) at X: 59.32, Y: 14.11.",
  "time": 0.0199999921
}
[1693482847202] [Character] Getting character: A4
[1693482847202] --- Observations received -- 
[1693482847202] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Tree at X: 55.4, Y: 4.5.",
  "time": 0.0199999921
}
[1693482847202] [Character] Getting character: A4
[1693482847203] --- Observations received -- 
[1693482847203] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Tree at X: 53.51, Y: 5.059999.",
  "time": 0.0199999921
}
[1693482847203] [Character] Getting character: A4
[1693482847203] --- Observations received -- 
[1693482847203] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Tree at X: 56.01, Y: 6.46.",
  "time": 0.0199999921
}
[1693482847203] [Character] Getting character: A4
[1693482847203] --- Observations received -- 
[1693482847203] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Tree at X: 52.41, Y: 11.03.",
  "time": 0.0199999921
}
[1693482847203] [Character] Getting character: A4
[1693482847203] --- Observations received -- 
[1693482847203] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Tree at X: 50.77, Y: 9.22.",
  "time": 0.0199999921
}
[1693482847203] [Character] Getting character: A4
[1693482847204] --- Observations received -- 
[1693482847204] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Tree at X: 53.93, Y: 9.11.",
  "time": 0.0199999921
}
[1693482847204] [Character] Getting character: A4
[1693482847204] --- Observations received -- 
[1693482847204] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Coal Ore Deposit (Small) at X: 56.74, Y: 14.81.",
  "time": 0.0199999921
}
[1693482847204] [Character] Getting character: A4
[1693482847204] --- Observations received -- 
[1693482847204] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Tree at X: 57.55001, Y: 10.45.",
  "time": 0.0199999921
}
[1693482847204] [Character] Getting character: A4
[1693482847204] --- Observations received -- 
[1693482847204] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Tree at X: 61.49, Y: 9.35.",
  "time": 0.0199999921
}
[1693482847204] [Character] Getting character: A4
[1693482847204] --- Observations received -- 
[1693482847204] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Tree at X: 58.16, Y: 5.91.",
  "time": 0.0199999921
}
[1693482847204] [Character] Getting character: A4
[1693482847207] [Character] Getting character: A3
[1693482847207] --- Observations received -- 
[1693482847207] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 38.75, Y: -9.01.",
  "time": 0.0199999921
}
[1693482847207] [Character] Getting character: A3
[1693482847208] --- Observations received -- 
[1693482847208] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 41.03, Y: -11.7.",
  "time": 0.0199999921
}
[1693482847208] [Character] Getting character: A3
[1693482847208] --- Observations received -- 
[1693482847208] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 42.72, Y: -12.97.",
  "time": 0.0199999921
}
[1693482847208] [Character] Getting character: A3
[1693482847279] [33m[OPENAI] Creating embedding...[39m
[1693482847282] [33m[OPENAI] Creating embedding...[39m
[1693482847300] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847300] [33m[OPENAI] Creating embedding...[39m
[1693482847301] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847301] [33m[OPENAI] Creating embedding...[39m
[1693482847301] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847301] [33m[OPENAI] Creating embedding...[39m
[1693482847301] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847301] [33m[OPENAI] Creating embedding...[39m
[1693482847303] [33m[OPENAI] Creating embedding...[39m
[1693482847304] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847304] [33m[OPENAI] Creating embedding...[39m
[1693482847305] [33m[OPENAI] Creating embedding...[39m
[1693482847312] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847312] [33m[OPENAI] Creating embedding...[39m
[1693482847315] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847315] [33m[OPENAI] Creating embedding...[39m
[1693482847323] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847323] [33m[OPENAI] Creating embedding...[39m
[1693482847328] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847328] [33m[OPENAI] Creating embedding...[39m
[1693482847337] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847337] [33m[OPENAI] Creating embedding...[39m
[1693482847337] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847337] [33m[OPENAI] Creating embedding...[39m
[1693482847338] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847338] [33m[OPENAI] Creating embedding...[39m
[1693482847338] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847338] [33m[OPENAI] Creating embedding...[39m
[1693482847338] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847338] [33m[OPENAI] Creating embedding...[39m
[1693482847338] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847338] [33m[OPENAI] Creating embedding...[39m
[1693482847338] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847338] [33m[OPENAI] Creating embedding...[39m
[1693482847338] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847338] [33m[OPENAI] Creating embedding...[39m
[1693482847338] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847339] [33m[OPENAI] Creating embedding...[39m
[1693482847339] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847339] [33m[OPENAI] Creating embedding...[39m
[1693482847339] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847339] [33m[OPENAI] Creating embedding...[39m
[1693482847343] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847343] [33m[OPENAI] Creating embedding...[39m
[1693482847367] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847367] [33m[OPENAI] Creating embedding...[39m
[1693482847368] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847368] [33m[OPENAI] Creating embedding...[39m
[1693482847373] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847373] [33m[OPENAI] Creating embedding...[39m
[1693482847373] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482847373] [33m[OPENAI] Creating embedding...[39m
[1693482847479] [32m[OPENAI] Embedding created successfully.[39m
[1693482847480] [32m[OPENAI] Embedding created successfully.[39m
[1693482847496] [32m[OPENAI] Embedding created successfully.[39m
[1693482847509] [32m[OPENAI] Embedding created successfully.[39m
[1693482847512] [32m[OPENAI] Embedding created successfully.[39m
[1693482847520] [32m[OPENAI] Embedding created successfully.[39m
[1693482847522] [32m[OPENAI] Embedding created successfully.[39m
[1693482847545] [32m[OPENAI] Embedding created successfully.[39m
[1693482847545] [32m[OPENAI] Embedding created successfully.[39m
[1693482847545] [32m[OPENAI] Embedding created successfully.[39m
[1693482847545] [32m[OPENAI] Embedding created successfully.[39m
[1693482847554] [32m[OPENAI] Embedding created successfully.[39m
[1693482847554] [32m[OPENAI] Embedding created successfully.[39m
[1693482847555] [32m[OPENAI] Embedding created successfully.[39m
[1693482847563] [32m[OPENAI] Embedding created successfully.[39m
[1693482847572] [32m[OPENAI] Embedding created successfully.[39m
[1693482847572] [32m[OPENAI] Embedding created successfully.[39m
[1693482847574] [32m[OPENAI] Embedding created successfully.[39m
[1693482847578] [32m[OPENAI] Embedding created successfully.[39m
[1693482847583] [32m[OPENAI] Embedding created successfully.[39m
[1693482847584] [32m[OPENAI] Embedding created successfully.[39m
[1693482847597] {
  "id": "chatcmpl-7taXPTcDxs5tWlTDKu8KnvbQnK73F",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482847598] {
  "role": "assistant",
  "content": "2"
}
[1693482847598] [36m[OPENAI] Chat completion took 293.61391603946686ms[39m
[1693482847598] [36m[OPENAI] Tokens per second: 3.4058331208851236tps[39m
[1693482847598] [32m[OPENAI] Chat completion created successfully.[39m
[1693482847598] {
  "id": "chatcmpl-7taXPLN4HK36jytPxbCbUswyBme8U",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482847598] {
  "role": "assistant",
  "content": "4"
}
[1693482847598] [36m[OPENAI] Chat completion took 283.1753749847412ms[39m
[1693482847598] [36m[OPENAI] Tokens per second: 3.5313805095301265tps[39m
[1693482847598] [32m[OPENAI] Chat completion created successfully.[39m
[1693482847600] {
  "id": "chatcmpl-7taXPtKu8tRNhvDaMCh2e0hhv5fyb",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482847600] {
  "role": "assistant",
  "content": "3"
}
[1693482847600] [36m[OPENAI] Chat completion took 276.7323750257492ms[39m
[1693482847600] [36m[OPENAI] Tokens per second: 3.6135996010837284tps[39m
[1693482847600] [32m[OPENAI] Chat completion created successfully.[39m
[1693482847605] {
  "id": "chatcmpl-7taXP40ZWEMSSb2eQvAbNwcugttjv",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482847605] {
  "role": "assistant",
  "content": "2"
}
[1693482847605] [36m[OPENAI] Chat completion took 266.3764170408249ms[39m
[1693482847605] [36m[OPENAI] Tokens per second: 3.7540860828034184tps[39m
[1693482847605] [32m[OPENAI] Chat completion created successfully.[39m
[1693482847605] [32m[OPENAI] Embedding created successfully.[39m
[1693482847605] {
  "id": "chatcmpl-7taXPnO0Ncrr48Tl63oGvJqI8P3vg",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482847605] {
  "role": "assistant",
  "content": "1"
}
[1693482847605] [36m[OPENAI] Chat completion took 304.3672090768814ms[39m
[1693482847605] [36m[OPENAI] Tokens per second: 3.2855050418634475tps[39m
[1693482847605] [32m[OPENAI] Chat completion created successfully.[39m
[1693482847614] {
  "id": "chatcmpl-7taXPrYmISNHV98qQ9ZAsvGVcFTS8",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482847615] {
  "role": "assistant",
  "content": "3"
}
[1693482847615] [36m[OPENAI] Chat completion took 276.42150008678436ms[39m
[1693482847615] [36m[OPENAI] Tokens per second: 3.6176636031786362tps[39m
[1693482847615] [32m[OPENAI] Chat completion created successfully.[39m
[1693482847616] [32m[OPENAI] Embedding created successfully.[39m
[1693482847616] {
  "id": "chatcmpl-7taXPsebZc01JHkf53fO5LTg0lt9H",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482847616] {
  "role": "assistant",
  "content": "2"
}
[1693482847616] [36m[OPENAI] Chat completion took 287.35891592502594ms[39m
[1693482847616] [36m[OPENAI] Tokens per second: 3.4799685848651634tps[39m
[1693482847616] [32m[OPENAI] Chat completion created successfully.[39m
[1693482847618] {
  "id": "chatcmpl-7taXPiSl4Xoge1Fv2Dn7n0GARjhta",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482847618] {
  "role": "assistant",
  "content": "3"
}
[1693482847618] [36m[OPENAI] Chat completion took 316.2800419330597ms[39m
[1693482847618] [36m[OPENAI] Tokens per second: 3.161754987409698tps[39m
[1693482847618] [32m[OPENAI] Chat completion created successfully.[39m
[1693482847619] [32m[OPENAI] Embedding created successfully.[39m
[1693482847634] {
  "id": "chatcmpl-7taXPYBuoV270wWL21mOgNNG4u0wq",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482847634] {
  "role": "assistant",
  "content": "1"
}
[1693482847634] [36m[OPENAI] Chat completion took 295.2645000219345ms[39m
[1693482847634] [36m[OPENAI] Tokens per second: 3.3867938743930015tps[39m
[1693482847634] [32m[OPENAI] Chat completion created successfully.[39m
[1693482847641] {
  "id": "chatcmpl-7taXPHQ0aCHZXq6JDJKAlLsGym5Tm",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693482847641] {
  "role": "assistant",
  "content": "1"
}
[1693482847641] [36m[OPENAI] Chat completion took 302.32137501239777ms[39m
[1693482847641] [36m[OPENAI] Tokens per second: 3.307738329646693tps[39m
[1693482847641] [32m[OPENAI] Chat completion created successfully.[39m
[1693482847644] {
  "id": "chatcmpl-7taXPDeGDsV8u8HeTPMwIuCi4Um2w",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482847645] {
  "role": "assistant",
  "content": "2"
}
[1693482847645] [36m[OPENAI] Chat completion took 344.46975004673004ms[39m
[1693482847645] [36m[OPENAI] Tokens per second: 2.9030125282825043tps[39m
[1693482847645] [32m[OPENAI] Chat completion created successfully.[39m
[1693482847647] {
  "id": "chatcmpl-7taXPfGG6jlhc7H7qEaSnlACtUpkZ",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482847647] {
  "role": "assistant",
  "content": "4"
}
[1693482847647] [36m[OPENAI] Chat completion took 303.13383400440216ms[39m
[1693482847647] [36m[OPENAI] Tokens per second: 3.2988729327570803tps[39m
[1693482847647] [32m[OPENAI] Chat completion created successfully.[39m
[1693482847658] [32m[OPENAI] Embedding created successfully.[39m
[1693482847659] {
  "id": "chatcmpl-7taXPODTiGmKybKFaxrWieVmQHR97",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482847659] {
  "role": "assistant",
  "content": "2"
}
[1693482847659] [36m[OPENAI] Chat completion took 320.1134999990463ms[39m
[1693482847659] [36m[OPENAI] Tokens per second: 3.123891994567487tps[39m
[1693482847659] [32m[OPENAI] Chat completion created successfully.[39m
[1693482847660] {
  "id": "chatcmpl-7taXPNymppRHayalW1I5K4z9MFeKM",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482847660] {
  "role": "assistant",
  "content": "3"
}
[1693482847660] [36m[OPENAI] Chat completion took 322.49150002002716ms[39m
[1693482847660] [36m[OPENAI] Tokens per second: 3.1008569216177753tps[39m
[1693482847660] [32m[OPENAI] Chat completion created successfully.[39m
[1693482847662] {
  "id": "chatcmpl-7taXPcdcdDpJzSR0BQg5tpOUhMnyy",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482847662] {
  "role": "assistant",
  "content": "3"
}
[1693482847662] [36m[OPENAI] Chat completion took 350.2158749103546ms[39m
[1693482847663] [36m[OPENAI] Tokens per second: 2.8553816992332854tps[39m
[1693482847663] [32m[OPENAI] Chat completion created successfully.[39m
[1693482847664] [32m[OPENAI] Embedding created successfully.[39m
[1693482847665] [32m[OPENAI] Embedding created successfully.[39m
[1693482847666] [32m[OPENAI] Embedding created successfully.[39m
[1693482847667] {
  "id": "chatcmpl-7taXPfmAVB9300OeiushYUdMRpY2R",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482847667] {
  "role": "assistant",
  "content": "1"
}
[1693482847667] [36m[OPENAI] Chat completion took 329.005292057991ms[39m
[1693482847667] [36m[OPENAI] Tokens per second: 3.039464787161352tps[39m
[1693482847667] [32m[OPENAI] Chat completion created successfully.[39m
[1693482847669] [32m[OPENAI] Embedding created successfully.[39m
[1693482847693] {
  "id": "chatcmpl-7taXPmESJAWVBTfhoMGVrtcGJLjKs",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482847693] {
  "role": "assistant",
  "content": "2"
}
[1693482847693] [36m[OPENAI] Chat completion took 355.05083298683167ms[39m
[1693482847693] [36m[OPENAI] Tokens per second: 2.8164981098272444tps[39m
[1693482847693] [32m[OPENAI] Chat completion created successfully.[39m
[1693482847695] {
  "id": "chatcmpl-7taXPbBqUjMDGU7LWA9orrawvXLqu",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2.5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 3,
    "total_tokens": 104
  }
}
[1693482847695] {
  "role": "assistant",
  "content": "2.5"
}
[1693482847695] [36m[OPENAI] Chat completion took 327.4814590215683ms[39m
[1693482847695] [36m[OPENAI] Tokens per second: 9.160823971418843tps[39m
[1693482847695] [32m[OPENAI] Chat completion created successfully.[39m
[1693482847699] {
  "id": "chatcmpl-7taXPP02rqkXRrVv9skiFEUu4m4bT",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482847699] {
  "role": "assistant",
  "content": "2"
}
[1693482847699] [36m[OPENAI] Chat completion took 325.4870409965515ms[39m
[1693482847699] [36m[OPENAI] Tokens per second: 3.072318937608932tps[39m
[1693482847699] [32m[OPENAI] Chat completion created successfully.[39m
[1693482847701] {
  "id": "chatcmpl-7taXPBiSJ9iYWMAcWJpH67RJA2Iop",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 2,
    "total_tokens": 103
  }
}
[1693482847701] {
  "role": "assistant",
  "content": "3."
}
[1693482847701] [36m[OPENAI] Chat completion took 328.26166594028473ms[39m
[1693482847701] [36m[OPENAI] Tokens per second: 6.092700450633268tps[39m
[1693482847701] [32m[OPENAI] Chat completion created successfully.[39m
[1693482847720] {
  "id": "chatcmpl-7taXPzdGBVZy7q7rBXiulkHfuANyl",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693482847720] {
  "role": "assistant",
  "content": "3"
}
[1693482847720] [36m[OPENAI] Chat completion took 382.93279099464417ms[39m
[1693482847720] [36m[OPENAI] Tokens per second: 2.6114243113068536tps[39m
[1693482847720] [32m[OPENAI] Chat completion created successfully.[39m
[1693482847757] {
  "id": "chatcmpl-7taXPuCy6uU6RcSPzC6dXim5bIaPz",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482847757] {
  "role": "assistant",
  "content": "3"
}
[1693482847757] [36m[OPENAI] Chat completion took 418.96170806884766ms[39m
[1693482847757] [36m[OPENAI] Tokens per second: 2.3868529766344917tps[39m
[1693482847757] [32m[OPENAI] Chat completion created successfully.[39m
[1693482847760] {
  "id": "chatcmpl-7taXPo2bbqH8p4N5Jshaqt3SCjBmu",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482847760] {
  "role": "assistant",
  "content": "1"
}
[1693482847760] [36m[OPENAI] Chat completion took 421.737625002861ms[39m
[1693482847760] [36m[OPENAI] Tokens per second: 2.37114248460335tps[39m
[1693482847760] [32m[OPENAI] Chat completion created successfully.[39m
[1693482847866] {
  "id": "chatcmpl-7taXP63Nr0fIyFkowucUyQkBYywwo",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 2,
    "total_tokens": 104
  }
}
[1693482847866] {
  "role": "assistant",
  "content": "1."
}
[1693482847866] [36m[OPENAI] Chat completion took 498.9369169473648ms[39m
[1693482847867] [36m[OPENAI] Tokens per second: 4.008522785278263tps[39m
[1693482847867] [32m[OPENAI] Chat completion created successfully.[39m
[1693482847882] {
  "id": "chatcmpl-7taXPwS6AqRMyinQA89jDndXtVMpr",
  "object": "chat.completion",
  "created": 1693482847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 2,
    "total_tokens": 104
  }
}
[1693482847882] {
  "role": "assistant",
  "content": "5."
}
[1693482847882] [36m[OPENAI] Chat completion took 580.9072089195251ms[39m
[1693482847882] [36m[OPENAI] Tokens per second: 3.442890653259333tps[39m
[1693482847882] [32m[OPENAI] Chat completion created successfully.[39m
[1693482848122] [33m[OPENAI] Creating embedding...[39m
[1693482848278] [33m[OPENAI] Creating embedding...[39m
[1693482848296] [32m[OPENAI] Embedding created successfully.[39m
[1693482848441] [33m[OPENAI] Creating embedding...[39m
[1693482848504] [32m[OPENAI] Embedding created successfully.[39m
[1693482848521] [33m[OPENAI] Creating embedding...[39m
[1693482848609] [32m[OPENAI] Embedding created successfully.[39m
[1693482848713] [32m[OPENAI] Embedding created successfully.[39m
[1693482848846] [33m[OPENAI] Creating embedding...[39m
[1693482848952] [33m[OPENAI] Creating embedding...[39m
[1693482849043] [32m[OPENAI] Embedding created successfully.[39m
[1693482849050] [33m[OPENAI] Creating embedding...[39m
[1693482849117] [32m[OPENAI] Embedding created successfully.[39m
[1693482849130] [33m[OPENAI] Creating embedding...[39m
[1693482849284] [32m[OPENAI] Embedding created successfully.[39m
[1693482849325] [32m[OPENAI] Embedding created successfully.[39m
[1693482849414] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482849487] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482849685] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482849780] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482863523] {
  "id": "chatcmpl-7taXRId7BQdbUEDe1HpGmYkkNBy9A",
  "object": "chat.completion",
  "created": 1693482849,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "[\n  {\n    \"task\": \"Eat some food\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Carry out your daily duties\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Find more food\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Maintain a healthy lifestyle\",\n    \"priority\": 4\n  },\n  {\n    \"task\": \"Catch up with other villagers\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Prepare for the night\",\n    \"priority\": 6\n  },\n  {\n    \"task\": \"Rest before a new day of work\",\n    \"priority\": 7\n  }\n]"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 1611,
    "completion_tokens": 154,
    "total_tokens": 1765
  }
}
[1693482863524] {
  "role": "assistant",
  "content": "[\n  {\n    \"task\": \"Eat some food\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Carry out your daily duties\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Find more food\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Maintain a healthy lifestyle\",\n    \"priority\": 4\n  },\n  {\n    \"task\": \"Catch up with other villagers\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Prepare for the night\",\n    \"priority\": 6\n  },\n  {\n    \"task\": \"Rest before a new day of work\",\n    \"priority\": 7\n  }\n]"
}
[1693482863524] [36m[OPENAI] Chat completion took 13837.46774995327ms[39m
[1693482863524] [36m[OPENAI] Tokens per second: 11.129203896465816tps[39m
[1693482863524] [32m[OPENAI] Chat completion created successfully.[39m
[1693482863524] [Character] Getting character: A4
[1693482863621] [33m[OPENAI] Creating embedding...[39m
[1693482863689] {
  "id": "chatcmpl-7taXRVY9JDUZtZ0dCFCfuXnQFfkid",
  "object": "chat.completion",
  "created": 1693482849,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "[\n  {\n    \"task\": \"Eat some food\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Carry out your daily duties\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Maintain a healthy lifestyle\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Cut down a tree\",\n    \"priority\": 4\n  },\n  {\n    \"task\": \"Catch up with other villagers\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Prepare to gather wood next day\",\n    \"priority\": 6\n  },\n  {\n    \"task\": \"Find more food\",\n    \"priority\": 7\n  }\n]"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 1211,
    "completion_tokens": 153,
    "total_tokens": 1364
  }
}
[1693482863689] {
  "role": "assistant",
  "content": "[\n  {\n    \"task\": \"Eat some food\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Carry out your daily duties\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Maintain a healthy lifestyle\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Cut down a tree\",\n    \"priority\": 4\n  },\n  {\n    \"task\": \"Catch up with other villagers\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Prepare to gather wood next day\",\n    \"priority\": 6\n  },\n  {\n    \"task\": \"Find more food\",\n    \"priority\": 7\n  }\n]"
}
[1693482863689] [36m[OPENAI] Chat completion took 13907.924749970436ms[39m
[1693482863689] [36m[OPENAI] Tokens per second: 11.000922333889191tps[39m
[1693482863689] [32m[OPENAI] Chat completion created successfully.[39m
[1693482863689] [Character] Getting character: A3
[1693482863722] [33m[OPENAI] Creating embedding...[39m
[1693482863801] [32m[OPENAI] Embedding created successfully.[39m
[1693482863897] [32m[OPENAI] Embedding created successfully.[39m
[1693482864305] [33m[OPENAI] Creating embedding...[39m
[1693482864377] [33m[OPENAI] Creating embedding...[39m
[1693482864447] [32m[OPENAI] Embedding created successfully.[39m
[1693482864614] [32m[OPENAI] Embedding created successfully.[39m
[1693482864899] [33m[OPENAI] Creating embedding...[39m
[1693482864972] [33m[OPENAI] Creating embedding...[39m
[1693482865161] [32m[OPENAI] Embedding created successfully.[39m
[1693482865204] [32m[OPENAI] Embedding created successfully.[39m
[1693482865387] {
  "id": "chatcmpl-7taXR8ijmhkIso5cEMC8lnQIB4Jk6",
  "object": "chat.completion",
  "created": 1693482849,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "[\n  {\n    \"task\": \"Eat berries\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Collect items from environment\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Explore stone ore deposits\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Chat with other villagers\",\n    \"priority\": 4\n  },\n  {\n    \"task\": \"Maintain a healthy lifestyle\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Begin daily duties in the forest (eg. guided by George's tales or Lucy's tips)\",\n    \"priority\": 6\n  },\n  {\n    \"task\": \"Visit personal hideout\",\n    \"priority\": 7\n  },\n  {\n    \"task\": \"Return home before sunset, guided by stars if necessary\",\n    \"priority\": 8\n  }\n]"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 968,
    "completion_tokens": 189,
    "total_tokens": 1157
  }
}
[1693482865387] {
  "role": "assistant",
  "content": "[\n  {\n    \"task\": \"Eat berries\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Collect items from environment\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Explore stone ore deposits\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Chat with other villagers\",\n    \"priority\": 4\n  },\n  {\n    \"task\": \"Maintain a healthy lifestyle\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Begin daily duties in the forest (eg. guided by George's tales or Lucy's tips)\",\n    \"priority\": 6\n  },\n  {\n    \"task\": \"Visit personal hideout\",\n    \"priority\": 7\n  },\n  {\n    \"task\": \"Return home before sunset, guided by stars if necessary\",\n    \"priority\": 8\n  }\n]"
}
[1693482865387] [36m[OPENAI] Chat completion took 15972.663707971573ms[39m
[1693482865388] [36m[OPENAI] Tokens per second: 11.832716411957927tps[39m
[1693482865388] [32m[OPENAI] Chat completion created successfully.[39m
[1693482865388] [Character] Getting character: A5
[1693482865441] [33m[OPENAI] Creating embedding...[39m
[1693482865515] [33m[OPENAI] Creating embedding...[39m
[1693482865579] [33m[OPENAI] Creating embedding...[39m
[1693482865598] [32m[OPENAI] Embedding created successfully.[39m
[1693482865768] [32m[OPENAI] Embedding created successfully.[39m
[1693482865832] [32m[OPENAI] Embedding created successfully.[39m
[1693482865926] [33m[OPENAI] Creating embedding...[39m
[1693482866163] [33m[OPENAI] Creating embedding...[39m
[1693482866166] [33m[OPENAI] Creating embedding...[39m
[1693482866251] [32m[OPENAI] Embedding created successfully.[39m
[1693482866419] [32m[OPENAI] Embedding created successfully.[39m
[1693482866565] [32m[OPENAI] Embedding created successfully.[39m
[1693482866599] [33m[OPENAI] Creating embedding...[39m
[1693482866730] [33m[OPENAI] Creating embedding...[39m
[1693482866821] [32m[OPENAI] Embedding created successfully.[39m
[1693482866837] [33m[OPENAI] Creating embedding...[39m
[1693482866875] [32m[OPENAI] Embedding created successfully.[39m
[1693482867043] [32m[OPENAI] Embedding created successfully.[39m
[1693482867219] [33m[OPENAI] Creating embedding...[39m
[1693482867232] [33m[OPENAI] Creating embedding...[39m
[1693482867364] [33m[OPENAI] Creating embedding...[39m
[1693482867365] [32m[OPENAI] Embedding created successfully.[39m
[1693482867580] [32m[OPENAI] Embedding created successfully.[39m
[1693482867628] [33m[OPENAI] Creating embedding...[39m
[1693482867642] [32m[OPENAI] Embedding created successfully.[39m
[1693482867774] [32m[OPENAI] Embedding created successfully.[39m
[1693482867863] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482868001] [33m[OPENAI] Creating embedding...[39m
[1693482868028] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482868212] [32m[OPENAI] Embedding created successfully.[39m
[1693482868550] [33m[OPENAI] Creating embedding...[39m
[1693482868695] [32m[OPENAI] Embedding created successfully.[39m
[1693482868998] [33m[OPENAI] Creating embedding...[39m
[1693482869145] [32m[OPENAI] Embedding created successfully.[39m
[1693482869428] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482870564] {
  "id": "chatcmpl-7taXj6JrEXs3X8xtFc2IBV4ATTXOh",
  "object": "chat.completion",
  "created": 1693482867,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "eat",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"foodId\": \"berries\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2061,
    "completion_tokens": 25,
    "total_tokens": 2086
  }
}
[1693482870564] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "eat",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"foodId\": \"berries\"\n}"
  }
}
[1693482870564] [36m[OPENAI] Chat completion took 2699.9384999275208ms[39m
[1693482870564] [36m[OPENAI] Tokens per second: 9.259470169661688tps[39m
[1693482870564] [32m[OPENAI] Chat completion created successfully.[39m
[1693482870635] [Character] Getting character: A4
[1693482870687] {
  "id": "chatcmpl-7taXkze0j25z1KC37EqSGqbRVuEwj",
  "object": "chat.completion",
  "created": 1693482868,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "eat",
          "arguments": "{\n  \"characterId\": \"A3\",\n  \"foodId\": \"berries\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1555,
    "completion_tokens": 25,
    "total_tokens": 1580
  }
}
[1693482870688] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "eat",
    "arguments": "{\n  \"characterId\": \"A3\",\n  \"foodId\": \"berries\"\n}"
  }
}
[1693482870688] [36m[OPENAI] Chat completion took 2658.804666996002ms[39m
[1693482870688] [36m[OPENAI] Tokens per second: 9.402721572715514tps[39m
[1693482870688] [32m[OPENAI] Chat completion created successfully.[39m
[1693482870708] [33m[OPENAI] Creating embedding...[39m
[1693482870712] [Character] Getting character: A3
[1693482870756] [33m[OPENAI] Creating embedding...[39m
[1693482870881] [32m[OPENAI] Embedding created successfully.[39m
[1693482871045] [32m[OPENAI] Embedding created successfully.[39m
[1693482871334] [33m[OPENAI] Creating embedding...[39m
[1693482871422] [33m[OPENAI] Creating embedding...[39m
[1693482871588] [32m[OPENAI] Embedding created successfully.[39m
[1693482871618] [32m[OPENAI] Embedding created successfully.[39m
[1693482871961] [33m[OPENAI] Creating embedding...[39m
[1693482872029] [33m[OPENAI] Creating embedding...[39m
[1693482872104] [32m[OPENAI] Embedding created successfully.[39m
[1693482872230] {
  "id": "chatcmpl-7taXlR8mF1gQtAXZtkRs24S8utoc3",
  "object": "chat.completion",
  "created": 1693482869,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "eat",
          "arguments": "{\n  \"characterId\": \"A5\",\n  \"foodId\": \"berries\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1376,
    "completion_tokens": 25,
    "total_tokens": 1401
  }
}
[1693482872231] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "eat",
    "arguments": "{\n  \"characterId\": \"A5\",\n  \"foodId\": \"berries\"\n}"
  }
}
[1693482872231] [36m[OPENAI] Chat completion took 2801.463874936104ms[39m
[1693482872231] [36m[OPENAI] Tokens per second: 8.923905899222136tps[39m
[1693482872231] [32m[OPENAI] Chat completion created successfully.[39m
[1693482872258] [Character] Getting character: A5
[1693482872259] [32m[OPENAI] Embedding created successfully.[39m
[1693482872293] [33m[OPENAI] Creating embedding...[39m
[1693482872458] [33m[OPENAI] Creating embedding...[39m
[1693482872645] [32m[OPENAI] Embedding created successfully.[39m
[1693482872648] [33m[OPENAI] Creating embedding...[39m
[1693482872961] [33m[OPENAI] Creating embedding...[39m
[1693482873145] [32m[OPENAI] Embedding created successfully.[39m
[1693482873192] [32m[OPENAI] Embedding created successfully.[39m
[1693482873202] [32m[OPENAI] Embedding created successfully.[39m
[1693482873511] [33m[OPENAI] Creating embedding...[39m
[1693482873539] [33m[OPENAI] Creating embedding...[39m
[1693482873550] [33m[OPENAI] Creating embedding...[39m
[1693482873686] [32m[OPENAI] Embedding created successfully.[39m
[1693482873710] [32m[OPENAI] Embedding created successfully.[39m
[1693482873798] [32m[OPENAI] Embedding created successfully.[39m
[1693482874036] [33m[OPENAI] Creating embedding...[39m
[1693482874043] [33m[OPENAI] Creating embedding...[39m
[1693482874178] [33m[OPENAI] Creating embedding...[39m
[1693482874268] [32m[OPENAI] Embedding created successfully.[39m
[1693482874331] [32m[OPENAI] Embedding created successfully.[39m
[1693482874348] [32m[OPENAI] Embedding created successfully.[39m
[1693482874624] [33m[OPENAI] Creating embedding...[39m
[1693482874665] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482874712] [33m[OPENAI] Creating embedding...[39m
[1693482874755] [32m[OPENAI] Embedding created successfully.[39m
[1693482874898] [32m[OPENAI] Embedding created successfully.[39m
[1693482875130] [33m[OPENAI] Creating embedding...[39m
[1693482875265] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482875397] [32m[OPENAI] Embedding created successfully.[39m
[1693482875734] [33m[OPENAI] Creating embedding...[39m
[1693482875900] {
  "id": "chatcmpl-7taXRfZRmCG1r3IAbMGMjOOTmOxrO",
  "object": "chat.completion",
  "created": 1693482849,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "[\n  {\n    \"task\": \"Eat the berries to satisfy hunger\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Mine the Closest Coal Ore Deposit (Small) at X: 54.64, Y: 16.97\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Check the Chest at X: 50.52, Y: 14.5 for additional food/resources\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Mine Copper Ore Deposit (Small) at X: 53.88, Y: 19.83\",\n    \"priority\": 4\n  },\n  {\n    \"task\": \"Go and chat with Thomas Smith at X: 48.72, Y: 13.43\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Carry out your daily duties\",\n    \"priority\": 6\n  },\n  {\n    \"task\": \"Maintain a healthy lifestyle\",\n    \"priority\": 7\n  },\n  {\n    \"task\": \"Catch up with other villagers\",\n    \"priority\": 8\n  },\n  {\n    \"task\": \"Replenish food resources, hunt or gather if necessary\",\n    \"priority\": 9\n  }\n]"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 1478,
    "completion_tokens": 274,
    "total_tokens": 1752
  }
}
[1693482875902] {
  "role": "assistant",
  "content": "[\n  {\n    \"task\": \"Eat the berries to satisfy hunger\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Mine the Closest Coal Ore Deposit (Small) at X: 54.64, Y: 16.97\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Check the Chest at X: 50.52, Y: 14.5 for additional food/resources\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Mine Copper Ore Deposit (Small) at X: 53.88, Y: 19.83\",\n    \"priority\": 4\n  },\n  {\n    \"task\": \"Go and chat with Thomas Smith at X: 48.72, Y: 13.43\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Carry out your daily duties\",\n    \"priority\": 6\n  },\n  {\n    \"task\": \"Maintain a healthy lifestyle\",\n    \"priority\": 7\n  },\n  {\n    \"task\": \"Catch up with other villagers\",\n    \"priority\": 8\n  },\n  {\n    \"task\": \"Replenish food resources, hunt or gather if necessary\",\n    \"priority\": 9\n  }\n]"
}
[1693482875907] [36m[OPENAI] Chat completion took 26412.391000032425ms[39m
[1693482875907] [36m[OPENAI] Tokens per second: 10.373918817106093tps[39m
[1693482875907] [32m[OPENAI] Chat completion created successfully.[39m
[1693482875922] [Character] Getting character: A2
[1693482875923] [32m[OPENAI] Embedding created successfully.[39m
[1693482875952] [33m[OPENAI] Creating embedding...[39m
[1693482876225] [33m[OPENAI] Creating embedding...[39m
[1693482876269] [32m[OPENAI] Embedding created successfully.[39m
[1693482876387] [32m[OPENAI] Embedding created successfully.[39m
[1693482876622] [33m[OPENAI] Creating embedding...[39m
[1693482876660] [33m[OPENAI] Creating embedding...[39m
[1693482876790] [32m[OPENAI] Embedding created successfully.[39m
[1693482876812] [32m[OPENAI] Embedding created successfully.[39m
[1693482877127] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482877197] [33m[OPENAI] Creating embedding...[39m
[1693482877461] [32m[OPENAI] Embedding created successfully.[39m
[1693482877846] [33m[OPENAI] Creating embedding...[39m
[1693482877978] [32m[OPENAI] Embedding created successfully.[39m
[1693482878348] [33m[OPENAI] Creating embedding...[39m
[1693482878489] [32m[OPENAI] Embedding created successfully.[39m
[1693482878660] {
  "id": "chatcmpl-7taXqAP8BBxkjOeqlPbMTNl1hk3Ke",
  "object": "chat.completion",
  "created": 1693482874,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A3\",\n  \"x\": 41.03,\n  \"y\": -11.7\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1457,
    "completion_tokens": 35,
    "total_tokens": 1492
  }
}
[1693482878660] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A3\",\n  \"x\": 41.03,\n  \"y\": -11.7\n}"
  }
}
[1693482878660] [36m[OPENAI] Chat completion took 3994.628832936287ms[39m
[1693482878660] [36m[OPENAI] Tokens per second: 8.761765226200739tps[39m
[1693482878660] [32m[OPENAI] Chat completion created successfully.[39m
[1693482878693] --- Observations received -- 
[1693482878693] {
  "observerId": "A3",
  "observation": "Will Turner has started walking to 41.03, Y: -11.7.",
  "time": 31.5344048
}
[1693482878693] [Character] Getting character: A3
[1693482878734] --- Observations received -- 
[1693482878734] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 38.63, Y: -11.64.",
  "time": 31.6013317
}
[1693482878734] [Character] Getting character: A3
[1693482878786] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482878786] [33m[OPENAI] Creating embedding...[39m
[1693482878787] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482878787] [33m[OPENAI] Creating embedding...[39m
[1693482878875] [33m[OPENAI] Creating embedding...[39m
[1693482878974] {
  "id": "chatcmpl-7taXraWM13uYcIIJcjyojHng1ka9Y",
  "object": "chat.completion",
  "created": 1693482875,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 57.55001,\n  \"y\": 10.45\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1963,
    "completion_tokens": 36,
    "total_tokens": 1999
  }
}
[1693482878974] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 57.55001,\n  \"y\": 10.45\n}"
  }
}
[1693482878974] [36m[OPENAI] Chat completion took 3707.9040828943253ms[39m
[1693482878974] [36m[OPENAI] Tokens per second: 9.708989012439348tps[39m
[1693482878974] [32m[OPENAI] Chat completion created successfully.[39m
[1693482878996] --- Observations received -- 
[1693482878996] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 57.55001, Y: 10.45.",
  "time": 31.86403
}
[1693482878996] [Character] Getting character: A4
[1693482879004] {
  "id": "chatcmpl-7taXuyjqfA0rDXuZpf4lYz7EYTwUw",
  "object": "chat.completion",
  "created": 1693482878,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693482879004] {
  "role": "assistant",
  "content": "1"
}
[1693482879004] [36m[OPENAI] Chat completion took 217.99195909500122ms[39m
[1693482879004] [36m[OPENAI] Tokens per second: 4.587325166265415tps[39m
[1693482879004] [32m[OPENAI] Chat completion created successfully.[39m
[1693482879066] {
  "id": "chatcmpl-7taXuV3TimIy9VCLn4gCyc4pQDbI4",
  "object": "chat.completion",
  "created": 1693482878,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482879066] {
  "role": "assistant",
  "content": "1"
}
[1693482879067] [36m[OPENAI] Chat completion took 278.9844579696655ms[39m
[1693482879067] [36m[OPENAI] Tokens per second: 3.584429065610285tps[39m
[1693482879067] [32m[OPENAI] Chat completion created successfully.[39m
[1693482879077] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482879077] [33m[OPENAI] Creating embedding...[39m
[1693482879214] --- Observations received -- 
[1693482879214] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees Tree (465) at X: 55.4, Y: 4.5",
  "time": 32.0802269
}
[1693482879215] [Character] Getting character: A4
[1693482879236] [32m[OPENAI] Embedding created successfully.[39m
[1693482879250] [32m[OPENAI] Embedding created successfully.[39m
[1693482879290] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482879290] [33m[OPENAI] Creating embedding...[39m
[1693482879299] --- Observations received -- 
[1693482879300] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees Tree (466) at X: 53.51, Y: 5.059999",
  "time": 32.16081
}
[1693482879300] [Character] Getting character: A4
[1693482879319] [32m[OPENAI] Embedding created successfully.[39m
[1693482879340] [32m[OPENAI] Embedding created successfully.[39m
[1693482879374] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482879375] [33m[OPENAI] Creating embedding...[39m
[1693482879394] --- Observations received -- 
[1693482879394] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 44.48, Y: -14.04.",
  "time": 32.2616463
}
[1693482879394] [Character] Getting character: A3
[1693482879432] --- Observations received -- 
[1693482879432] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 40.96, Y: -14.27.",
  "time": 32.30032
}
[1693482879432] [Character] Getting character: A3
[1693482879456] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482879456] [33m[OPENAI] Creating embedding...[39m
[1693482879528] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482879529] [33m[OPENAI] Creating embedding...[39m
[1693482879560] {
  "id": "chatcmpl-7taXvulKFhF8bH7Cg6eVLE8A7P4qH",
  "object": "chat.completion",
  "created": 1693482879,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482879560] {
  "role": "assistant",
  "content": "3"
}
[1693482879560] [36m[OPENAI] Chat completion took 270.3637501001358ms[39m
[1693482879560] [36m[OPENAI] Tokens per second: 3.698720703606255tps[39m
[1693482879560] [32m[OPENAI] Chat completion created successfully.[39m
[1693482879577] {
  "id": "chatcmpl-7taXvzo4Ib9ligvANxBYFQSBksrsp",
  "object": "chat.completion",
  "created": 1693482879,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482879577] {
  "role": "assistant",
  "content": "3"
}
[1693482879577] [36m[OPENAI] Chat completion took 499.9988340139389ms[39m
[1693482879577] [36m[OPENAI] Tokens per second: 2.0000046639551208tps[39m
[1693482879577] [32m[OPENAI] Chat completion created successfully.[39m
[1693482879614] --- Observations received -- 
[1693482879614] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees Tree (484) at X: 50.77, Y: 9.22",
  "time": 32.48229
}
[1693482879614] [Character] Getting character: A4
[1693482879635] [32m[OPENAI] Embedding created successfully.[39m
[1693482879669] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482879669] [33m[OPENAI] Creating embedding...[39m
[1693482879698] --- Observations received -- 
[1693482879698] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 36.64, Y: -10.67.",
  "time": 32.56
}
[1693482879698] [Character] Getting character: A3
[1693482879722] [32m[OPENAI] Embedding created successfully.[39m
[1693482879727] {
  "id": "chatcmpl-7taXvP9WMDi91DmM202mZRWISjCVe",
  "object": "chat.completion",
  "created": 1693482879,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482879727] {
  "role": "assistant",
  "content": "4"
}
[1693482879727] [36m[OPENAI] Chat completion took 352.29783403873444ms[39m
[1693482879727] [36m[OPENAI] Tokens per second: 2.838507374672227tps[39m
[1693482879727] [32m[OPENAI] Chat completion created successfully.[39m
[1693482879752] {
  "id": "chatcmpl-7taXvbUgY8ZTeVt23IWgM84Ly5quK",
  "object": "chat.completion",
  "created": 1693482879,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482879752] {
  "role": "assistant",
  "content": "4"
}
[1693482879752] [36m[OPENAI] Chat completion took 295.5575420856476ms[39m
[1693482879752] [36m[OPENAI] Tokens per second: 3.383435905385276tps[39m
[1693482879752] [32m[OPENAI] Chat completion created successfully.[39m
[1693482879760] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482879761] [33m[OPENAI] Creating embedding...[39m
[1693482879767] [33m[OPENAI] Creating embedding...[39m
[1693482879793] [32m[OPENAI] Embedding created successfully.[39m
[1693482879813] [32m[OPENAI] Embedding created successfully.[39m
[1693482879842] {
  "id": "chatcmpl-7taXvMzbzk5yrg3lwI2WgT19sjjJm",
  "object": "chat.completion",
  "created": 1693482879,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482879842] {
  "role": "assistant",
  "content": "2"
}
[1693482879842] [36m[OPENAI] Chat completion took 313.38462495803833ms[39m
[1693482879842] [36m[OPENAI] Tokens per second: 3.190967011013697tps[39m
[1693482879842] [32m[OPENAI] Chat completion created successfully.[39m
[1693482879884] [32m[OPENAI] Embedding created successfully.[39m
[1693482879920] [32m[OPENAI] Embedding created successfully.[39m
[1693482879932] [32m[OPENAI] Embedding created successfully.[39m
[1693482879937] {
  "id": "chatcmpl-7taXvt7nWfWH39rvkUggIrWzbSxTU",
  "object": "chat.completion",
  "created": 1693482879,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482879937] {
  "role": "assistant",
  "content": "2"
}
[1693482879937] [36m[OPENAI] Chat completion took 267.5142910480499ms[39m
[1693482879937] [36m[OPENAI] Tokens per second: 3.738118050001238tps[39m
[1693482879937] [32m[OPENAI] Chat completion created successfully.[39m
[1693482880124] --- Observations received -- 
[1693482880125] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 36.7, Y: -12.62.",
  "time": 32.9806061
}
[1693482880125] [Character] Getting character: A3
[1693482880154] --- Observations received -- 
[1693482880154] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 38.39, Y: -14.58.",
  "time": 33.021244
}
[1693482880154] [Character] Getting character: A3
[1693482880198] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482880200] [33m[OPENAI] Creating embedding...[39m
[1693482880228] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482880228] [33m[OPENAI] Creating embedding...[39m
[1693482880242] {
  "id": "chatcmpl-7taXvdzN6OWqxmKBKwuJHzQGN0JoI",
  "object": "chat.completion",
  "created": 1693482879,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482880242] {
  "role": "assistant",
  "content": "3"
}
[1693482880242] [36m[OPENAI] Chat completion took 481.4606659412384ms[39m
[1693482880242] [36m[OPENAI] Tokens per second: 2.0770128709165383tps[39m
[1693482880242] [32m[OPENAI] Chat completion created successfully.[39m
[1693482880296] [33m[OPENAI] Creating embedding...[39m
[1693482880328] --- Observations received -- 
[1693482880329] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 57.55001, Y: 10.45.",
  "time": 33.17999
}
[1693482880329] [Character] Getting character: A4
[1693482880329] [Character] Getting character: A4
[1693482880364] [33m[OPENAI] Creating embedding...[39m
[1693482880409] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482880409] [33m[OPENAI] Creating embedding...[39m
[1693482880433] [32m[OPENAI] Embedding created successfully.[39m
[1693482880451] [32m[OPENAI] Embedding created successfully.[39m
[1693482880473] [32m[OPENAI] Embedding created successfully.[39m
[1693482880490] {
  "id": "chatcmpl-7taXwPa9tLsklWniIItolnw3ns1Pq",
  "object": "chat.completion",
  "created": 1693482880,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482880490] {
  "role": "assistant",
  "content": "1"
}
[1693482880490] [36m[OPENAI] Chat completion took 261.9895409345627ms[39m
[1693482880490] [36m[OPENAI] Tokens per second: 3.816946265995293tps[39m
[1693482880490] [32m[OPENAI] Chat completion created successfully.[39m
[1693482880495] --- Observations received -- 
[1693482880495] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 41.43, Y: -16.",
  "time": 33.36246
}
[1693482880495] [Character] Getting character: A3
[1693482880496] {
  "id": "chatcmpl-7taXwil4s6ePNbTatXFQwgFyqDr3q",
  "object": "chat.completion",
  "created": 1693482880,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482880496] {
  "role": "assistant",
  "content": "1"
}
[1693482880496] [36m[OPENAI] Chat completion took 296.59591698646545ms[39m
[1693482880496] [36m[OPENAI] Tokens per second: 3.3715905807483955tps[39m
[1693482880496] [32m[OPENAI] Chat completion created successfully.[39m
[1693482880518] [32m[OPENAI] Embedding created successfully.[39m
[1693482880561] [32m[OPENAI] Embedding created successfully.[39m
[1693482880588] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482880588] [33m[OPENAI] Creating embedding...[39m
[1693482880723] {
  "id": "chatcmpl-7taXwOrVEH2GxFMOFczVyPiaMK2Ph",
  "object": "chat.completion",
  "created": 1693482880,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693482880723] {
  "role": "assistant",
  "content": "5"
}
[1693482880723] [36m[OPENAI] Chat completion took 313.8877919912338ms[39m
[1693482880723] [36m[OPENAI] Tokens per second: 3.1858518410551233tps[39m
[1693482880723] [32m[OPENAI] Chat completion created successfully.[39m
[1693482880777] --- Observations received -- 
[1693482880778] {
  "observerId": "A3",
  "observation": "Will Turner finished walking to 41.03, Y: -11.7.",
  "time": 33.6399879
}
[1693482880778] [Character] Getting character: A3
[1693482880783] [Character] Getting character: A3
[1693482880794] [32m[OPENAI] Embedding created successfully.[39m
[1693482880832] {
  "id": "chatcmpl-7taXwD1ZeZ1tIIS3F5Gy9A2nBgNl4",
  "object": "chat.completion",
  "created": 1693482880,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693482880832] {
  "role": "assistant",
  "content": "3"
}
[1693482880832] [36m[OPENAI] Chat completion took 243.06025004386902ms[39m
[1693482880832] [36m[OPENAI] Tokens per second: 4.114206250588131tps[39m
[1693482880832] [32m[OPENAI] Chat completion created successfully.[39m
[1693482880849] [33m[OPENAI] Creating embedding...[39m
[1693482880858] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482880858] [33m[OPENAI] Creating embedding...[39m
[1693482880891] [33m[OPENAI] Creating embedding...[39m
[1693482880954] [33m[OPENAI] Creating embedding...[39m
[1693482881021] [32m[OPENAI] Embedding created successfully.[39m
[1693482881030] {
  "id": "chatcmpl-7taXta0kcmOkJtr5ZwWQwh1LnfIO1",
  "object": "chat.completion",
  "created": 1693482877,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 41.33658,\n  \"y\": 13.99647\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1278,
    "completion_tokens": 37,
    "total_tokens": 1315
  }
}
[1693482881030] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 41.33658,\n  \"y\": 13.99647\n}"
  }
}
[1693482881030] [36m[OPENAI] Chat completion took 3903.0564999580383ms[39m
[1693482881030] [36m[OPENAI] Tokens per second: 9.479750037028104tps[39m
[1693482881030] [32m[OPENAI] Chat completion created successfully.[39m
[1693482881036] --- Observations received -- 
[1693482881036] {
  "observerId": "A5",
  "observation": "Eli Green has started walking to 41.33658, Y: 13.99647.",
  "time": 33.90419
}
[1693482881036] [Character] Getting character: A5
[1693482881066] [32m[OPENAI] Embedding created successfully.[39m
[1693482881115] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482881115] [33m[OPENAI] Creating embedding...[39m
[1693482881120] {
  "id": "chatcmpl-7taXw05nOjbLtdegecNds0d58DvQM",
  "object": "chat.completion",
  "created": 1693482880,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693482881120] {
  "role": "assistant",
  "content": "1"
}
[1693482881120] [36m[OPENAI] Chat completion took 261.53429198265076ms[39m
[1693482881120] [36m[OPENAI] Tokens per second: 3.823590369045511tps[39m
[1693482881120] [32m[OPENAI] Chat completion created successfully.[39m
[1693482881126] [32m[OPENAI] Embedding created successfully.[39m
[1693482881158] [32m[OPENAI] Embedding created successfully.[39m
[1693482881262] --- Observations received -- 
[1693482881266] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Small) at X: 38.24, Y: 15.93.",
  "time": 34.12006
}
[1693482881266] [Character] Getting character: A5
[1693482881283] [32m[OPENAI] Embedding created successfully.[39m
[1693482881362] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482881362] [33m[OPENAI] Creating embedding...[39m
[1693482881363] {
  "id": "chatcmpl-7taXxyrj4PftaUw7MTqiq2MptTRid",
  "object": "chat.completion",
  "created": 1693482881,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693482881363] {
  "role": "assistant",
  "content": "3"
}
[1693482881363] [36m[OPENAI] Chat completion took 247.77162504196167ms[39m
[1693482881363] [36m[OPENAI] Tokens per second: 4.035974659449579tps[39m
[1693482881363] [32m[OPENAI] Chat completion created successfully.[39m
[1693482881427] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482881433] --- Observations received -- 
[1693482881433] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 45.24001, Y: 10.2.",
  "time": 34.3014145
}
[1693482881433] [Character] Getting character: A5
[1693482881433] --- Observations received -- 
[1693482881433] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees Tree (205) at X: 42.12, Y: 5.77",
  "time": 34.3014145
}
[1693482881434] [Character] Getting character: A5
[1693482881515] [33m[OPENAI] Creating embedding...[39m
[1693482881517] [32m[OPENAI] Embedding created successfully.[39m
[1693482881519] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482881519] [33m[OPENAI] Creating embedding...[39m
[1693482881556] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482881558] [33m[OPENAI] Creating embedding...[39m
[1693482881561] [33m[OPENAI] Creating embedding...[39m
[1693482881636] {
  "id": "chatcmpl-7taXxBhSq6UAUGxHsscwHX3Xp1qf8",
  "object": "chat.completion",
  "created": 1693482881,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482881636] {
  "role": "assistant",
  "content": "1"
}
[1693482881636] [36m[OPENAI] Chat completion took 274.33325004577637ms[39m
[1693482881636] [36m[OPENAI] Tokens per second: 3.6452015927093635tps[39m
[1693482881636] [32m[OPENAI] Chat completion created successfully.[39m
[1693482881693] [32m[OPENAI] Embedding created successfully.[39m
[1693482881711] [32m[OPENAI] Embedding created successfully.[39m
[1693482881799] {
  "id": "chatcmpl-7taXxkNbJnqYhPE4MXsI65IcLtK7L",
  "object": "chat.completion",
  "created": 1693482881,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693482881799] {
  "role": "assistant",
  "content": "2"
}
[1693482881799] [36m[OPENAI] Chat completion took 279.7106249332428ms[39m
[1693482881799] [36m[OPENAI] Tokens per second: 3.5751233984717787tps[39m
[1693482881799] [32m[OPENAI] Chat completion created successfully.[39m
[1693482881806] {
  "id": "chatcmpl-7taXxfQ0NchN7Lrfr8YgjR2nqMDRM",
  "object": "chat.completion",
  "created": 1693482881,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482881806] {
  "role": "assistant",
  "content": "3"
}
[1693482881806] [36m[OPENAI] Chat completion took 247.4875830411911ms[39m
[1693482881806] [36m[OPENAI] Tokens per second: 4.040606755748077tps[39m
[1693482881806] [32m[OPENAI] Chat completion created successfully.[39m
[1693482881806] [32m[OPENAI] Embedding created successfully.[39m
[1693482881852] [32m[OPENAI] Embedding created successfully.[39m
[1693482882062] [33m[OPENAI] Creating embedding...[39m
[1693482882194] --- Observations received -- 
[1693482882196] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Medium) at X: 42.53862, Y: 17.00157.",
  "time": 35.0614738
}
[1693482882196] [Character] Getting character: A5
[1693482882211] [33m[OPENAI] Creating embedding...[39m
[1693482882291] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482882292] [33m[OPENAI] Creating embedding...[39m
[1693482882302] [32m[OPENAI] Embedding created successfully.[39m
[1693482882378] [32m[OPENAI] Embedding created successfully.[39m
[1693482882449] [32m[OPENAI] Embedding created successfully.[39m
[1693482882508] {
  "id": "chatcmpl-7taXy0V1VeSuidJ494ROGytJUzkCA",
  "object": "chat.completion",
  "created": 1693482882,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693482882508] {
  "role": "assistant",
  "content": "3"
}
[1693482882508] [36m[OPENAI] Chat completion took 216.85120797157288ms[39m
[1693482882508] [36m[OPENAI] Tokens per second: 4.611456903348634tps[39m
[1693482882508] [32m[OPENAI] Chat completion created successfully.[39m
[1693482882629] [33m[OPENAI] Creating embedding...[39m
[1693482882713] [33m[OPENAI] Creating embedding...[39m
[1693482882795] [32m[OPENAI] Embedding created successfully.[39m
[1693482882891] [32m[OPENAI] Embedding created successfully.[39m
[1693482882940] --- Observations received -- 
[1693482882940] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees Tree (479) at X: 45.24001, Y: 10.2",
  "time": 35.80242
}
[1693482882940] [Character] Getting character: A5
[1693482882993] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482882993] [33m[OPENAI] Creating embedding...[39m
[1693482883157] [33m[OPENAI] Creating embedding...[39m
[1693482883158] [32m[OPENAI] Embedding created successfully.[39m
[1693482883175] --- Observations received -- 
[1693482883176] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Medium) at X: 38.03, Y: 18.78.",
  "time": 36.0435677
}
[1693482883176] [Character] Getting character: A5
[1693482883239] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482883239] [33m[OPENAI] Creating embedding...[39m
[1693482883248] {
  "id": "chatcmpl-7taXzv77Lve3MdxcXNc7c2rpUGno5",
  "object": "chat.completion",
  "created": 1693482883,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482883248] {
  "role": "assistant",
  "content": "3"
}
[1693482883248] [36m[OPENAI] Chat completion took 254.50366699695587ms[39m
[1693482883248] [36m[OPENAI] Tokens per second: 3.9292164698434817tps[39m
[1693482883248] [32m[OPENAI] Chat completion created successfully.[39m
[1693482883254] [33m[OPENAI] Creating embedding...[39m
[1693482883369] [32m[OPENAI] Embedding created successfully.[39m
[1693482883393] [32m[OPENAI] Embedding created successfully.[39m
[1693482883393] [32m[OPENAI] Embedding created successfully.[39m
[1693482883506] {
  "id": "chatcmpl-7taXzDauQ6idqEn6uJ9cDsj5JTgnD",
  "object": "chat.completion",
  "created": 1693482883,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482883506] {
  "role": "assistant",
  "content": "3"
}
[1693482883506] [36m[OPENAI] Chat completion took 266.00133299827576ms[39m
[1693482883506] [36m[OPENAI] Tokens per second: 3.7593796569676665tps[39m
[1693482883506] [32m[OPENAI] Chat completion created successfully.[39m
[1693482883557] --- Observations received -- 
[1693482883557] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Large) at X: 40.75, Y: 19.74.",
  "time": 36.4216423
}
[1693482883557] [Character] Getting character: A5
[1693482883561] --- Observations received -- 
[1693482883563] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Small) at X: 45.73, Y: 15.31.",
  "time": 36.4216423
}
[1693482883564] [Character] Getting character: A5
[1693482883625] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482883625] [33m[OPENAI] Creating embedding...[39m
[1693482883631] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482883631] [33m[OPENAI] Creating embedding...[39m
[1693482883766] [33m[OPENAI] Creating embedding...[39m
[1693482883790] [32m[OPENAI] Embedding created successfully.[39m
[1693482883801] [32m[OPENAI] Embedding created successfully.[39m
[1693482883802] [33m[OPENAI] Creating embedding...[39m
[1693482883930] [32m[OPENAI] Embedding created successfully.[39m
[1693482883950] {
  "id": "chatcmpl-7taXzr7VvTFmG1416aC5PXfTeIb5H",
  "object": "chat.completion",
  "created": 1693482883,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482883950] {
  "role": "assistant",
  "content": "2"
}
[1693482883950] [36m[OPENAI] Chat completion took 318.9238750934601ms[39m
[1693482883950] [36m[OPENAI] Tokens per second: 3.1355444922615208tps[39m
[1693482883950] [32m[OPENAI] Chat completion created successfully.[39m
[1693482883967] {
  "id": "chatcmpl-7taXzXfCTww80g3wREvnqy7no5yf3",
  "object": "chat.completion",
  "created": 1693482883,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482883967] {
  "role": "assistant",
  "content": "4"
}
[1693482883967] [36m[OPENAI] Chat completion took 341.93791604042053ms[39m
[1693482883968] [36m[OPENAI] Tokens per second: 2.9245075000158507tps[39m
[1693482883968] [32m[OPENAI] Chat completion created successfully.[39m
[1693482884009] [32m[OPENAI] Embedding created successfully.[39m
[1693482884077] {
  "id": "chatcmpl-7taXxAwxrlaX3pg1UpUkTV8ErdWr2",
  "object": "chat.completion",
  "created": 1693482881,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "eat",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"foodId\": \"berries\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1974,
    "completion_tokens": 25,
    "total_tokens": 1999
  }
}
[1693482884078] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "eat",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"foodId\": \"berries\"\n}"
  }
}
[1693482884078] [36m[OPENAI] Chat completion took 2643.325917005539ms[39m
[1693482884078] [36m[OPENAI] Tokens per second: 9.457781894833824tps[39m
[1693482884078] [32m[OPENAI] Chat completion created successfully.[39m
[1693482884097] [Character] Getting character: A2
[1693482884129] [33m[OPENAI] Creating embedding...[39m
[1693482884260] --- Observations received -- 
[1693482884260] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Medium) at X: 46.05, Y: 17.85.",
  "time": 37.1204262
}
[1693482884260] [Character] Getting character: A5
[1693482884297] [33m[OPENAI] Creating embedding...[39m
[1693482884322] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482884322] [33m[OPENAI] Creating embedding...[39m
[1693482884338] --- Observations received -- 
[1693482884338] {
  "observerId": "A5",
  "observation": "Eli Green finished walking to 41.33658, Y: 13.99647.",
  "time": 37.1999855
}
[1693482884338] [Character] Getting character: A5
[1693482884338] [Character] Getting character: A5
[1693482884368] [33m[OPENAI] Creating embedding...[39m
[1693482884382] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482884393] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482884393] [33m[OPENAI] Creating embedding...[39m
[1693482884412] [32m[OPENAI] Embedding created successfully.[39m
[1693482884444] [32m[OPENAI] Embedding created successfully.[39m
[1693482884598] [32m[OPENAI] Embedding created successfully.[39m
[1693482884623] [32m[OPENAI] Embedding created successfully.[39m
[1693482884623] [32m[OPENAI] Embedding created successfully.[39m
[1693482884626] {
  "id": "chatcmpl-7taY0tfwbwAKgqtMDuf8EuNPpiMbA",
  "object": "chat.completion",
  "created": 1693482884,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482884626] {
  "role": "assistant",
  "content": "4"
}
[1693482884626] [36m[OPENAI] Chat completion took 303.8282080888748ms[39m
[1693482884626] [36m[OPENAI] Tokens per second: 3.291333633207234tps[39m
[1693482884626] [32m[OPENAI] Chat completion created successfully.[39m
[1693482884750] {
  "id": "chatcmpl-7taY0oIL5aWZT2OCF2umYiQUYydoU",
  "object": "chat.completion",
  "created": 1693482884,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482884750] {
  "role": "assistant",
  "content": "1"
}
[1693482884750] [36m[OPENAI] Chat completion took 356.4904170036316ms[39m
[1693482884750] [36m[OPENAI] Tokens per second: 2.8051244922800067tps[39m
[1693482884750] [32m[OPENAI] Chat completion created successfully.[39m
[1693482884855] [33m[OPENAI] Creating embedding...[39m
[1693482884921] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482885032] [33m[OPENAI] Creating embedding...[39m
[1693482885035] [32m[OPENAI] Embedding created successfully.[39m
[1693482885167] [32m[OPENAI] Embedding created successfully.[39m
[1693482885382] [33m[OPENAI] Creating embedding...[39m
[1693482885546] [33m[OPENAI] Creating embedding...[39m
[1693482885706] [32m[OPENAI] Embedding created successfully.[39m
[1693482885784] [32m[OPENAI] Embedding created successfully.[39m
[1693482886052] [33m[OPENAI] Creating embedding...[39m
[1693482886199] [33m[OPENAI] Creating embedding...[39m
[1693482886351] [32m[OPENAI] Embedding created successfully.[39m
[1693482886358] [32m[OPENAI] Embedding created successfully.[39m
[1693482886441] {
  "id": "chatcmpl-7taY0uF0e4HWK7GFP2v8VjLT7q1Vx",
  "object": "chat.completion",
  "created": 1693482884,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_axe",
          "arguments": "{\n  \"characterId\": \"A4\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1753,
    "completion_tokens": 18,
    "total_tokens": 1771
  }
}
[1693482886441] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_axe",
    "arguments": "{\n  \"characterId\": \"A4\"\n}"
  }
}
[1693482886441] [36m[OPENAI] Chat completion took 2058.6950410604477ms[39m
[1693482886441] [36m[OPENAI] Tokens per second: 8.743402806628454tps[39m
[1693482886441] [32m[OPENAI] Chat completion created successfully.[39m
[1693482886729] [33m[OPENAI] Creating embedding...[39m
[1693482886765] [33m[OPENAI] Creating embedding...[39m
[1693482886861] [32m[OPENAI] Embedding created successfully.[39m
[1693482886939] [32m[OPENAI] Embedding created successfully.[39m
[1693482887185] {
  "id": "chatcmpl-7taY1Z3XRJdjj5w81LRolOxYSJtJg",
  "object": "chat.completion",
  "created": 1693482885,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_axe",
          "arguments": "{\n  \"characterId\": \"A3\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1923,
    "completion_tokens": 18,
    "total_tokens": 1941
  }
}
[1693482887186] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_axe",
    "arguments": "{\n  \"characterId\": \"A3\"\n}"
  }
}
[1693482887186] [36m[OPENAI] Chat completion took 2263.7689999341965ms[39m
[1693482887186] [36m[OPENAI] Tokens per second: 7.951341325251484tps[39m
[1693482887186] [32m[OPENAI] Chat completion created successfully.[39m
[1693482887227] [33m[OPENAI] Creating embedding...[39m
[1693482887359] [33m[OPENAI] Creating embedding...[39m
[1693482887399] [32m[OPENAI] Embedding created successfully.[39m
[1693482887464] [Character] Getting character: A4
[1693482887503] [33m[OPENAI] Creating embedding...[39m
[1693482887552] [32m[OPENAI] Embedding created successfully.[39m
[1693482887661] [32m[OPENAI] Embedding created successfully.[39m
[1693482887722] [33m[OPENAI] Creating embedding...[39m
[1693482887878] [32m[OPENAI] Embedding created successfully.[39m
[1693482887913] [33m[OPENAI] Creating embedding...[39m
[1693482888049] [33m[OPENAI] Creating embedding...[39m
[1693482888056] [32m[OPENAI] Embedding created successfully.[39m
[1693482888211] [Character] Getting character: A3
[1693482888238] [33m[OPENAI] Creating embedding...[39m
[1693482888260] [32m[OPENAI] Embedding created successfully.[39m
[1693482888261] [33m[OPENAI] Creating embedding...[39m
[1693482888411] [33m[OPENAI] Creating embedding...[39m
[1693482888483] [32m[OPENAI] Embedding created successfully.[39m
[1693482888505] [32m[OPENAI] Embedding created successfully.[39m
[1693482888617] [33m[OPENAI] Creating embedding...[39m
[1693482888625] [32m[OPENAI] Embedding created successfully.[39m
[1693482888761] [33m[OPENAI] Creating embedding...[39m
[1693482888792] [33m[OPENAI] Creating embedding...[39m
[1693482888824] [32m[OPENAI] Embedding created successfully.[39m
[1693482888899] [32m[OPENAI] Embedding created successfully.[39m
[1693482888992] [32m[OPENAI] Embedding created successfully.[39m
[1693482889025] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482889142] [33m[OPENAI] Creating embedding...[39m
[1693482889263] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482889332] [33m[OPENAI] Creating embedding...[39m
[1693482889423] [32m[OPENAI] Embedding created successfully.[39m
[1693482889462] [32m[OPENAI] Embedding created successfully.[39m
[1693482889732] [33m[OPENAI] Creating embedding...[39m
[1693482889825] [33m[OPENAI] Creating embedding...[39m
[1693482889982] [32m[OPENAI] Embedding created successfully.[39m
[1693482890054] [32m[OPENAI] Embedding created successfully.[39m
[1693482890343] [33m[OPENAI] Creating embedding...[39m
[1693482890492] [33m[OPENAI] Creating embedding...[39m
[1693482890514] [32m[OPENAI] Embedding created successfully.[39m
[1693482890629] [32m[OPENAI] Embedding created successfully.[39m
[1693482890828] [33m[OPENAI] Creating embedding...[39m
[1693482890955] {
  "id": "chatcmpl-7taY5bXaWPEqMrV91f3BY7pOrvpOD",
  "object": "chat.completion",
  "created": 1693482889,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_pickaxe",
          "arguments": "{\n  \"characterId\": \"A5\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1630,
    "completion_tokens": 18,
    "total_tokens": 1648
  }
}
[1693482890955] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_pickaxe",
    "arguments": "{\n  \"characterId\": \"A5\"\n}"
  }
}
[1693482890955] [36m[OPENAI] Chat completion took 1929.1157079935074ms[39m
[1693482890955] [36m[OPENAI] Tokens per second: 9.330700032877749tps[39m
[1693482890955] [32m[OPENAI] Chat completion created successfully.[39m
[1693482890968] [32m[OPENAI] Embedding created successfully.[39m
[1693482890992] [33m[OPENAI] Creating embedding...[39m
[1693482891156] [32m[OPENAI] Embedding created successfully.[39m
[1693482891319] [33m[OPENAI] Creating embedding...[39m
[1693482891477] [32m[OPENAI] Embedding created successfully.[39m
[1693482891526] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482891588] --- Observations received -- 
[1693482891588] {
  "observerId": "A5",
  "observation": "Eli Green picked up Stone at X: 41.20406, Y: 14.52373",
  "time": 44.4542046
}
[1693482891588] [Character] Getting character: A5
[1693482891651] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482891651] [33m[OPENAI] Creating embedding...[39m
[1693482891804] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482891837] [32m[OPENAI] Embedding created successfully.[39m
[1693482891972] [Character] Getting character: A5
[1693482892004] [33m[OPENAI] Creating embedding...[39m
[1693482892077] {
  "id": "chatcmpl-7taY763078uXftUnxAN1JUtTdkdvB",
  "object": "chat.completion",
  "created": 1693482891,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693482892077] {
  "role": "assistant",
  "content": "1"
}
[1693482892077] [36m[OPENAI] Chat completion took 425.668624997139ms[39m
[1693482892077] [36m[OPENAI] Tokens per second: 2.3492452609273733tps[39m
[1693482892077] [32m[OPENAI] Chat completion created successfully.[39m
[1693482892262] [32m[OPENAI] Embedding created successfully.[39m
[1693482892290] {
  "id": "chatcmpl-7taY5kbzMEi53nq1uQ8TXPrYQJanj",
  "object": "chat.completion",
  "created": 1693482889,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 54.64,\n  \"y\": 16.97\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1876,
    "completion_tokens": 35,
    "total_tokens": 1911
  }
}
[1693482892290] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 54.64,\n  \"y\": 16.97\n}"
  }
}
[1693482892290] [36m[OPENAI] Chat completion took 3026.7934579849243ms[39m
[1693482892290] [36m[OPENAI] Tokens per second: 11.563392245238006tps[39m
[1693482892290] [32m[OPENAI] Chat completion created successfully.[39m
[1693482892301] --- Observations received -- 
[1693482892302] {
  "observerId": "A2",
  "observation": "George Brown has started walking to 54.64, Y: 16.97.",
  "time": 45.16421
}
[1693482892302] [Character] Getting character: A2
[1693482892375] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482892376] [33m[OPENAI] Creating embedding...[39m
[1693482892475] --- Observations received -- 
[1693482892475] {
  "observerId": "A2",
  "observation": "George Brown no longer sees Human at X: 48.72, Y: 13.43",
  "time": 45.3425674
}
[1693482892475] [Character] Getting character: A2
[1693482892533] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482892533] [33m[OPENAI] Creating embedding...[39m
[1693482892542] [32m[OPENAI] Embedding created successfully.[39m
[1693482892603] [33m[OPENAI] Creating embedding...[39m
[1693482892698] {
  "id": "chatcmpl-7taY8ABV0XShKhk0UwBKjpHFNUwEm",
  "object": "chat.completion",
  "created": 1693482892,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693482892698] {
  "role": "assistant",
  "content": "1"
}
[1693482892698] [36m[OPENAI] Chat completion took 322.90891695022583ms[39m
[1693482892698] [36m[OPENAI] Tokens per second: 3.096848515193351tps[39m
[1693482892698] [32m[OPENAI] Chat completion created successfully.[39m
[1693482892748] [32m[OPENAI] Embedding created successfully.[39m
[1693482892755] --- Observations received -- 
[1693482892755] {
  "observerId": "A2",
  "observation": "George Brown no longer sees StoneOreSmall (5) at X: 47.58, Y: 19.17",
  "time": 45.6225853
}
[1693482892755] [Character] Getting character: A2
[1693482892766] [32m[OPENAI] Embedding created successfully.[39m
[1693482892790] {
  "id": "chatcmpl-7taY8nfzOUGMqwSrvhrpCabw662Jp",
  "object": "chat.completion",
  "created": 1693482892,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693482892790] {
  "role": "assistant",
  "content": "2"
}
[1693482892790] [36m[OPENAI] Chat completion took 257.2717499732971ms[39m
[1693482892790] [36m[OPENAI] Tokens per second: 3.886940560336658tps[39m
[1693482892790] [32m[OPENAI] Chat completion created successfully.[39m
[1693482892820] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482892821] [33m[OPENAI] Creating embedding...[39m
[1693482892995] [32m[OPENAI] Embedding created successfully.[39m
[1693482893069] {
  "id": "chatcmpl-7taY8ExfMyvimbhXkWVuDoQcNCIkO",
  "object": "chat.completion",
  "created": 1693482892,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693482893069] {
  "role": "assistant",
  "content": "5"
}
[1693482893069] [36m[OPENAI] Chat completion took 248.6894999742508ms[39m
[1693482893069] [36m[OPENAI] Tokens per second: 4.021078493879072tps[39m
[1693482893069] [32m[OPENAI] Chat completion created successfully.[39m
[1693482893101] [33m[OPENAI] Creating embedding...[39m
[1693482893154] --- Observations received -- 
[1693482893154] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Large) at X: 58.91, Y: 19.37.",
  "time": 46.02123
}
[1693482893155] [Character] Getting character: A2
[1693482893223] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482893224] [33m[OPENAI] Creating embedding...[39m
[1693482893371] [32m[OPENAI] Embedding created successfully.[39m
[1693482893372] {
  "id": "chatcmpl-7taY7Y7cGG1xkAnVPtHnpmYyyqxQI",
  "object": "chat.completion",
  "created": 1693482891,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_axe",
          "arguments": "{\n  \"characterId\": \"A4\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1792,
    "completion_tokens": 18,
    "total_tokens": 1810
  }
}
[1693482893372] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_axe",
    "arguments": "{\n  \"characterId\": \"A4\"\n}"
  }
}
[1693482893372] [36m[OPENAI] Chat completion took 1845.8218749761581ms[39m
[1693482893372] [36m[OPENAI] Tokens per second: 9.75175353809939tps[39m
[1693482893372] [32m[OPENAI] Chat completion created successfully.[39m
[1693482893454] [32m[OPENAI] Embedding created successfully.[39m
[1693482893528] {
  "id": "chatcmpl-7taY953YAooAkMO5VQUaPxgrsep0E",
  "object": "chat.completion",
  "created": 1693482893,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482893528] {
  "role": "assistant",
  "content": "1"
}
[1693482893528] [36m[OPENAI] Chat completion took 305.20387506484985ms[39m
[1693482893528] [36m[OPENAI] Tokens per second: 3.276498372727147tps[39m
[1693482893528] [32m[OPENAI] Chat completion created successfully.[39m
[1693482893547] {
  "id": "chatcmpl-7taY7PIzMbvrxy7zhytr6KwRpDHaU",
  "object": "chat.completion",
  "created": 1693482891,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_axe",
          "arguments": "{\n  \"characterId\": \"A3\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1959,
    "completion_tokens": 18,
    "total_tokens": 1977
  }
}
[1693482893547] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_axe",
    "arguments": "{\n  \"characterId\": \"A3\"\n}"
  }
}
[1693482893547] [36m[OPENAI] Chat completion took 1742.990042090416ms[39m
[1693482893547] [36m[OPENAI] Tokens per second: 10.327081374723235tps[39m
[1693482893547] [32m[OPENAI] Chat completion created successfully.[39m
[1693482893617] --- Observations received -- 
[1693482893617] {
  "observerId": "A2",
  "observation": "George Brown sees Copper Ore Deposit (Medium) at X: 52.01, Y: 23.05.",
  "time": 46.4816742
}
[1693482893617] [Character] Getting character: A2
[1693482893673] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482893673] [33m[OPENAI] Creating embedding...[39m
[1693482893738] [33m[OPENAI] Creating embedding...[39m
[1693482893773] --- Observations received -- 
[1693482893773] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Medium) at X: 59.9, Y: 16.03.",
  "time": 46.6408157
}
[1693482893773] [Character] Getting character: A2
[1693482893813] --- Observations received -- 
[1693482893813] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CopperOreMedium at X: 52.01, Y: 23.05",
  "time": 46.68047
}
[1693482893813] [Character] Getting character: A2
[1693482893839] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482893840] [33m[OPENAI] Creating embedding...[39m
[1693482893876] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482893876] [33m[OPENAI] Creating embedding...[39m
[1693482893935] [32m[OPENAI] Embedding created successfully.[39m
[1693482893959] --- Observations received -- 
[1693482893959] {
  "observerId": "A2",
  "observation": "George Brown finished walking to 54.64, Y: 16.97.",
  "time": 46.8199844
}
[1693482893959] [Character] Getting character: A2
[1693482893959] [Character] Getting character: A2
[1693482893960] [32m[OPENAI] Embedding created successfully.[39m
[1693482893996] --- Observations received -- 
[1693482893996] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Tree Stump at X: 57.55001, Y: 10.45.",
  "time": 46.8622131
}
[1693482893996] [Character] Getting character: A4
[1693482893996] --- Observations received -- 
[1693482893996] {
  "observerId": "A4",
  "observation": "Lucy Wilde picked up Wood at X: 57.35769, Y: 10.52531",
  "time": 46.8622131
}
[1693482893996] [Character] Getting character: A4
[1693482894030] [33m[OPENAI] Creating embedding...[39m
[1693482894031] [32m[OPENAI] Embedding created successfully.[39m
[1693482894037] {
  "id": "chatcmpl-7taY9CON9emgIk9OOATEuuCc7HsPq",
  "object": "chat.completion",
  "created": 1693482893,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 2,
    "total_tokens": 108
  }
}
[1693482894037] {
  "role": "assistant",
  "content": "2."
}
[1693482894037] [36m[OPENAI] Chat completion took 363.6212919950485ms[39m
[1693482894037] [36m[OPENAI] Tokens per second: 5.500227968023485tps[39m
[1693482894037] [32m[OPENAI] Chat completion created successfully.[39m
[1693482894065] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482894065] [33m[OPENAI] Creating embedding...[39m
[1693482894068] [32m[OPENAI] Embedding created successfully.[39m
[1693482894097] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482894097] [33m[OPENAI] Creating embedding...[39m
[1693482894097] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482894097] [33m[OPENAI] Creating embedding...[39m
[1693482894118] {
  "id": "chatcmpl-7taY9KIOPF6QW0S6NPd33DdjSE3hf",
  "object": "chat.completion",
  "created": 1693482893,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482894118] {
  "role": "assistant",
  "content": "2"
}
[1693482894118] [36m[OPENAI] Chat completion took 241.94087505340576ms[39m
[1693482894118] [36m[OPENAI] Tokens per second: 4.133241230028871tps[39m
[1693482894118] [32m[OPENAI] Chat completion created successfully.[39m
[1693482894160] [32m[OPENAI] Embedding created successfully.[39m
[1693482894161] --- Observations received -- 
[1693482894161] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree Stump at X: 41.03, Y: -11.7.",
  "time": 47.02862
}
[1693482894161] [Character] Getting character: A3
[1693482894161] --- Observations received -- 
[1693482894161] {
  "observerId": "A3",
  "observation": "Will Turner picked up Wood at X: 41.54372, Y: -11.35713",
  "time": 47.02862
}
[1693482894161] [Character] Getting character: A3
[1693482894197] {
  "id": "chatcmpl-7taY9bLZnzG0DenHd0WOE3EMCizaR",
  "object": "chat.completion",
  "created": 1693482893,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482894197] {
  "role": "assistant",
  "content": "5"
}
[1693482894197] [36m[OPENAI] Chat completion took 357.87020790576935ms[39m
[1693482894198] [36m[OPENAI] Tokens per second: 2.794309159882092tps[39m
[1693482894198] [32m[OPENAI] Chat completion created successfully.[39m
[1693482894208] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482894208] [33m[OPENAI] Creating embedding...[39m
[1693482894216] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482894216] [33m[OPENAI] Creating embedding...[39m
[1693482894236] [32m[OPENAI] Embedding created successfully.[39m
[1693482894262] [32m[OPENAI] Embedding created successfully.[39m
[1693482894287] [32m[OPENAI] Embedding created successfully.[39m
[1693482894320] [33m[OPENAI] Creating embedding...[39m
[1693482894370] {
  "id": "chatcmpl-7taYATkje04xbsfOVlbj3v86Api2y",
  "object": "chat.completion",
  "created": 1693482894,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693482894370] {
  "role": "assistant",
  "content": "4"
}
[1693482894370] [36m[OPENAI] Chat completion took 272.27008295059204ms[39m
[1693482894370] [36m[OPENAI] Tokens per second: 3.6728236505568144tps[39m
[1693482894370] [32m[OPENAI] Chat completion created successfully.[39m
[1693482894377] {
  "id": "chatcmpl-7taYAHhbdtIQ0lbRU3dEAsUPvGqv3",
  "object": "chat.completion",
  "created": 1693482894,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693482894377] {
  "role": "assistant",
  "content": "1"
}
[1693482894377] [36m[OPENAI] Chat completion took 312.4925410747528ms[39m
[1693482894377] [36m[OPENAI] Tokens per second: 3.2000763812176407tps[39m
[1693482894377] [32m[OPENAI] Chat completion created successfully.[39m
[1693482894378] [32m[OPENAI] Embedding created successfully.[39m
[1693482894385] [Character] Getting character: A4
[1693482894399] {
  "id": "chatcmpl-7taYAp8PR8IihnTG0sMYn3L9jzuSF",
  "object": "chat.completion",
  "created": 1693482894,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1693482894399] {
  "role": "assistant",
  "content": "1"
}
[1693482894399] [36m[OPENAI] Chat completion took 301.44079208374023ms[39m
[1693482894399] [36m[OPENAI] Tokens per second: 3.3174010494312927tps[39m
[1693482894399] [32m[OPENAI] Chat completion created successfully.[39m
[1693482894407] [33m[OPENAI] Creating embedding...[39m
[1693482894423] [32m[OPENAI] Embedding created successfully.[39m
[1693482894484] {
  "id": "chatcmpl-7taYAqGwfe8GBWGmlha8kXUkt4Cx7",
  "object": "chat.completion",
  "created": 1693482894,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693482894484] {
  "role": "assistant",
  "content": "1"
}
[1693482894484] [36m[OPENAI] Chat completion took 268.01754105091095ms[39m
[1693482894484] [36m[OPENAI] Tokens per second: 3.7310990768699206tps[39m
[1693482894484] [32m[OPENAI] Chat completion created successfully.[39m
[1693482894520] [32m[OPENAI] Embedding created successfully.[39m
[1693482894533] {
  "id": "chatcmpl-7taYAHdtOobTVY62xAfKy73HakNps",
  "object": "chat.completion",
  "created": 1693482894,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693482894533] {
  "role": "assistant",
  "content": "4"
}
[1693482894533] [36m[OPENAI] Chat completion took 325.09391701221466ms[39m
[1693482894533] [36m[OPENAI] Tokens per second: 3.0760341786476038tps[39m
[1693482894533] [32m[OPENAI] Chat completion created successfully.[39m
[1693482894536] [33m[OPENAI] Creating embedding...[39m
[1693482894555] [Character] Getting character: A3
[1693482894580] [32m[OPENAI] Embedding created successfully.[39m
[1693482894585] [33m[OPENAI] Creating embedding...[39m
[1693482894715] [32m[OPENAI] Embedding created successfully.[39m
[1693482894743] [32m[OPENAI] Embedding created successfully.[39m
[1693482894846] [33m[OPENAI] Creating embedding...[39m
[1693482894961] [33m[OPENAI] Creating embedding...[39m
[1693482895023] [32m[OPENAI] Embedding created successfully.[39m
[1693482895137] [33m[OPENAI] Creating embedding...[39m
[1693482895142] [33m[OPENAI] Creating embedding...[39m
[1693482895314] [32m[OPENAI] Embedding created successfully.[39m
[1693482895345] [32m[OPENAI] Embedding created successfully.[39m
[1693482895399] [33m[OPENAI] Creating embedding...[39m
[1693482895595] [32m[OPENAI] Embedding created successfully.[39m
[1693482895682] [33m[OPENAI] Creating embedding...[39m
[1693482895707] [33m[OPENAI] Creating embedding...[39m
[1693482895810] [32m[OPENAI] Embedding created successfully.[39m
[1693482895865] [32m[OPENAI] Embedding created successfully.[39m
[1693482895866] [32m[OPENAI] Embedding created successfully.[39m
[1693482895939] [33m[OPENAI] Creating embedding...[39m
[1693482896107] [32m[OPENAI] Embedding created successfully.[39m
[1693482896181] [33m[OPENAI] Creating embedding...[39m
[1693482896200] [33m[OPENAI] Creating embedding...[39m
[1693482896271] [33m[OPENAI] Creating embedding...[39m
[1693482896352] [32m[OPENAI] Embedding created successfully.[39m
[1693482896448] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482896449] [32m[OPENAI] Embedding created successfully.[39m
[1693482896450] [32m[OPENAI] Embedding created successfully.[39m
[1693482896712] [33m[OPENAI] Creating embedding...[39m
[1693482896777] [33m[OPENAI] Creating embedding...[39m
[1693482896833] [33m[OPENAI] Creating embedding...[39m
[1693482896865] [32m[OPENAI] Embedding created successfully.[39m
[1693482896931] [32m[OPENAI] Embedding created successfully.[39m
[1693482897011] [32m[OPENAI] Embedding created successfully.[39m
[1693482897258] [33m[OPENAI] Creating embedding...[39m
[1693482897340] [33m[OPENAI] Creating embedding...[39m
[1693482897362] [33m[OPENAI] Creating embedding...[39m
[1693482897458] [32m[OPENAI] Embedding created successfully.[39m
[1693482897516] [32m[OPENAI] Embedding created successfully.[39m
[1693482897538] [32m[OPENAI] Embedding created successfully.[39m
[1693482897809] [33m[OPENAI] Creating embedding...[39m
[1693482897849] [33m[OPENAI] Creating embedding...[39m
[1693482897911] [33m[OPENAI] Creating embedding...[39m
[1693482898014] [32m[OPENAI] Embedding created successfully.[39m
[1693482898148] [32m[OPENAI] Embedding created successfully.[39m
[1693482898270] [32m[OPENAI] Embedding created successfully.[39m
[1693482898343] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482898492] [33m[OPENAI] Creating embedding...[39m
[1693482898590] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482898681] [32m[OPENAI] Embedding created successfully.[39m
[1693482899060] [33m[OPENAI] Creating embedding...[39m
[1693482899195] [32m[OPENAI] Embedding created successfully.[39m
[1693482899548] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482900463] {
  "id": "chatcmpl-7taYCyfkfsk6Sy8wZoYuxV4j9eXlx",
  "object": "chat.completion",
  "created": 1693482896,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 42.53862,\n  \"y\": 17.00157\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1587,
    "completion_tokens": 37,
    "total_tokens": 1624
  }
}
[1693482900463] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 42.53862,\n  \"y\": 17.00157\n}"
  }
}
[1693482900463] [36m[OPENAI] Chat completion took 4013.8600829839706ms[39m
[1693482900464] [36m[OPENAI] Tokens per second: 9.218059233518069tps[39m
[1693482900464] [32m[OPENAI] Chat completion created successfully.[39m
[1693482900473] --- Observations received -- 
[1693482900474] {
  "observerId": "A5",
  "observation": "Eli Green has started walking to 42.53862, Y: 17.00157.",
  "time": 53.3376427
}
[1693482900474] [Character] Getting character: A5
[1693482900544] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482900544] [33m[OPENAI] Creating embedding...[39m
[1693482900798] [32m[OPENAI] Embedding created successfully.[39m
[1693482900875] --- Observations received -- 
[1693482900881] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Large) at X: 44.3, Y: 20.36.",
  "time": 53.7427254
}
[1693482900881] [Character] Getting character: A5
[1693482900945] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482900947] [33m[OPENAI] Creating embedding...[39m
[1693482901022] {
  "id": "chatcmpl-7taYGtBFI2caIlEzi7mL7SXtJouSK",
  "object": "chat.completion",
  "created": 1693482900,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693482901023] {
  "role": "assistant",
  "content": "1"
}
[1693482901023] [36m[OPENAI] Chat completion took 477.7319999933243ms[39m
[1693482901023] [36m[OPENAI] Tokens per second: 2.0932238158925376tps[39m
[1693482901023] [32m[OPENAI] Chat completion created successfully.[39m
[1693482901199] [32m[OPENAI] Embedding created successfully.[39m
[1693482901296] {
  "id": "chatcmpl-7taYHeTjtU2WLxGbT0GtfrF0vdtwM",
  "object": "chat.completion",
  "created": 1693482901,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482901297] {
  "role": "assistant",
  "content": "1"
}
[1693482901297] [36m[OPENAI] Chat completion took 350.3449590206146ms[39m
[1693482901297] [36m[OPENAI] Tokens per second: 2.8543296378389136tps[39m
[1693482901297] [32m[OPENAI] Chat completion created successfully.[39m
[1693482901396] {
  "id": "chatcmpl-7taYF8nORY7fFXjr7Nh5r7c0qTAcG",
  "object": "chat.completion",
  "created": 1693482899,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_pickaxe",
          "arguments": "{\n  \"characterId\": \"A2\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2031,
    "completion_tokens": 18,
    "total_tokens": 2049
  }
}
[1693482901397] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_pickaxe",
    "arguments": "{\n  \"characterId\": \"A2\"\n}"
  }
}
[1693482901397] [36m[OPENAI] Chat completion took 1847.9451659917831ms[39m
[1693482901397] [36m[OPENAI] Tokens per second: 9.740548762624938tps[39m
[1693482901397] [32m[OPENAI] Chat completion created successfully.[39m
[1693482901776] --- Observations received -- 
[1693482901776] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Large) at X: 41.29, Y: 22.52.",
  "time": 54.642765
}
[1693482901776] [Character] Getting character: A5
[1693482901841] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482901841] [33m[OPENAI] Creating embedding...[39m
[1693482902013] [32m[OPENAI] Embedding created successfully.[39m
[1693482902017] --- Observations received -- 
[1693482902017] {
  "observerId": "A2",
  "observation": "George Brown picked up Coal at X: 54.51481, Y: 17.53818",
  "time": 54.8852348
}
[1693482902017] [Character] Getting character: A2
[1693482902081] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482902082] [33m[OPENAI] Creating embedding...[39m
[1693482902100] {
  "id": "chatcmpl-7taYHGvSQB08XO8xE7v6KfSD3NwRA",
  "object": "chat.completion",
  "created": 1693482901,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482902100] {
  "role": "assistant",
  "content": "2"
}
[1693482902100] [36m[OPENAI] Chat completion took 258.25970792770386ms[39m
[1693482902100] [36m[OPENAI] Tokens per second: 3.872071288332502tps[39m
[1693482902100] [32m[OPENAI] Chat completion created successfully.[39m
[1693482902250] [32m[OPENAI] Embedding created successfully.[39m
[1693482902390] {
  "id": "chatcmpl-7taYEAAPDGhfMgzwZWbvhSNhAXrrz",
  "object": "chat.completion",
  "created": 1693482898,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A3\",\n  \"x\": 42.72,\n  \"y\": -12.97\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1989,
    "completion_tokens": 35,
    "total_tokens": 2024
  }
}
[1693482902390] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A3\",\n  \"x\": 42.72,\n  \"y\": -12.97\n}"
  }
}
[1693482902390] [36m[OPENAI] Chat completion took 4046.4860830307007ms[39m
[1693482902390] [36m[OPENAI] Tokens per second: 8.649479889916245tps[39m
[1693482902390] [32m[OPENAI] Chat completion created successfully.[39m
[1693482902393] --- Observations received -- 
[1693482902393] {
  "observerId": "A3",
  "observation": "Will Turner has started walking to 42.72, Y: -12.97.",
  "time": 55.26054
}
[1693482902393] [Character] Getting character: A3
[1693482902414] [Character] Getting character: A2
[1693482902433] --- Observations received -- 
[1693482902433] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 43.22001, Y: -16.37.",
  "time": 55.30103
}
[1693482902433] [Character] Getting character: A3
[1693482902438] [33m[OPENAI] Creating embedding...[39m
[1693482902464] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482902464] [33m[OPENAI] Creating embedding...[39m
[1693482902466] {
  "id": "chatcmpl-7taYEwZjWZWe6yBZBWA536TYnzdEW",
  "object": "chat.completion",
  "created": 1693482898,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.93,\n  \"y\": 9.11\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1817,
    "completion_tokens": 35,
    "total_tokens": 1852
  }
}
[1693482902466] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.93,\n  \"y\": 9.11\n}"
  }
}
[1693482902466] [36m[OPENAI] Chat completion took 3875.928290963173ms[39m
[1693482902466] [36m[OPENAI] Tokens per second: 9.030094824407202tps[39m
[1693482902466] [32m[OPENAI] Chat completion created successfully.[39m
[1693482902473] --- Observations received -- 
[1693482902473] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 53.93, Y: 9.11.",
  "time": 55.34085
}
[1693482902473] [Character] Getting character: A4
[1693482902497] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482902497] [33m[OPENAI] Creating embedding...[39m
[1693482902527] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482902528] [33m[OPENAI] Creating embedding...[39m
[1693482902574] [32m[OPENAI] Embedding created successfully.[39m
[1693482902596] {
  "id": "chatcmpl-7taYIqqb7yPxXXCJY7GsrYRYiEPV7",
  "object": "chat.completion",
  "created": 1693482902,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693482902596] {
  "role": "assistant",
  "content": "1"
}
[1693482902596] [36m[OPENAI] Chat completion took 514.3686250448227ms[39m
[1693482902596] [36m[OPENAI] Tokens per second: 1.9441310206524722tps[39m
[1693482902596] [32m[OPENAI] Chat completion created successfully.[39m
[1693482902626] [32m[OPENAI] Embedding created successfully.[39m
[1693482902639] --- Observations received -- 
[1693482902642] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Small) at X: 47.58, Y: 19.17.",
  "time": 55.5024147
}
[1693482902643] [Character] Getting character: A5
[1693482902693] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482902693] [33m[OPENAI] Creating embedding...[39m
[1693482902773] --- Observations received -- 
[1693482902773] {
  "observerId": "A5",
  "observation": "Eli Green finished walking to 42.53862, Y: 17.00157.",
  "time": 55.63998
}
[1693482902773] [Character] Getting character: A5
[1693482902775] [Character] Getting character: A5
[1693482902788] [32m[OPENAI] Embedding created successfully.[39m
[1693482902796] {
  "id": "chatcmpl-7taYInCthXqXvKMEjvV1ZAWjtpOTe",
  "object": "chat.completion",
  "created": 1693482902,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693482902796] {
  "role": "assistant",
  "content": "4"
}
[1693482902796] [36m[OPENAI] Chat completion took 298.6944580078125ms[39m
[1693482902796] [36m[OPENAI] Tokens per second: 3.3479027587912076tps[39m
[1693482902796] [32m[OPENAI] Chat completion created successfully.[39m
[1693482902799] [33m[OPENAI] Creating embedding...[39m
[1693482902825] [32m[OPENAI] Embedding created successfully.[39m
[1693482902828] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482902828] [33m[OPENAI] Creating embedding...[39m
[1693482902834] --- Observations received -- 
[1693482902834] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 45.66, Y: -15.94.",
  "time": 55.70213
}
[1693482902834] [Character] Getting character: A3
[1693482902871] [32m[OPENAI] Embedding created successfully.[39m
[1693482902887] {
  "id": "chatcmpl-7taYIWfoDM6r23BrqjdMFVnSJ6Mj9",
  "object": "chat.completion",
  "created": 1693482902,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693482902887] {
  "role": "assistant",
  "content": "3"
}
[1693482902887] [36m[OPENAI] Chat completion took 359.3900419473648ms[39m
[1693482902887] [36m[OPENAI] Tokens per second: 2.782492232064841tps[39m
[1693482902887] [32m[OPENAI] Chat completion created successfully.[39m
[1693482902893] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482902893] [33m[OPENAI] Creating embedding...[39m
[1693482902932] [33m[OPENAI] Creating embedding...[39m
[1693482902967] [32m[OPENAI] Embedding created successfully.[39m
[1693482902972] {
  "id": "chatcmpl-7taYI7KhfNYeIjVeUXpp1rodNdeX8",
  "object": "chat.completion",
  "created": 1693482902,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482902972] {
  "role": "assistant",
  "content": "1"
}
[1693482902972] [36m[OPENAI] Chat completion took 279.4588339328766ms[39m
[1693482902972] [36m[OPENAI] Tokens per second: 3.5783445666283384tps[39m
[1693482902972] [32m[OPENAI] Chat completion created successfully.[39m
[1693482902994] {
  "id": "chatcmpl-7taYIdMefd6MvIFN66MdqCJ4zp9gP",
  "object": "chat.completion",
  "created": 1693482902,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693482902994] {
  "role": "assistant",
  "content": "1"
}
[1693482902994] [36m[OPENAI] Chat completion took 529.4698749780655ms[39m
[1693482902994] [36m[OPENAI] Tokens per second: 1.8886815799320542tps[39m
[1693482902994] [32m[OPENAI] Chat completion created successfully.[39m
[1693482903065] [32m[OPENAI] Embedding created successfully.[39m
[1693482903074] --- Observations received -- 
[1693482903074] {
  "observerId": "A3",
  "observation": "Will Turner no longer sees Tree (217) at X: 36.64, Y: -10.67",
  "time": 55.9412651
}
[1693482903074] [Character] Getting character: A3
[1693482903090] {
  "id": "chatcmpl-7taYIck5OZWkffIDmSGTG934n4dMf",
  "object": "chat.completion",
  "created": 1693482902,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482903090] {
  "role": "assistant",
  "content": "2"
}
[1693482903090] [36m[OPENAI] Chat completion took 261.6151250600815ms[39m
[1693482903090] [36m[OPENAI] Tokens per second: 3.8224089672580814tps[39m
[1693482903090] [32m[OPENAI] Chat completion created successfully.[39m
[1693482903116] --- Observations received -- 
[1693482903116] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 38.96, Y: -16.52.",
  "time": 55.98308
}
[1693482903116] [Character] Getting character: A3
[1693482903131] {
  "id": "chatcmpl-7taYIQWDrpWWykpfyNZ6mtVcYwE4L",
  "object": "chat.completion",
  "created": 1693482902,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482903131] {
  "role": "assistant",
  "content": "2"
}
[1693482903131] [36m[OPENAI] Chat completion took 237.4595000743866ms[39m
[1693482903131] [36m[OPENAI] Tokens per second: 4.2112444424701465tps[39m
[1693482903131] [32m[OPENAI] Chat completion created successfully.[39m
[1693482903149] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482903149] [33m[OPENAI] Creating embedding...[39m
[1693482903150] [32m[OPENAI] Embedding created successfully.[39m
[1693482903178] --- Observations received -- 
[1693482903178] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Tree at X: 50.77, Y: 9.22.",
  "time": 56.04099
}
[1693482903178] [Character] Getting character: A4
[1693482903180] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482903180] [33m[OPENAI] Creating embedding...[39m
[1693482903190] [32m[OPENAI] Embedding created successfully.[39m
[1693482903193] --- Observations received -- 
[1693482903193] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree Stump at X: 40.39, Y: -17.62.",
  "time": 56.0604477
}
[1693482903193] [Character] Getting character: A3
[1693482903213] --- Observations received -- 
[1693482903213] {
  "observerId": "A3",
  "observation": "Will Turner no longer sees Tree (90) at X: 36.7, Y: -12.62",
  "time": 56.08057
}
[1693482903213] [Character] Getting character: A3
[1693482903241] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482903241] [33m[OPENAI] Creating embedding...[39m
[1693482903259] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482903259] [33m[OPENAI] Creating embedding...[39m
[1693482903278] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482903279] [33m[OPENAI] Creating embedding...[39m
[1693482903286] [32m[OPENAI] Embedding created successfully.[39m
[1693482903336] [32m[OPENAI] Embedding created successfully.[39m
[1693482903392] [33m[OPENAI] Creating embedding...[39m
[1693482903402] [32m[OPENAI] Embedding created successfully.[39m
[1693482903411] {
  "id": "chatcmpl-7taYJftIfO4ERmjPIFTEyOD0LXDdu",
  "object": "chat.completion",
  "created": 1693482903,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 2,
    "total_tokens": 107
  }
}
[1693482903411] {
  "role": "assistant",
  "content": "3."
}
[1693482903411] [36m[OPENAI] Chat completion took 261.84683299064636ms[39m
[1693482903411] [36m[OPENAI] Tokens per second: 7.638053044817401tps[39m
[1693482903411] [32m[OPENAI] Chat completion created successfully.[39m
[1693482903412] [32m[OPENAI] Embedding created successfully.[39m
[1693482903433] {
  "id": "chatcmpl-7taYJMkBMR29FOx7nuXW1oA77SGld",
  "object": "chat.completion",
  "created": 1693482903,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482903433] {
  "role": "assistant",
  "content": "2"
}
[1693482903433] [36m[OPENAI] Chat completion took 252.67079198360443ms[39m
[1693482903433] [36m[OPENAI] Tokens per second: 3.957719023039628tps[39m
[1693482903433] [32m[OPENAI] Chat completion created successfully.[39m
[1693482903475] --- Observations received -- 
[1693482903475] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees Tree (506) at X: 61.49, Y: 9.35",
  "time": 56.340023
}
[1693482903475] [Character] Getting character: A4
[1693482903497] [32m[OPENAI] Embedding created successfully.[39m
[1693482903521] {
  "id": "chatcmpl-7taYJuf4OY8P5X50W4BZeCEAmF1QW",
  "object": "chat.completion",
  "created": 1693482903,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482903521] {
  "role": "assistant",
  "content": "3"
}
[1693482903521] [36m[OPENAI] Chat completion took 279.7613340616226ms[39m
[1693482903521] [36m[OPENAI] Tokens per second: 3.5744753768572304tps[39m
[1693482903521] [32m[OPENAI] Chat completion created successfully.[39m
[1693482903522] [32m[OPENAI] Embedding created successfully.[39m
[1693482903526] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482903526] [33m[OPENAI] Creating embedding...[39m
[1693482903546] {
  "id": "chatcmpl-7taYJsFuftudrRM5MHiMOYF9XVx9E",
  "object": "chat.completion",
  "created": 1693482903,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693482903546] {
  "role": "assistant",
  "content": "2"
}
[1693482903546] [36m[OPENAI] Chat completion took 287.3613750934601ms[39m
[1693482903546] [36m[OPENAI] Tokens per second: 3.47993880414431tps[39m
[1693482903546] [32m[OPENAI] Chat completion created successfully.[39m
[1693482903555] --- Observations received -- 
[1693482903555] {
  "observerId": "A3",
  "observation": "Will Turner finished walking to 42.72, Y: -12.97.",
  "time": 56.41998
}
[1693482903555] [Character] Getting character: A3
[1693482903558] [33m[OPENAI] Creating embedding...[39m
[1693482903558] [Character] Getting character: A3
[1693482903584] {
  "id": "chatcmpl-7taYJ9go1jYDiMKI9imTd466PQpXs",
  "object": "chat.completion",
  "created": 1693482903,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482903584] {
  "role": "assistant",
  "content": "6"
}
[1693482903584] [36m[OPENAI] Chat completion took 305.09762501716614ms[39m
[1693482903584] [36m[OPENAI] Tokens per second: 3.277639411135159tps[39m
[1693482903584] [32m[OPENAI] Chat completion created successfully.[39m
[1693482903590] [33m[OPENAI] Creating embedding...[39m
[1693482903617] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482903617] [33m[OPENAI] Creating embedding...[39m
[1693482903668] [32m[OPENAI] Embedding created successfully.[39m
[1693482903715] --- Observations received -- 
[1693482903715] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Tree at X: 53.51, Y: 5.059999.",
  "time": 56.5829735
}
[1693482903715] [Character] Getting character: A4
[1693482903717] [32m[OPENAI] Embedding created successfully.[39m
[1693482903772] {
  "id": "chatcmpl-7taYJXAPYFodUjk6WhrXclFaTqAt0",
  "object": "chat.completion",
  "created": 1693482903,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482903772] {
  "role": "assistant",
  "content": "5"
}
[1693482903772] [36m[OPENAI] Chat completion took 245.84541702270508ms[39m
[1693482903772] [36m[OPENAI] Tokens per second: 4.06759667156067tps[39m
[1693482903772] [32m[OPENAI] Chat completion created successfully.[39m
[1693482903773] [32m[OPENAI] Embedding created successfully.[39m
[1693482903782] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482903782] [33m[OPENAI] Creating embedding...[39m
[1693482903797] [32m[OPENAI] Embedding created successfully.[39m
[1693482903910] {
  "id": "chatcmpl-7taYJQP4DTzkfNKb3Pk47vWkLQE9k",
  "object": "chat.completion",
  "created": 1693482903,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693482903911] {
  "role": "assistant",
  "content": "2"
}
[1693482903911] [36m[OPENAI] Chat completion took 293.2607500553131ms[39m
[1693482903911] [36m[OPENAI] Tokens per second: 3.409934673533318tps[39m
[1693482903911] [32m[OPENAI] Chat completion created successfully.[39m
[1693482903936] --- Observations received -- 
[1693482903936] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees CoalOreSmall (2) at X: 59.32, Y: 14.11",
  "time": 56.80096
}
[1693482903936] [Character] Getting character: A4
[1693482903948] [33m[OPENAI] Creating embedding...[39m
[1693482903979] [32m[OPENAI] Embedding created successfully.[39m
[1693482904006] {
  "id": "chatcmpl-7taYJ9itGUXJ4Uwqi32DRnIsDXhvN",
  "object": "chat.completion",
  "created": 1693482903,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693482904006] {
  "role": "assistant",
  "content": "5"
}
[1693482904006] [36m[OPENAI] Chat completion took 223.596333026886ms[39m
[1693482904006] [36m[OPENAI] Tokens per second: 4.472345259256809tps[39m
[1693482904006] [32m[OPENAI] Chat completion created successfully.[39m
[1693482904010] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482904010] [33m[OPENAI] Creating embedding...[39m
[1693482904134] [33m[OPENAI] Creating embedding...[39m
[1693482904136] [32m[OPENAI] Embedding created successfully.[39m
[1693482904141] [33m[OPENAI] Creating embedding...[39m
[1693482904213] [32m[OPENAI] Embedding created successfully.[39m
[1693482904282] {
  "id": "chatcmpl-7taYK2r4e6NdNTYYWlasbHfZB1bkt",
  "object": "chat.completion",
  "created": 1693482904,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693482904283] {
  "role": "assistant",
  "content": "5"
}
[1693482904283] [36m[OPENAI] Chat completion took 271.8319169282913ms[39m
[1693482904283] [36m[OPENAI] Tokens per second: 3.6787438770988685tps[39m
[1693482904283] [32m[OPENAI] Chat completion created successfully.[39m
[1693482904297] --- Observations received -- 
[1693482904297] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Tree at X: 50.12, Y: 6.280001.",
  "time": 57.16215
}
[1693482904297] [Character] Getting character: A4
[1693482904365] [32m[OPENAI] Embedding created successfully.[39m
[1693482904372] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482904372] [33m[OPENAI] Creating embedding...[39m
[1693482904374] [32m[OPENAI] Embedding created successfully.[39m
[1693482904498] --- Observations received -- 
[1693482904499] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Tree at X: 55.4, Y: 4.5.",
  "time": 57.3621559
}
[1693482904499] [Character] Getting character: A4
[1693482904538] --- Observations received -- 
[1693482904540] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 53.93, Y: 9.11.",
  "time": 57.39998
}
[1693482904540] [Character] Getting character: A4
[1693482904541] [Character] Getting character: A4
[1693482904591] [33m[OPENAI] Creating embedding...[39m
[1693482904625] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482904625] [33m[OPENAI] Creating embedding...[39m
[1693482904625] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482904625] [33m[OPENAI] Creating embedding...[39m
[1693482904648] [33m[OPENAI] Creating embedding...[39m
[1693482904776] [32m[OPENAI] Embedding created successfully.[39m
[1693482904818] [33m[OPENAI] Creating embedding...[39m
[1693482904818] [33m[OPENAI] Creating embedding...[39m
[1693482904820] [32m[OPENAI] Embedding created successfully.[39m
[1693482904855] [32m[OPENAI] Embedding created successfully.[39m
[1693482904859] [32m[OPENAI] Embedding created successfully.[39m
[1693482904881] {
  "id": "chatcmpl-7taYKxWLPSrwj8aJs6U2AMRpeXR2m",
  "object": "chat.completion",
  "created": 1693482904,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693482904881] {
  "role": "assistant",
  "content": "3"
}
[1693482904881] [36m[OPENAI] Chat completion took 255.92570793628693ms[39m
[1693482904881] [36m[OPENAI] Tokens per second: 3.9073839360012688tps[39m
[1693482904881] [32m[OPENAI] Chat completion created successfully.[39m
[1693482904882] [32m[OPENAI] Embedding created successfully.[39m
[1693482904884] {
  "id": "chatcmpl-7taYK3GUxEJVXHvOCRV5ALbsiZCaf",
  "object": "chat.completion",
  "created": 1693482904,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 2,
    "total_tokens": 103
  }
}
[1693482904884] {
  "role": "assistant",
  "content": "3."
}
[1693482904884] [36m[OPENAI] Chat completion took 259.10116696357727ms[39m
[1693482904884] [36m[OPENAI] Tokens per second: 7.7189926368843675tps[39m
[1693482904884] [32m[OPENAI] Chat completion created successfully.[39m
[1693482904898] {
  "id": "chatcmpl-7taYKcy9PqZdfGl6dUZ9roy6esxkC",
  "object": "chat.completion",
  "created": 1693482904,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693482904898] {
  "role": "assistant",
  "content": "5"
}
[1693482904898] [36m[OPENAI] Chat completion took 526.0685420036316ms[39m
[1693482904898] [36m[OPENAI] Tokens per second: 1.900892982863622tps[39m
[1693482904898] [32m[OPENAI] Chat completion created successfully.[39m
[1693482904984] [32m[OPENAI] Embedding created successfully.[39m
[1693482905178] [33m[OPENAI] Creating embedding...[39m
[1693482905283] [33m[OPENAI] Creating embedding...[39m
[1693482905379] [33m[OPENAI] Creating embedding...[39m
[1693482905443] [32m[OPENAI] Embedding created successfully.[39m
[1693482905447] [32m[OPENAI] Embedding created successfully.[39m
[1693482905529] [32m[OPENAI] Embedding created successfully.[39m
[1693482905783] [33m[OPENAI] Creating embedding...[39m
[1693482905823] [33m[OPENAI] Creating embedding...[39m
[1693482905894] [33m[OPENAI] Creating embedding...[39m
[1693482905964] [32m[OPENAI] Embedding created successfully.[39m
[1693482906010] [32m[OPENAI] Embedding created successfully.[39m
[1693482906033] [32m[OPENAI] Embedding created successfully.[39m
[1693482906363] [33m[OPENAI] Creating embedding...[39m
[1693482906394] [33m[OPENAI] Creating embedding...[39m
[1693482906398] [33m[OPENAI] Creating embedding...[39m
[1693482906499] [32m[OPENAI] Embedding created successfully.[39m
[1693482906617] [32m[OPENAI] Embedding created successfully.[39m
[1693482906729] [32m[OPENAI] Embedding created successfully.[39m
[1693482906881] [33m[OPENAI] Creating embedding...[39m
[1693482907012] [32m[OPENAI] Embedding created successfully.[39m
[1693482907058] [33m[OPENAI] Creating embedding...[39m
[1693482907111] [33m[OPENAI] Creating embedding...[39m
[1693482907249] [32m[OPENAI] Embedding created successfully.[39m
[1693482907300] [32m[OPENAI] Embedding created successfully.[39m
[1693482907315] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482907582] [33m[OPENAI] Creating embedding...[39m
[1693482907672] [32m[OPENAI] Embedding created successfully.[39m
[1693482907675] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482907956] [32m[OPENAI] Embedding created successfully.[39m
[1693482908078] [33m[OPENAI] Creating embedding...[39m
[1693482908346] [33m[OPENAI] Creating embedding...[39m
[1693482908465] [32m[OPENAI] Embedding created successfully.[39m
[1693482908532] [32m[OPENAI] Embedding created successfully.[39m
[1693482908861] [33m[OPENAI] Creating embedding...[39m
[1693482908901] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482909281] {
  "id": "chatcmpl-7taYNrdj4xzr6O8zqcnvM4BMZ9CDo",
  "object": "chat.completion",
  "created": 1693482907,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_pickaxe",
          "arguments": "{\n  \"characterId\": \"A5\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1812,
    "completion_tokens": 18,
    "total_tokens": 1830
  }
}
[1693482909282] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_pickaxe",
    "arguments": "{\n  \"characterId\": \"A5\"\n}"
  }
}
[1693482909282] [36m[OPENAI] Chat completion took 1965.716208100319ms[39m
[1693482909282] [36m[OPENAI] Tokens per second: 9.15696778905604tps[39m
[1693482909282] [32m[OPENAI] Chat completion created successfully.[39m
[1693482909348] [32m[OPENAI] Embedding created successfully.[39m
[1693482909794] [33m[OPENAI] Creating embedding...[39m
[1693482910001] [32m[OPENAI] Embedding created successfully.[39m
[1693482910298] [Character] Getting character: A5
[1693482910324] [33m[OPENAI] Creating embedding...[39m
[1693482910463] [33m[OPENAI] Creating embedding...[39m
[1693482910498] [32m[OPENAI] Embedding created successfully.[39m
[1693482910595] [32m[OPENAI] Embedding created successfully.[39m
[1693482910960] [33m[OPENAI] Creating embedding...[39m
[1693482911008] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482911099] {
  "id": "chatcmpl-7taYNlMqtfzJr9WVzSUBgkPRa2tKy",
  "object": "chat.completion",
  "created": 1693482907,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 50.52,\n  \"y\": 14.5\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1980,
    "completion_tokens": 35,
    "total_tokens": 2015
  }
}
[1693482911099] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 50.52,\n  \"y\": 14.5\n}"
  }
}
[1693482911099] [36m[OPENAI] Chat completion took 3423.155874967575ms[39m
[1693482911099] [36m[OPENAI] Tokens per second: 10.224483277534514tps[39m
[1693482911099] [32m[OPENAI] Chat completion created successfully.[39m
[1693482911107] --- Observations received -- 
[1693482911107] {
  "observerId": "A2",
  "observation": "George Brown has started walking to 50.52, Y: 14.5.",
  "time": 63.9748154
}
[1693482911107] [Character] Getting character: A2
[1693482911127] [32m[OPENAI] Embedding created successfully.[39m
[1693482911205] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482911205] [33m[OPENAI] Creating embedding...[39m
[1693482911214] --- Observations received -- 
[1693482911214] {
  "observerId": "A2",
  "observation": "George Brown sees Copper Ore Deposit (Medium) at X: 52.01, Y: 23.05.",
  "time": 64.08076
}
[1693482911214] [Character] Getting character: A2
[1693482911262] --- Observations received -- 
[1693482911263] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CopperOreMedium at X: 52.01, Y: 23.05",
  "time": 64.12397
}
[1693482911263] [Character] Getting character: A2
[1693482911268] {
  "id": "chatcmpl-7taYPBlOCTdzrpJ0CQMwLvDNJGSaR",
  "object": "chat.completion",
  "created": 1693482909,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_axe",
          "arguments": "{\n  \"characterId\": \"A4\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2061,
    "completion_tokens": 18,
    "total_tokens": 2079
  }
}
[1693482911269] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_axe",
    "arguments": "{\n  \"characterId\": \"A4\"\n}"
  }
}
[1693482911269] [36m[OPENAI] Chat completion took 2366.82608294487ms[39m
[1693482911269] [36m[OPENAI] Tokens per second: 7.605121529505837tps[39m
[1693482911269] [32m[OPENAI] Chat completion created successfully.[39m
[1693482911281] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482911281] [33m[OPENAI] Creating embedding...[39m
[1693482911315] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482911315] [33m[OPENAI] Creating embedding...[39m
[1693482911333] --- Observations received -- 
[1693482911333] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CoalOreMedium (2) at X: 59.9, Y: 16.03",
  "time": 64.20086
}
[1693482911333] [Character] Getting character: A2
[1693482911340] [32m[OPENAI] Embedding created successfully.[39m
[1693482911379] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482911379] [33m[OPENAI] Creating embedding...[39m
[1693482911434] {
  "id": "chatcmpl-7taYRxLzypFFxepnuSFd7ZEMZZdiz",
  "object": "chat.completion",
  "created": 1693482911,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693482911434] {
  "role": "assistant",
  "content": "1"
}
[1693482911434] [36m[OPENAI] Chat completion took 228.75683295726776ms[39m
[1693482911434] [36m[OPENAI] Tokens per second: 4.371454120396928tps[39m
[1693482911434] [32m[OPENAI] Chat completion created successfully.[39m
[1693482911478] [33m[OPENAI] Creating embedding...[39m
[1693482911516] {
  "id": "chatcmpl-7taYRwE7QtraDdr4ZEhMFVxYgjzz2",
  "object": "chat.completion",
  "created": 1693482911,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482911516] {
  "role": "assistant",
  "content": "3"
}
[1693482911516] [36m[OPENAI] Chat completion took 234.9458750486374ms[39m
[1693482911516] [36m[OPENAI] Tokens per second: 4.256299455323422tps[39m
[1693482911516] [32m[OPENAI] Chat completion created successfully.[39m
[1693482911519] [32m[OPENAI] Embedding created successfully.[39m
[1693482911548] [32m[OPENAI] Embedding created successfully.[39m
[1693482911645] {
  "id": "chatcmpl-7taYRbrnVXoOiNjdIb1iU0668zUKT",
  "object": "chat.completion",
  "created": 1693482911,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693482911645] {
  "role": "assistant",
  "content": "2"
}
[1693482911645] [36m[OPENAI] Chat completion took 265.40358304977417ms[39m
[1693482911645] [36m[OPENAI] Tokens per second: 3.767846645131609tps[39m
[1693482911645] [32m[OPENAI] Chat completion created successfully.[39m
[1693482911748] [32m[OPENAI] Embedding created successfully.[39m
[1693482911856] {
  "id": "chatcmpl-7taYRpaZ9Kqlt3PvlH4eCZ4ByRKGk",
  "object": "chat.completion",
  "created": 1693482911,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482911856] {
  "role": "assistant",
  "content": "1"
}
[1693482911856] [36m[OPENAI] Chat completion took 540.5113749504089ms[39m
[1693482911856] [36m[OPENAI] Tokens per second: 1.8500998246183968tps[39m
[1693482911856] [32m[OPENAI] Chat completion created successfully.[39m
[1693482911949] [32m[OPENAI] Embedding created successfully.[39m
[1693482911980] --- Observations received -- 
[1693482911980] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CoalOreLarge (1) at X: 58.91, Y: 19.37",
  "time": 64.84736
}
[1693482911980] [Character] Getting character: A2
[1693482912076] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482912076] [33m[OPENAI] Creating embedding...[39m
[1693482912156] [33m[OPENAI] Creating embedding...[39m
[1693482912282] [Character] Getting character: A4
[1693482912295] [32m[OPENAI] Embedding created successfully.[39m
[1693482912310] [33m[OPENAI] Creating embedding...[39m
[1693482912328] {
  "id": "chatcmpl-7taYSuDIJ0SKG2Wfz994tjSFaUq1m",
  "object": "chat.completion",
  "created": 1693482912,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693482912328] {
  "role": "assistant",
  "content": "2"
}
[1693482912328] [36m[OPENAI] Chat completion took 251.8145830631256ms[39m
[1693482912328] [36m[OPENAI] Tokens per second: 3.9711758859863853tps[39m
[1693482912328] [32m[OPENAI] Chat completion created successfully.[39m
[1693482912332] [32m[OPENAI] Embedding created successfully.[39m
[1693482912415] --- Observations received -- 
[1693482912415] {
  "observerId": "A2",
  "observation": "George Brown sees Thomas Smith at X: 48.72, Y: 13.43.",
  "time": 65.28037
}
[1693482912415] [Character] Getting character: A2
[1693482912483] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482912483] [33m[OPENAI] Creating embedding...[39m
[1693482912494] [32m[OPENAI] Embedding created successfully.[39m
[1693482912553] --- Observations received -- 
[1693482912553] {
  "observerId": "A2",
  "observation": "George Brown sees Tree at X: 52.41, Y: 11.03.",
  "time": 65.42054
}
[1693482912554] [Character] Getting character: A2
[1693482912628] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482912628] [33m[OPENAI] Creating embedding...[39m
[1693482912635] --- Observations received -- 
[1693482912635] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CopperOreMedium (2) at X: 53.76, Y: 21.7",
  "time": 65.50138
}
[1693482912635] [Character] Getting character: A2
[1693482912643] [32m[OPENAI] Embedding created successfully.[39m
[1693482912709] [33m[OPENAI] Creating embedding...[39m
[1693482912709] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482912709] [33m[OPENAI] Creating embedding...[39m
[1693482912726] {
  "id": "chatcmpl-7taYSUo1WKfqT55bwqVc4WDRFGmH3",
  "object": "chat.completion",
  "created": 1693482912,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693482912726] {
  "role": "assistant",
  "content": "3"
}
[1693482912726] [36m[OPENAI] Chat completion took 243.49658298492432ms[39m
[1693482912726] [36m[OPENAI] Tokens per second: 4.106833811552556tps[39m
[1693482912726] [32m[OPENAI] Chat completion created successfully.[39m
[1693482912773] [32m[OPENAI] Embedding created successfully.[39m
[1693482912776] --- Observations received -- 
[1693482912776] {
  "observerId": "A2",
  "observation": "George Brown sees Stone Ore Deposit (Small) at X: 47.58, Y: 19.17.",
  "time": 65.643425
}
[1693482912776] [Character] Getting character: A2
[1693482912855] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482912856] [33m[OPENAI] Creating embedding...[39m
[1693482912887] [32m[OPENAI] Embedding created successfully.[39m
[1693482912914] {
  "id": "chatcmpl-7taYShVvj7YLiVLn79BKSVeSXElMy",
  "object": "chat.completion",
  "created": 1693482912,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482912914] {
  "role": "assistant",
  "content": "2"
}
[1693482912914] [36m[OPENAI] Chat completion took 285.2493749856949ms[39m
[1693482912914] [36m[OPENAI] Tokens per second: 3.505704438616735tps[39m
[1693482912914] [32m[OPENAI] Chat completion created successfully.[39m
[1693482912944] [33m[OPENAI] Creating embedding...[39m
[1693482912966] {
  "id": "chatcmpl-7taYSnEtZEfOM4NoJYV8EDGwMWa1R",
  "object": "chat.completion",
  "created": 1693482912,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693482912966] {
  "role": "assistant",
  "content": "1"
}
[1693482912966] [36m[OPENAI] Chat completion took 256.2062920331955ms[39m
[1693482912966] [36m[OPENAI] Tokens per second: 3.9031047678970916tps[39m
[1693482912966] [32m[OPENAI] Chat completion created successfully.[39m
[1693482912995] [32m[OPENAI] Embedding created successfully.[39m
[1693482913091] [32m[OPENAI] Embedding created successfully.[39m
[1693482913141] {
  "id": "chatcmpl-7taYShrdPcZmYW5PyTyN6pcyujc6c",
  "object": "chat.completion",
  "created": 1693482912,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482913141] {
  "role": "assistant",
  "content": "1"
}
[1693482913141] [36m[OPENAI] Chat completion took 285.29237496852875ms[39m
[1693482913141] [36m[OPENAI] Tokens per second: 3.5051760500444926tps[39m
[1693482913141] [32m[OPENAI] Chat completion created successfully.[39m
[1693482913219] [33m[OPENAI] Creating embedding...[39m
[1693482913224] [32m[OPENAI] Embedding created successfully.[39m
[1693482913316] --- Observations received -- 
[1693482913316] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CoalOreMedium (1) at X: 57.27, Y: 17.32",
  "time": 66.18007
}
[1693482913316] [Character] Getting character: A2
[1693482913391] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482913391] [33m[OPENAI] Creating embedding...[39m
[1693482913391] {
  "id": "chatcmpl-7taYRPZg4zMiIqH1j6j7fM34ViACG",
  "object": "chat.completion",
  "created": 1693482911,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_axe",
          "arguments": "{\n  \"characterId\": \"A3\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2115,
    "completion_tokens": 18,
    "total_tokens": 2133
  }
}
[1693482913391] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_axe",
    "arguments": "{\n  \"characterId\": \"A3\"\n}"
  }
}
[1693482913391] [36m[OPENAI] Chat completion took 2383.456666111946ms[39m
[1693482913391] [36m[OPENAI] Tokens per second: 7.552056748471455tps[39m
[1693482913391] [32m[OPENAI] Chat completion created successfully.[39m
[1693482913393] [32m[OPENAI] Embedding created successfully.[39m
[1693482913462] --- Observations received -- 
[1693482913462] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CopperOreSmall (2) at X: 50.43, Y: 20.71",
  "time": 66.30186
}
[1693482913462] [Character] Getting character: A2
[1693482913502] [33m[OPENAI] Creating embedding...[39m
[1693482913517] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482913520] [33m[OPENAI] Creating embedding...[39m
[1693482913548] [32m[OPENAI] Embedding created successfully.[39m
[1693482913660] {
  "id": "chatcmpl-7taYT7MYUYeeMm99nWFEOpUCwOMNV",
  "object": "chat.completion",
  "created": 1693482913,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693482913660] {
  "role": "assistant",
  "content": "3"
}
[1693482913660] [36m[OPENAI] Chat completion took 269.6105419397354ms[39m
[1693482913660] [36m[OPENAI] Tokens per second: 3.709053781077761tps[39m
[1693482913660] [32m[OPENAI] Chat completion created successfully.[39m
[1693482913674] --- Observations received -- 
[1693482913675] {
  "observerId": "A2",
  "observation": "George Brown sees Stone Ore Deposit (Small) at X: 45.73, Y: 15.31.",
  "time": 66.5406647
}
[1693482913675] [Character] Getting character: A2
[1693482913679] [32m[OPENAI] Embedding created successfully.[39m
[1693482913681] [32m[OPENAI] Embedding created successfully.[39m
[1693482913733] --- Observations received -- 
[1693482913733] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CoalOreSmall at X: 56.74, Y: 14.81",
  "time": 66.60007
}
[1693482913733] [Character] Getting character: A2
[1693482913746] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482913749] [33m[OPENAI] Creating embedding...[39m
[1693482913757] --- Observations received -- 
[1693482913757] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CopperOreSmall (3) at X: 53.88, Y: 19.83",
  "time": 66.6217
}
[1693482913757] [Character] Getting character: A2
[1693482913794] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482913794] [33m[OPENAI] Creating embedding...[39m
[1693482913801] --- Observations received -- 
[1693482913801] {
  "observerId": "A2",
  "observation": "George Brown finished walking to 50.52, Y: 14.5.",
  "time": 66.65997
}
[1693482913801] [Character] Getting character: A2
[1693482913829] [Character] Getting character: A2
[1693482913829] [33m[OPENAI] Creating embedding...[39m
[1693482913830] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482913830] [33m[OPENAI] Creating embedding...[39m
[1693482913830] {
  "id": "chatcmpl-7taYTFUMoJT7vp9pX19dn5jON859a",
  "object": "chat.completion",
  "created": 1693482913,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693482913830] {
  "role": "assistant",
  "content": "2"
}
[1693482913830] [36m[OPENAI] Chat completion took 313.0418750047684ms[39m
[1693482913830] [36m[OPENAI] Tokens per second: 3.1944608049155327tps[39m
[1693482913830] [32m[OPENAI] Chat completion created successfully.[39m
[1693482913865] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482913866] [33m[OPENAI] Creating embedding...[39m
[1693482913866] [33m[OPENAI] Creating embedding...[39m
[1693482913894] [32m[OPENAI] Embedding created successfully.[39m
[1693482913998] [32m[OPENAI] Embedding created successfully.[39m
[1693482914046] [33m[OPENAI] Creating embedding...[39m
[1693482914057] [32m[OPENAI] Embedding created successfully.[39m
[1693482914062] {
  "id": "chatcmpl-7taYTNHlGP8I19KVkdivbSntFUhwX",
  "object": "chat.completion",
  "created": 1693482913,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482914062] {
  "role": "assistant",
  "content": "3"
}
[1693482914062] [36m[OPENAI] Chat completion took 267.8934580087662ms[39m
[1693482914062] [36m[OPENAI] Tokens per second: 3.7328272494331585tps[39m
[1693482914062] [32m[OPENAI] Chat completion created successfully.[39m
[1693482914087] {
  "id": "chatcmpl-7taYT98yGcABU7bp0yyzT9hQvKv4F",
  "object": "chat.completion",
  "created": 1693482913,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482914087] {
  "role": "assistant",
  "content": "2"
}
[1693482914087] [36m[OPENAI] Chat completion took 339.98162496089935ms[39m
[1693482914087] [36m[OPENAI] Tokens per second: 2.9413354328046646tps[39m
[1693482914087] [32m[OPENAI] Chat completion created successfully.[39m
[1693482914100] [32m[OPENAI] Embedding created successfully.[39m
[1693482914117] {
  "id": "chatcmpl-7taYTewTsQI7niZJvXcsISqoJ7j3c",
  "object": "chat.completion",
  "created": 1693482913,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693482914121] {
  "role": "assistant",
  "content": "2"
}
[1693482914121] [36m[OPENAI] Chat completion took 286.35666596889496ms[39m
[1693482914121] [36m[OPENAI] Tokens per second: 3.4921484946630277tps[39m
[1693482914121] [32m[OPENAI] Chat completion created successfully.[39m
[1693482914183] {
  "id": "chatcmpl-7taYTPXGCXPLJwdEBZl6GXsiqV60a",
  "object": "chat.completion",
  "created": 1693482913,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693482914183] {
  "role": "assistant",
  "content": "3"
}
[1693482914183] [36m[OPENAI] Chat completion took 317.5570830106735ms[39m
[1693482914183] [36m[OPENAI] Tokens per second: 3.1490401364040386tps[39m
[1693482914183] [32m[OPENAI] Chat completion created successfully.[39m
[1693482914186] [32m[OPENAI] Embedding created successfully.[39m
[1693482914227] [32m[OPENAI] Embedding created successfully.[39m
[1693482914230] [32m[OPENAI] Embedding created successfully.[39m
[1693482914402] [Character] Getting character: A3
[1693482914478] [33m[OPENAI] Creating embedding...[39m
[1693482914527] [33m[OPENAI] Creating embedding...[39m
[1693482914595] [33m[OPENAI] Creating embedding...[39m
[1693482914664] [32m[OPENAI] Embedding created successfully.[39m
[1693482914679] [32m[OPENAI] Embedding created successfully.[39m
[1693482914695] [33m[OPENAI] Creating embedding...[39m
[1693482914875] --- Observations received -- 
[1693482914875] {
  "observerId": "A5",
  "observation": "Eli Green sees Thomas Smith at X: 47.33401, Y: 16.32092.",
  "time": 67.74162
}
[1693482914875] [Character] Getting character: A5
[1693482914904] [32m[OPENAI] Embedding created successfully.[39m
[1693482914941] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482914941] [33m[OPENAI] Creating embedding...[39m
[1693482914969] [32m[OPENAI] Embedding created successfully.[39m
[1693482915083] [33m[OPENAI] Creating embedding...[39m
[1693482915127] [33m[OPENAI] Creating embedding...[39m
[1693482915238] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482915239] [32m[OPENAI] Embedding created successfully.[39m
[1693482915306] [32m[OPENAI] Embedding created successfully.[39m
[1693482915323] {
  "id": "chatcmpl-7taYVF17QdC1Ng9Wnx8KqSJPxNuco",
  "object": "chat.completion",
  "created": 1693482915,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1693482915323] {
  "role": "assistant",
  "content": "2"
}
[1693482915323] [36m[OPENAI] Chat completion took 381.93912494182587ms[39m
[1693482915323] [36m[OPENAI] Tokens per second: 2.61821828322069tps[39m
[1693482915323] [32m[OPENAI] Chat completion created successfully.[39m
[1693482915362] [32m[OPENAI] Embedding created successfully.[39m
[1693482915415] [33m[OPENAI] Creating embedding...[39m
[1693482915613] --- Observations received -- 
[1693482915613] {
  "observerId": "A2",
  "observation": "George Brown no longer sees Human at X: 46.13127, Y: 16.54365",
  "time": 68.48054
}
[1693482915613] [Character] Getting character: A2
[1693482915661] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482915661] [33m[OPENAI] Creating embedding...[39m
[1693482915705] [32m[OPENAI] Embedding created successfully.[39m
[1693482915800] [33m[OPENAI] Creating embedding...[39m
[1693482915816] [32m[OPENAI] Embedding created successfully.[39m
[1693482915827] [33m[OPENAI] Creating embedding...[39m
[1693482915933] {
  "id": "chatcmpl-7taYVLzxOA1nxI4YxAfRhh8MlZg9T",
  "object": "chat.completion",
  "created": 1693482915,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1693482915933] {
  "role": "assistant",
  "content": "4"
}
[1693482915933] [36m[OPENAI] Chat completion took 271.38699996471405ms[39m
[1693482915933] [36m[OPENAI] Tokens per second: 3.6847748791578843tps[39m
[1693482915933] [32m[OPENAI] Chat completion created successfully.[39m
[1693482916042] [33m[OPENAI] Creating embedding...[39m
[1693482916121] [32m[OPENAI] Embedding created successfully.[39m
[1693482916134] [32m[OPENAI] Embedding created successfully.[39m
[1693482916230] [32m[OPENAI] Embedding created successfully.[39m
[1693482916483] [33m[OPENAI] Creating embedding...[39m
[1693482916593] [33m[OPENAI] Creating embedding...[39m
[1693482916612] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482916731] [32m[OPENAI] Embedding created successfully.[39m
[1693482916762] [32m[OPENAI] Embedding created successfully.[39m
[1693482917132] [33m[OPENAI] Creating embedding...[39m
[1693482917255] [33m[OPENAI] Creating embedding...[39m
[1693482917307] [32m[OPENAI] Embedding created successfully.[39m
[1693482917533] [32m[OPENAI] Embedding created successfully.[39m
[1693482917614] --- Observations received -- 
[1693482917614] {
  "observerId": "A5",
  "observation": "Thomas Smith started a conversation with me.",
  "time": 70.4766541
}
[1693482917614] [Character] Getting character: A5
[1693482917709] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482917709] [33m[OPENAI] Creating embedding...[39m
[1693482917719] [33m[OPENAI] Creating embedding...[39m
[1693482917844] [32m[OPENAI] Embedding created successfully.[39m
[1693482917903] [32m[OPENAI] Embedding created successfully.[39m
[1693482917932] [33m[OPENAI] Creating embedding...[39m
[1693482917965] {
  "id": "chatcmpl-7taYXHRBkkvQsqFOJWejfW1XnlOBE",
  "object": "chat.completion",
  "created": 1693482917,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 90,
    "completion_tokens": 1,
    "total_tokens": 91
  }
}
[1693482917965] {
  "role": "assistant",
  "content": "3"
}
[1693482917965] [36m[OPENAI] Chat completion took 255.58062505722046ms[39m
[1693482917965] [36m[OPENAI] Tokens per second: 3.9126596539785274tps[39m
[1693482917965] [32m[OPENAI] Chat completion created successfully.[39m
[1693482918109] [32m[OPENAI] Embedding created successfully.[39m
[1693482918315] [33m[OPENAI] Creating embedding...[39m
[1693482918482] [33m[OPENAI] Creating embedding...[39m
[1693482918515] [32m[OPENAI] Embedding created successfully.[39m
[1693482918615] [32m[OPENAI] Embedding created successfully.[39m
[1693482918833] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482918962] [33m[OPENAI] Creating embedding...[39m
[1693482919203] [32m[OPENAI] Embedding created successfully.[39m
[1693482919509] {
  "id": "chatcmpl-7taYV2TT6HP3kSafsfN2shBx9wr3B",
  "object": "chat.completion",
  "created": 1693482915,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 40.75,\n  \"y\": 19.74\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1854,
    "completion_tokens": 35,
    "total_tokens": 1889
  }
}
[1693482919509] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 40.75,\n  \"y\": 19.74\n}"
  }
}
[1693482919509] [36m[OPENAI] Chat completion took 4270.139667034149ms[39m
[1693482919509] [36m[OPENAI] Tokens per second: 8.196453214447072tps[39m
[1693482919515] [32m[OPENAI] Chat completion created successfully.[39m
[1693482919532] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482920124] {
  "id": "chatcmpl-7taYWzo3AcKtrPIoK7mf6vjfzvwVj",
  "object": "chat.completion",
  "created": 1693482916,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 52.41,\n  \"y\": 11.03\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2100,
    "completion_tokens": 35,
    "total_tokens": 2135
  }
}
[1693482920124] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 52.41,\n  \"y\": 11.03\n}"
  }
}
[1693482920124] [36m[OPENAI] Chat completion took 3512.271959066391ms[39m
[1693482920124] [36m[OPENAI] Tokens per second: 9.965059769831567tps[39m
[1693482920124] [32m[OPENAI] Chat completion created successfully.[39m
[1693482920132] --- Observations received -- 
[1693482920133] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 52.41, Y: 11.03.",
  "time": 73.00039
}
[1693482920133] [Character] Getting character: A4
[1693482920174] --- Observations received -- 
[1693482920174] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees Tree (465) at X: 55.4, Y: 4.5",
  "time": 73.04084
}
[1693482920174] [Character] Getting character: A4
[1693482920195] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482920199] [33m[OPENAI] Creating embedding...[39m
[1693482920241] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482920241] [33m[OPENAI] Creating embedding...[39m
[1693482920258] --- Observations received -- 
[1693482920259] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees Tree (500) at X: 58.16, Y: 5.91",
  "time": 73.12214
}
[1693482920259] [Character] Getting character: A4
[1693482920340] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482920341] [33m[OPENAI] Creating embedding...[39m
[1693482920355] [32m[OPENAI] Embedding created successfully.[39m
[1693482920412] --- Observations received -- 
[1693482920413] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees George Brown at X: 51.10558, Y: 14.60557.",
  "time": 73.27999
}
[1693482920413] [Character] Getting character: A4
[1693482920413] --- Observations received -- 
[1693482920413] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Chest at X: 50.52, Y: 14.5.",
  "time": 73.27999
}
[1693482920413] [Character] Getting character: A4
[1693482920428] {
  "id": "chatcmpl-7taYarufEeFsUX008Thj2e5dTdXuT",
  "object": "chat.completion",
  "created": 1693482920,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693482920428] {
  "role": "assistant",
  "content": "1"
}
[1693482920428] [36m[OPENAI] Chat completion took 233.58762502670288ms[39m
[1693482920428] [36m[OPENAI] Tokens per second: 4.28104870660714tps[39m
[1693482920428] [32m[OPENAI] Chat completion created successfully.[39m
[1693482920490] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482920490] [33m[OPENAI] Creating embedding...[39m
[1693482920496] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482920496] [33m[OPENAI] Creating embedding...[39m
[1693482920509] {
  "id": "chatcmpl-7taYaaCowoSw6hGgpqrRzUJVV0lXB",
  "object": "chat.completion",
  "created": 1693482920,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482920509] {
  "role": "assistant",
  "content": "2"
}
[1693482920509] [36m[OPENAI] Chat completion took 268.04524993896484ms[39m
[1693482920509] [36m[OPENAI] Tokens per second: 3.7307133785347983tps[39m
[1693482920509] [32m[OPENAI] Chat completion created successfully.[39m
[1693482920532] [32m[OPENAI] Embedding created successfully.[39m
[1693482920533] [32m[OPENAI] Embedding created successfully.[39m
[1693482920554] --- Observations received -- 
[1693482920554] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees Tree (466) at X: 53.51, Y: 5.059999",
  "time": 73.4215
}
[1693482920554] [Character] Getting character: A4
[1693482920632] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482920633] [33m[OPENAI] Creating embedding...[39m
[1693482920656] [32m[OPENAI] Embedding created successfully.[39m
[1693482920729] [32m[OPENAI] Embedding created successfully.[39m
[1693482920798] --- Observations received -- 
[1693482920798] {
  "observerId": "A2",
  "observation": "George Brown sees Lucy Wilde at X: 53.51617, Y: 10.45909.",
  "time": 73.66231
}
[1693482920798] [Character] Getting character: A2
[1693482920807] {
  "id": "chatcmpl-7taYaWBp4j5QkMtICLUSBugyrpcT7",
  "object": "chat.completion",
  "created": 1693482920,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482920807] {
  "role": "assistant",
  "content": "1"
}
[1693482920808] [36m[OPENAI] Chat completion took 311.707750082016ms[39m
[1693482920808] [36m[OPENAI] Tokens per second: 3.208133258595212tps[39m
[1693482920808] [32m[OPENAI] Chat completion created successfully.[39m
[1693482920809] [32m[OPENAI] Embedding created successfully.[39m
[1693482920829] {
  "id": "chatcmpl-7taYa1CEauLtyUp5DgkzAVo2UOK0A",
  "object": "chat.completion",
  "created": 1693482920,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1693482920829] {
  "role": "assistant",
  "content": "6"
}
[1693482920829] [36m[OPENAI] Chat completion took 338.145250082016ms[39m
[1693482920829] [36m[OPENAI] Tokens per second: 2.9573090255073917tps[39m
[1693482920829] [32m[OPENAI] Chat completion created successfully.[39m
[1693482920864] {
  "id": "chatcmpl-7taYawn7xfJPXD1jmRm7I8WwxFGii",
  "object": "chat.completion",
  "created": 1693482920,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6.5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 3,
    "total_tokens": 108
  }
}
[1693482920864] {
  "role": "assistant",
  "content": "6.5"
}
[1693482920864] [36m[OPENAI] Chat completion took 522.7401659488678ms[39m
[1693482920864] [36m[OPENAI] Tokens per second: 5.738988880937546tps[39m
[1693482920864] [32m[OPENAI] Chat completion created successfully.[39m
[1693482920870] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482920870] [33m[OPENAI] Creating embedding...[39m
[1693482920903] {
  "id": "chatcmpl-7taYaYEL3WA568GWjCbSgRtInipdk",
  "object": "chat.completion",
  "created": 1693482920,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482920907] {
  "role": "assistant",
  "content": "2"
}
[1693482920907] [36m[OPENAI] Chat completion took 268.7024999856949ms[39m
[1693482920907] [36m[OPENAI] Tokens per second: 3.7215880017984118tps[39m
[1693482920907] [32m[OPENAI] Chat completion created successfully.[39m
[1693482920913] --- Observations received -- 
[1693482920914] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Tree at X: 47.72001, Y: 10.21.",
  "time": 73.78099
}
[1693482920914] [Character] Getting character: A4
[1693482920978] --- Observations received -- 
[1693482920978] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees Tree (533) at X: 50.12, Y: 6.280001",
  "time": 73.84257
}
[1693482920978] [Character] Getting character: A4
[1693482920979] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482920979] [33m[OPENAI] Creating embedding...[39m
[1693482921043] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482921043] [33m[OPENAI] Creating embedding...[39m
[1693482921043] {
  "id": "chatcmpl-7taYYZVtr39YR4nNP4SeydoSLhqPs",
  "object": "chat.completion",
  "created": 1693482918,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_axe",
          "arguments": "{\n  \"characterId\": \"A3\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2154,
    "completion_tokens": 18,
    "total_tokens": 2172
  }
}
[1693482921043] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_axe",
    "arguments": "{\n  \"characterId\": \"A3\"\n}"
  }
}
[1693482921043] [36m[OPENAI] Chat completion took 2210.444333076477ms[39m
[1693482921043] [36m[OPENAI] Tokens per second: 8.143159151602681tps[39m
[1693482921043] [32m[OPENAI] Chat completion created successfully.[39m
[1693482921063] [32m[OPENAI] Embedding created successfully.[39m
[1693482921130] {
  "id": "chatcmpl-7taYapPf9YIM3kYu3kOHTvfYcmcU0",
  "object": "chat.completion",
  "created": 1693482920,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1693482921130] {
  "role": "assistant",
  "content": "5"
}
[1693482921130] [36m[OPENAI] Chat completion took 259.38679099082947ms[39m
[1693482921130] [36m[OPENAI] Tokens per second: 3.855246430167505tps[39m
[1693482921130] [32m[OPENAI] Chat completion created successfully.[39m
[1693482921177] [32m[OPENAI] Embedding created successfully.[39m
[1693482921234] --- Observations received -- 
[1693482921235] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees Tree (535) at X: 56.01, Y: 6.46",
  "time": 74.10163
}
[1693482921235] [Character] Getting character: A4
[1693482921245] [32m[OPENAI] Embedding created successfully.[39m
[1693482921313] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482921313] [33m[OPENAI] Creating embedding...[39m
[1693482921315] {
  "id": "chatcmpl-7taYbBbZWV4mbdCFNyhwgKv7JCU0M",
  "object": "chat.completion",
  "created": 1693482921,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482921315] {
  "role": "assistant",
  "content": "5"
}
[1693482921315] [36m[OPENAI] Chat completion took 272.4779589176178ms[39m
[1693482921316] [36m[OPENAI] Tokens per second: 3.670021619261852tps[39m
[1693482921316] [32m[OPENAI] Chat completion created successfully.[39m
[1693482921318] {
  "id": "chatcmpl-7taYbx2FFgp0tHs6WLO80yGMpQTin",
  "object": "chat.completion",
  "created": 1693482921,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693482921318] {
  "role": "assistant",
  "content": "4"
}
[1693482921318] [36m[OPENAI] Chat completion took 338.9788329601288ms[39m
[1693482921318] [36m[OPENAI] Tokens per second: 2.950036706621211tps[39m
[1693482921318] [32m[OPENAI] Chat completion created successfully.[39m
[1693482921467] [32m[OPENAI] Embedding created successfully.[39m
[1693482921535] --- Observations received -- 
[1693482921538] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 52.41, Y: 11.03.",
  "time": 74.39997
}
[1693482921540] [Character] Getting character: A4
[1693482921541] [Character] Getting character: A4
[1693482921579] [33m[OPENAI] Creating embedding...[39m
[1693482921593] {
  "id": "chatcmpl-7taYbGbEByHnvjhV9SUuGJcRB3l4W",
  "object": "chat.completion",
  "created": 1693482921,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482921593] {
  "role": "assistant",
  "content": "2"
}
[1693482921593] [36m[OPENAI] Chat completion took 279.78883397579193ms[39m
[1693482921593] [36m[OPENAI] Tokens per second: 3.574124048447633tps[39m
[1693482921593] [32m[OPENAI] Chat completion created successfully.[39m
[1693482921604] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482921604] [33m[OPENAI] Creating embedding...[39m
[1693482921664] --- Observations received -- 
[1693482921664] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree Stump at X: 42.72, Y: -12.97.",
  "time": 74.53151
}
[1693482921664] [Character] Getting character: A3
[1693482921664] --- Observations received -- 
[1693482921664] {
  "observerId": "A3",
  "observation": "Will Turner picked up Wood at X: 42.65073, Y: -12.84937",
  "time": 74.53151
}
[1693482921664] [Character] Getting character: A3
[1693482921720] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482921720] [33m[OPENAI] Creating embedding...[39m
[1693482921726] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482921726] [33m[OPENAI] Creating embedding...[39m
[1693482921843] [32m[OPENAI] Embedding created successfully.[39m
[1693482921849] {
  "id": "chatcmpl-7taYb3bnKXeVVGa8Ubzvyh5P0ZUjL",
  "object": "chat.completion",
  "created": 1693482921,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693482921849] {
  "role": "assistant",
  "content": "2"
}
[1693482921849] [36m[OPENAI] Chat completion took 244.81783294677734ms[39m
[1693482921849] [36m[OPENAI] Tokens per second: 4.084669764303473tps[39m
[1693482921849] [32m[OPENAI] Chat completion created successfully.[39m
[1693482921863] [32m[OPENAI] Embedding created successfully.[39m
[1693482921888] [32m[OPENAI] Embedding created successfully.[39m
[1693482921926] [32m[OPENAI] Embedding created successfully.[39m
[1693482921992] {
  "id": "chatcmpl-7taYbrYYMGOoU7S548DypErVLeUAG",
  "object": "chat.completion",
  "created": 1693482921,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 2,
    "total_tokens": 105
  }
}
[1693482921992] {
  "role": "assistant",
  "content": "2."
}
[1693482921993] [36m[OPENAI] Chat completion took 264.2123329639435ms[39m
[1693482921993] [36m[OPENAI] Tokens per second: 7.569669354809928tps[39m
[1693482921993] [32m[OPENAI] Chat completion created successfully.[39m
[1693482922037] {
  "id": "chatcmpl-7taYbNe2Sfsg6Ru6yZVkJFRfPDo9H",
  "object": "chat.completion",
  "created": 1693482921,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693482922037] {
  "role": "assistant",
  "content": "2"
}
[1693482922037] [36m[OPENAI] Chat completion took 317.0151250362396ms[39m
[1693482922037] [36m[OPENAI] Tokens per second: 3.154423625326031tps[39m
[1693482922037] [32m[OPENAI] Chat completion created successfully.[39m
[1693482922060] [Character] Getting character: A3
[1693482922097] [33m[OPENAI] Creating embedding...[39m
[1693482922313] [33m[OPENAI] Creating embedding...[39m
[1693482922324] [32m[OPENAI] Embedding created successfully.[39m
[1693482922631] [32m[OPENAI] Embedding created successfully.[39m
[1693482922757] [33m[OPENAI] Creating embedding...[39m
[1693482922967] [32m[OPENAI] Embedding created successfully.[39m
[1693482923056] [33m[OPENAI] Creating embedding...[39m
[1693482923355] [32m[OPENAI] Embedding created successfully.[39m
[1693482923366] [33m[OPENAI] Creating embedding...[39m
[1693482923645] [32m[OPENAI] Embedding created successfully.[39m
[1693482923837] [33m[OPENAI] Creating embedding...[39m
[1693482923839] {
  "id": "chatcmpl-7taYZnTiJ3x04rgaBrOXpuuQLeP80",
  "object": "chat.completion",
  "created": 1693482919,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "add_coal_to_chest",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"chestId\": \"chest_(50.52,14.5)\",\n  \"itemId\": \"coal\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2459,
    "completion_tokens": 44,
    "total_tokens": 2503
  }
}
[1693482923839] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "add_coal_to_chest",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"chestId\": \"chest_(50.52,14.5)\",\n  \"itemId\": \"coal\"\n}"
  }
}
[1693482923839] [36m[OPENAI] Chat completion took 4306.850041985512ms[39m
[1693482923839] [36m[OPENAI] Tokens per second: 10.21628326295648tps[39m
[1693482923839] [32m[OPENAI] Chat completion created successfully.[39m
[1693482923850] [Character] Getting character: A2
[1693482923875] [33m[OPENAI] Creating embedding...[39m
[1693482923998] [33m[OPENAI] Creating embedding...[39m
[1693482924045] [32m[OPENAI] Embedding created successfully.[39m
[1693482924095] [32m[OPENAI] Embedding created successfully.[39m
[1693482924165] [32m[OPENAI] Embedding created successfully.[39m
[1693482924495] [33m[OPENAI] Creating embedding...[39m
[1693482924604] [33m[OPENAI] Creating embedding...[39m
[1693482924649] [33m[OPENAI] Creating embedding...[39m
[1693482924846] [32m[OPENAI] Embedding created successfully.[39m
[1693482924948] [32m[OPENAI] Embedding created successfully.[39m
[1693482925033] [32m[OPENAI] Embedding created successfully.[39m
[1693482925285] [33m[OPENAI] Creating embedding...[39m
[1693482925353] [33m[OPENAI] Creating embedding...[39m
[1693482925428] [33m[OPENAI] Creating embedding...[39m
[1693482925447] [32m[OPENAI] Embedding created successfully.[39m
[1693482925519] [32m[OPENAI] Embedding created successfully.[39m
[1693482925711] [32m[OPENAI] Embedding created successfully.[39m
[1693482925816] [33m[OPENAI] Creating embedding...[39m
[1693482925927] [33m[OPENAI] Creating embedding...[39m
[1693482926011] [32m[OPENAI] Embedding created successfully.[39m
[1693482926124] [32m[OPENAI] Embedding created successfully.[39m
[1693482926176] [33m[OPENAI] Creating embedding...[39m
[1693482926362] [33m[OPENAI] Creating embedding...[39m
[1693482926390] [32m[OPENAI] Embedding created successfully.[39m
[1693482926573] [32m[OPENAI] Embedding created successfully.[39m
[1693482926574] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482926720] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482926986] [33m[OPENAI] Creating embedding...[39m
[1693482927191] [32m[OPENAI] Embedding created successfully.[39m
[1693482927714] [33m[OPENAI] Creating embedding...[39m
[1693482927862] [32m[OPENAI] Embedding created successfully.[39m
[1693482928305] [33m[OPENAI] Creating embedding...[39m
[1693482928470] [32m[OPENAI] Embedding created successfully.[39m
[1693482928745] {
  "id": "chatcmpl-7taYgJ6u8FlIoQAdVpTZTwCsJj1o6",
  "object": "chat.completion",
  "created": 1693482926,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_axe",
          "arguments": "{\n  \"characterId\": \"A4\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1927,
    "completion_tokens": 18,
    "total_tokens": 1945
  }
}
[1693482928745] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_axe",
    "arguments": "{\n  \"characterId\": \"A4\"\n}"
  }
}
[1693482928745] [36m[OPENAI] Chat completion took 2170.4895420074463ms[39m
[1693482928745] [36m[OPENAI] Tokens per second: 8.293059999428575tps[39m
[1693482928745] [32m[OPENAI] Chat completion created successfully.[39m
[1693482928844] [33m[OPENAI] Creating embedding...[39m
[1693482929028] [32m[OPENAI] Embedding created successfully.[39m
[1693482929361] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482929777] [Character] Getting character: A4
[1693482929806] [33m[OPENAI] Creating embedding...[39m
[1693482929980] [32m[OPENAI] Embedding created successfully.[39m
[1693482930045] {
  "id": "chatcmpl-7taYgufoODTTbdGBQH0RNanNcuWTL",
  "object": "chat.completion",
  "created": 1693482926,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A3\",\n  \"x\": 44.48,\n  \"y\": -14.04\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2108,
    "completion_tokens": 35,
    "total_tokens": 2143
  }
}
[1693482930045] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A3\",\n  \"x\": 44.48,\n  \"y\": -14.04\n}"
  }
}
[1693482930045] [36m[OPENAI] Chat completion took 3320.35837495327ms[39m
[1693482930045] [36m[OPENAI] Tokens per second: 10.541030830894146tps[39m
[1693482930045] [32m[OPENAI] Chat completion created successfully.[39m
[1693482930058] --- Observations received -- 
[1693482930058] {
  "observerId": "A3",
  "observation": "Will Turner has started walking to 44.48, Y: -14.04.",
  "time": 82.9169159
}
[1693482930058] [Character] Getting character: A3
[1693482930164] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482930164] [33m[OPENAI] Creating embedding...[39m
[1693482930314] --- Observations received -- 
[1693482930314] {
  "observerId": "A3",
  "observation": "Will Turner no longer sees Tree (169) at X: 38.96, Y: -16.52",
  "time": 83.18184
}
[1693482930314] [Character] Getting character: A3
[1693482930374] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482930374] [33m[OPENAI] Creating embedding...[39m
[1693482930396] --- Observations received -- 
[1693482930396] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 47.86, Y: -15.94.",
  "time": 83.26093
}
[1693482930396] [Character] Getting character: A3
[1693482930415] [33m[OPENAI] Creating embedding...[39m
[1693482930436] [32m[OPENAI] Embedding created successfully.[39m
[1693482930462] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482930462] [33m[OPENAI] Creating embedding...[39m
[1693482930475] --- Observations received -- 
[1693482930475] {
  "observerId": "A3",
  "observation": "Will Turner no longer sees Tree (285) at X: 38.75, Y: -9.01",
  "time": 83.3420944
}
[1693482930475] [Character] Getting character: A3
[1693482930487] {
  "id": "chatcmpl-7taYkz53zVGCe6snagdgZmKPFCz47",
  "object": "chat.completion",
  "created": 1693482930,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693482930487] {
  "role": "assistant",
  "content": "1"
}
[1693482930487] [36m[OPENAI] Chat completion took 323.2068330049515ms[39m
[1693482930487] [36m[OPENAI] Tokens per second: 3.093993993575873tps[39m
[1693482930487] [32m[OPENAI] Chat completion created successfully.[39m
[1693482930557] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482930558] [33m[OPENAI] Creating embedding...[39m
[1693482930569] [32m[OPENAI] Embedding created successfully.[39m
[1693482930633] --- Observations received -- 
[1693482930635] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 42.61, Y: -18.15.",
  "time": 83.5002
}
[1693482930635] [Character] Getting character: A3
[1693482930649] [32m[OPENAI] Embedding created successfully.[39m
[1693482930687] [32m[OPENAI] Embedding created successfully.[39m
[1693482930712] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482930713] [33m[OPENAI] Creating embedding...[39m
[1693482930740] {
  "id": "chatcmpl-7taYkLZ6Elgp1DnSNmtrROppoRLjA",
  "object": "chat.completion",
  "created": 1693482930,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482930740] {
  "role": "assistant",
  "content": "1"
}
[1693482930740] [36m[OPENAI] Chat completion took 276.9591660499573ms[39m
[1693482930740] [36m[OPENAI] Tokens per second: 3.610640565763482tps[39m
[1693482930740] [32m[OPENAI] Chat completion created successfully.[39m
[1693482930747] [32m[OPENAI] Embedding created successfully.[39m
[1693482930754] --- Observations received -- 
[1693482930754] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 44.34, Y: -18.3.",
  "time": 83.6211
}
[1693482930754] [Character] Getting character: A3
[1693482930823] {
  "id": "chatcmpl-7taYkELluslLoJ8yXAIcdHqF0L6s8",
  "object": "chat.completion",
  "created": 1693482930,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482930823] {
  "role": "assistant",
  "content": "5"
}
[1693482930823] [36m[OPENAI] Chat completion took 265.9032920598984ms[39m
[1693482930823] [36m[OPENAI] Tokens per second: 3.7607657741023237tps[39m
[1693482930823] [32m[OPENAI] Chat completion created successfully.[39m
[1693482930824] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482930824] [33m[OPENAI] Creating embedding...[39m
[1693482930875] {
  "id": "chatcmpl-7taYkYTfWho7VbIZm1fDT4k1Lo5cD",
  "object": "chat.completion",
  "created": 1693482930,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482930875] {
  "role": "assistant",
  "content": "2"
}
[1693482930875] [36m[OPENAI] Chat completion took 500.5732500553131ms[39m
[1693482930875] [36m[OPENAI] Tokens per second: 1.997709625693144tps[39m
[1693482930875] [32m[OPENAI] Chat completion created successfully.[39m
[1693482930908] [32m[OPENAI] Embedding created successfully.[39m
[1693482930978] --- Observations received -- 
[1693482930978] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 46.7, Y: -18.14.",
  "time": 83.84329
}
[1693482930978] [Character] Getting character: A3
[1693482931020] {
  "id": "chatcmpl-7taYkcY48Rz59mQemFcBp29rOvtYn",
  "object": "chat.completion",
  "created": 1693482930,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482931020] {
  "role": "assistant",
  "content": "3"
}
[1693482931020] [36m[OPENAI] Chat completion took 307.6174590587616ms[39m
[1693482931020] [36m[OPENAI] Tokens per second: 3.2507907810556955tps[39m
[1693482931020] [32m[OPENAI] Chat completion created successfully.[39m
[1693482931023] [32m[OPENAI] Embedding created successfully.[39m
[1693482931048] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482931048] [33m[OPENAI] Creating embedding...[39m
[1693482931128] [33m[OPENAI] Creating embedding...[39m
[1693482931145] {
  "id": "chatcmpl-7taYkVKPAeUtDSCfVGsXTNFxEB43h",
  "object": "chat.completion",
  "created": 1693482930,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482931145] {
  "role": "assistant",
  "content": "1"
}
[1693482931145] [36m[OPENAI] Chat completion took 320.45995903015137ms[39m
[1693482931145] [36m[OPENAI] Tokens per second: 3.1205146596985998tps[39m
[1693482931145] [32m[OPENAI] Chat completion created successfully.[39m
[1693482931175] --- Observations received -- 
[1693482931175] {
  "observerId": "A3",
  "observation": "Will Turner finished walking to 44.48, Y: -14.04.",
  "time": 84.03997
}
[1693482931175] [Character] Getting character: A3
[1693482931180] [Character] Getting character: A3
[1693482931216] [33m[OPENAI] Creating embedding...[39m
[1693482931246] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482931246] [33m[OPENAI] Creating embedding...[39m
[1693482931310] {
  "id": "chatcmpl-7taYlqEnow2sBjzUUrScwXvlCwFkU",
  "object": "chat.completion",
  "created": 1693482931,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 2,
    "total_tokens": 103
  }
}
[1693482931311] {
  "role": "assistant",
  "content": "4."
}
[1693482931311] [36m[OPENAI] Chat completion took 262.2132499217987ms[39m
[1693482931311] [36m[OPENAI] Tokens per second: 7.627379625539406tps[39m
[1693482931311] [32m[OPENAI] Chat completion created successfully.[39m
[1693482931320] [32m[OPENAI] Embedding created successfully.[39m
[1693482931405] [32m[OPENAI] Embedding created successfully.[39m
[1693482931405] [32m[OPENAI] Embedding created successfully.[39m
[1693482931513] {
  "id": "chatcmpl-7taYlgalkNSpcMN3EmXQghO8RFB5K",
  "object": "chat.completion",
  "created": 1693482931,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693482931513] {
  "role": "assistant",
  "content": "1"
}
[1693482931513] [36m[OPENAI] Chat completion took 266.51716697216034ms[39m
[1693482931513] [36m[OPENAI] Tokens per second: 3.7521035187367775tps[39m
[1693482931513] [32m[OPENAI] Chat completion created successfully.[39m
[1693482931760] [32m[OPENAI] Embedding created successfully.[39m
[1693482931827] [33m[OPENAI] Creating embedding...[39m
[1693482931896] [33m[OPENAI] Creating embedding...[39m
[1693482932028] [32m[OPENAI] Embedding created successfully.[39m
[1693482932030] [32m[OPENAI] Embedding created successfully.[39m
[1693482932474] [33m[OPENAI] Creating embedding...[39m
[1693482932485] [33m[OPENAI] Creating embedding...[39m
[1693482932672] [32m[OPENAI] Embedding created successfully.[39m
[1693482932673] [33m[CONVERSATION] Starting conversation as player ...[39m
[1693482932673] [33m[CONVERSATION] Starting conversation...[39m
[1693482932673] [33m[CONVERSATION] Player: A1[39m
[1693482932673] [33m[CONVERSATION] Character: A5[39m
[1693482932706] [32m[OPENAI] Embedding created successfully.[39m
[1693482932737] [33m[OPENAI] Creating embedding...[39m
[1693482932930] [32m[OPENAI] Embedding created successfully.[39m
[1693482933161] [33m[OPENAI] Creating embedding...[39m
[1693482933244] [33m[OPENAI] Creating embedding...[39m
[1693482933302] [32m[OPENAI] Embedding created successfully.[39m
[1693482933525] [32m[OPENAI] Embedding created successfully.[39m
[1693482933551] {
  "id": "chatcmpl-7taYj0WPfzSo8Yrcp7EwPWXekmrT7",
  "object": "chat.completion",
  "created": 1693482929,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 54.64,\n  \"y\": 16.97\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2455,
    "completion_tokens": 35,
    "total_tokens": 2490
  }
}
[1693482933551] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 54.64,\n  \"y\": 16.97\n}"
  }
}
[1693482933551] [36m[OPENAI] Chat completion took 4188.970791935921ms[39m
[1693482933551] [36m[OPENAI] Tokens per second: 8.355274299686595tps[39m
[1693482933551] [32m[OPENAI] Chat completion created successfully.[39m
[1693482933561] --- Observations received -- 
[1693482933561] {
  "observerId": "A2",
  "observation": "George Brown has started walking to 54.64, Y: 16.97.",
  "time": 86.42502
}
[1693482933561] [Character] Getting character: A2
[1693482933615] --- Observations received -- 
[1693482933616] {
  "observerId": "A2",
  "observation": "George Brown sees Copper Ore Deposit (Small) at X: 53.88, Y: 19.83.",
  "time": 86.48173
}
[1693482933616] [Character] Getting character: A2
[1693482933626] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482933626] [33m[OPENAI] Creating embedding...[39m
[1693482933635] --- Observations received -- 
[1693482933635] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Small) at X: 56.74, Y: 14.81.",
  "time": 86.50197
}
[1693482933635] [Character] Getting character: A2
[1693482933680] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482933680] [33m[OPENAI] Creating embedding...[39m
[1693482933695] --- Observations received -- 
[1693482933695] {
  "observerId": "A2",
  "observation": "George Brown no longer sees StoneOreSmall (4) at X: 45.73, Y: 15.31",
  "time": 86.56199
}
[1693482933695] [Character] Getting character: A2
[1693482933713] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482933714] [33m[OPENAI] Creating embedding...[39m
[1693482933716] [33m[OPENAI] Creating embedding...[39m
[1693482933749] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482933749] [33m[OPENAI] Creating embedding...[39m
[1693482933864] [32m[OPENAI] Embedding created successfully.[39m
[1693482933929] [33m[OPENAI] Creating embedding...[39m
[1693482933937] --- Observations received -- 
[1693482933937] {
  "observerId": "A2",
  "observation": "George Brown sees Copper Ore Deposit (Small) at X: 50.43, Y: 20.71.",
  "time": 86.80158
}
[1693482933937] [Character] Getting character: A2
[1693482933938] [32m[OPENAI] Embedding created successfully.[39m
[1693482933980] [32m[OPENAI] Embedding created successfully.[39m
[1693482933984] {
  "id": "chatcmpl-7taYnp2HvOIS7E8qw8GuDnLXeRVPB",
  "object": "chat.completion",
  "created": 1693482933,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693482933984] {
  "role": "assistant",
  "content": "1"
}
[1693482933984] [36m[OPENAI] Chat completion took 358.2395420074463ms[39m
[1693482933984] [36m[OPENAI] Tokens per second: 2.7914283118953245tps[39m
[1693482933984] [32m[OPENAI] Chat completion created successfully.[39m
[1693482933994] {
  "id": "chatcmpl-7taYnIRRZmrj5KDMRyjRODzZDbcJV",
  "object": "chat.completion",
  "created": 1693482933,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482933994] {
  "role": "assistant",
  "content": "1"
}
[1693482933994] [36m[OPENAI] Chat completion took 313.47100007534027ms[39m
[1693482933994] [36m[OPENAI] Tokens per second: 3.1900877585475462tps[39m
[1693482933994] [32m[OPENAI] Chat completion created successfully.[39m
[1693482934004] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482934004] [33m[OPENAI] Creating embedding...[39m
[1693482934013] [32m[OPENAI] Embedding created successfully.[39m
[1693482934017] [32m[OPENAI] Embedding created successfully.[39m
[1693482934055] --- Observations received -- 
[1693482934057] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Medium) at X: 57.27, Y: 17.32.",
  "time": 86.9220047
}
[1693482934057] [Character] Getting character: A2
[1693482934066] {
  "id": "chatcmpl-7taYnP9qhU3q7SR3HzIvj68bi1Mpt",
  "object": "chat.completion",
  "created": 1693482933,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693482934066] {
  "role": "assistant",
  "content": "4"
}
[1693482934066] [36m[OPENAI] Chat completion took 316.74929201602936ms[39m
[1693482934066] [36m[OPENAI] Tokens per second: 3.157070987073885tps[39m
[1693482934066] [32m[OPENAI] Chat completion created successfully.[39m
[1693482934101] [32m[OPENAI] Embedding created successfully.[39m
[1693482934132] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482934132] [33m[OPENAI] Creating embedding...[39m
[1693482934166] [32m[OPENAI] Embedding created successfully.[39m
[1693482934265] {
  "id": "chatcmpl-7taYo6Dqx7L49cZJrltrYbPrNq880",
  "object": "chat.completion",
  "created": 1693482934,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482934265] {
  "role": "assistant",
  "content": "4"
}
[1693482934265] [36m[OPENAI] Chat completion took 261.13579201698303ms[39m
[1693482934265] [36m[OPENAI] Tokens per second: 3.8294252667400133tps[39m
[1693482934265] [32m[OPENAI] Chat completion created successfully.[39m
[1693482934325] {
  "id": "chatcmpl-7taYnKMMXdCFZgsRrkTo4tRUWLgCI",
  "object": "chat.completion",
  "created": 1693482933,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482934325] {
  "role": "assistant",
  "content": "1"
}
[1693482934325] [36m[OPENAI] Chat completion took 611.2944169044495ms[39m
[1693482934325] [36m[OPENAI] Tokens per second: 1.635872948200521tps[39m
[1693482934325] [32m[OPENAI] Chat completion created successfully.[39m
[1693482934361] {
  "id": "chatcmpl-7taYolfaIXOx61jHHXiGpOw2hYFF7",
  "object": "chat.completion",
  "created": 1693482934,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482934361] {
  "role": "assistant",
  "content": "3"
}
[1693482934361] [36m[OPENAI] Chat completion took 228.27174997329712ms[39m
[1693482934361] [36m[OPENAI] Tokens per second: 4.380743566021545tps[39m
[1693482934361] [32m[OPENAI] Chat completion created successfully.[39m
[1693482934451] [33m[OPENAI] Creating embedding...[39m
[1693482934466] [32m[OPENAI] Embedding created successfully.[39m
[1693482934475] --- Observations received -- 
[1693482934475] {
  "observerId": "A2",
  "observation": "George Brown no longer sees Human (3) at X: 52.5535, Y: 11.06466",
  "time": 87.3420944
}
[1693482934475] [Character] Getting character: A2
[1693482934530] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482934531] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482934531] [33m[OPENAI] Creating embedding...[39m
[1693482934595] --- Observations received -- 
[1693482934595] {
  "observerId": "A2",
  "observation": "George Brown no longer sees StoneOreSmall (5) at X: 47.58, Y: 19.17",
  "time": 87.46133
}
[1693482934595] [Character] Getting character: A2
[1693482934666] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482934666] [33m[OPENAI] Creating embedding...[39m
[1693482934680] [32m[OPENAI] Embedding created successfully.[39m
[1693482934734] --- Observations received -- 
[1693482934734] {
  "observerId": "A2",
  "observation": "George Brown sees Copper Ore Deposit (Medium) at X: 53.76, Y: 21.7.",
  "time": 87.60177
}
[1693482934734] [Character] Getting character: A2
[1693482934742] [32m[OPENAI] Embedding created successfully.[39m
[1693482934823] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482934823] [33m[OPENAI] Creating embedding...[39m
[1693482934823] --- Observations received -- 
[1693482934823] {
  "observerId": "A2",
  "observation": "George Brown no longer sees Tree (486) at X: 52.41, Y: 11.03",
  "time": 87.681015
}
[1693482934823] [Character] Getting character: A2
[1693482934878] {
  "id": "chatcmpl-7taYocbwwbSXFRdC7SQoEQpWdPYAp",
  "object": "chat.completion",
  "created": 1693482934,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 107,
    "completion_tokens": 1,
    "total_tokens": 108
  }
}
[1693482934878] {
  "role": "assistant",
  "content": "3"
}
[1693482934878] [36m[OPENAI] Chat completion took 347.23279201984406ms[39m
[1693482934878] [36m[OPENAI] Tokens per second: 2.8799123325392926tps[39m
[1693482934878] [32m[OPENAI] Chat completion created successfully.[39m
[1693482934891] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482934891] [33m[OPENAI] Creating embedding...[39m
[1693482934912] {
  "id": "chatcmpl-7taYo2OHaMEpOFABtmAwyxW3jnmkT",
  "object": "chat.completion",
  "created": 1693482934,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693482934912] {
  "role": "assistant",
  "content": "2"
}
[1693482934912] [36m[OPENAI] Chat completion took 245.95837497711182ms[39m
[1693482934912] [36m[OPENAI] Tokens per second: 4.065728601813445tps[39m
[1693482934912] [32m[OPENAI] Chat completion created successfully.[39m
[1693482934925] [32m[OPENAI] Embedding created successfully.[39m
[1693482934972] [32m[OPENAI] Embedding created successfully.[39m
[1693482934990] [33m[OPENAI] Creating embedding...[39m
[1693482935078] [32m[OPENAI] Embedding created successfully.[39m
[1693482935132] {
  "id": "chatcmpl-7taYochSDeTqcQaNsuOcxhnTldpd5",
  "object": "chat.completion",
  "created": 1693482934,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482935132] {
  "role": "assistant",
  "content": "2"
}
[1693482935132] [36m[OPENAI] Chat completion took 240.74699997901917ms[39m
[1693482935132] [36m[OPENAI] Tokens per second: 4.1537381570160745tps[39m
[1693482935132] [32m[OPENAI] Chat completion created successfully.[39m
[1693482935144] --- Observations received -- 
[1693482935144] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees Human (1) at X: 53.03603, Y: 16.53602",
  "time": 88.00171
}
[1693482935144] [Character] Getting character: A4
[1693482935145] {
  "id": "chatcmpl-7taYo73M5ReCG5COyGDkBfCM6XXIK",
  "object": "chat.completion",
  "created": 1693482934,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482935145] {
  "role": "assistant",
  "content": "2"
}
[1693482935145] [36m[OPENAI] Chat completion took 322.2604579925537ms[39m
[1693482935145] [36m[OPENAI] Tokens per second: 3.103080055894125tps[39m
[1693482935145] [32m[OPENAI] Chat completion created successfully.[39m
[1693482935157] [32m[OPENAI] Embedding created successfully.[39m
[1693482935202] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482935202] [33m[OPENAI] Creating embedding...[39m
[1693482935416] [32m[OPENAI] Embedding created successfully.[39m
[1693482935434] {
  "id": "chatcmpl-7taYp1aVO3Kn1wH4TIq26aEj0JYii",
  "object": "chat.completion",
  "created": 1693482935,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 107,
    "completion_tokens": 1,
    "total_tokens": 108
  }
}
[1693482935435] {
  "role": "assistant",
  "content": "5"
}
[1693482935435] [36m[OPENAI] Chat completion took 232.52508294582367ms[39m
[1693482935435] [36m[OPENAI] Tokens per second: 4.300611303224398tps[39m
[1693482935435] [32m[OPENAI] Chat completion created successfully.[39m
[1693482935479] --- Observations received -- 
[1693482935479] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Large) at X: 58.91, Y: 19.37.",
  "time": 88.3406
}
[1693482935479] [Character] Getting character: A2
[1693482935523] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482935546] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482935546] [33m[OPENAI] Creating embedding...[39m
[1693482935702] [32m[OPENAI] Embedding created successfully.[39m
[1693482935821] {
  "id": "chatcmpl-7taYpDvO0NJAe7Ii685kglpbj44KO",
  "object": "chat.completion",
  "created": 1693482935,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482935821] {
  "role": "assistant",
  "content": "1"
}
[1693482935822] [36m[OPENAI] Chat completion took 275.1458330154419ms[39m
[1693482935825] [36m[OPENAI] Tokens per second: 3.6344362879879686tps[39m
[1693482935825] [32m[OPENAI] Chat completion created successfully.[39m
[1693482935934] --- Observations received -- 
[1693482935935] {
  "observerId": "A2",
  "observation": "George Brown sees Copper Ore Deposit (Medium) at X: 52.01, Y: 23.05.",
  "time": 88.80147
}
[1693482935935] [Character] Getting character: A2
[1693482935993] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482935994] [33m[OPENAI] Creating embedding...[39m
[1693482936094] --- Observations received -- 
[1693482936094] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Medium) at X: 59.9, Y: 16.03.",
  "time": 88.96085
}
[1693482936094] [Character] Getting character: A2
[1693482936134] --- Observations received -- 
[1693482936134] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CopperOreMedium at X: 52.01, Y: 23.05",
  "time": 89.00069
}
[1693482936134] [Character] Getting character: A2
[1693482936162] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482936163] [33m[OPENAI] Creating embedding...[39m
[1693482936169] [32m[OPENAI] Embedding created successfully.[39m
[1693482936188] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482936189] [33m[OPENAI] Creating embedding...[39m
[1693482936258] --- Observations received -- 
[1693482936258] {
  "observerId": "A2",
  "observation": "George Brown finished walking to 54.64, Y: 16.97.",
  "time": 89.11997
}
[1693482936258] [Character] Getting character: A2
[1693482936265] [Character] Getting character: A2
[1693482936269] {
  "id": "chatcmpl-7taYqOLNKRBxgQdlR4q2iHyxtXCTF",
  "object": "chat.completion",
  "created": 1693482936,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482936269] {
  "role": "assistant",
  "content": "5"
}
[1693482936269] [36m[OPENAI] Chat completion took 275.27187502384186ms[39m
[1693482936269] [36m[OPENAI] Tokens per second: 3.632772145404931tps[39m
[1693482936269] [32m[OPENAI] Chat completion created successfully.[39m
[1693482936303] [33m[OPENAI] Creating embedding...[39m
[1693482936312] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482936312] [33m[OPENAI] Creating embedding...[39m
[1693482936366] [32m[OPENAI] Embedding created successfully.[39m
[1693482936377] [32m[OPENAI] Embedding created successfully.[39m
[1693482936436] {
  "id": "chatcmpl-7taYqS6ifKhP4glLlPRZN0VEXe7bc",
  "object": "chat.completion",
  "created": 1693482936,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482936436] {
  "role": "assistant",
  "content": "3"
}
[1693482936436] [36m[OPENAI] Chat completion took 247.67658305168152ms[39m
[1693482936436] [36m[OPENAI] Tokens per second: 4.037523401198307tps[39m
[1693482936436] [32m[OPENAI] Chat completion created successfully.[39m
[1693482936438] {
  "id": "chatcmpl-7taYqjHZkHq5ilsjFTPPADMgWskr6",
  "object": "chat.completion",
  "created": 1693482936,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482936438] {
  "role": "assistant",
  "content": "4"
}
[1693482936438] [36m[OPENAI] Chat completion took 275.60025000572205ms[39m
[1693482936438] [36m[OPENAI] Tokens per second: 3.6284437331941386tps[39m
[1693482936438] [32m[OPENAI] Chat completion created successfully.[39m
[1693482936439] [32m[OPENAI] Embedding created successfully.[39m
[1693482936463] [32m[OPENAI] Embedding created successfully.[39m
[1693482936567] {
  "id": "chatcmpl-7taYqzPgT50s5JcV3Vv6trthQhcYf",
  "object": "chat.completion",
  "created": 1693482936,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693482936567] {
  "role": "assistant",
  "content": "2"
}
[1693482936567] [36m[OPENAI] Chat completion took 254.48624992370605ms[39m
[1693482936567] [36m[OPENAI] Tokens per second: 3.929485385948341tps[39m
[1693482936567] [32m[OPENAI] Chat completion created successfully.[39m
[1693482936667] {
  "id": "chatcmpl-7taYowQLxnAHwqND7MkjDeJa6juEI",
  "object": "chat.completion",
  "created": 1693482934,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_axe",
          "arguments": "{\n  \"characterId\": \"A4\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1966,
    "completion_tokens": 18,
    "total_tokens": 1984
  }
}
[1693482936667] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_axe",
    "arguments": "{\n  \"characterId\": \"A4\"\n}"
  }
}
[1693482936667] [36m[OPENAI] Chat completion took 2136.338500022888ms[39m
[1693482936667] [36m[OPENAI] Tokens per second: 8.42563105041975tps[39m
[1693482936667] [32m[OPENAI] Chat completion created successfully.[39m
[1693482936911] [33m[OPENAI] Creating embedding...[39m
[1693482937099] [32m[OPENAI] Embedding created successfully.[39m
[1693482937302] --- Observations received -- 
[1693482937302] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Tree Stump at X: 52.41, Y: 11.03.",
  "time": 90.16179
}
[1693482937302] [Character] Getting character: A4
[1693482937302] --- Observations received -- 
[1693482937302] {
  "observerId": "A4",
  "observation": "Lucy Wilde picked up Wood at X: 52.5535, Y: 11.06466",
  "time": 90.16179
}
[1693482937302] [Character] Getting character: A4
[1693482937361] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482937361] [33m[OPENAI] Creating embedding...[39m
[1693482937363] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482937363] [33m[OPENAI] Creating embedding...[39m
[1693482937476] {
  "id": "chatcmpl-7taYpNAHxAmDOsd8LLFm4kyBX6K2U",
  "object": "chat.completion",
  "created": 1693482935,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_axe",
          "arguments": "{\n  \"characterId\": \"A3\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2366,
    "completion_tokens": 18,
    "total_tokens": 2384
  }
}
[1693482937476] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_axe",
    "arguments": "{\n  \"characterId\": \"A3\"\n}"
  }
}
[1693482937476] [36m[OPENAI] Chat completion took 1953.0532920360565ms[39m
[1693482937476] [36m[OPENAI] Tokens per second: 9.21633837304819tps[39m
[1693482937476] [32m[OPENAI] Chat completion created successfully.[39m
[1693482937503] [32m[OPENAI] Embedding created successfully.[39m
[1693482937534] [32m[OPENAI] Embedding created successfully.[39m
[1693482937555] [33m[OPENAI] Creating embedding...[39m
[1693482937596] {
  "id": "chatcmpl-7taYrqWGZJB9rExIGO3ip1N9V0snC",
  "object": "chat.completion",
  "created": 1693482937,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693482937596] {
  "role": "assistant",
  "content": "1"
}
[1693482937596] [36m[OPENAI] Chat completion took 232.7117919921875ms[39m
[1693482937596] [36m[OPENAI] Tokens per second: 4.297160841912006tps[39m
[1693482937596] [32m[OPENAI] Chat completion created successfully.[39m
[1693482937629] {
  "id": "chatcmpl-7taYr1xTCjPpMxGBgyFXzqx8n6RYG",
  "object": "chat.completion",
  "created": 1693482937,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693482937629] {
  "role": "assistant",
  "content": "2"
}
[1693482937629] [36m[OPENAI] Chat completion took 268.15291595458984ms[39m
[1693482937629] [36m[OPENAI] Tokens per second: 3.729215460664035tps[39m
[1693482937629] [32m[OPENAI] Chat completion created successfully.[39m
[1693482937679] [Character] Getting character: A4
[1693482937706] [33m[OPENAI] Creating embedding...[39m
[1693482937741] [32m[OPENAI] Embedding created successfully.[39m
[1693482938148] [33m[OPENAI] Creating embedding...[39m
[1693482938151] [32m[OPENAI] Embedding created successfully.[39m
[1693482938338] [32m[OPENAI] Embedding created successfully.[39m
[1693482938490] [Character] Getting character: A3
[1693482938523] [33m[OPENAI] Creating embedding...[39m
[1693482938571] [33m[OPENAI] Creating embedding...[39m
[1693482938730] [32m[OPENAI] Embedding created successfully.[39m
[1693482938750] [33m[OPENAI] Creating embedding...[39m
[1693482938753] [32m[OPENAI] Embedding created successfully.[39m
[1693482938996] [32m[OPENAI] Embedding created successfully.[39m
[1693482939089] [33m[OPENAI] Creating embedding...[39m
[1693482939196] [33m[OPENAI] Creating embedding...[39m
[1693482939287] [32m[OPENAI] Embedding created successfully.[39m
[1693482939393] [32m[OPENAI] Embedding created successfully.[39m
[1693482939428] [33m[OPENAI] Creating embedding...[39m
[1693482939596] [32m[OPENAI] Embedding created successfully.[39m
[1693482939696] [33m[OPENAI] Creating embedding...[39m
[1693482939800] [33m[OPENAI] Creating embedding...[39m
[1693482939864] [32m[OPENAI] Embedding created successfully.[39m
[1693482939958] [32m[OPENAI] Embedding created successfully.[39m
[1693482940111] [33m[OPENAI] Creating embedding...[39m
[1693482940326] [33m[OPENAI] Creating embedding...[39m
[1693482940349] [32m[OPENAI] Embedding created successfully.[39m
[1693482940352] [33m[OPENAI] Creating embedding...[39m
[1693482940521] [32m[OPENAI] Embedding created successfully.[39m
[1693482940561] [32m[OPENAI] Embedding created successfully.[39m
[1693482940881] [33m[OPENAI] Creating embedding...[39m
[1693482941012] [33m[OPENAI] Creating embedding...[39m
[1693482941016] [33m[OPENAI] Creating embedding...[39m
[1693482941017] [32m[OPENAI] Embedding created successfully.[39m
[1693482941151] [32m[OPENAI] Embedding created successfully.[39m
[1693482941181] [32m[OPENAI] Embedding created successfully.[39m
[1693482941434] [33m[OPENAI] Creating embedding...[39m
[1693482941561] [33m[OPENAI] Creating embedding...[39m
[1693482941575] [33m[OPENAI] Creating embedding...[39m
[1693482941637] [32m[OPENAI] Embedding created successfully.[39m
[1693482941754] [32m[OPENAI] Embedding created successfully.[39m
[1693482941845] [32m[OPENAI] Embedding created successfully.[39m
[1693482942072] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482942180] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482942227] [33m[OPENAI] Creating embedding...[39m
[1693482942655] [32m[OPENAI] Embedding created successfully.[39m
[1693482943002] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482945107] {
  "id": "chatcmpl-7taYxqoaVtFCzBnxgupB4xz6BCSF8",
  "object": "chat.completion",
  "created": 1693482943,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_axe",
          "arguments": "{\n  \"characterId\": \"A3\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2405,
    "completion_tokens": 18,
    "total_tokens": 2423
  }
}
[1693482945107] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_axe",
    "arguments": "{\n  \"characterId\": \"A3\"\n}"
  }
}
[1693482945107] [36m[OPENAI] Chat completion took 2105.1016659736633ms[39m
[1693482945107] [36m[OPENAI] Tokens per second: 8.550655909378392tps[39m
[1693482945107] [32m[OPENAI] Chat completion created successfully.[39m
[1693482945307] {
  "id": "chatcmpl-7taYwsbfD9L78FtXtuFVfOZzVVh9q",
  "object": "chat.completion",
  "created": 1693482942,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 54.64,\n  \"y\": 16.97\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2057,
    "completion_tokens": 35,
    "total_tokens": 2092
  }
}
[1693482945309] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 54.64,\n  \"y\": 16.97\n}"
  }
}
[1693482945309] [36m[OPENAI] Chat completion took 3231.0645829439163ms[39m
[1693482945309] [36m[OPENAI] Tokens per second: 10.832343056451842tps[39m
[1693482945309] [32m[OPENAI] Chat completion created successfully.[39m
[1693482945316] --- Observations received -- 
[1693482945316] {
  "observerId": "A2",
  "observation": "George Brown has started walking to 54.64, Y: 16.97.",
  "time": 98.18369
}
[1693482945316] [Character] Getting character: A2
[1693482945376] --- Observations received -- 
[1693482945376] {
  "observerId": "A2",
  "observation": "George Brown finished walking to 54.64, Y: 16.97.",
  "time": 98.23997
}
[1693482945376] [Character] Getting character: A2
[1693482945379] [Character] Getting character: A2
[1693482945380] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482945380] [33m[OPENAI] Creating embedding...[39m
[1693482945381] {
  "id": "chatcmpl-7taYwE54yhJvV9xmaLxgDfcNY31Zc",
  "object": "chat.completion",
  "created": 1693482942,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 50.52,\n  \"y\": 14.5\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1920,
    "completion_tokens": 35,
    "total_tokens": 1955
  }
}
[1693482945381] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 50.52,\n  \"y\": 14.5\n}"
  }
}
[1693482945381] [36m[OPENAI] Chat completion took 3200.159250020981ms[39m
[1693482945381] [36m[OPENAI] Tokens per second: 10.936955715491512tps[39m
[1693482945381] [32m[OPENAI] Chat completion created successfully.[39m
[1693482945386] --- Observations received -- 
[1693482945386] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 50.52, Y: 14.5.",
  "time": 98.2536545
}
[1693482945386] [Character] Getting character: A4
[1693482945414] [33m[OPENAI] Creating embedding...[39m
[1693482945444] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482945444] [33m[OPENAI] Creating embedding...[39m
[1693482945449] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482945449] [33m[OPENAI] Creating embedding...[39m
[1693482945565] [32m[OPENAI] Embedding created successfully.[39m
[1693482945592] [32m[OPENAI] Embedding created successfully.[39m
[1693482945617] {
  "id": "chatcmpl-7taYzf6CukmiKqMoG4CbT2nS7ArlY",
  "object": "chat.completion",
  "created": 1693482945,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693482945617] {
  "role": "assistant",
  "content": "1"
}
[1693482945617] [36m[OPENAI] Chat completion took 236.92104196548462ms[39m
[1693482945617] [36m[OPENAI] Tokens per second: 4.220815473813774tps[39m
[1693482945617] [32m[OPENAI] Chat completion created successfully.[39m
[1693482945659] [32m[OPENAI] Embedding created successfully.[39m
[1693482945718] {
  "id": "chatcmpl-7taYzvltAvwy4solzAUWYK05iGwTP",
  "object": "chat.completion",
  "created": 1693482945,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693482945718] {
  "role": "assistant",
  "content": "1"
}
[1693482945718] [36m[OPENAI] Chat completion took 268.85433292388916ms[39m
[1693482945718] [36m[OPENAI] Tokens per second: 3.7194862702216267tps[39m
[1693482945718] [32m[OPENAI] Chat completion created successfully.[39m
[1693482945721] --- Observations received -- 
[1693482945721] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree Stump at X: 44.48, Y: -14.04.",
  "time": 98.587265
}
[1693482945721] [Character] Getting character: A3
[1693482945721] --- Observations received -- 
[1693482945721] {
  "observerId": "A3",
  "observation": "Will Turner picked up Wood at X: 43.94453, Y: -13.87289",
  "time": 98.587265
}
[1693482945721] [Character] Getting character: A3
[1693482945738] {
  "id": "chatcmpl-7taYzlyxQdrR4kkeNs2cc79tl3y4J",
  "object": "chat.completion",
  "created": 1693482945,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693482945738] {
  "role": "assistant",
  "content": "1"
}
[1693482945738] [36m[OPENAI] Chat completion took 293.2664580345154ms[39m
[1693482945738] [36m[OPENAI] Tokens per second: 3.409868304415185tps[39m
[1693482945738] [32m[OPENAI] Chat completion created successfully.[39m
[1693482945753] [32m[OPENAI] Embedding created successfully.[39m
[1693482945795] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482945795] [33m[OPENAI] Creating embedding...[39m
[1693482945795] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482945795] [33m[OPENAI] Creating embedding...[39m
[1693482945917] --- Observations received -- 
[1693482945917] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees Stump(Clone) at X: 57.55001, Y: 10.45",
  "time": 98.7815247
}
[1693482945917] [Character] Getting character: A4
[1693482945952] [32m[OPENAI] Embedding created successfully.[39m
[1693482945978] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482945978] [33m[OPENAI] Creating embedding...[39m
[1693482945992] [32m[OPENAI] Embedding created successfully.[39m
[1693482946044] {
  "id": "chatcmpl-7taYzCVUkJIld3pQ3R7yyFXFUNiRR",
  "object": "chat.completion",
  "created": 1693482945,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693482946044] {
  "role": "assistant",
  "content": "1"
}
[1693482946045] [36m[OPENAI] Chat completion took 248.9800000190735ms[39m
[1693482946045] [36m[OPENAI] Tokens per second: 4.016386858074518tps[39m
[1693482946045] [32m[OPENAI] Chat completion created successfully.[39m
[1693482946066] {
  "id": "chatcmpl-7taYzWhJluSOnYsOSnaFdnkrpql8B",
  "object": "chat.completion",
  "created": 1693482945,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693482946066] {
  "role": "assistant",
  "content": "3"
}
[1693482946066] [36m[OPENAI] Chat completion took 271.12049996852875ms[39m
[1693482946066] [36m[OPENAI] Tokens per second: 3.688396857176342tps[39m
[1693482946066] [32m[OPENAI] Chat completion created successfully.[39m
[1693482946115] [Character] Getting character: A3
[1693482946120] [32m[OPENAI] Embedding created successfully.[39m
[1693482946146] [33m[OPENAI] Creating embedding...[39m
[1693482946183] [33m[OPENAI] Creating embedding...[39m
[1693482946279] {
  "id": "chatcmpl-7taZ0WHSTQ4et69dzubwqeEqEsxvR",
  "object": "chat.completion",
  "created": 1693482946,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482946279] {
  "role": "assistant",
  "content": "3"
}
[1693482946279] [36m[OPENAI] Chat completion took 300.53725004196167ms[39m
[1693482946279] [36m[OPENAI] Tokens per second: 3.3273745595941193tps[39m
[1693482946279] [32m[OPENAI] Chat completion created successfully.[39m
[1693482946360] [32m[OPENAI] Embedding created successfully.[39m
[1693482946382] [32m[OPENAI] Embedding created successfully.[39m
[1693482946694] --- Observations received -- 
[1693482946694] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees George Brown at X: 54.51799, Y: 17.53727.",
  "time": 99.56128
}
[1693482946694] [Character] Getting character: A4
[1693482946742] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482946742] [33m[OPENAI] Creating embedding...[39m
[1693482946807] [33m[OPENAI] Creating embedding...[39m
[1693482946895] [33m[OPENAI] Creating embedding...[39m
[1693482946917] [32m[OPENAI] Embedding created successfully.[39m
[1693482946976] [32m[OPENAI] Embedding created successfully.[39m
[1693482947066] {
  "id": "chatcmpl-7taZ0y38BFtdm8E3d7CoNSTDeLZEG",
  "object": "chat.completion",
  "created": 1693482946,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1693482947066] {
  "role": "assistant",
  "content": "2"
}
[1693482947066] [36m[OPENAI] Chat completion took 324.47325003147125ms[39m
[1693482947066] [36m[OPENAI] Tokens per second: 3.0819181547415946tps[39m
[1693482947066] [32m[OPENAI] Chat completion created successfully.[39m
[1693482947067] [32m[OPENAI] Embedding created successfully.[39m
[1693482947182] --- Observations received -- 
[1693482947182] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees Tree (485) at X: 53.93, Y: 9.11",
  "time": 100.041634
}
[1693482947182] [Character] Getting character: A4
[1693482947234] --- Observations received -- 
[1693482947234] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Stone Ore Deposit (Small) at X: 45.73, Y: 15.31.",
  "time": 100.100815
}
[1693482947234] [Character] Getting character: A4
[1693482947296] --- Observations received -- 
[1693482947296] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees CoalOreSmall at X: 56.74, Y: 14.81",
  "time": 100.161819
}
[1693482947296] [Character] Getting character: A4
[1693482947310] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482947310] [33m[OPENAI] Creating embedding...[39m
[1693482947311] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482947311] [33m[OPENAI] Creating embedding...[39m
[1693482947345] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482947345] [33m[OPENAI] Creating embedding...[39m
[1693482947353] --- Observations received -- 
[1693482947353] {
  "observerId": "A2",
  "observation": "George Brown sees Lucy Wilde at X: 51.12772, Y: 14.0836.",
  "time": 100.22049
}
[1693482947353] [Character] Getting character: A2
[1693482947405] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482947406] [33m[OPENAI] Creating embedding...[39m
[1693482947443] [32m[OPENAI] Embedding created successfully.[39m
[1693482947478] [33m[OPENAI] Creating embedding...[39m
[1693482947494] --- Observations received -- 
[1693482947494] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees Tree (484) at X: 50.77, Y: 9.22",
  "time": 100.36058
}
[1693482947494] [Character] Getting character: A4
[1693482947517] [33m[OPENAI] Creating embedding...[39m
[1693482947527] [32m[OPENAI] Embedding created successfully.[39m
[1693482947536] --- Observations received -- 
[1693482947536] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 50.52, Y: 14.5.",
  "time": 100.399963
}
[1693482947536] [Character] Getting character: A4
[1693482947538] [32m[OPENAI] Embedding created successfully.[39m
[1693482947538] [Character] Getting character: A4
[1693482947547] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482947548] [33m[OPENAI] Creating embedding...[39m
[1693482947563] {
  "id": "chatcmpl-7taZ1QV2afsiZvjHuXYC1IzmByCp0",
  "object": "chat.completion",
  "created": 1693482947,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482947563] {
  "role": "assistant",
  "content": "1"
}
[1693482947563] [36m[OPENAI] Chat completion took 252.39012503623962ms[39m
[1693482947563] [36m[OPENAI] Tokens per second: 3.9621201497341234tps[39m
[1693482947563] [32m[OPENAI] Chat completion created successfully.[39m
[1693482947566] {
  "id": "chatcmpl-7taZ1Oo7lCelxPQtDXWLgbVVXJcLc",
  "object": "chat.completion",
  "created": 1693482947,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482947566] {
  "role": "assistant",
  "content": "4"
}
[1693482947566] [36m[OPENAI] Chat completion took 255.70124995708466ms[39m
[1693482947566] [36m[OPENAI] Tokens per second: 3.910813889911895tps[39m
[1693482947566] [32m[OPENAI] Chat completion created successfully.[39m
[1693482947567] [33m[OPENAI] Creating embedding...[39m
[1693482947577] [32m[OPENAI] Embedding created successfully.[39m
[1693482947587] {
  "id": "chatcmpl-7taZ1FYbhJnMsC7VPF5lGhnuH4VC1",
  "object": "chat.completion",
  "created": 1693482947,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482947587] {
  "role": "assistant",
  "content": "5"
}
[1693482947587] [36m[OPENAI] Chat completion took 242.03679203987122ms[39m
[1693482947587] [36m[OPENAI] Tokens per second: 4.131603263999913tps[39m
[1693482947587] [32m[OPENAI] Chat completion created successfully.[39m
[1693482947602] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482947602] [33m[OPENAI] Creating embedding...[39m
[1693482947662] [32m[OPENAI] Embedding created successfully.[39m
[1693482947665] {
  "id": "chatcmpl-7taZ1F3zN5YhbXVO3Qb3TNXaepzK7",
  "object": "chat.completion",
  "created": 1693482947,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1693482947665] {
  "role": "assistant",
  "content": "1"
}
[1693482947665] [36m[OPENAI] Chat completion took 259.25212502479553ms[39m
[1693482947665] [36m[OPENAI] Tokens per second: 3.857249000000896tps[39m
[1693482947665] [32m[OPENAI] Chat completion created successfully.[39m
[1693482947692] [32m[OPENAI] Embedding created successfully.[39m
[1693482947712] [32m[OPENAI] Embedding created successfully.[39m
[1693482947738] [32m[OPENAI] Embedding created successfully.[39m
[1693482947762] [32m[OPENAI] Embedding created successfully.[39m
[1693482947804] {
  "id": "chatcmpl-7taZ17D8DipKvLSTGu5IJ8cQ25Q29",
  "object": "chat.completion",
  "created": 1693482947,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482947804] {
  "role": "assistant",
  "content": "4"
}
[1693482947804] [36m[OPENAI] Chat completion took 255.91441595554352ms[39m
[1693482947804] [36m[OPENAI] Tokens per second: 3.90755634560937tps[39m
[1693482947804] [32m[OPENAI] Chat completion created successfully.[39m
[1693482947941] {
  "id": "chatcmpl-7taZ1yp0wvGhnRvDXT9pB01cb3VB8",
  "object": "chat.completion",
  "created": 1693482947,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693482947942] {
  "role": "assistant",
  "content": "2"
}
[1693482947942] [36m[OPENAI] Chat completion took 339.09470796585083ms[39m
[1693482947942] [36m[OPENAI] Tokens per second: 2.949028623887303tps[39m
[1693482947942] [32m[OPENAI] Chat completion created successfully.[39m
[1693482948124] [33m[OPENAI] Creating embedding...[39m
[1693482948179] [33m[OPENAI] Creating embedding...[39m
[1693482948261] [33m[OPENAI] Creating embedding...[39m
[1693482948269] [32m[OPENAI] Embedding created successfully.[39m
[1693482948470] [32m[OPENAI] Embedding created successfully.[39m
[1693482948526] [32m[OPENAI] Embedding created successfully.[39m
[1693482948639] [33m[OPENAI] Creating embedding...[39m
[1693482948790] [32m[OPENAI] Embedding created successfully.[39m
[1693482948941] [33m[OPENAI] Creating embedding...[39m
[1693482949042] [33m[OPENAI] Creating embedding...[39m
[1693482949212] [33m[OPENAI] Creating embedding...[39m
[1693482949284] [32m[OPENAI] Embedding created successfully.[39m
[1693482949311] [32m[OPENAI] Embedding created successfully.[39m
[1693482949425] [32m[OPENAI] Embedding created successfully.[39m
[1693482949759] [33m[OPENAI] Creating embedding...[39m
[1693482949823] [33m[OPENAI] Creating embedding...[39m
[1693482949830] [33m[OPENAI] Creating embedding...[39m
[1693482949984] [32m[OPENAI] Embedding created successfully.[39m
[1693482950063] [32m[OPENAI] Embedding created successfully.[39m
[1693482950094] [32m[OPENAI] Embedding created successfully.[39m
[1693482950483] [33m[OPENAI] Creating embedding...[39m
[1693482950515] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482950583] [33m[OPENAI] Creating embedding...[39m
[1693482950643] [32m[OPENAI] Embedding created successfully.[39m
[1693482950741] [32m[OPENAI] Embedding created successfully.[39m
[1693482951079] [33m[OPENAI] Creating embedding...[39m
[1693482951211] [33m[OPENAI] Creating embedding...[39m
[1693482951288] [32m[OPENAI] Embedding created successfully.[39m
[1693482951346] [32m[OPENAI] Embedding created successfully.[39m
[1693482951760] [33m[OPENAI] Creating embedding...[39m
[1693482951795] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482951908] [32m[OPENAI] Embedding created successfully.[39m
[1693482952319] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482954579] {
  "id": "chatcmpl-7taZ4KXCMMqX5dxb1fEg7NaypaXow",
  "object": "chat.completion",
  "created": 1693482950,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A3\",\n  \"x\": 42.72,\n  \"y\": -12.97\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2359,
    "completion_tokens": 35,
    "total_tokens": 2394
  }
}
[1693482954579] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A3\",\n  \"x\": 42.72,\n  \"y\": -12.97\n}"
  }
}
[1693482954579] [36m[OPENAI] Chat completion took 4063.869250059128ms[39m
[1693482954579] [36m[OPENAI] Tokens per second: 8.612481811389666tps[39m
[1693482954579] [32m[OPENAI] Chat completion created successfully.[39m
[1693482954591] --- Observations received -- 
[1693482954591] {
  "observerId": "A3",
  "observation": "Will Turner has started walking to 42.72, Y: -12.97.",
  "time": 107.452606
}
[1693482954591] [Character] Getting character: A3
[1693482954649] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482954650] [33m[OPENAI] Creating embedding...[39m
[1693482954814] --- Observations received -- 
[1693482954814] {
  "observerId": "A3",
  "observation": "Will Turner no longer sees Tree (274) at X: 46.7, Y: -18.14",
  "time": 107.680511
}
[1693482954814] [Character] Getting character: A3
[1693482954826] [32m[OPENAI] Embedding created successfully.[39m
[1693482954874] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482954875] [33m[OPENAI] Creating embedding...[39m
[1693482954908] {
  "id": "chatcmpl-7taZ8SDdGjYJRtlfO6Lgj8WiC4R9N",
  "object": "chat.completion",
  "created": 1693482954,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 2,
    "total_tokens": 102
  }
}
[1693482954908] {
  "role": "assistant",
  "content": "1."
}
[1693482954908] [36m[OPENAI] Chat completion took 257.83354091644287ms[39m
[1693482954908] [36m[OPENAI] Tokens per second: 7.756942688260049tps[39m
[1693482954908] [32m[OPENAI] Chat completion created successfully.[39m
[1693482955036] --- Observations received -- 
[1693482955037] {
  "observerId": "A3",
  "observation": "Will Turner no longer sees Tree (275) at X: 44.34, Y: -18.3",
  "time": 107.902237
}
[1693482955037] [Character] Getting character: A3
[1693482955100] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482955100] [33m[OPENAI] Creating embedding...[39m
[1693482955134] --- Observations received -- 
[1693482955134] {
  "observerId": "A3",
  "observation": "Will Turner no longer sees Tree (173) at X: 42.61, Y: -18.15",
  "time": 108.000923
}
[1693482955134] [Character] Getting character: A3
[1693482955136] {
  "id": "chatcmpl-7taZ8FwP9oXPf0DjUVhSTmIY0j9mG",
  "object": "chat.completion",
  "created": 1693482954,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482955136] {
  "role": "assistant",
  "content": "4"
}
[1693482955136] [36m[OPENAI] Chat completion took 261.31529200077057ms[39m
[1693482955136] [36m[OPENAI] Tokens per second: 3.8267947977459014tps[39m
[1693482955136] [32m[OPENAI] Chat completion created successfully.[39m
[1693482955136] [32m[OPENAI] Embedding created successfully.[39m
[1693482955199] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482955199] [33m[OPENAI] Creating embedding...[39m
[1693482955313] --- Observations received -- 
[1693482955313] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 38.75, Y: -9.01.",
  "time": 108.180016
}
[1693482955313] [Character] Getting character: A3
[1693482955338] {
  "id": "chatcmpl-7taZ9SEWzs57IGPbqYx8URhg5u7An",
  "object": "chat.completion",
  "created": 1693482955,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482955338] {
  "role": "assistant",
  "content": "6"
}
[1693482955338] [36m[OPENAI] Chat completion took 237.5685830116272ms[39m
[1693482955338] [36m[OPENAI] Tokens per second: 4.209310790690945tps[39m
[1693482955338] [32m[OPENAI] Chat completion created successfully.[39m
[1693482955363] [32m[OPENAI] Embedding created successfully.[39m
[1693482955369] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482955369] [33m[OPENAI] Creating embedding...[39m
[1693482955395] --- Observations received -- 
[1693482955395] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 38.96, Y: -16.52.",
  "time": 108.261826
}
[1693482955395] [Character] Getting character: A3
[1693482955436] --- Observations received -- 
[1693482955437] {
  "observerId": "A3",
  "observation": "Will Turner no longer sees Tree (273) at X: 47.86, Y: -15.94",
  "time": 108.300392
}
[1693482955437] [Character] Getting character: A3
[1693482955458] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482955458] [33m[OPENAI] Creating embedding...[39m
[1693482955485] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482955487] [33m[OPENAI] Creating embedding...[39m
[1693482955577] --- Observations received -- 
[1693482955577] {
  "observerId": "A3",
  "observation": "Will Turner finished walking to 42.72, Y: -12.97.",
  "time": 108.439964
}
[1693482955577] [Character] Getting character: A3
[1693482955579] [Character] Getting character: A3
[1693482955586] [32m[OPENAI] Embedding created successfully.[39m
[1693482955611] [33m[OPENAI] Creating embedding...[39m
[1693482955638] [32m[OPENAI] Embedding created successfully.[39m
[1693482955643] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482955643] [33m[OPENAI] Creating embedding...[39m
[1693482955712] {
  "id": "chatcmpl-7taZ9SkQCDqsur8DvDRgQyji1CAIH",
  "object": "chat.completion",
  "created": 1693482955,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482955712] {
  "role": "assistant",
  "content": "2"
}
[1693482955712] [36m[OPENAI] Chat completion took 341.13058400154114ms[39m
[1693482955712] [36m[OPENAI] Tokens per second: 2.931428745759959tps[39m
[1693482955712] [32m[OPENAI] Chat completion created successfully.[39m
[1693482955753] {
  "id": "chatcmpl-7taZ92wSR6i4cJ9XGcuPpIq2ETVTw",
  "object": "chat.completion",
  "created": 1693482955,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482955753] {
  "role": "assistant",
  "content": "4"
}
[1693482955753] [36m[OPENAI] Chat completion took 553.8042089939117ms[39m
[1693482955753] [36m[OPENAI] Tokens per second: 1.8056923074251925tps[39m
[1693482955753] [32m[OPENAI] Chat completion created successfully.[39m
[1693482955757] [32m[OPENAI] Embedding created successfully.[39m
[1693482955822] {
  "id": "chatcmpl-7taZ9lkJ5ch3HdTTdIxeZJh4KGNvM",
  "object": "chat.completion",
  "created": 1693482955,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6.5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 3,
    "total_tokens": 108
  }
}
[1693482955822] {
  "role": "assistant",
  "content": "6.5"
}
[1693482955822] [36m[OPENAI] Chat completion took 336.62029099464417ms[39m
[1693482955822] [36m[OPENAI] Tokens per second: 8.912118729193695tps[39m
[1693482955822] [32m[OPENAI] Chat completion created successfully.[39m
[1693482955838] [32m[OPENAI] Embedding created successfully.[39m
[1693482955861] {
  "id": "chatcmpl-7taZ9kscBm5OQlsrTfv3P9BUXAOnZ",
  "object": "chat.completion",
  "created": 1693482955,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 2,
    "total_tokens": 103
  }
}
[1693482955861] {
  "role": "assistant",
  "content": "2."
}
[1693482955861] [36m[OPENAI] Chat completion took 402.5504170656204ms[39m
[1693482955861] [36m[OPENAI] Tokens per second: 4.96832176843572tps[39m
[1693482955861] [32m[OPENAI] Chat completion created successfully.[39m
[1693482955896] [32m[OPENAI] Embedding created successfully.[39m
[1693482955919] {
  "id": "chatcmpl-7taZ9P7GYMzwU0SiSz0sdiXJwkui7",
  "object": "chat.completion",
  "created": 1693482955,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693482955921] {
  "role": "assistant",
  "content": "1"
}
[1693482955921] [36m[OPENAI] Chat completion took 274.51900005340576ms[39m
[1693482955921] [36m[OPENAI] Tokens per second: 3.6427351105222483tps[39m
[1693482955921] [32m[OPENAI] Chat completion created successfully.[39m
[1693482956017] [32m[OPENAI] Embedding created successfully.[39m
[1693482956246] {
  "id": "chatcmpl-7taZ6rhmIOTtJOaZV34VK44R4fbi4",
  "object": "chat.completion",
  "created": 1693482952,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "add_wood_to_chest",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"chestId\": \"chest_(50.52,14.5)\",\n  \"itemId\": \"wood\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2516,
    "completion_tokens": 44,
    "total_tokens": 2560
  }
}
[1693482956246] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "add_wood_to_chest",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"chestId\": \"chest_(50.52,14.5)\",\n  \"itemId\": \"wood\"\n}"
  }
}
[1693482956246] [36m[OPENAI] Chat completion took 3925.065665960312ms[39m
[1693482956246] [36m[OPENAI] Tokens per second: 11.21000353741468tps[39m
[1693482956246] [32m[OPENAI] Chat completion created successfully.[39m
[1693482956255] [Character] Getting character: A4
[1693482956266] [33m[OPENAI] Creating embedding...[39m
[1693482956286] {
  "id": "chatcmpl-7taZ54BLNGBptrB1p5huxBpfQwMgO",
  "object": "chat.completion",
  "created": 1693482951,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 53.88,\n  \"y\": 19.83\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2087,
    "completion_tokens": 35,
    "total_tokens": 2122
  }
}
[1693482956286] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 53.88,\n  \"y\": 19.83\n}"
  }
}
[1693482956286] [36m[OPENAI] Chat completion took 4490.888167023659ms[39m
[1693482956286] [36m[OPENAI] Tokens per second: 7.7935585786800585tps[39m
[1693482956286] [32m[OPENAI] Chat completion created successfully.[39m
[1693482956292] --- Observations received -- 
[1693482956292] {
  "observerId": "A2",
  "observation": "George Brown has started walking to 53.88, Y: 19.83.",
  "time": 109.157707
}
[1693482956292] [Character] Getting character: A2
[1693482956308] [33m[OPENAI] Creating embedding...[39m
[1693482956362] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482956363] [33m[OPENAI] Creating embedding...[39m
[1693482956434] --- Observations received -- 
[1693482956434] {
  "observerId": "A2",
  "observation": "George Brown sees Copper Ore Deposit (Medium) at X: 52.01, Y: 23.05.",
  "time": 109.30024
}
[1693482956434] [Character] Getting character: A2
[1693482956434] --- Observations received -- 
[1693482956435] {
  "observerId": "A2",
  "observation": "George Brown no longer sees Human (3) at X: 51.04561, Y: 14.3513",
  "time": 109.30024
}
[1693482956435] [Character] Getting character: A2
[1693482956500] [32m[OPENAI] Embedding created successfully.[39m
[1693482956509] [32m[OPENAI] Embedding created successfully.[39m
[1693482956544] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482956544] [33m[OPENAI] Creating embedding...[39m
[1693482956545] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482956546] [33m[OPENAI] Creating embedding...[39m
[1693482956596] [32m[OPENAI] Embedding created successfully.[39m
[1693482956613] {
  "id": "chatcmpl-7taZAvsnoHCBsKPAicDYCVp8w847O",
  "object": "chat.completion",
  "created": 1693482956,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693482956613] {
  "role": "assistant",
  "content": "2"
}
[1693482956613] [36m[OPENAI] Chat completion took 250.83783292770386ms[39m
[1693482956613] [36m[OPENAI] Tokens per second: 3.9866394487956636tps[39m
[1693482956613] [32m[OPENAI] Chat completion created successfully.[39m
[1693482956675] --- Observations received -- 
[1693482956675] {
  "observerId": "A2",
  "observation": "George Brown sees Diamond Ore Deposit (Small) at X: 58.32, Y: 22.87.",
  "time": 109.540321
}
[1693482956675] [Character] Getting character: A2
[1693482956775] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482956777] [33m[OPENAI] Creating embedding...[39m
[1693482956802] {
  "id": "chatcmpl-7taZAs5EfyXauW4YYzrdt76GWt8xQ",
  "object": "chat.completion",
  "created": 1693482956,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 107,
    "completion_tokens": 1,
    "total_tokens": 108
  }
}
[1693482956802] {
  "role": "assistant",
  "content": "2"
}
[1693482956802] [36m[OPENAI] Chat completion took 256.0535420179367ms[39m
[1693482956802] [36m[OPENAI] Tokens per second: 3.90543318447807tps[39m
[1693482956802] [32m[OPENAI] Chat completion created successfully.[39m
[1693482956818] [32m[OPENAI] Embedding created successfully.[39m
[1693482956834] --- Observations received -- 
[1693482956834] {
  "observerId": "A2",
  "observation": "George Brown no longer sees Chest (1) at X: 50.52, Y: 14.5",
  "time": 109.700676
}
[1693482956834] [Character] Getting character: A2
[1693482956834] --- Observations received -- 
[1693482956834] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees Human (1) at X: 54.7254, Y: 18.4172",
  "time": 109.700676
}
[1693482956834] [Character] Getting character: A4
[1693482956838] [32m[OPENAI] Embedding created successfully.[39m
[1693482956841] {
  "id": "chatcmpl-7taZA0wtiKZ39sQMM0K1SvDRTGraE",
  "object": "chat.completion",
  "created": 1693482956,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482956841] {
  "role": "assistant",
  "content": "2"
}
[1693482956841] [36m[OPENAI] Chat completion took 296.65787494182587ms[39m
[1693482956841] [36m[OPENAI] Tokens per second: 3.3708864131656653tps[39m
[1693482956841] [32m[OPENAI] Chat completion created successfully.[39m
[1693482956900] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482956900] [33m[OPENAI] Creating embedding...[39m
[1693482956996] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482956996] [33m[OPENAI] Creating embedding...[39m
[1693482956999] [33m[OPENAI] Creating embedding...[39m
[1693482957000] [32m[OPENAI] Embedding created successfully.[39m
[1693482957044] --- Observations received -- 
[1693482957045] {
  "observerId": "A2",
  "observation": "George Brown sees Copper Ore Deposit (Medium) at X: 54.06, Y: 24.46.",
  "time": 109.901825
}
[1693482957045] [Character] Getting character: A2
[1693482957083] {
  "id": "chatcmpl-7taZARfHP3TTw1SnNjKOyvqGRkBTC",
  "object": "chat.completion",
  "created": 1693482956,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1.5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 3,
    "total_tokens": 109
  }
}
[1693482957083] {
  "role": "assistant",
  "content": "1.5"
}
[1693482957083] [36m[OPENAI] Chat completion took 308.35520899295807ms[39m
[1693482957083] [36m[OPENAI] Tokens per second: 9.729039473007608tps[39m
[1693482957083] [32m[OPENAI] Chat completion created successfully.[39m
[1693482957101] [32m[OPENAI] Embedding created successfully.[39m
[1693482957101] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482957101] [33m[OPENAI] Creating embedding...[39m
[1693482957110] [33m[OPENAI] Creating embedding...[39m
[1693482957150] {
  "id": "chatcmpl-7taZAxiMt4unjVHH6Yz8FpfwG20fB",
  "object": "chat.completion",
  "created": 1693482956,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 107,
    "completion_tokens": 1,
    "total_tokens": 108
  }
}
[1693482957150] {
  "role": "assistant",
  "content": "2"
}
[1693482957150] [36m[OPENAI] Chat completion took 249.42783296108246ms[39m
[1693482957165] [36m[OPENAI] Tokens per second: 4.009175672692579tps[39m
[1693482957165] [32m[OPENAI] Chat completion created successfully.[39m
[1693482957170] [32m[OPENAI] Embedding created successfully.[39m
[1693482957198] --- Observations received -- 
[1693482957198] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CoalOreMedium (2) at X: 59.9, Y: 16.03",
  "time": 110.064552
}
[1693482957198] [Character] Getting character: A2
[1693482957238] --- Observations received -- 
[1693482957238] {
  "observerId": "A2",
  "observation": "George Brown sees Copper Ore Deposit (Small) at X: 57.1, Y: 24.45.",
  "time": 110.103485
}
[1693482957238] [Character] Getting character: A2
[1693482957250] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482957250] [33m[OPENAI] Creating embedding...[39m
[1693482957251] [32m[OPENAI] Embedding created successfully.[39m
[1693482957285] {
  "id": "chatcmpl-7taZBRDs8YefRIqHGBwB04vF1IW6z",
  "object": "chat.completion",
  "created": 1693482957,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482957285] {
  "role": "assistant",
  "content": "3"
}
[1693482957285] [36m[OPENAI] Chat completion took 288.8972090482712ms[39m
[1693482957285] [36m[OPENAI] Tokens per second: 3.461438770192177tps[39m
[1693482957285] [32m[OPENAI] Chat completion created successfully.[39m
[1693482957288] [32m[OPENAI] Embedding created successfully.[39m
[1693482957314] [32m[OPENAI] Embedding created successfully.[39m
[1693482957315] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482957315] [33m[OPENAI] Creating embedding...[39m
[1693482957368] {
  "id": "chatcmpl-7taZBXZuVlg3zZGCxe81vHfbhbE0c",
  "object": "chat.completion",
  "created": 1693482957,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482957368] {
  "role": "assistant",
  "content": "4"
}
[1693482957368] [36m[OPENAI] Chat completion took 265.83112490177155ms[39m
[1693482957368] [36m[OPENAI] Tokens per second: 3.7617867372359597tps[39m
[1693482957368] [32m[OPENAI] Chat completion created successfully.[39m
[1693482957430] [32m[OPENAI] Embedding created successfully.[39m
[1693482957477] {
  "id": "chatcmpl-7taZB8vPNFPIwbaS11SgYLlqI5lkv",
  "object": "chat.completion",
  "created": 1693482957,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693482957477] {
  "role": "assistant",
  "content": "5"
}
[1693482957477] [36m[OPENAI] Chat completion took 226.1229169368744ms[39m
[1693482957477] [36m[OPENAI] Tokens per second: 4.422373519439275tps[39m
[1693482957477] [32m[OPENAI] Chat completion created successfully.[39m
[1693482957488] [32m[OPENAI] Embedding created successfully.[39m
[1693482957571] {
  "id": "chatcmpl-7taZBDpkz98YizHyV4n6fObFnSCdK",
  "object": "chat.completion",
  "created": 1693482957,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482957571] {
  "role": "assistant",
  "content": "1"
}
[1693482957571] [36m[OPENAI] Chat completion took 256.0867919921875ms[39m
[1693482957571] [36m[OPENAI] Tokens per second: 3.904926108139569tps[39m
[1693482957571] [32m[OPENAI] Chat completion created successfully.[39m
[1693482957629] [33m[OPENAI] Creating embedding...[39m
[1693482957680] --- Observations received -- 
[1693482957680] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CoalOreSmall at X: 56.74, Y: 14.81",
  "time": 110.541389
}
[1693482957680] [Character] Getting character: A2
[1693482957748] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482957748] [33m[OPENAI] Creating embedding...[39m
[1693482957758] [33m[OPENAI] Creating embedding...[39m
[1693482957765] [32m[OPENAI] Embedding created successfully.[39m
[1693482957896] [32m[OPENAI] Embedding created successfully.[39m
[1693482957935] --- Observations received -- 
[1693482957935] {
  "observerId": "A2",
  "observation": "George Brown finished walking to 53.88, Y: 19.83.",
  "time": 110.799957
}
[1693482957935] [Character] Getting character: A2
[1693482957938] [Character] Getting character: A2
[1693482957966] [33m[OPENAI] Creating embedding...[39m
[1693482958008] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482958008] [33m[OPENAI] Creating embedding...[39m
[1693482958052] [32m[OPENAI] Embedding created successfully.[39m
[1693482958139] [32m[OPENAI] Embedding created successfully.[39m
[1693482958199] [33m[OPENAI] Creating embedding...[39m
[1693482958309] {
  "id": "chatcmpl-7taZCvPvdmebB4bfiALkd5FktNWCF",
  "object": "chat.completion",
  "created": 1693482958,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693482958309] {
  "role": "assistant",
  "content": "1"
}
[1693482958309] [36m[OPENAI] Chat completion took 300.1655000448227ms[39m
[1693482958309] [36m[OPENAI] Tokens per second: 3.331495457841336tps[39m
[1693482958309] [32m[OPENAI] Chat completion created successfully.[39m
[1693482958379] [32m[OPENAI] Embedding created successfully.[39m
[1693482958559] [33m[OPENAI] Creating embedding...[39m
[1693482958631] {
  "id": "chatcmpl-7taZC7ZF2xfve1bycwBvodm6YN10f",
  "object": "chat.completion",
  "created": 1693482958,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 2,
    "total_tokens": 107
  }
}
[1693482958631] {
  "role": "assistant",
  "content": "3."
}
[1693482958631] [36m[OPENAI] Chat completion took 882.3290410041809ms[39m
[1693482958631] [36m[OPENAI] Tokens per second: 2.2667280652167983tps[39m
[1693482958631] [32m[OPENAI] Chat completion created successfully.[39m
[1693482958729] [32m[OPENAI] Embedding created successfully.[39m
[1693482958738] [33m[OPENAI] Creating embedding...[39m
[1693482958746] [32m[OPENAI] Embedding created successfully.[39m
[1693482958844] [33m[OPENAI] Creating embedding...[39m
[1693482958875] [32m[OPENAI] Embedding created successfully.[39m
[1693482958930] [33m[CONVERSATION] Continuing conversation as player...[39m
[1693482958930] [33m[CONVERSATION] Continuing conversation...[39m
[1693482958930] [33m[CONVERSATION] Player: A1[39m
[1693482958930] [33m[CONVERSATION] Character: A5[39m
[1693482959126] [32m[OPENAI] Embedding created successfully.[39m
[1693482959163] [33m[OPENAI] Creating embedding...[39m
[1693482959291] [32m[OPENAI] Embedding created successfully.[39m
[1693482959506] [33m[OPENAI] Creating embedding...[39m
[1693482959616] [33m[OPENAI] Creating embedding...[39m
[1693482959651] [32m[OPENAI] Embedding created successfully.[39m
[1693482959744] [32m[OPENAI] Embedding created successfully.[39m
[1693482959799] [33m[OPENAI] Creating embedding...[39m
[1693482960052] [32m[OPENAI] Embedding created successfully.[39m
[1693482960253] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482960290] [33m[OPENAI] Creating embedding...[39m
[1693482960436] [33m[OPENAI] Creating embedding...[39m
[1693482960470] [32m[OPENAI] Embedding created successfully.[39m
[1693482960800] [32m[OPENAI] Embedding created successfully.[39m
[1693482960864] [33m[OPENAI] Creating embedding...[39m
[1693482961069] [32m[OPENAI] Embedding created successfully.[39m
[1693482961369] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482961577] [33m[OPENAI] Creating embedding...[39m
[1693482961813] [32m[OPENAI] Embedding created successfully.[39m
[1693482962365] [33m[OPENAI] Creating embedding...[39m
[1693482962725] [32m[OPENAI] Embedding created successfully.[39m
[1693482963275] [33m[OPENAI] Creating embedding...[39m
[1693482963412] [32m[OPENAI] Embedding created successfully.[39m
[1693482963911] [33m[OPENAI] Creating embedding...[39m
[1693482964069] [32m[OPENAI] Embedding created successfully.[39m
[1693482964331] {
  "id": "chatcmpl-7taZE9weJ8PdTLxyxVeEmoZtzI2Nl",
  "object": "chat.completion",
  "created": 1693482960,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A3\",\n  \"x\": 44.48,\n  \"y\": -14.04\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2207,
    "completion_tokens": 35,
    "total_tokens": 2242
  }
}
[1693482964331] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A3\",\n  \"x\": 44.48,\n  \"y\": -14.04\n}"
  }
}
[1693482964331] [36m[OPENAI] Chat completion took 4077.502624988556ms[39m
[1693482964331] [36m[OPENAI] Tokens per second: 8.58368546117079tps[39m
[1693482964331] [32m[OPENAI] Chat completion created successfully.[39m
[1693482964356] --- Observations received -- 
[1693482964356] {
  "observerId": "A3",
  "observation": "Will Turner has started walking to 44.48, Y: -14.04.",
  "time": 117.200012
}
[1693482964356] [Character] Getting character: A3
[1693482964416] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482964416] [33m[OPENAI] Creating embedding...[39m
[1693482964522] --- Observations received -- 
[1693482964522] {
  "observerId": "A3",
  "observation": "Will Turner no longer sees Tree (169) at X: 38.96, Y: -16.52",
  "time": 117.3809
}
[1693482964522] [Character] Getting character: A3
[1693482964548] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482964555] --- Observations received -- 
[1693482964555] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 47.86, Y: -15.94.",
  "time": 117.421173
}
[1693482964555] [Character] Getting character: A3
[1693482964612] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482964613] [33m[OPENAI] Creating embedding...[39m
[1693482964615] [32m[OPENAI] Embedding created successfully.[39m
[1693482964617] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482964617] [33m[OPENAI] Creating embedding...[39m
[1693482964636] --- Observations received -- 
[1693482964636] {
  "observerId": "A3",
  "observation": "Will Turner no longer sees Tree (285) at X: 38.75, Y: -9.01",
  "time": 117.502205
}
[1693482964636] [Character] Getting character: A3
[1693482964709] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482964709] [33m[OPENAI] Creating embedding...[39m
[1693482964772] {
  "id": "chatcmpl-7taZIjpbmPzdW7cEhsbWtYpWGhwTz",
  "object": "chat.completion",
  "created": 1693482964,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693482964772] {
  "role": "assistant",
  "content": "1"
}
[1693482964774] [36m[OPENAI] Chat completion took 356.0853749513626ms[39m
[1693482964774] [36m[OPENAI] Tokens per second: 2.8083152815152523tps[39m
[1693482964774] [32m[OPENAI] Chat completion created successfully.[39m
[1693482964776] --- Observations received -- 
[1693482964776] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 42.61, Y: -18.15.",
  "time": 117.640007
}
[1693482964777] [Character] Getting character: A3
[1693482964795] [32m[OPENAI] Embedding created successfully.[39m
[1693482964817] [32m[OPENAI] Embedding created successfully.[39m
[1693482964840] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482964841] [33m[OPENAI] Creating embedding...[39m
[1693482964901] [32m[OPENAI] Embedding created successfully.[39m
[1693482964915] --- Observations received -- 
[1693482964915] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 44.34, Y: -18.3.",
  "time": 117.781212
}
[1693482964915] [Character] Getting character: A3
[1693482964930] {
  "id": "chatcmpl-7taZIlWAse7sAUjVST84f3WMlfDwK",
  "object": "chat.completion",
  "created": 1693482964,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482964930] {
  "role": "assistant",
  "content": "3"
}
[1693482964930] [36m[OPENAI] Chat completion took 312.9089580774307ms[39m
[1693482964930] [36m[OPENAI] Tokens per second: 3.1958177424647123tps[39m
[1693482964930] [32m[OPENAI] Chat completion created successfully.[39m
[1693482964940] {
  "id": "chatcmpl-7taZIDJZ64XcIdm6d3d41vWY1ctYe",
  "object": "chat.completion",
  "created": 1693482964,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 2,
    "total_tokens": 107
  }
}
[1693482964940] {
  "role": "assistant",
  "content": "5."
}
[1693482964940] [36m[OPENAI] Chat completion took 326.9372079372406ms[39m
[1693482964940] [36m[OPENAI] Tokens per second: 6.11738263937191tps[39m
[1693482964940] [32m[OPENAI] Chat completion created successfully.[39m
[1693482964972] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482964973] [33m[OPENAI] Creating embedding...[39m
[1693482965116] --- Observations received -- 
[1693482965116] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 46.7, Y: -18.14.",
  "time": 117.980522
}
[1693482965116] [Character] Getting character: A3
[1693482965130] {
  "id": "chatcmpl-7taZIGLsaqbV2wGqaxAWSkgQuvacw",
  "object": "chat.completion",
  "created": 1693482964,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482965130] {
  "role": "assistant",
  "content": "3"
}
[1693482965130] [36m[OPENAI] Chat completion took 289.55049991607666ms[39m
[1693482965130] [36m[OPENAI] Tokens per second: 3.4536289879998137tps[39m
[1693482965130] [32m[OPENAI] Chat completion created successfully.[39m
[1693482965187] [32m[OPENAI] Embedding created successfully.[39m
[1693482965192] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482965192] [33m[OPENAI] Creating embedding...[39m
[1693482965212] [32m[OPENAI] Embedding created successfully.[39m
[1693482965227] {
  "id": "chatcmpl-7taZJXfYOdcdzlR7IjV1muhXGeQ95",
  "object": "chat.completion",
  "created": 1693482965,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482965227] {
  "role": "assistant",
  "content": "3"
}
[1693482965227] [36m[OPENAI] Chat completion took 254.6562920808792ms[39m
[1693482965227] [36m[OPENAI] Tokens per second: 3.9268615427825306tps[39m
[1693482965227] [32m[OPENAI] Chat completion created successfully.[39m
[1693482965339] --- Observations received -- 
[1693482965339] {
  "observerId": "A3",
  "observation": "Will Turner finished walking to 44.48, Y: -14.04.",
  "time": 118.199959
}
[1693482965339] [Character] Getting character: A3
[1693482965340] [Character] Getting character: A3
[1693482965411] [33m[OPENAI] Creating embedding...[39m
[1693482965444] [32m[OPENAI] Embedding created successfully.[39m
[1693482965446] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482965446] [33m[OPENAI] Creating embedding...[39m
[1693482965459] {
  "id": "chatcmpl-7taZJNNiaQ7oLdZ5E9NMFfzSIhkod",
  "object": "chat.completion",
  "created": 1693482965,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482965459] {
  "role": "assistant",
  "content": "5"
}
[1693482965459] [36m[OPENAI] Chat completion took 267.3600000143051ms[39m
[1693482965459] [36m[OPENAI] Tokens per second: 3.740275284060798tps[39m
[1693482965459] [32m[OPENAI] Chat completion created successfully.[39m
[1693482965620] {
  "id": "chatcmpl-7taZJHE3gJm05a8t3YFsFViEHt9h8",
  "object": "chat.completion",
  "created": 1693482965,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 2,
    "total_tokens": 107
  }
}
[1693482965620] {
  "role": "assistant",
  "content": "4."
}
[1693482965620] [36m[OPENAI] Chat completion took 910.5159159898758ms[39m
[1693482965620] [36m[OPENAI] Tokens per second: 2.196556880420571tps[39m
[1693482965620] [32m[OPENAI] Chat completion created successfully.[39m
[1693482965626] [32m[OPENAI] Embedding created successfully.[39m
[1693482965654] [32m[OPENAI] Embedding created successfully.[39m
[1693482965797] {
  "id": "chatcmpl-7taZJRMziowXa9XySKDMaeY4OGeNz",
  "object": "chat.completion",
  "created": 1693482965,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693482965798] {
  "role": "assistant",
  "content": "1"
}
[1693482965798] [36m[OPENAI] Chat completion took 351.63324999809265ms[39m
[1693482965798] [36m[OPENAI] Tokens per second: 2.843872130992801tps[39m
[1693482965798] [32m[OPENAI] Chat completion created successfully.[39m
[1693482966178] [33m[OPENAI] Creating embedding...[39m
[1693482966321] [32m[OPENAI] Embedding created successfully.[39m
[1693482966350] {
  "id": "chatcmpl-7taZFJgzRUyOWJpmHlh1oZRqgO1EU",
  "object": "chat.completion",
  "created": 1693482961,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "add_wood_to_chest",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"chestId\": \"chest_(50.52,14.5)\",\n  \"itemId\": \"wood\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2494,
    "completion_tokens": 44,
    "total_tokens": 2538
  }
}
[1693482966350] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "add_wood_to_chest",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"chestId\": \"chest_(50.52,14.5)\",\n  \"itemId\": \"wood\"\n}"
  }
}
[1693482966350] [36m[OPENAI] Chat completion took 4980.06375002861ms[39m
[1693482966350] [36m[OPENAI] Tokens per second: 8.835228263844458tps[39m
[1693482966350] [32m[OPENAI] Chat completion created successfully.[39m
[1693482966357] [Character] Getting character: A4
[1693482966397] [33m[OPENAI] Creating embedding...[39m
[1693482966629] [32m[OPENAI] Embedding created successfully.[39m
[1693482966803] [33m[OPENAI] Creating embedding...[39m
[1693482967066] [32m[OPENAI] Embedding created successfully.[39m
[1693482967099] [33m[OPENAI] Creating embedding...[39m
[1693482967119] {
  "id": "chatcmpl-7taZI0iIzkom6MZ2M9ybcR6UJ6f7T",
  "object": "chat.completion",
  "created": 1693482964,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_pickaxe",
          "arguments": "{\n  \"characterId\": \"A2\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2391,
    "completion_tokens": 18,
    "total_tokens": 2409
  }
}
[1693482967119] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_pickaxe",
    "arguments": "{\n  \"characterId\": \"A2\"\n}"
  }
}
[1693482967120] [36m[OPENAI] Chat completion took 2571.207291007042ms[39m
[1693482967120] [36m[OPENAI] Tokens per second: 7.000602426321723tps[39m
[1693482967120] [32m[OPENAI] Chat completion created successfully.[39m
[1693482967480] [32m[OPENAI] Embedding created successfully.[39m
[1693482967547] [33m[OPENAI] Creating embedding...[39m
[1693482967696] [32m[OPENAI] Embedding created successfully.[39m
[1693482967745] --- Observations received -- 
[1693482967745] {
  "observerId": "A2",
  "observation": "George Brown picked up Copper at X: 54.12965, Y: 19.93195",
  "time": 120.61158
}
[1693482967745] [Character] Getting character: A2
[1693482967821] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482967821] [33m[OPENAI] Creating embedding...[39m
[1693482967914] [33m[OPENAI] Creating embedding...[39m
[1693482968079] [33m[OPENAI] Creating embedding...[39m
[1693482968081] {
  "id": "chatcmpl-7taZLWSQMZT9UKZuBb5G3TarnrqZc",
  "object": "chat.completion",
  "created": 1693482967,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693482968081] {
  "role": "assistant",
  "content": "1"
}
[1693482968081] [36m[OPENAI] Chat completion took 259.3812919855118ms[39m
[1693482968081] [36m[OPENAI] Tokens per second: 3.8553281632040632tps[39m
[1693482968081] [32m[OPENAI] Chat completion created successfully.[39m
[1693482968083] [32m[OPENAI] Embedding created successfully.[39m
[1693482968134] [Character] Getting character: A2
[1693482968179] [33m[OPENAI] Creating embedding...[39m
[1693482968247] [32m[OPENAI] Embedding created successfully.[39m
[1693482968263] [32m[OPENAI] Embedding created successfully.[39m
[1693482968338] [32m[OPENAI] Embedding created successfully.[39m
[1693482968551] [33m[OPENAI] Creating embedding...[39m
[1693482968680] [33m[OPENAI] Creating embedding...[39m
[1693482968781] [32m[OPENAI] Embedding created successfully.[39m
[1693482968914] [33m[OPENAI] Creating embedding...[39m
[1693482968950] [32m[OPENAI] Embedding created successfully.[39m
[1693482969062] [32m[OPENAI] Embedding created successfully.[39m
[1693482969310] [33m[OPENAI] Creating embedding...[39m
[1693482969430] [33m[OPENAI] Creating embedding...[39m
[1693482969467] [32m[OPENAI] Embedding created successfully.[39m
[1693482969496] [33m[OPENAI] Creating embedding...[39m
[1693482969620] [32m[OPENAI] Embedding created successfully.[39m
[1693482969731] [32m[OPENAI] Embedding created successfully.[39m
[1693482969928] [33m[OPENAI] Creating embedding...[39m
[1693482970072] [32m[OPENAI] Embedding created successfully.[39m
[1693482970124] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482970309] [33m[OPENAI] Creating embedding...[39m
[1693482970443] [32m[OPENAI] Embedding created successfully.[39m
[1693482970508] [33m[OPENAI] Creating embedding...[39m
[1693482970696] [32m[OPENAI] Embedding created successfully.[39m
[1693482970883] [33m[OPENAI] Creating embedding...[39m
[1693482971091] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482971158] [32m[OPENAI] Embedding created successfully.[39m
[1693482971574] [33m[OPENAI] Creating embedding...[39m
[1693482971711] [32m[OPENAI] Embedding created successfully.[39m
[1693482972228] [33m[OPENAI] Creating embedding...[39m
[1693482972379] [32m[OPENAI] Embedding created successfully.[39m
[1693482972832] [33m[OPENAI] Creating embedding...[39m
[1693482972974] [32m[OPENAI] Embedding created successfully.[39m
[1693482973443] [33m[OPENAI] Creating embedding...[39m
[1693482973634] [32m[OPENAI] Embedding created successfully.[39m
[1693482974094] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482974808] {
  "id": "chatcmpl-7taZOniOW5mJyBN6bIceKnwtrt9MS",
  "object": "chat.completion",
  "created": 1693482970,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A3\",\n  \"x\": 44.48,\n  \"y\": -14.04\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2379,
    "completion_tokens": 35,
    "total_tokens": 2414
  }
}
[1693482974808] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A3\",\n  \"x\": 44.48,\n  \"y\": -14.04\n}"
  }
}
[1693482974808] [36m[OPENAI] Chat completion took 4684.068083047867ms[39m
[1693482974808] [36m[OPENAI] Tokens per second: 7.472137334354439tps[39m
[1693482974808] [32m[OPENAI] Chat completion created successfully.[39m
[1693482974815] --- Observations received -- 
[1693482974815] {
  "observerId": "A3",
  "observation": "Will Turner has started walking to 44.48, Y: -14.04.",
  "time": 127.68132
}
[1693482974815] [Character] Getting character: A3
[1693482974882] --- Observations received -- 
[1693482974882] {
  "observerId": "A3",
  "observation": "Will Turner finished walking to 44.48, Y: -14.04.",
  "time": 127.739952
}
[1693482974882] [Character] Getting character: A3
[1693482974883] [Character] Getting character: A3
[1693482974883] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482974883] [33m[OPENAI] Creating embedding...[39m
[1693482974913] [33m[OPENAI] Creating embedding...[39m
[1693482974962] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482974966] [33m[OPENAI] Creating embedding...[39m
[1693482975067] [32m[OPENAI] Embedding created successfully.[39m
[1693482975102] [32m[OPENAI] Embedding created successfully.[39m
[1693482975116] {
  "id": "chatcmpl-7taZS4T0CwM0lBUoKlT0IwmhHsfUx",
  "object": "chat.completion",
  "created": 1693482974,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693482975116] {
  "role": "assistant",
  "content": "1"
}
[1693482975116] [36m[OPENAI] Chat completion took 232.43208301067352ms[39m
[1693482975116] [36m[OPENAI] Tokens per second: 4.302332049203719tps[39m
[1693482975116] [32m[OPENAI] Chat completion created successfully.[39m
[1693482975282] {
  "id": "chatcmpl-7taZT434chyaQfh7862zaJNUfjpno",
  "object": "chat.completion",
  "created": 1693482975,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693482975283] {
  "role": "assistant",
  "content": "2"
}
[1693482975283] [36m[OPENAI] Chat completion took 318.9082080125809ms[39m
[1693482975283] [36m[OPENAI] Tokens per second: 3.13569853291625tps[39m
[1693482975283] [32m[OPENAI] Chat completion created successfully.[39m
[1693482975338] {
  "id": "chatcmpl-7taZP7TncfF2y2jmsC6r1q28iIMH6",
  "object": "chat.completion",
  "created": 1693482971,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "add_wood_to_chest",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"chestId\": \"chest_(50.52,14.5)\",\n  \"itemId\": \"wood\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2465,
    "completion_tokens": 44,
    "total_tokens": 2509
  }
}
[1693482975338] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "add_wood_to_chest",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"chestId\": \"chest_(50.52,14.5)\",\n  \"itemId\": \"wood\"\n}"
  }
}
[1693482975338] [36m[OPENAI] Chat completion took 4246.7186670303345ms[39m
[1693482975338] [36m[OPENAI] Tokens per second: 10.360940634376547tps[39m
[1693482975338] [32m[OPENAI] Chat completion created successfully.[39m
[1693482975346] [Character] Getting character: A4
[1693482975397] [33m[OPENAI] Creating embedding...[39m
[1693482975620] [33m[OPENAI] Creating embedding...[39m
[1693482975679] [32m[OPENAI] Embedding created successfully.[39m
[1693482975760] [32m[OPENAI] Embedding created successfully.[39m
[1693482975818] [32m[OPENAI] Embedding created successfully.[39m
[1693482976258] [33m[OPENAI] Creating embedding...[39m
[1693482976328] [33m[OPENAI] Creating embedding...[39m
[1693482976430] [32m[OPENAI] Embedding created successfully.[39m
[1693482976511] [32m[OPENAI] Embedding created successfully.[39m
[1693482976941] [33m[OPENAI] Creating embedding...[39m
[1693482977068] [33m[OPENAI] Creating embedding...[39m
[1693482977145] [32m[OPENAI] Embedding created successfully.[39m
[1693482977249] [32m[OPENAI] Embedding created successfully.[39m
[1693482977683] [33m[OPENAI] Creating embedding...[39m
[1693482977685] [33m[OPENAI] Creating embedding...[39m
[1693482977799] {
  "id": "chatcmpl-7taZSuo7edMwsbF8vtrvJcMd9IcGo",
  "object": "chat.completion",
  "created": 1693482974,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 54.64,\n  \"y\": 16.97\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2349,
    "completion_tokens": 35,
    "total_tokens": 2384
  }
}
[1693482977799] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 54.64,\n  \"y\": 16.97\n}"
  }
}
[1693482977799] [36m[OPENAI] Chat completion took 3704.4897919893265ms[39m
[1693482977799] [36m[OPENAI] Tokens per second: 9.44799472134727tps[39m
[1693482977799] [32m[OPENAI] Chat completion created successfully.[39m
[1693482977805] --- Observations received -- 
[1693482977805] {
  "observerId": "A2",
  "observation": "George Brown has started walking to 54.64, Y: 16.97.",
  "time": 130.671936
}
[1693482977805] [Character] Getting character: A2
[1693482977849] [32m[OPENAI] Embedding created successfully.[39m
[1693482977867] [32m[OPENAI] Embedding created successfully.[39m
[1693482977880] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482977880] [33m[OPENAI] Creating embedding...[39m
[1693482978053] [32m[OPENAI] Embedding created successfully.[39m
[1693482978148] --- Observations received -- 
[1693482978148] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Small) at X: 56.74, Y: 14.81.",
  "time": 131.0016
}
[1693482978148] [Character] Getting character: A2
[1693482978168] {
  "id": "chatcmpl-7taZVbElIVAzUJQIEKEvgfwWEDPFn",
  "object": "chat.completion",
  "created": 1693482977,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693482978168] {
  "role": "assistant",
  "content": "1"
}
[1693482978168] [36m[OPENAI] Chat completion took 287.4635419845581ms[39m
[1693482978168] [36m[OPENAI] Tokens per second: 3.478702005465854tps[39m
[1693482978168] [32m[OPENAI] Chat completion created successfully.[39m
[1693482978216] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482978216] [33m[OPENAI] Creating embedding...[39m
[1693482978368] [33m[OPENAI] Creating embedding...[39m
[1693482978382] [33m[OPENAI] Creating embedding...[39m
[1693482978383] [32m[OPENAI] Embedding created successfully.[39m
[1693482978516] --- Observations received -- 
[1693482978516] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CopperOreSmall (4) at X: 57.1, Y: 24.45",
  "time": 131.38205
}
[1693482978516] [Character] Getting character: A2
[1693482978547] [32m[OPENAI] Embedding created successfully.[39m
[1693482978567] [32m[OPENAI] Embedding created successfully.[39m
[1693482978591] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482978591] [33m[OPENAI] Creating embedding...[39m
[1693482978596] --- Observations received -- 
[1693482978596] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Medium) at X: 59.9, Y: 16.03.",
  "time": 131.460831
}
[1693482978596] [Character] Getting character: A2
[1693482978627] Generated memories for Eli Green: - Thomas Smith asked for my help with chopping wood for the campfire.
- We decided to finish chopping the wood before lunch.
- I was excited about this new adventure and the possibility of learning something new.
- I realized Thomas started the conversation because he needed my help.
[1693482978628] [33m[CONVERSATION] Created 4 memories for Eli Green.[39m
[1693482978629] [Character] Getting character: A5
[1693482978674] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482978674] [33m[OPENAI] Creating embedding...[39m
[1693482978707] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482978707] [33m[OPENAI] Creating embedding...[39m
[1693482978708] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482978708] [33m[OPENAI] Creating embedding...[39m
[1693482978708] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482978708] [33m[OPENAI] Creating embedding...[39m
[1693482978709] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482978710] [33m[OPENAI] Creating embedding...[39m
[1693482978722] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482978723] --- Observations received -- 
[1693482978723] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CopperOreMedium (1) at X: 54.06, Y: 24.46",
  "time": 131.5801
}
[1693482978723] [Character] Getting character: A2
[1693482978724] {
  "id": "chatcmpl-7taZW3A1iHH7tJlTwQjPUxEdWWxYn",
  "object": "chat.completion",
  "created": 1693482978,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482978724] {
  "role": "assistant",
  "content": "2"
}
[1693482978724] [36m[OPENAI] Chat completion took 508.1059579849243ms[39m
[1693482978724] [36m[OPENAI] Tokens per second: 1.9680934346171757tps[39m
[1693482978724] [32m[OPENAI] Chat completion created successfully.[39m
[1693482978770] [32m[OPENAI] Embedding created successfully.[39m
[1693482978809] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482978809] [33m[OPENAI] Creating embedding...[39m
[1693482978857] [32m[OPENAI] Embedding created successfully.[39m
[1693482978916] [32m[OPENAI] Embedding created successfully.[39m
[1693482978938] --- Observations received -- 
[1693482978939] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees George Brown at X: 54.74415, Y: 18.37014.",
  "time": 131.80072
}
[1693482978939] [Character] Getting character: A4
[1693482978940] {
  "id": "chatcmpl-7taZWgzWaQc4uO8zt171fMaYQ7vNf",
  "object": "chat.completion",
  "created": 1693482978,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482978940] {
  "role": "assistant",
  "content": "3"
}
[1693482978940] [36m[OPENAI] Chat completion took 266.24774992465973ms[39m
[1693482978940] [36m[OPENAI] Tokens per second: 3.7559002856661534tps[39m
[1693482978940] [32m[OPENAI] Chat completion created successfully.[39m
[1693482978944] {
  "id": "chatcmpl-7taZWvEEjL4uxVcV8zdpH28f8RndD",
  "object": "chat.completion",
  "created": 1693482978,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 2,
    "total_tokens": 110
  }
}
[1693482978944] {
  "role": "assistant",
  "content": "3."
}
[1693482978944] [36m[OPENAI] Chat completion took 352.94200003147125ms[39m
[1693482978944] [36m[OPENAI] Tokens per second: 5.66665344397001tps[39m
[1693482978944] [32m[OPENAI] Chat completion created successfully.[39m
[1693482978960] --- Observations received -- 
[1693482978961] {
  "observerId": "A2",
  "observation": "George Brown sees Chest at X: 50.52, Y: 14.5.",
  "time": 131.8203
}
[1693482978962] [Character] Getting character: A2
[1693482978983] {
  "id": "chatcmpl-7taZWdwXJzW3ZgaVyBHWCSzr6dPtw",
  "object": "chat.completion",
  "created": 1693482978,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 96,
    "completion_tokens": 1,
    "total_tokens": 97
  }
}
[1693482978983] {
  "role": "assistant",
  "content": "2"
}
[1693482978983] [36m[OPENAI] Chat completion took 276.2754579782486ms[39m
[1693482978983] [36m[OPENAI] Tokens per second: 3.619575938152027tps[39m
[1693482978983] [32m[OPENAI] Chat completion created successfully.[39m
[1693482978984] [32m[OPENAI] Embedding created successfully.[39m
[1693482978984] [32m[OPENAI] Embedding created successfully.[39m
[1693482978988] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482978988] [33m[OPENAI] Creating embedding...[39m
[1693482979018] {
  "id": "chatcmpl-7taZWZ1YlWRtfcWfPoQEzxZJF3ob5",
  "object": "chat.completion",
  "created": 1693482978,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 92,
    "completion_tokens": 1,
    "total_tokens": 93
  }
}
[1693482979018] {
  "role": "assistant",
  "content": "2"
}
[1693482979018] [36m[OPENAI] Chat completion took 310.3370840549469ms[39m
[1693482979018] [36m[OPENAI] Tokens per second: 3.222302623114627tps[39m
[1693482979018] [32m[OPENAI] Chat completion created successfully.[39m
[1693482979020] [32m[OPENAI] Embedding created successfully.[39m
[1693482979022] {
  "id": "chatcmpl-7taZWHH6vwtJcOdczLIexTtgjPCYR",
  "object": "chat.completion",
  "created": 1693482978,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "9"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693482979022] {
  "role": "assistant",
  "content": "9"
}
[1693482979022] [36m[OPENAI] Chat completion took 312.55070888996124ms[39m
[1693482979022] [36m[OPENAI] Tokens per second: 3.199480825212484tps[39m
[1693482979022] [32m[OPENAI] Chat completion created successfully.[39m
[1693482979030] [33m[OPENAI] Creating embedding...[39m
[1693482979031] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482979031] [33m[OPENAI] Creating embedding...[39m
[1693482979097] --- Observations received -- 
[1693482979097] {
  "observerId": "A2",
  "observation": "George Brown no longer sees DiamondOreSmall at X: 58.32, Y: 22.87",
  "time": 131.960678
}
[1693482979097] [Character] Getting character: A2
[1693482979097] [33m[OPENAI] Creating embedding...[39m
[1693482979098] {
  "id": "chatcmpl-7taZWopstDXS0NICcPbHEWya2yTyH",
  "object": "chat.completion",
  "created": 1693482978,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693482979098] {
  "role": "assistant",
  "content": "1"
}
[1693482979098] [36m[OPENAI] Chat completion took 289.3504589796066ms[39m
[1693482979098] [36m[OPENAI] Tokens per second: 3.456016636457037tps[39m
[1693482979098] [32m[OPENAI] Chat completion created successfully.[39m
[1693482979115] {
  "id": "chatcmpl-7taZW5qA2A1Z51UOdOD2S3ouWjTrV",
  "object": "chat.completion",
  "created": 1693482978,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693482979115] {
  "role": "assistant",
  "content": "4"
}
[1693482979115] [36m[OPENAI] Chat completion took 407.0572910308838ms[39m
[1693482979115] [36m[OPENAI] Tokens per second: 2.4566566476858145tps[39m
[1693482979115] [32m[OPENAI] Chat completion created successfully.[39m
[1693482979126] [32m[OPENAI] Embedding created successfully.[39m
[1693482979153] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482979153] [33m[OPENAI] Creating embedding...[39m
[1693482979171] [32m[OPENAI] Embedding created successfully.[39m
[1693482979211] [32m[OPENAI] Embedding created successfully.[39m
[1693482979213] [32m[OPENAI] Embedding created successfully.[39m
[1693482979250] {
  "id": "chatcmpl-7taZXHXNI2rJdyPrAZxsWXblJY0Po",
  "object": "chat.completion",
  "created": 1693482979,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1693482979250] {
  "role": "assistant",
  "content": "2"
}
[1693482979250] [36m[OPENAI] Chat completion took 261.38387501239777ms[39m
[1693482979250] [36m[OPENAI] Tokens per second: 3.8257907070685544tps[39m
[1693482979250] [32m[OPENAI] Chat completion created successfully.[39m
[1693482979286] [32m[OPENAI] Embedding created successfully.[39m
[1693482979301] --- Observations received -- 
[1693482979304] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CopperOreMedium at X: 52.01, Y: 23.05",
  "time": 132.161987
}
[1693482979304] [Character] Getting character: A2
[1693482979333] {
  "id": "chatcmpl-7taZX0nt3WbQazSWxvKzkYRrO5mfz",
  "object": "chat.completion",
  "created": 1693482979,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482979333] {
  "role": "assistant",
  "content": "2"
}
[1693482979333] [36m[OPENAI] Chat completion took 302.15345907211304ms[39m
[1693482979333] [36m[OPENAI] Tokens per second: 3.3095765412413707tps[39m
[1693482979333] [32m[OPENAI] Chat completion created successfully.[39m
[1693482979380] --- Observations received -- 
[1693482979380] {
  "observerId": "A2",
  "observation": "George Brown finished walking to 54.64, Y: 16.97.",
  "time": 132.23996
}
[1693482979380] [Character] Getting character: A2
[1693482979380] [Character] Getting character: A2
[1693482979396] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482979396] [33m[OPENAI] Creating embedding...[39m
[1693482979405] [32m[OPENAI] Embedding created successfully.[39m
[1693482979477] [33m[OPENAI] Creating embedding...[39m
[1693482979491] {
  "id": "chatcmpl-7taZXEMBsLCdHqwFsWD32v9ld5Ql8",
  "object": "chat.completion",
  "created": 1693482979,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482979491] {
  "role": "assistant",
  "content": "3"
}
[1693482979491] [36m[OPENAI] Chat completion took 337.5680409669876ms[39m
[1693482979491] [36m[OPENAI] Tokens per second: 2.9623657415418503tps[39m
[1693482979491] [32m[OPENAI] Chat completion created successfully.[39m
[1693482979509] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482979510] [33m[OPENAI] Creating embedding...[39m
[1693482979592] [32m[OPENAI] Embedding created successfully.[39m
[1693482979634] [33m[OPENAI] Creating embedding...[39m
[1693482979638] {
  "id": "chatcmpl-7taZX7FnzeCgpeFpEiLfm1lSa7NUz",
  "object": "chat.completion",
  "created": 1693482979,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482979638] {
  "role": "assistant",
  "content": "2"
}
[1693482979638] [36m[OPENAI] Chat completion took 242.10858297348022ms[39m
[1693482979638] [36m[OPENAI] Tokens per second: 4.130378145699761tps[39m
[1693482979638] [32m[OPENAI] Chat completion created successfully.[39m
[1693482979639] [32m[OPENAI] Embedding created successfully.[39m
[1693482979672] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482979673] [32m[OPENAI] Embedding created successfully.[39m
[1693482979807] {
  "id": "chatcmpl-7taZXi4igcZEinUrwAhpXSaPAwKJa",
  "object": "chat.completion",
  "created": 1693482979,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693482979807] {
  "role": "assistant",
  "content": "4"
}
[1693482979807] [36m[OPENAI] Chat completion took 296.83808302879333ms[39m
[1693482979807] [36m[OPENAI] Tokens per second: 3.368839974293325tps[39m
[1693482979807] [32m[OPENAI] Chat completion created successfully.[39m
[1693482979869] [32m[OPENAI] Embedding created successfully.[39m
[1693482980063] [33m[OPENAI] Creating embedding...[39m
[1693482980298] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482980716] --- Observations received -- 
[1693482980716] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Thomas Smith at X: 46.04252, Y: 16.35239.",
  "time": 133.581772
}
[1693482980716] [Character] Getting character: A4
[1693482980775] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482980775] [33m[OPENAI] Creating embedding...[39m
[1693482981036] {
  "id": "chatcmpl-7taZYECtkFzZBi2k7S5m5hjN6LiJr",
  "object": "chat.completion",
  "created": 1693482980,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1693482981036] {
  "role": "assistant",
  "content": "4"
}
[1693482981037] [36m[OPENAI] Chat completion took 261.37433302402496ms[39m
[1693482981037] [36m[OPENAI] Tokens per second: 3.8259303751454516tps[39m
[1693482981037] [32m[OPENAI] Chat completion created successfully.[39m
[1693482981085] [32m[OPENAI] Embedding created successfully.[39m
[1693482981164] [32m[OPENAI] Embedding created successfully.[39m
[1693482981457] --- Observations received -- 
[1693482981458] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees Human at X: 47.15302, Y: 15.90692",
  "time": 134.320374
}
[1693482981458] [Character] Getting character: A5
[1693482981569] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482981570] [33m[OPENAI] Creating embedding...[39m
[1693482981713] [33m[OPENAI] Creating embedding...[39m
[1693482981844] {
  "id": "chatcmpl-7taZZexNZK7vsDb0mqaMqdKrY4D9N",
  "object": "chat.completion",
  "created": 1693482981,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1693482981844] {
  "role": "assistant",
  "content": "3"
}
[1693482981844] [36m[OPENAI] Chat completion took 274.77045798301697ms[39m
[1693482981844] [36m[OPENAI] Tokens per second: 3.6394014383518916tps[39m
[1693482981844] [32m[OPENAI] Chat completion created successfully.[39m
[1693482981855] [32m[OPENAI] Embedding created successfully.[39m
[1693482981909] [32m[OPENAI] Embedding created successfully.[39m
[1693482982429] [33m[OPENAI] Creating embedding...[39m
[1693482982616] [32m[OPENAI] Embedding created successfully.[39m
[1693482983116] {
  "id": "chatcmpl-7taZXx4HTgHdVdOnvsgWzh2Rx0IgC",
  "object": "chat.completion",
  "created": 1693482979,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A3\",\n  \"x\": 43.22001,\n  \"y\": -16.37\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2368,
    "completion_tokens": 36,
    "total_tokens": 2404
  }
}
[1693482983116] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A3\",\n  \"x\": 43.22001,\n  \"y\": -16.37\n}"
  }
}
[1693482983116] [36m[OPENAI] Chat completion took 3444.400665998459ms[39m
[1693482983116] [36m[OPENAI] Tokens per second: 10.451745743570271tps[39m
[1693482983116] [32m[OPENAI] Chat completion created successfully.[39m
[1693482983118] --- Observations received -- 
[1693482983118] {
  "observerId": "A3",
  "observation": "Will Turner has started walking to 43.22001, Y: -16.37.",
  "time": 135.984818
}
[1693482983118] [Character] Getting character: A3
[1693482983172] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482983172] [33m[OPENAI] Creating embedding...[39m
[1693482983176] --- Observations received -- 
[1693482983176] {
  "observerId": "A3",
  "observation": "Will Turner no longer sees Tree (17) at X: 38.39, Y: -14.58",
  "time": 136.042389
}
[1693482983176] [Character] Getting character: A3
[1693482983199] [33m[OPENAI] Creating embedding...[39m
[1693482983226] --- Observations received -- 
[1693482983226] {
  "observerId": "A3",
  "observation": "Will Turner no longer sees Tree (94) at X: 38.63, Y: -11.64",
  "time": 136.0805
}
[1693482983226] [Character] Getting character: A3
[1693482983229] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482983229] [33m[OPENAI] Creating embedding...[39m
[1693482983290] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482983291] [33m[OPENAI] Creating embedding...[39m
[1693482983332] [32m[OPENAI] Embedding created successfully.[39m
[1693482983344] [32m[OPENAI] Embedding created successfully.[39m
[1693482983446] [32m[OPENAI] Embedding created successfully.[39m
[1693482983480] {
  "id": "chatcmpl-7taZbIZtoVK21vVwIifIOtq1ntzmW",
  "object": "chat.completion",
  "created": 1693482983,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482983480] {
  "role": "assistant",
  "content": "1"
}
[1693482983480] [36m[OPENAI] Chat completion took 307.07545804977417ms[39m
[1693482983480] [36m[OPENAI] Tokens per second: 3.256528562559073tps[39m
[1693482983480] [32m[OPENAI] Chat completion created successfully.[39m
[1693482983486] {
  "id": "chatcmpl-7taZbleP7tZ7gJyZtWXkqgWsXJSdx",
  "object": "chat.completion",
  "created": 1693482983,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482983486] {
  "role": "assistant",
  "content": "6"
}
[1693482983486] [36m[OPENAI] Chat completion took 257.28479194641113ms[39m
[1693482983486] [36m[OPENAI] Tokens per second: 3.8867435281922385tps[39m
[1693482983486] [32m[OPENAI] Chat completion created successfully.[39m
[1693482983500] [32m[OPENAI] Embedding created successfully.[39m
[1693482983535] --- Observations received -- 
[1693482983535] {
  "observerId": "A3",
  "observation": "Will Turner no longer sees Stump (17) at X: 40.39, Y: -17.62",
  "time": 136.40062
}
[1693482983535] [Character] Getting character: A3
[1693482983591] {
  "id": "chatcmpl-7taZb9UZavlteXOgraNnUE2AgHKSy",
  "object": "chat.completion",
  "created": 1693482983,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482983591] {
  "role": "assistant",
  "content": "6"
}
[1693482983591] [36m[OPENAI] Chat completion took 301.0450419187546ms[39m
[1693482983591] [36m[OPENAI] Tokens per second: 3.3217620646610015tps[39m
[1693482983591] [32m[OPENAI] Chat completion created successfully.[39m
[1693482983597] --- Observations received -- 
[1693482983597] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 49.51, Y: -10.13.",
  "time": 136.46106
}
[1693482983597] [Character] Getting character: A3
[1693482983606] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482983607] [33m[OPENAI] Creating embedding...[39m
[1693482983686] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482983686] [33m[OPENAI] Creating embedding...[39m
[1693482983815] [32m[OPENAI] Embedding created successfully.[39m
[1693482983883] [33m[OPENAI] Creating embedding...[39m
[1693482983884] [32m[OPENAI] Embedding created successfully.[39m
[1693482983891] {
  "id": "chatcmpl-7taZbqQnJPXRH9A9YnGIaIIM3a6X6",
  "object": "chat.completion",
  "created": 1693482983,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482983891] {
  "role": "assistant",
  "content": "7"
}
[1693482983891] [36m[OPENAI] Chat completion took 284.3005840778351ms[39m
[1693482983891] [36m[OPENAI] Tokens per second: 3.5174039590654607tps[39m
[1693482983891] [32m[OPENAI] Chat completion created successfully.[39m
[1693482984053] [32m[OPENAI] Embedding created successfully.[39m
[1693482984536] --- Observations received -- 
[1693482984536] {
  "observerId": "A3",
  "observation": "Will Turner no longer sees Tree (421) at X: 49.51, Y: -10.13",
  "time": 137.400726
}
[1693482984536] [Character] Getting character: A3
[1693482984575] [33m[OPENAI] Creating embedding...[39m
[1693482984591] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482984591] [33m[OPENAI] Creating embedding...[39m
[1693482984712] [32m[OPENAI] Embedding created successfully.[39m
[1693482984734] --- Observations received -- 
[1693482984734] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree Stump at X: 40.39, Y: -17.62.",
  "time": 137.600281
}
[1693482984734] [Character] Getting character: A3
[1693482984798] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482984798] [33m[OPENAI] Creating embedding...[39m
[1693482984800] [32m[OPENAI] Embedding created successfully.[39m
[1693482984838] {
  "id": "chatcmpl-7taZc1mr07Q8viEIHTVGQNkOjZiZQ",
  "object": "chat.completion",
  "created": 1693482984,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482984838] {
  "role": "assistant",
  "content": "1"
}
[1693482984838] [36m[OPENAI] Chat completion took 246.67750000953674ms[39m
[1693482984838] [36m[OPENAI] Tokens per second: 4.053876012045441tps[39m
[1693482984838] [32m[OPENAI] Chat completion created successfully.[39m
[1693482984982] --- Observations received -- 
[1693482984982] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 44.3, Y: -20.42.",
  "time": 137.84169
}
[1693482984982] [Character] Getting character: A3
[1693482984997] [32m[OPENAI] Embedding created successfully.[39m
[1693482985006] {
  "id": "chatcmpl-7taZY19VEpGgvWkX4w3wz8xzYwj5T",
  "object": "chat.completion",
  "created": 1693482980,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "add_wood_to_chest",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"chestId\": \"chest_(50.52,14.5)\",\n  \"itemId\": \"wood\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2387,
    "completion_tokens": 44,
    "total_tokens": 2431
  }
}
[1693482985006] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "add_wood_to_chest",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"chestId\": \"chest_(50.52,14.5)\",\n  \"itemId\": \"wood\"\n}"
  }
}
[1693482985006] [36m[OPENAI] Chat completion took 4707.428417086601ms[39m
[1693482985006] [36m[OPENAI] Tokens per second: 9.346929172686462tps[39m
[1693482985006] [32m[OPENAI] Chat completion created successfully.[39m
[1693482985012] [Character] Getting character: A4
[1693482985028] {
  "id": "chatcmpl-7taZbZaiavwTKIYrkLHMe4yAcngrT",
  "object": "chat.completion",
  "created": 1693482983,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482985029] {
  "role": "assistant",
  "content": "3"
}
[1693482985029] [36m[OPENAI] Chat completion took 1342.6150419712067ms[39m
[1693482985029] [36m[OPENAI] Tokens per second: 0.7448151322152741tps[39m
[1693482985029] [32m[OPENAI] Chat completion created successfully.[39m
[1693482985046] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482985046] [33m[OPENAI] Creating embedding...[39m
[1693482985047] [33m[OPENAI] Creating embedding...[39m
[1693482985118] {
  "id": "chatcmpl-7taZcgrjz5ROtEBbsU4KcM6PvoViB",
  "object": "chat.completion",
  "created": 1693482984,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693482985119] {
  "role": "assistant",
  "content": "1"
}
[1693482985119] [36m[OPENAI] Chat completion took 320.7707920074463ms[39m
[1693482985119] [36m[OPENAI] Tokens per second: 3.117490821847602tps[39m
[1693482985119] [32m[OPENAI] Chat completion created successfully.[39m
[1693482985196] --- Observations received -- 
[1693482985196] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 40.79, Y: -19.31.",
  "time": 138.060211
}
[1693482985196] [Character] Getting character: A3
[1693482985214] [32m[OPENAI] Embedding created successfully.[39m
[1693482985214] [33m[OPENAI] Creating embedding...[39m
[1693482985253] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482985254] [33m[OPENAI] Creating embedding...[39m
[1693482985296] [32m[OPENAI] Embedding created successfully.[39m
[1693482985358] [32m[OPENAI] Embedding created successfully.[39m
[1693482985363] {
  "id": "chatcmpl-7taZdrgWGdIjGeBZ0iVL5lENvihMI",
  "object": "chat.completion",
  "created": 1693482985,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482985363] {
  "role": "assistant",
  "content": "2"
}
[1693482985363] [36m[OPENAI] Chat completion took 316.93683302402496ms[39m
[1693482985363] [36m[OPENAI] Tokens per second: 3.155202853699861tps[39m
[1693482985363] [32m[OPENAI] Chat completion created successfully.[39m
[1693482985396] --- Observations received -- 
[1693482985396] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 38.96, Y: -16.52.",
  "time": 138.261826
}
[1693482985396] [Character] Getting character: A3
[1693482985442] [32m[OPENAI] Embedding created successfully.[39m
[1693482985466] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482985466] [33m[OPENAI] Creating embedding...[39m
[1693482985478] {
  "id": "chatcmpl-7taZdlpBvH74xTyFlYDBtClhEKDeN",
  "object": "chat.completion",
  "created": 1693482985,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482985478] {
  "role": "assistant",
  "content": "4"
}
[1693482985478] [36m[OPENAI] Chat completion took 225.49783301353455ms[39m
[1693482985478] [36m[OPENAI] Tokens per second: 4.434632415913191tps[39m
[1693482985479] [32m[OPENAI] Chat completion created successfully.[39m
[1693482985562] --- Observations received -- 
[1693482985563] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 42.4, Y: -20.7.",
  "time": 138.420639
}
[1693482985563] [Character] Getting character: A3
[1693482985663] [32m[OPENAI] Embedding created successfully.[39m
[1693482985664] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482985664] [33m[OPENAI] Creating embedding...[39m
[1693482985725] [33m[OPENAI] Creating embedding...[39m
[1693482985725] --- Observations received -- 
[1693482985725] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree at X: 38.39, Y: -14.58.",
  "time": 138.581268
}
[1693482985725] [Character] Getting character: A3
[1693482985790] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482985796] [33m[OPENAI] Creating embedding...[39m
[1693482985813] {
  "id": "chatcmpl-7taZdzeYSqtHSmSCbKdhtni7culFy",
  "object": "chat.completion",
  "created": 1693482985,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482985813] {
  "role": "assistant",
  "content": "5"
}
[1693482985813] [36m[OPENAI] Chat completion took 346.7011669874191ms[39m
[1693482985813] [36m[OPENAI] Tokens per second: 2.884328335809401tps[39m
[1693482985813] [32m[OPENAI] Chat completion created successfully.[39m
[1693482985864] [33m[OPENAI] Creating embedding...[39m
[1693482985915] [32m[OPENAI] Embedding created successfully.[39m
[1693482985931] {
  "id": "chatcmpl-7taZdud3s28Gtlkip1HVgPKMaETrl",
  "object": "chat.completion",
  "created": 1693482985,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482985931] {
  "role": "assistant",
  "content": "2"
}
[1693482985931] [36m[OPENAI] Chat completion took 266.6102499961853ms[39m
[1693482985931] [36m[OPENAI] Tokens per second: 3.7507935273092765tps[39m
[1693482985931] [32m[OPENAI] Chat completion created successfully.[39m
[1693482985956] --- Observations received -- 
[1693482985957] {
  "observerId": "A3",
  "observation": "Will Turner finished walking to 43.22001, Y: -16.37.",
  "time": 138.819946
}
[1693482985957] [Character] Getting character: A3
[1693482985965] [Character] Getting character: A3
[1693482985982] [32m[OPENAI] Embedding created successfully.[39m
[1693482985997] [33m[OPENAI] Creating embedding...[39m
[1693482985998] [32m[OPENAI] Embedding created successfully.[39m
[1693482986014] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482986015] [33m[OPENAI] Creating embedding...[39m
[1693482986063] [32m[OPENAI] Embedding created successfully.[39m
[1693482986131] [32m[OPENAI] Embedding created successfully.[39m
[1693482986162] [32m[OPENAI] Embedding created successfully.[39m
[1693482986273] {
  "id": "chatcmpl-7taZecgvQzlIZ3s8mKxBCK36mUplo",
  "object": "chat.completion",
  "created": 1693482986,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693482986273] {
  "role": "assistant",
  "content": "2"
}
[1693482986274] [36m[OPENAI] Chat completion took 258.5341670513153ms[39m
[1693482986274] [36m[OPENAI] Tokens per second: 3.867960708657569tps[39m
[1693482986274] [32m[OPENAI] Chat completion created successfully.[39m
[1693482986297] --- Observations received -- 
[1693482986297] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees Human at X: 49.0015, Y: 10.07454",
  "time": 139.1623
}
[1693482986297] [Character] Getting character: A4
[1693482986314] {
  "id": "chatcmpl-7taZdOoLpCIZz93cO1eZSf87KS2Sr",
  "object": "chat.completion",
  "created": 1693482985,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693482986314] {
  "role": "assistant",
  "content": "1"
}
[1693482986314] [36m[OPENAI] Chat completion took 523.6436250209808ms[39m
[1693482986314] [36m[OPENAI] Tokens per second: 1.9096957400368104tps[39m
[1693482986314] [32m[OPENAI] Chat completion created successfully.[39m
[1693482986364] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482986365] [33m[OPENAI] Creating embedding...[39m
[1693482986512] [32m[OPENAI] Embedding created successfully.[39m
[1693482986549] [33m[OPENAI] Creating embedding...[39m
[1693482986611] {
  "id": "chatcmpl-7taZeLXX0hKKx0QaQPqUHotmLhfzo",
  "object": "chat.completion",
  "created": 1693482986,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1693482986611] {
  "role": "assistant",
  "content": "7"
}
[1693482986611] [36m[OPENAI] Chat completion took 246.1230000257492ms[39m
[1693482986611] [36m[OPENAI] Tokens per second: 4.063009145408518tps[39m
[1693482986611] [32m[OPENAI] Chat completion created successfully.[39m
[1693482986626] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482986691] [33m[OPENAI] Creating embedding...[39m
[1693482986708] [32m[OPENAI] Embedding created successfully.[39m
[1693482986894] [32m[OPENAI] Embedding created successfully.[39m
[1693482987269] [33m[OPENAI] Creating embedding...[39m
[1693482987514] [33m[OPENAI] Creating embedding...[39m
[1693482987527] [32m[OPENAI] Embedding created successfully.[39m
[1693482987719] [32m[OPENAI] Embedding created successfully.[39m
[1693482987948] [33m[OPENAI] Creating embedding...[39m
[1693482988159] [32m[OPENAI] Embedding created successfully.[39m
[1693482988197] [33m[OPENAI] Creating embedding...[39m
[1693482988399] [32m[OPENAI] Embedding created successfully.[39m
[1693482988680] [33m[OPENAI] Creating embedding...[39m
[1693482988822] --- Observations received -- 
[1693482988822] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Tree Stump at X: 47.72001, Y: 10.21.",
  "time": 141.687775
}
[1693482988822] [Character] Getting character: A4
[1693482988833] [33m[OPENAI] Creating embedding...[39m
[1693482988868] [32m[OPENAI] Embedding created successfully.[39m
[1693482988888] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482988888] [33m[OPENAI] Creating embedding...[39m
[1693482988915] --- Observations received -- 
[1693482988915] {
  "observerId": "A1",
  "observation": "Thomas Smith picked up Wood at X: 48.8965, Y: 10.07454",
  "time": 141.781784
}
[1693482988915] [Character] Getting character: A1
[1693482988979] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482988980] [33m[OPENAI] Creating embedding...[39m
[1693482988993] [32m[OPENAI] Embedding created successfully.[39m
[1693482989083] [32m[OPENAI] Embedding created successfully.[39m
[1693482989197] [32m[OPENAI] Embedding created successfully.[39m
[1693482989213] {
  "id": "chatcmpl-7taZhdrjNR2iBcT8trMgUvxEzDsQg",
  "object": "chat.completion",
  "created": 1693482989,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693482989214] {
  "role": "assistant",
  "content": "1"
}
[1693482989214] [36m[OPENAI] Chat completion took 233.257542014122ms[39m
[1693482989214] [36m[OPENAI] Tokens per second: 4.287106823493224tps[39m
[1693482989214] [32m[OPENAI] Chat completion created successfully.[39m
[1693482989269] {
  "id": "chatcmpl-7taZhJKJP3DxLHqjpUI8KNgdbZYFZ",
  "object": "chat.completion",
  "created": 1693482989,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1693482989269] {
  "role": "assistant",
  "content": "3"
}
[1693482989270] [36m[OPENAI] Chat completion took 380.7994999885559ms[39m
[1693482989270] [36m[OPENAI] Tokens per second: 2.62605386832192tps[39m
[1693482989270] [32m[OPENAI] Chat completion created successfully.[39m
[1693482989380] [33m[OPENAI] Creating embedding...[39m
[1693482989512] [33m[OPENAI] Creating embedding...[39m
[1693482989552] [32m[OPENAI] Embedding created successfully.[39m
[1693482989747] [32m[OPENAI] Embedding created successfully.[39m
[1693482990090] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482990226] [33m[OPENAI] Creating embedding...[39m
[1693482990419] [32m[OPENAI] Embedding created successfully.[39m
[1693482990597] {
  "id": "chatcmpl-7taZeQc6tRcAPOO3YC8ngBC1Woscm",
  "object": "chat.completion",
  "created": 1693482986,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 50.52,\n  \"y\": 14.5\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2256,
    "completion_tokens": 35,
    "total_tokens": 2291
  }
}
[1693482990598] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 50.52,\n  \"y\": 14.5\n}"
  }
}
[1693482990598] [36m[OPENAI] Chat completion took 3971.4159170389175ms[39m
[1693482990598] [36m[OPENAI] Tokens per second: 8.812977721581968tps[39m
[1693482990598] [32m[OPENAI] Chat completion created successfully.[39m
[1693482990606] --- Observations received -- 
[1693482990606] {
  "observerId": "A2",
  "observation": "George Brown has started walking to 50.52, Y: 14.5.",
  "time": 143.472229
}
[1693482990606] [Character] Getting character: A2
[1693482990635] --- Observations received -- 
[1693482990635] {
  "observerId": "A2",
  "observation": "George Brown sees Lucy Wilde at X: 51.04561, Y: 14.3513.",
  "time": 143.5012
}
[1693482990635] [Character] Getting character: A2
[1693482990681] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482990681] [33m[OPENAI] Creating embedding...[39m
[1693482990704] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482990706] [33m[OPENAI] Creating embedding...[39m
[1693482990714] --- Observations received -- 
[1693482990714] {
  "observerId": "A2",
  "observation": "George Brown sees Copper Ore Deposit (Medium) at X: 52.01, Y: 23.05.",
  "time": 143.580322
}
[1693482990714] [Character] Getting character: A2
[1693482990772] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482990772] [33m[OPENAI] Creating embedding...[39m
[1693482990896] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482990899] --- Observations received -- 
[1693482990899] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CoalOreMedium (2) at X: 59.9, Y: 16.03",
  "time": 143.760727
}
[1693482990899] [Character] Getting character: A2
[1693482990917] --- Observations received -- 
[1693482990917] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CopperOreMedium at X: 52.01, Y: 23.05",
  "time": 143.781387
}
[1693482990917] [Character] Getting character: A2
[1693482990955] [32m[OPENAI] Embedding created successfully.[39m
[1693482990964] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482990965] [33m[OPENAI] Creating embedding...[39m
[1693482990979] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482990979] [33m[OPENAI] Creating embedding...[39m
[1693482991029] [32m[OPENAI] Embedding created successfully.[39m
[1693482991092] [32m[OPENAI] Embedding created successfully.[39m
[1693482991145] [32m[OPENAI] Embedding created successfully.[39m
[1693482991230] {
  "id": "chatcmpl-7taZj3vmT4ndzGoPvINjNe8kCNxfd",
  "object": "chat.completion",
  "created": 1693482991,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693482991230] {
  "role": "assistant",
  "content": "3"
}
[1693482991230] [36m[OPENAI] Chat completion took 264.6085419654846ms[39m
[1693482991230] [36m[OPENAI] Tokens per second: 3.779167492372334tps[39m
[1693482991230] [32m[OPENAI] Chat completion created successfully.[39m
[1693482991233] [32m[OPENAI] Embedding created successfully.[39m
[1693482991348] {
  "id": "chatcmpl-7taZjJqqZWCQy6b4MYVxZUttyUViU",
  "object": "chat.completion",
  "created": 1693482991,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1693482991348] {
  "role": "assistant",
  "content": "2"
}
[1693482991348] [36m[OPENAI] Chat completion took 643.8422919511795ms[39m
[1693482991348] [36m[OPENAI] Tokens per second: 1.5531753854961532tps[39m
[1693482991348] [32m[OPENAI] Chat completion created successfully.[39m
[1693482991497] --- Observations received -- 
[1693482991497] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CoalOreLarge (1) at X: 58.91, Y: 19.37",
  "time": 144.361786
}
[1693482991497] [Character] Getting character: A2
[1693482991562] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482991563] [33m[OPENAI] Creating embedding...[39m
[1693482991596] {
  "id": "chatcmpl-7taZjnmt9sysASG9rMla4nOtjvdHQ",
  "object": "chat.completion",
  "created": 1693482991,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482991596] {
  "role": "assistant",
  "content": "1"
}
[1693482991596] [36m[OPENAI] Chat completion took 617.2492090463638ms[39m
[1693482991597] [36m[OPENAI] Tokens per second: 1.620091180910507tps[39m
[1693482991597] [32m[OPENAI] Chat completion created successfully.[39m
[1693482991636] {
  "id": "chatcmpl-7taZjT0fQYzAn6JroEB6f7oqD2Hit",
  "object": "chat.completion",
  "created": 1693482991,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693482991636] {
  "role": "assistant",
  "content": "1"
}
[1693482991636] [36m[OPENAI] Chat completion took 954.6405420303345ms[39m
[1693482991636] [36m[OPENAI] Tokens per second: 1.047514698960087tps[39m
[1693482991636] [32m[OPENAI] Chat completion created successfully.[39m
[1693482991788] [32m[OPENAI] Embedding created successfully.[39m
[1693482991816] --- Observations received -- 
[1693482991816] {
  "observerId": "A2",
  "observation": "George Brown sees Tree Stump at X: 52.41, Y: 11.03.",
  "time": 144.682388
}
[1693482991816] [Character] Getting character: A2
[1693482991880] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482991881] [33m[OPENAI] Creating embedding...[39m
[1693482991897] {
  "id": "chatcmpl-7taZj8VVf85GdL98hzT2ubPAqmQX8",
  "object": "chat.completion",
  "created": 1693482991,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693482991897] {
  "role": "assistant",
  "content": "5"
}
[1693482991897] [36m[OPENAI] Chat completion took 334.6874170303345ms[39m
[1693482991897] [36m[OPENAI] Tokens per second: 2.987862552088012tps[39m
[1693482991898] [32m[OPENAI] Chat completion created successfully.[39m
[1693482992030] [32m[OPENAI] Embedding created successfully.[39m
[1693482992199] {
  "id": "chatcmpl-7taZjNI2ztVBQDwAbmMGelrHO1lep",
  "object": "chat.completion",
  "created": 1693482991,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693482992199] {
  "role": "assistant",
  "content": "2"
}
[1693482992199] [36m[OPENAI] Chat completion took 318.3012499809265ms[39m
[1693482992199] [36m[OPENAI] Tokens per second: 3.141677891808225tps[39m
[1693482992199] [32m[OPENAI] Chat completion created successfully.[39m
[1693482992216] --- Observations received -- 
[1693482992216] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CopperOreMedium (2) at X: 53.76, Y: 21.7",
  "time": 145.08226
}
[1693482992216] [Character] Getting character: A2
[1693482992281] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482992282] [33m[OPENAI] Creating embedding...[39m
[1693482992356] --- Observations received -- 
[1693482992358] {
  "observerId": "A2",
  "observation": "George Brown sees Stone Ore Deposit (Small) at X: 47.58, Y: 19.17.",
  "time": 145.2218
}
[1693482992358] [Character] Getting character: A2
[1693482992431] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482992431] [33m[OPENAI] Creating embedding...[39m
[1693482992517] [32m[OPENAI] Embedding created successfully.[39m
[1693482992564] {
  "id": "chatcmpl-7taZkAkYIOEzxz8U23KWbS6lAWdeb",
  "object": "chat.completion",
  "created": 1693482992,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693482992564] {
  "role": "assistant",
  "content": "2"
}
[1693482992564] [36m[OPENAI] Chat completion took 282.79845809936523ms[39m
[1693482992564] [36m[OPENAI] Tokens per second: 3.5360871721890224tps[39m
[1693482992564] [32m[OPENAI] Chat completion created successfully.[39m
[1693482992761] {
  "id": "chatcmpl-7taZkfkc7QezxSLnLwO2SVl8fdAvo",
  "object": "chat.completion",
  "created": 1693482992,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482992761] {
  "role": "assistant",
  "content": "1"
}
[1693482992761] [36m[OPENAI] Chat completion took 330.6310830116272ms[39m
[1693482992761] [36m[OPENAI] Tokens per second: 3.024519022504709tps[39m
[1693482992761] [32m[OPENAI] Chat completion created successfully.[39m
[1693482992776] --- Observations received -- 
[1693482992776] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Tree Stump at X: 50.77, Y: 9.22.",
  "time": 145.641937
}
[1693482992776] [Character] Getting character: A4
[1693482992830] [32m[OPENAI] Embedding created successfully.[39m
[1693482992846] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482992846] [33m[OPENAI] Creating embedding...[39m
[1693482992857] --- Observations received -- 
[1693482992857] {
  "observerId": "A1",
  "observation": "Thomas Smith picked up Wood at X: 49.61424, Y: 9.18183",
  "time": 145.721817
}
[1693482992857] [Character] Getting character: A1
[1693482992915] --- Observations received -- 
[1693482992915] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CoalOreMedium (1) at X: 57.27, Y: 17.32",
  "time": 145.781448
}
[1693482992915] [Character] Getting character: A2
[1693482992930] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482992930] [33m[OPENAI] Creating embedding...[39m
[1693482992963] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482992963] [33m[OPENAI] Creating embedding...[39m
[1693482993015] --- Observations received -- 
[1693482993016] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CopperOreSmall (2) at X: 50.43, Y: 20.71",
  "time": 145.8817
}
[1693482993016] [Character] Getting character: A2
[1693482993067] [32m[OPENAI] Embedding created successfully.[39m
[1693482993077] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482993077] [33m[OPENAI] Creating embedding...[39m
[1693482993148] [32m[OPENAI] Embedding created successfully.[39m
[1693482993170] [32m[OPENAI] Embedding created successfully.[39m
[1693482993180] {
  "id": "chatcmpl-7taZldIogKbWj2eKiUIb1yL13dt3e",
  "object": "chat.completion",
  "created": 1693482993,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693482993180] {
  "role": "assistant",
  "content": "1"
}
[1693482993180] [36m[OPENAI] Chat completion took 249.76437497138977ms[39m
[1693482993180] [36m[OPENAI] Tokens per second: 4.003773557035702tps[39m
[1693482993180] [32m[OPENAI] Chat completion created successfully.[39m
[1693482993250] [32m[OPENAI] Embedding created successfully.[39m
[1693482993257] --- Observations received -- 
[1693482993257] {
  "observerId": "A2",
  "observation": "George Brown sees Stone Ore Deposit (Small) at X: 45.73, Y: 15.31.",
  "time": 146.122116
}
[1693482993257] [Character] Getting character: A2
[1693482993276] --- Observations received -- 
[1693482993276] {
  "observerId": "A2",
  "observation": "George Brown sees Tree Stump at X: 50.77, Y: 9.22.",
  "time": 146.141769
}
[1693482993276] [Character] Getting character: A2
[1693482993276] --- Observations received -- 
[1693482993276] {
  "observerId": "A2",
  "observation": "George Brown sees Tree Stump at X: 47.72001, Y: 10.21.",
  "time": 146.141769
}
[1693482993276] [Character] Getting character: A2
[1693482993313] {
  "id": "chatcmpl-7taZljzFWPp907l3zkDFJsZMJJflx",
  "object": "chat.completion",
  "created": 1693482993,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693482993313] {
  "role": "assistant",
  "content": "2"
}
[1693482993313] [36m[OPENAI] Chat completion took 466.7461669445038ms[39m
[1693482993313] [36m[OPENAI] Tokens per second: 2.142492152739843tps[39m
[1693482993313] [32m[OPENAI] Chat completion created successfully.[39m
[1693482993316] --- Observations received -- 
[1693482993317] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CoalOreSmall at X: 56.74, Y: 14.81",
  "time": 146.182846
}
[1693482993317] [Character] Getting character: A2
[1693482993317] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482993317] [33m[OPENAI] Creating embedding...[39m
[1693482993334] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482993335] [33m[OPENAI] Creating embedding...[39m
[1693482993347] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482993350] [33m[OPENAI] Creating embedding...[39m
[1693482993355] {
  "id": "chatcmpl-7taZl91OjvQocVIXofkIq9P2U313Z",
  "object": "chat.completion",
  "created": 1693482993,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693482993355] {
  "role": "assistant",
  "content": "2"
}
[1693482993355] [36m[OPENAI] Chat completion took 277.70929193496704ms[39m
[1693482993355] [36m[OPENAI] Tokens per second: 3.6008877954079277tps[39m
[1693482993355] [32m[OPENAI] Chat completion created successfully.[39m
[1693482993377] --- Observations received -- 
[1693482993378] {
  "observerId": "A2",
  "observation": "George Brown finished walking to 50.52, Y: 14.5.",
  "time": 146.239944
}
[1693482993378] [Character] Getting character: A2
[1693482993380] [Character] Getting character: A2
[1693482993383] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482993383] [33m[OPENAI] Creating embedding...[39m
[1693482993408] [33m[OPENAI] Creating embedding...[39m
[1693482993447] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482993448] [33m[OPENAI] Creating embedding...[39m
[1693482993513] [32m[OPENAI] Embedding created successfully.[39m
[1693482993514] {
  "id": "chatcmpl-7taZjT3QAMh2kermTZHHLNmdqVFWs",
  "object": "chat.completion",
  "created": 1693482991,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_axe",
          "arguments": "{\n  \"characterId\": \"A3\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2498,
    "completion_tokens": 18,
    "total_tokens": 2516
  }
}
[1693482993514] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_axe",
    "arguments": "{\n  \"characterId\": \"A3\"\n}"
  }
}
[1693482993514] [36m[OPENAI] Chat completion took 2618.309499979019ms[39m
[1693482993514] [36m[OPENAI] Tokens per second: 6.874664740797158tps[39m
[1693482993514] [32m[OPENAI] Chat completion created successfully.[39m
[1693482993535] [32m[OPENAI] Embedding created successfully.[39m
[1693482993587] {
  "id": "chatcmpl-7taZlE0aGXKMjgU64EMtROfc8ekkY",
  "object": "chat.completion",
  "created": 1693482993,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482993589] {
  "role": "assistant",
  "content": "2"
}
[1693482993589] [36m[OPENAI] Chat completion took 268.3280420303345ms[39m
[1693482993589] [36m[OPENAI] Tokens per second: 3.726781563467564tps[39m
[1693482993589] [32m[OPENAI] Chat completion created successfully.[39m
[1693482993599] [32m[OPENAI] Embedding created successfully.[39m
[1693482993633] {
  "id": "chatcmpl-7taZl1BjYkJskw4Mr03gLWN1StJov",
  "object": "chat.completion",
  "created": 1693482993,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693482993633] {
  "role": "assistant",
  "content": "6"
}
[1693482993633] [36m[OPENAI] Chat completion took 248.82508301734924ms[39m
[1693482993633] [36m[OPENAI] Tokens per second: 4.01888743640156tps[39m
[1693482993633] [32m[OPENAI] Chat completion created successfully.[39m
[1693482993638] [32m[OPENAI] Embedding created successfully.[39m
[1693482993638] {
  "id": "chatcmpl-7taZl55JKnP0EahwnH8LOxMFkjoh1",
  "object": "chat.completion",
  "created": 1693482993,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1693482993638] {
  "role": "assistant",
  "content": "2"
}
[1693482993638] [36m[OPENAI] Chat completion took 303.22812497615814ms[39m
[1693482993638] [36m[OPENAI] Tokens per second: 3.297847124433549tps[39m
[1693482993638] [32m[OPENAI] Chat completion created successfully.[39m
[1693482993644] [32m[OPENAI] Embedding created successfully.[39m
[1693482993664] [32m[OPENAI] Embedding created successfully.[39m
[1693482993726] {
  "id": "chatcmpl-7taZlOsNiOfRatoPP2FIPEUNsTywD",
  "object": "chat.completion",
  "created": 1693482993,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693482993726] {
  "role": "assistant",
  "content": "1"
}
[1693482993726] [36m[OPENAI] Chat completion took 376.31383299827576ms[39m
[1693482993726] [36m[OPENAI] Tokens per second: 2.657356473006885tps[39m
[1693482993726] [32m[OPENAI] Chat completion created successfully.[39m
[1693482993787] --- Observations received -- 
[1693482993787] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Thomas Smith at X: 49.61424, Y: 9.881827.",
  "time": 146.641266
}
[1693482993787] [Character] Getting character: A4
[1693482993787] {
  "id": "chatcmpl-7taZluXQDm9wA3ZesmTYco71wdFGN",
  "object": "chat.completion",
  "created": 1693482993,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693482993787] {
  "role": "assistant",
  "content": "1"
}
[1693482993787] [36m[OPENAI] Chat completion took 339.77033400535583ms[39m
[1693482993787] [36m[OPENAI] Tokens per second: 2.9431645435655867tps[39m
[1693482993787] [32m[OPENAI] Chat completion created successfully.[39m
[1693482993867] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482993867] [33m[OPENAI] Creating embedding...[39m
[1693482993950] --- Observations received -- 
[1693482993951] {
  "observerId": "A2",
  "observation": "George Brown sees Thomas Smith at X: 49.61424, Y: 10.16183.",
  "time": 146.800934
}
[1693482993951] [Character] Getting character: A2
[1693482994024] [32m[OPENAI] Embedding created successfully.[39m
[1693482994025] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482994025] [33m[OPENAI] Creating embedding...[39m
[1693482994127] {
  "id": "chatcmpl-7taZlfhS9FdzkptCm46T7LNVQ6s4o",
  "object": "chat.completion",
  "created": 1693482993,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693482994127] {
  "role": "assistant",
  "content": "3"
}
[1693482994127] [36m[OPENAI] Chat completion took 3354.626667022705ms[39m
[1693482994127] [36m[OPENAI] Tokens per second: 0.2980957642262824tps[39m
[1693482994127] [32m[OPENAI] Chat completion created successfully.[39m
[1693482994137] {
  "id": "chatcmpl-7taZl0AVZ51wzSwJDZfc3E4pXzH4K",
  "object": "chat.completion",
  "created": 1693482993,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1693482994137] {
  "role": "assistant",
  "content": "2"
}
[1693482994137] [36m[OPENAI] Chat completion took 270.4733330011368ms[39m
[1693482994137] [36m[OPENAI] Tokens per second: 3.69722215829609tps[39m
[1693482994137] [32m[OPENAI] Chat completion created successfully.[39m
[1693482994188] [32m[OPENAI] Embedding created successfully.[39m
[1693482994258] [33m[OPENAI] Creating embedding...[39m
[1693482994279] {
  "id": "chatcmpl-7taZm8cl5e7nBbUTGmgA2knIf7PwD",
  "object": "chat.completion",
  "created": 1693482994,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1693482994279] {
  "role": "assistant",
  "content": "2"
}
[1693482994279] [36m[OPENAI] Chat completion took 253.71195900440216ms[39m
[1693482994279] [36m[OPENAI] Tokens per second: 3.9414775871193712tps[39m
[1693482994279] [32m[OPENAI] Chat completion created successfully.[39m
[1693482994506] {
  "id": "chatcmpl-7taZiC4NQ3yM29GxQgEBCTnLnAmCg",
  "object": "chat.completion",
  "created": 1693482990,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "add_wood_to_chest",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"chestId\": \"chest_(50.52,14.5)\",\n  \"itemId\": \"wood\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2348,
    "completion_tokens": 44,
    "total_tokens": 2392
  }
}
[1693482994506] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "add_wood_to_chest",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"chestId\": \"chest_(50.52,14.5)\",\n  \"itemId\": \"wood\"\n}"
  }
}
[1693482994506] [36m[OPENAI] Chat completion took 4415.544667005539ms[39m
[1693482994506] [36m[OPENAI] Tokens per second: 9.96479558428727tps[39m
[1693482994506] [32m[OPENAI] Chat completion created successfully.[39m
[1693482994512] [Character] Getting character: A4
[1693482994526] [Character] Getting character: A3
[1693482994551] [33m[OPENAI] Creating embedding...[39m
[1693482994558] [33m[OPENAI] Creating embedding...[39m
[1693482994680] [32m[OPENAI] Embedding created successfully.[39m
[1693482994901] [32m[OPENAI] Embedding created successfully.[39m
[1693482995282] [33m[OPENAI] Creating embedding...[39m
[1693482995428] [33m[OPENAI] Creating embedding...[39m
[1693482995441] [32m[OPENAI] Embedding created successfully.[39m
[1693482995455] [32m[OPENAI] Embedding created successfully.[39m
[1693482995599] [32m[OPENAI] Embedding created successfully.[39m
[1693482995948] [33m[OPENAI] Creating embedding...[39m
[1693482996046] [33m[OPENAI] Creating embedding...[39m
[1693482996133] [32m[OPENAI] Embedding created successfully.[39m
[1693482996165] [33m[OPENAI] Creating embedding...[39m
[1693482996199] --- Observations received -- 
[1693482996199] {
  "observerId": "A2",
  "observation": "Thomas Smith started a conversation with me.",
  "time": 149.06517
}
[1693482996199] [Character] Getting character: A2
[1693482996200] [32m[OPENAI] Embedding created successfully.[39m
[1693482996270] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693482996270] [33m[OPENAI] Creating embedding...[39m
[1693482996346] [32m[OPENAI] Embedding created successfully.[39m
[1693482996432] [32m[OPENAI] Embedding created successfully.[39m
[1693482996496] {
  "id": "chatcmpl-7taZo9BTMcGMZfWXUfpOai84CEju2",
  "object": "chat.completion",
  "created": 1693482996,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 90,
    "completion_tokens": 1,
    "total_tokens": 91
  }
}
[1693482996497] {
  "role": "assistant",
  "content": "2"
}
[1693482996497] [36m[OPENAI] Chat completion took 226.1865829229355ms[39m
[1693482996497] [36m[OPENAI] Tokens per second: 4.421128729552947tps[39m
[1693482996498] [32m[OPENAI] Chat completion created successfully.[39m
[1693482996625] [33m[OPENAI] Creating embedding...[39m
[1693482996815] [32m[OPENAI] Embedding created successfully.[39m
[1693482996829] [33m[OPENAI] Creating embedding...[39m
[1693482996897] [33m[OPENAI] Creating embedding...[39m
[1693482997026] [32m[OPENAI] Embedding created successfully.[39m
[1693482997063] [32m[OPENAI] Embedding created successfully.[39m
[1693482997309] [33m[OPENAI] Creating embedding...[39m
[1693482997481] [33m[OPENAI] Creating embedding...[39m
[1693482997488] [32m[OPENAI] Embedding created successfully.[39m
[1693482997616] [33m[OPENAI] Creating embedding...[39m
[1693482997636] [32m[OPENAI] Embedding created successfully.[39m
[1693482997785] [32m[OPENAI] Embedding created successfully.[39m
[1693482997978] [33m[OPENAI] Creating embedding...[39m
[1693482998164] [32m[OPENAI] Embedding created successfully.[39m
[1693482998208] [33m[OPENAI] Creating embedding...[39m
[1693482998366] [32m[OPENAI] Embedding created successfully.[39m
[1693482998452] [33m[OPENAI] Creating embedding...[39m
[1693482998629] [32m[OPENAI] Embedding created successfully.[39m
[1693482998696] [33m[OPENAI] Creating embedding...[39m
[1693482998820] [33m[OPENAI] Creating embedding...[39m
[1693482998853] [32m[OPENAI] Embedding created successfully.[39m
[1693482999002] [32m[OPENAI] Embedding created successfully.[39m
[1693482999062] [33m[OPENAI] Creating embedding...[39m
[1693482999254] [32m[OPENAI] Embedding created successfully.[39m
[1693482999364] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482999398] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693482999893] {
  "id": "chatcmpl-7taZWZexsvFqImNmyik0JA4McBmkJ",
  "object": "chat.completion",
  "created": 1693482978,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "[\n  {\n    \"task\": \"Help Thomas Smith chop wood for the campfire\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Eat lunch\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Eat berries\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Collect items from environment\",\n    \"priority\": 4\n  },\n  {\n    \"task\": \"Explore stone ore deposits\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Chat with other villagers\",\n    \"priority\": 6\n  },\n  {\n    \"task\": \"Maintain a healthy lifestyle\",\n    \"priority\": 7\n  },\n  {\n    \"task\": \"Begin daily duties in the forest (eg. guided by George's tales or Lucy's tips)\",\n    \"priority\": 8\n  },\n  {\n    \"task\": \"Visit personal hideout\",\n    \"priority\": 9\n  },\n  {\n    \"task\": \"Return home before sunset, guided by stars if necessary\",\n    \"priority\": 10\n  }\n]"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 388,
    "completion_tokens": 234,
    "total_tokens": 622
  }
}
[1693482999894] {
  "role": "assistant",
  "content": "[\n  {\n    \"task\": \"Help Thomas Smith chop wood for the campfire\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Eat lunch\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Eat berries\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Collect items from environment\",\n    \"priority\": 4\n  },\n  {\n    \"task\": \"Explore stone ore deposits\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Chat with other villagers\",\n    \"priority\": 6\n  },\n  {\n    \"task\": \"Maintain a healthy lifestyle\",\n    \"priority\": 7\n  },\n  {\n    \"task\": \"Begin daily duties in the forest (eg. guided by George's tales or Lucy's tips)\",\n    \"priority\": 8\n  },\n  {\n    \"task\": \"Visit personal hideout\",\n    \"priority\": 9\n  },\n  {\n    \"task\": \"Return home before sunset, guided by stars if necessary\",\n    \"priority\": 10\n  }\n]"
}
[1693482999894] [36m[OPENAI] Chat completion took 21169.725458025932ms[39m
[1693482999894] [36m[OPENAI] Tokens per second: 11.053520767851298tps[39m
[1693482999894] [32m[OPENAI] Chat completion created successfully.[39m
[1693482999917] [33m[CONVERSATION] Starting conversation as player ...[39m
[1693482999917] [33m[CONVERSATION] Starting conversation...[39m
[1693482999917] [33m[CONVERSATION] Player: A1[39m
[1693482999917] [33m[CONVERSATION] Character: A2[39m
[1693482999918] [Character] Getting character: A5
[1693482999918] [Character] Getting character: A2
[1693482999918] [33m[OPENAI] Creating embedding...[39m
[1693482999992] [33m[OPENAI] Creating embedding...[39m
[1693482999997] [33m[OPENAI] Creating embedding...[39m
[1693483000047] [33m[OPENAI] Creating embedding...[39m
[1693483000064] [32m[OPENAI] Embedding created successfully.[39m
[1693483000238] [32m[OPENAI] Embedding created successfully.[39m
[1693483000306] [32m[OPENAI] Embedding created successfully.[39m
[1693483000382] [32m[OPENAI] Embedding created successfully.[39m
[1693483000748] [33m[OPENAI] Creating embedding...[39m
[1693483000796] [33m[OPENAI] Creating embedding...[39m
[1693483000948] [32m[OPENAI] Embedding created successfully.[39m
[1693483000965] [33m[OPENAI] Creating embedding...[39m
[1693483000973] [32m[OPENAI] Embedding created successfully.[39m
[1693483001133] [32m[OPENAI] Embedding created successfully.[39m
[1693483001334] [33m[OPENAI] Creating embedding...[39m
[1693483001514] [32m[OPENAI] Embedding created successfully.[39m
[1693483001568] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693483001601] [33m[OPENAI] Creating embedding...[39m
[1693483001735] {
  "id": "chatcmpl-7taZrxaFFtomuq88JUMwNO8NsJgpP",
  "object": "chat.completion",
  "created": 1693482999,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_axe",
          "arguments": "{\n  \"characterId\": \"A4\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2411,
    "completion_tokens": 18,
    "total_tokens": 2429
  }
}
[1693483001735] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_axe",
    "arguments": "{\n  \"characterId\": \"A4\"\n}"
  }
}
[1693483001735] [36m[OPENAI] Chat completion took 2370.0610830783844ms[39m
[1693483001735] [36m[OPENAI] Tokens per second: 7.594740966178167tps[39m
[1693483001735] [32m[OPENAI] Chat completion created successfully.[39m
[1693483001916] [33m[OPENAI] Creating embedding...[39m
[1693483002047] [32m[OPENAI] Embedding created successfully.[39m
[1693483002330] [32m[OPENAI] Embedding created successfully.[39m
[1693483002383] [33m[OPENAI] Creating embedding...[39m
[1693483002598] [32m[OPENAI] Embedding created successfully.[39m
[1693483002755] [Character] Getting character: A4
[1693483002784] [33m[OPENAI] Creating embedding...[39m
[1693483002920] [33m[OPENAI] Creating embedding...[39m
[1693483003013] [33m[OPENAI] Creating embedding...[39m
[1693483003022] [32m[OPENAI] Embedding created successfully.[39m
[1693483003089] [32m[OPENAI] Embedding created successfully.[39m
[1693483003203] [32m[OPENAI] Embedding created successfully.[39m
[1693483003597] [33m[OPENAI] Creating embedding...[39m
[1693483003630] [33m[OPENAI] Creating embedding...[39m
[1693483003664] [33m[OPENAI] Creating embedding...[39m
[1693483003755] [32m[OPENAI] Embedding created successfully.[39m
[1693483003809] {
  "id": "chatcmpl-7taZr8xwUVELp6zRRciTEJOcYJOcg",
  "object": "chat.completion",
  "created": 1693482999,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A3\",\n  \"x\": 43.22001,\n  \"y\": -16.37\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2509,
    "completion_tokens": 36,
    "total_tokens": 2545
  }
}
[1693483003810] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A3\",\n  \"x\": 43.22001,\n  \"y\": -16.37\n}"
  }
}
[1693483003810] [36m[OPENAI] Chat completion took 4410.950958013535ms[39m
[1693483003810] [36m[OPENAI] Tokens per second: 8.161505385725835tps[39m
[1693483003810] [32m[OPENAI] Chat completion created successfully.[39m
[1693483003814] --- Observations received -- 
[1693483003814] {
  "observerId": "A3",
  "observation": "Will Turner has started walking to 43.22001, Y: -16.37.",
  "time": 156.679077
}
[1693483003814] [Character] Getting character: A3
[1693483003816] [32m[OPENAI] Embedding created successfully.[39m
[1693483003867] [32m[OPENAI] Embedding created successfully.[39m
[1693483003881] --- Observations received -- 
[1693483003881] {
  "observerId": "A3",
  "observation": "Will Turner finished walking to 43.22001, Y: -16.37.",
  "time": 156.739944
}
[1693483003881] [Character] Getting character: A3
[1693483003881] [Character] Getting character: A3
[1693483003884] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483003884] [33m[OPENAI] Creating embedding...[39m
[1693483003916] [33m[OPENAI] Creating embedding...[39m
[1693483003949] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483003949] [33m[OPENAI] Creating embedding...[39m
[1693483003987] {
  "id": "chatcmpl-7taZtrGnSbZOhu2AwrZnnnU8oUIce",
  "object": "chat.completion",
  "created": 1693483001,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_pickaxe",
          "arguments": "{\n  \"characterId\": \"A2\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2864,
    "completion_tokens": 18,
    "total_tokens": 2882
  }
}
[1693483003987] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_pickaxe",
    "arguments": "{\n  \"characterId\": \"A2\"\n}"
  }
}
[1693483003987] [36m[OPENAI] Chat completion took 2418.772458910942ms[39m
[1693483003987] [36m[OPENAI] Tokens per second: 7.441791365569187tps[39m
[1693483003987] [32m[OPENAI] Chat completion created successfully.[39m
[1693483004038] [32m[OPENAI] Embedding created successfully.[39m
[1693483004108] [32m[OPENAI] Embedding created successfully.[39m
[1693483004143] {
  "id": "chatcmpl-7taZvo36rNuZ4Xn65swO4ZkkFK43S",
  "object": "chat.completion",
  "created": 1693483003,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693483004143] {
  "role": "assistant",
  "content": "1"
}
[1693483004143] [36m[OPENAI] Chat completion took 258.82045805454254ms[39m
[1693483004143] [36m[OPENAI] Tokens per second: 3.863682212436487tps[39m
[1693483004143] [32m[OPENAI] Chat completion created successfully.[39m
[1693483004199] {
  "id": "chatcmpl-7taZwmS4Yv5FHJykY0I6hAjphEItg",
  "object": "chat.completion",
  "created": 1693483004,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693483004199] {
  "role": "assistant",
  "content": "1"
}
[1693483004199] [36m[OPENAI] Chat completion took 250.47924995422363ms[39m
[1693483004199] [36m[OPENAI] Tokens per second: 3.9923466721604886tps[39m
[1693483004199] [32m[OPENAI] Chat completion created successfully.[39m
[1693483004251] [32m[OPENAI] Embedding created successfully.[39m
[1693483004303] [33m[OPENAI] Creating embedding...[39m
[1693483004320] [33m[OPENAI] Creating embedding...[39m
[1693483004438] [32m[OPENAI] Embedding created successfully.[39m
[1693483004496] [33m[OPENAI] Creating embedding...[39m
[1693483004597] [32m[OPENAI] Embedding created successfully.[39m
[1693483004664] [32m[OPENAI] Embedding created successfully.[39m
[1693483004863] [33m[OPENAI] Creating embedding...[39m
[1693483004871] [33m[OPENAI] Creating embedding...[39m
[1693483005066] [32m[OPENAI] Embedding created successfully.[39m
[1693483005069] [33m[OPENAI] Creating embedding...[39m
[1693483005178] [32m[OPENAI] Embedding created successfully.[39m
[1693483005185] [33m[OPENAI] Creating embedding...[39m
[1693483005225] [32m[OPENAI] Embedding created successfully.[39m
[1693483005336] [32m[OPENAI] Embedding created successfully.[39m
[1693483005530] [33m[OPENAI] Creating embedding...[39m
[1693483005637] [33m[OPENAI] Creating embedding...[39m
[1693483005672] [32m[OPENAI] Embedding created successfully.[39m
[1693483005679] [33m[OPENAI] Creating embedding...[39m
[1693483005779] [33m[OPENAI] Creating embedding...[39m
[1693483005896] [32m[OPENAI] Embedding created successfully.[39m
[1693483005946] [32m[OPENAI] Embedding created successfully.[39m
[1693483005967] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693483005972] [32m[OPENAI] Embedding created successfully.[39m
[1693483006553] [33m[OPENAI] Creating embedding...[39m
[1693483006580] [33m[OPENAI] Creating embedding...[39m
[1693483006652] [33m[OPENAI] Creating embedding...[39m
[1693483006690] [32m[OPENAI] Embedding created successfully.[39m
[1693483006748] [32m[OPENAI] Embedding created successfully.[39m
[1693483006864] [32m[OPENAI] Embedding created successfully.[39m
[1693483007291] [33m[OPENAI] Creating embedding...[39m
[1693483007322] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693483007452] [33m[OPENAI] Creating embedding...[39m
[1693483007551] [32m[OPENAI] Embedding created successfully.[39m
[1693483007615] --- Observations received -- 
[1693483007616] {
  "observerId": "A2",
  "observation": "Thomas Smith started a conversation with me.",
  "time": 160.480576
}
[1693483007616] [Character] Getting character: A2
[1693483007665] [32m[OPENAI] Embedding created successfully.[39m
[1693483007685] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483007686] [33m[OPENAI] Creating embedding...[39m
[1693483007823] [32m[OPENAI] Embedding created successfully.[39m
[1693483007939] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693483007945] {
  "id": "chatcmpl-7taZzUX3Y5N9WnEo3rjs9N426XQv6",
  "object": "chat.completion",
  "created": 1693483007,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 90,
    "completion_tokens": 1,
    "total_tokens": 91
  }
}
[1693483007946] {
  "role": "assistant",
  "content": "3"
}
[1693483007946] [36m[OPENAI] Chat completion took 259.8367500305176ms[39m
[1693483007946] [36m[OPENAI] Tokens per second: 3.848570303787093tps[39m
[1693483007946] [32m[OPENAI] Chat completion created successfully.[39m
[1693483008150] [33m[OPENAI] Creating embedding...[39m
[1693483008383] [32m[OPENAI] Embedding created successfully.[39m
[1693483008895] [33m[OPENAI] Creating embedding...[39m
[1693483009101] [32m[OPENAI] Embedding created successfully.[39m
[1693483009657] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693483009796] {
  "id": "chatcmpl-7taZy3uPV4SPj20dbXVtlLV9Lqazs",
  "object": "chat.completion",
  "created": 1693483006,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 45.24001,\n  \"y\": 10.2\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1807,
    "completion_tokens": 36,
    "total_tokens": 1843
  }
}
[1693483009797] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 45.24001,\n  \"y\": 10.2\n}"
  }
}
[1693483009797] [36m[OPENAI] Chat completion took 3829.6419999599457ms[39m
[1693483009797] [36m[OPENAI] Tokens per second: 9.400356482505813tps[39m
[1693483009797] [32m[OPENAI] Chat completion created successfully.[39m
[1693483009805] --- Observations received -- 
[1693483009805] {
  "observerId": "A5",
  "observation": "Eli Green has started walking to 45.24001, Y: 10.2.",
  "time": 162.669464
}
[1693483009805] [Character] Getting character: A5
[1693483009846] --- Observations received -- 
[1693483009847] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Small) at X: 46.53, Y: 21.65.",
  "time": 162.7021
}
[1693483009847] [Character] Getting character: A5
[1693483009881] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483009881] [33m[OPENAI] Creating embedding...[39m
[1693483009934] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483009934] [33m[OPENAI] Creating embedding...[39m
[1693483010049] [32m[OPENAI] Embedding created successfully.[39m
[1693483010163] {
  "id": "chatcmpl-7taa1cI8Q7gUWsCQEefMclmIxGZZt",
  "object": "chat.completion",
  "created": 1693483009,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693483010163] {
  "role": "assistant",
  "content": "5"
}
[1693483010163] [36m[OPENAI] Chat completion took 282.2975000143051ms[39m
[1693483010163] [36m[OPENAI] Tokens per second: 3.5423622240697354tps[39m
[1693483010163] [32m[OPENAI] Chat completion created successfully.[39m
[1693483010198] [32m[OPENAI] Embedding created successfully.[39m
[1693483010465] {
  "id": "chatcmpl-7taa2c0z4RcqWmxUwoFw1iZV8wsQ4",
  "object": "chat.completion",
  "created": 1693483010,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693483010465] {
  "role": "assistant",
  "content": "2"
}
[1693483010465] [36m[OPENAI] Chat completion took 530.9146670103073ms[39m
[1693483010465] [36m[OPENAI] Tokens per second: 1.8835418611265937tps[39m
[1693483010465] [32m[OPENAI] Chat completion created successfully.[39m
[1693483010636] --- Observations received -- 
[1693483010637] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees StoneOreSmall (6) at X: 38.24, Y: 15.93",
  "time": 163.501221
}
[1693483010637] [Character] Getting character: A5
[1693483010714] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483010714] [33m[OPENAI] Creating embedding...[39m
[1693483010737] --- Observations received -- 
[1693483010737] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees StoneOreMedium (2) at X: 38.03, Y: 18.78",
  "time": 163.601318
}
[1693483010737] [Character] Getting character: A5
[1693483010803] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483010803] [33m[OPENAI] Creating embedding...[39m
[1693483010834] --- Observations received -- 
[1693483010834] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees StoneOreLarge (3) at X: 41.29, Y: 22.52",
  "time": 163.700211
}
[1693483010834] [Character] Getting character: A5
[1693483010846] [32m[OPENAI] Embedding created successfully.[39m
[1693483010873] [33m[CONVERSATION] Starting conversation as player ...[39m
[1693483010873] [33m[CONVERSATION] Starting conversation...[39m
[1693483010873] [33m[CONVERSATION] Player: A1[39m
[1693483010873] [33m[CONVERSATION] Character: A2[39m
[1693483010901] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483010909] [33m[OPENAI] Creating embedding...[39m
[1693483010982] [33m[OPENAI] Creating embedding...[39m
[1693483010988] [32m[OPENAI] Embedding created successfully.[39m
[1693483010994] {
  "id": "chatcmpl-7taa24RcwT3k6CVMLE3rqkPjtZjqx",
  "object": "chat.completion",
  "created": 1693483010,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693483010994] {
  "role": "assistant",
  "content": "6"
}
[1693483010994] [36m[OPENAI] Chat completion took 280.0229580402374ms[39m
[1693483010994] [36m[OPENAI] Tokens per second: 3.5711357632909038tps[39m
[1693483010994] [32m[OPENAI] Chat completion created successfully.[39m
[1693483011050] {
  "id": "chatcmpl-7taa2czg6KNGLngxQKphlVdU4sG9l",
  "object": "chat.completion",
  "created": 1693483010,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693483011050] {
  "role": "assistant",
  "content": "2"
}
[1693483011050] [36m[OPENAI] Chat completion took 247.40745902061462ms[39m
[1693483011050] [36m[OPENAI] Tokens per second: 4.041915324455426tps[39m
[1693483011051] [32m[OPENAI] Chat completion created successfully.[39m
[1693483011115] [32m[OPENAI] Embedding created successfully.[39m
[1693483011116] --- Observations received -- 
[1693483011116] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Small) at X: 38.24, Y: 15.93.",
  "time": 163.98111
}
[1693483011116] [Character] Getting character: A5
[1693483011156] --- Observations received -- 
[1693483011156] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees StoneOreSmall (9) at X: 46.53, Y: 21.65",
  "time": 164.0221
}
[1693483011156] [Character] Getting character: A5
[1693483011157] [32m[OPENAI] Embedding created successfully.[39m
[1693483011163] {
  "id": "chatcmpl-7taa2v62cYLi5euj7nloys84boyK2",
  "object": "chat.completion",
  "created": 1693483010,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693483011163] {
  "role": "assistant",
  "content": "2"
}
[1693483011163] [36m[OPENAI] Chat completion took 261.3634160757065ms[39m
[1693483011163] [36m[OPENAI] Tokens per second: 3.826090181306554tps[39m
[1693483011163] [32m[OPENAI] Chat completion created successfully.[39m
[1693483011176] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483011177] [33m[OPENAI] Creating embedding...[39m
[1693483011211] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483011213] [33m[OPENAI] Creating embedding...[39m
[1693483011327] [32m[OPENAI] Embedding created successfully.[39m
[1693483011378] {
  "id": "chatcmpl-7taZzkVuPEd4E8yWMX6g4YMlVcNX6",
  "object": "chat.completion",
  "created": 1693483007,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 48.72,\n  \"y\": 13.43\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2947,
    "completion_tokens": 35,
    "total_tokens": 2982
  }
}
[1693483011378] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 48.72,\n  \"y\": 13.43\n}"
  }
}
[1693483011378] [36m[OPENAI] Chat completion took 4055.7181659936905ms[39m
[1693483011378] [36m[OPENAI] Tokens per second: 8.629790968580446tps[39m
[1693483011378] [32m[OPENAI] Chat completion created successfully.[39m
[1693483011416] [32m[OPENAI] Embedding created successfully.[39m
[1693483011483] {
  "id": "chatcmpl-7taa331B2j3h3LNf3ILgj7MJDkTgv",
  "object": "chat.completion",
  "created": 1693483011,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "8"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693483011483] {
  "role": "assistant",
  "content": "8"
}
[1693483011483] [36m[OPENAI] Chat completion took 270.3209580183029ms[39m
[1693483011483] [36m[OPENAI] Tokens per second: 3.6993062148451394tps[39m
[1693483011483] [32m[OPENAI] Chat completion created successfully.[39m
[1693483011520] {
  "id": "chatcmpl-7taa3FOCHfYtxoIPbO8qps8WRgJ6L",
  "object": "chat.completion",
  "created": 1693483011,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693483011520] {
  "role": "assistant",
  "content": "2"
}
[1693483011520] [36m[OPENAI] Chat completion took 343.45991599559784ms[39m
[1693483011520] [36m[OPENAI] Tokens per second: 2.911547908294536tps[39m
[1693483011520] [32m[OPENAI] Chat completion created successfully.[39m
[1693483011875] --- Observations received -- 
[1693483011875] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 45.24001, Y: 10.2.",
  "time": 164.7408
}
[1693483011875] [Character] Getting character: A5
[1693483011947] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483011948] [33m[OPENAI] Creating embedding...[39m
[1693483011987] {
  "id": "chatcmpl-7taa29pwAnnrJBTX2MmPE0JL1RYXv",
  "object": "chat.completion",
  "created": 1693483010,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_axe",
          "arguments": "{\n  \"characterId\": \"A3\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2498,
    "completion_tokens": 18,
    "total_tokens": 2516
  }
}
[1693483011988] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_axe",
    "arguments": "{\n  \"characterId\": \"A3\"\n}"
  }
}
[1693483011988] [36m[OPENAI] Chat completion took 2327.1208750009537ms[39m
[1693483011988] [36m[OPENAI] Tokens per second: 7.734879693343228tps[39m
[1693483011988] [32m[OPENAI] Chat completion created successfully.[39m
[1693483012015] --- Observations received -- 
[1693483012015] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees StoneOreSmall (6) at X: 38.24, Y: 15.93",
  "time": 164.880951
}
[1693483012015] [Character] Getting character: A5
[1693483012080] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483012080] [33m[OPENAI] Creating embedding...[39m
[1693483012118] [32m[OPENAI] Embedding created successfully.[39m
[1693483012155] --- Observations received -- 
[1693483012155] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees StoneOreSmall (5) at X: 47.58, Y: 19.17",
  "time": 165.020615
}
[1693483012155] [Character] Getting character: A5
[1693483012224] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483012224] [33m[OPENAI] Creating embedding...[39m
[1693483012237] --- Observations received -- 
[1693483012237] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees StoneOreLarge (2) at X: 44.3, Y: 20.36",
  "time": 165.102875
}
[1693483012237] [Character] Getting character: A5
[1693483012280] --- Observations received -- 
[1693483012280] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees StoneOreLarge (1) at X: 40.75, Y: 19.74",
  "time": 165.1418
}
[1693483012280] [Character] Getting character: A5
[1693483012283] [32m[OPENAI] Embedding created successfully.[39m
[1693483012285] {
  "id": "chatcmpl-7taa46nF2DQfaFi3bqDmbrHeFg8XQ",
  "object": "chat.completion",
  "created": 1693483012,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693483012285] {
  "role": "assistant",
  "content": "5"
}
[1693483012285] [36m[OPENAI] Chat completion took 336.975958943367ms[39m
[1693483012285] [36m[OPENAI] Tokens per second: 2.967570752333885tps[39m
[1693483012285] [32m[OPENAI] Chat completion created successfully.[39m
[1693483012301] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483012302] [33m[OPENAI] Creating embedding...[39m
[1693483012343] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483012344] [33m[OPENAI] Creating embedding...[39m
[1693483012356] {
  "id": "chatcmpl-7taa44zsWAVQ4BuVbbue9G0dkhFAe",
  "object": "chat.completion",
  "created": 1693483012,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693483012356] {
  "role": "assistant",
  "content": "6"
}
[1693483012356] [36m[OPENAI] Chat completion took 275.1663340330124ms[39m
[1693483012356] [36m[OPENAI] Tokens per second: 3.6341655076163044tps[39m
[1693483012356] [32m[OPENAI] Chat completion created successfully.[39m
[1693483012395] --- Observations received -- 
[1693483012395] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree Stump at X: 47.72001, Y: 10.21.",
  "time": 165.260132
}
[1693483012395] [Character] Getting character: A5
[1693483012438] [32m[OPENAI] Embedding created successfully.[39m
[1693483012463] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483012464] [33m[OPENAI] Creating embedding...[39m
[1693483012487] [32m[OPENAI] Embedding created successfully.[39m
[1693483012549] {
  "id": "chatcmpl-7taa4SiI9UgAOys1MwhhD5CLF8NZM",
  "object": "chat.completion",
  "created": 1693483012,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693483012549] {
  "role": "assistant",
  "content": "1"
}
[1693483012549] [36m[OPENAI] Chat completion took 324.72091698646545ms[39m
[1693483012549] [36m[OPENAI] Tokens per second: 3.0795675538255534tps[39m
[1693483012549] [32m[OPENAI] Chat completion created successfully.[39m
[1693483012570] {
  "id": "chatcmpl-7taa4aYNeL7M81Xf4NAhX3clHWBcX",
  "object": "chat.completion",
  "created": 1693483012,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693483012570] {
  "role": "assistant",
  "content": "1"
}
[1693483012570] [36m[OPENAI] Chat completion took 268.8009999990463ms[39m
[1693483012570] [36m[OPENAI] Tokens per second: 3.7202242551312974tps[39m
[1693483012570] [32m[OPENAI] Chat completion created successfully.[39m
[1693483012596] [32m[OPENAI] Embedding created successfully.[39m
[1693483012604] [32m[OPENAI] Embedding created successfully.[39m
[1693483012625] --- Observations received -- 
[1693483012626] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree Stump at X: 41.43, Y: -16.",
  "time": 165.486115
}
[1693483012626] [Character] Getting character: A3
[1693483012626] --- Observations received -- 
[1693483012626] {
  "observerId": "A3",
  "observation": "Will Turner sees Tree Stump at X: 43.22001, Y: -16.37.",
  "time": 165.486115
}
[1693483012626] [Character] Getting character: A3
[1693483012626] --- Observations received -- 
[1693483012627] {
  "observerId": "A3",
  "observation": "Will Turner picked up Wood at X: 43.59655, Y: -15.97039",
  "time": 165.486115
}
[1693483012627] [Character] Getting character: A3
[1693483012700] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483012700] [33m[OPENAI] Creating embedding...[39m
[1693483012700] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483012700] [33m[OPENAI] Creating embedding...[39m
[1693483012700] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483012701] [33m[OPENAI] Creating embedding...[39m
[1693483012769] {
  "id": "chatcmpl-7taa47cXnZRkeSyfwyjaLj0xMEhix",
  "object": "chat.completion",
  "created": 1693483012,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1693483012769] {
  "role": "assistant",
  "content": "2"
}
[1693483012769] [36m[OPENAI] Chat completion took 305.692999958992ms[39m
[1693483012769] [36m[OPENAI] Tokens per second: 3.2712558028288106tps[39m
[1693483012769] [32m[OPENAI] Chat completion created successfully.[39m
[1693483012815] {
  "id": "chatcmpl-7taa41hwyaZBzZ1gc6eQMdYQjlXP5",
  "object": "chat.completion",
  "created": 1693483012,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693483012815] {
  "role": "assistant",
  "content": "2"
}
[1693483012815] [36m[OPENAI] Chat completion took 471.2905830144882ms[39m
[1693483012815] [36m[OPENAI] Tokens per second: 2.121833187507713tps[39m
[1693483012815] [32m[OPENAI] Chat completion created successfully.[39m
[1693483012881] [32m[OPENAI] Embedding created successfully.[39m
[1693483012885] [32m[OPENAI] Embedding created successfully.[39m
[1693483012959] {
  "id": "chatcmpl-7taa4IuMSNNJNZ6L5hDAXVJmFldIz",
  "object": "chat.completion",
  "created": 1693483012,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693483012959] {
  "role": "assistant",
  "content": "3"
}
[1693483012960] [36m[OPENAI] Chat completion took 259.258749961853ms[39m
[1693483012960] [36m[OPENAI] Tokens per second: 3.857150434255887tps[39m
[1693483012960] [32m[OPENAI] Chat completion created successfully.[39m
[1693483012977] [32m[OPENAI] Embedding created successfully.[39m
[1693483012981] {
  "id": "chatcmpl-7taa4SdClrEBlCk2WN3T0Gop4d9q4",
  "object": "chat.completion",
  "created": 1693483012,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1693483012981] {
  "role": "assistant",
  "content": "3"
}
[1693483012981] [36m[OPENAI] Chat completion took 280.95329093933105ms[39m
[1693483012981] [36m[OPENAI] Tokens per second: 3.5593105055172303tps[39m
[1693483012981] [32m[OPENAI] Chat completion created successfully.[39m
[1693483013009] [Character] Getting character: A3
[1693483013046] [33m[OPENAI] Creating embedding...[39m
[1693483013053] {
  "id": "chatcmpl-7taa4qFztj2CAyxJ2ywgGhocNRcg0",
  "object": "chat.completion",
  "created": 1693483012,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693483013053] {
  "role": "assistant",
  "content": "4"
}
[1693483013053] [36m[OPENAI] Chat completion took 352.6078749895096ms[39m
[1693483013053] [36m[OPENAI] Tokens per second: 2.8360115327252715tps[39m
[1693483013053] [32m[OPENAI] Chat completion created successfully.[39m
[1693483013230] [32m[OPENAI] Embedding created successfully.[39m
[1693483013506] {
  "id": "chatcmpl-7taa0eRT1681chcyoiiqc7Z5LXtac",
  "object": "chat.completion",
  "created": 1693483008,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 47.72001,\n  \"y\": 10.21\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2495,
    "completion_tokens": 36,
    "total_tokens": 2531
  }
}
[1693483013510] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 47.72001,\n  \"y\": 10.21\n}"
  }
}
[1693483013510] [36m[OPENAI] Chat completion took 5566.081165909767ms[39m
[1693483013510] [36m[OPENAI] Tokens per second: 6.467746144358615tps[39m
[1693483013510] [32m[OPENAI] Chat completion created successfully.[39m
[1693483013521] --- Observations received -- 
[1693483013522] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 47.72001, Y: 10.21.",
  "time": 166.385666
}
[1693483013522] [Character] Getting character: A4
[1693483013621] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483013621] [33m[OPENAI] Creating embedding...[39m
[1693483013675] --- Observations received -- 
[1693483013678] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees StoneOreMedium (1) at X: 46.05, Y: 17.85",
  "time": 166.540436
}
[1693483013678] [Character] Getting character: A5
[1693483013733] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483013734] [33m[OPENAI] Creating embedding...[39m
[1693483013824] [33m[OPENAI] Creating embedding...[39m
[1693483013835] [32m[OPENAI] Embedding created successfully.[39m
[1693483013980] {
  "id": "chatcmpl-7taa5AcToQYBy2YIk1RSPIzmE2sFe",
  "object": "chat.completion",
  "created": 1693483013,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693483013980] {
  "role": "assistant",
  "content": "5"
}
[1693483013980] [36m[OPENAI] Chat completion took 358.0060828924179ms[39m
[1693483013980] [36m[OPENAI] Tokens per second: 2.7932486284052986tps[39m
[1693483013980] [32m[OPENAI] Chat completion created successfully.[39m
[1693483013989] {
  "id": "chatcmpl-7taa5awVinaf5uMqvaXgEAFevAnKv",
  "object": "chat.completion",
  "created": 1693483013,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693483013989] {
  "role": "assistant",
  "content": "3"
}
[1693483013989] [36m[OPENAI] Chat completion took 255.13445794582367ms[39m
[1693483013989] [36m[OPENAI] Tokens per second: 3.9195019287137773tps[39m
[1693483013989] [32m[OPENAI] Chat completion created successfully.[39m
[1693483014025] [32m[OPENAI] Embedding created successfully.[39m
[1693483014103] [32m[OPENAI] Embedding created successfully.[39m
[1693483014155] --- Observations received -- 
[1693483014160] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees StoneOreMedium at X: 42.53862, Y: 17.00157",
  "time": 167.019989
}
[1693483014161] [Character] Getting character: A5
[1693483014227] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483014230] [33m[OPENAI] Creating embedding...[39m
[1693483014437] --- Observations received -- 
[1693483014438] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Tree at X: 53.93, Y: 9.11.",
  "time": 167.30101
}
[1693483014438] [Character] Getting character: A4
[1693483014476] --- Observations received -- 
[1693483014476] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Tree at X: 45.24001, Y: 10.2.",
  "time": 167.341782
}
[1693483014476] [Character] Getting character: A4
[1693483014486] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483014486] [33m[OPENAI] Creating embedding...[39m
[1693483014535] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483014535] [33m[OPENAI] Creating embedding...[39m
[1693483014565] [32m[OPENAI] Embedding created successfully.[39m
[1693483014579] {
  "id": "chatcmpl-7taa6JNm0Ek7inHHqsXjasgfRHLmn",
  "object": "chat.completion",
  "created": 1693483014,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3.5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 107,
    "completion_tokens": 3,
    "total_tokens": 110
  }
}
[1693483014579] {
  "role": "assistant",
  "content": "3.5"
}
[1693483014579] [36m[OPENAI] Chat completion took 351.93041598796844ms[39m
[1693483014579] [36m[OPENAI] Tokens per second: 8.524412394359691tps[39m
[1693483014579] [32m[OPENAI] Chat completion created successfully.[39m
[1693483014597] [33m[OPENAI] Creating embedding...[39m
[1693483014617] --- Observations received -- 
[1693483014617] {
  "observerId": "A5",
  "observation": "Eli Green sees Lucy Wilde at X: 49.88139, Y: 12.88389.",
  "time": 167.4811
}
[1693483014617] [Character] Getting character: A5
[1693483014697] --- Observations received -- 
[1693483014697] {
  "observerId": "A5",
  "observation": "Eli Green finished walking to 45.24001, Y: 10.2.",
  "time": 167.559937
}
[1693483014697] [Character] Getting character: A5
[1693483014698] [Character] Getting character: A5
[1693483014698] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483014698] [33m[OPENAI] Creating embedding...[39m
[1693483014699] [32m[OPENAI] Embedding created successfully.[39m
[1693483014730] [33m[OPENAI] Creating embedding...[39m
[1693483014737] {
  "id": "chatcmpl-7taa6SUFhGZNTsCes7LUQBsguWik1",
  "object": "chat.completion",
  "created": 1693483014,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693483014738] {
  "role": "assistant",
  "content": "4"
}
[1693483014738] [36m[OPENAI] Chat completion took 251.14083409309387ms[39m
[1693483014738] [36m[OPENAI] Tokens per second: 3.9818295722841954tps[39m
[1693483014738] [32m[OPENAI] Chat completion created successfully.[39m
[1693483014762] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483014763] [33m[OPENAI] Creating embedding...[39m
[1693483014769] [32m[OPENAI] Embedding created successfully.[39m
[1693483014783] {
  "id": "chatcmpl-7taa69fBoZ3ZYQW6EXr8QbO4oeFQp",
  "object": "chat.completion",
  "created": 1693483014,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693483014783] {
  "role": "assistant",
  "content": "1"
}
[1693483014783] [36m[OPENAI] Chat completion took 247.85441601276398ms[39m
[1693483014783] [36m[OPENAI] Tokens per second: 4.034626520225091tps[39m
[1693483014783] [32m[OPENAI] Chat completion created successfully.[39m
[1693483014816] [32m[OPENAI] Embedding created successfully.[39m
[1693483014836] --- Observations received -- 
[1693483014836] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Eli Green at X: 44.95745, Y: 10.64188.",
  "time": 167.700333
}
[1693483014836] [Character] Getting character: A4
[1693483014855] [32m[OPENAI] Embedding created successfully.[39m
[1693483014892] [32m[OPENAI] Embedding created successfully.[39m
[1693483014910] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483014917] [33m[OPENAI] Creating embedding...[39m
[1693483014985] {
  "id": "chatcmpl-7taa6KtGrwhtCWtIrvlobeK0SMDrb",
  "object": "chat.completion",
  "created": 1693483014,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1693483014985] {
  "role": "assistant",
  "content": "3"
}
[1693483014985] [36m[OPENAI] Chat completion took 287.34274995326996ms[39m
[1693483014985] [36m[OPENAI] Tokens per second: 3.4801643687290813tps[39m
[1693483014985] [32m[OPENAI] Chat completion created successfully.[39m
[1693483014986] [32m[OPENAI] Embedding created successfully.[39m
[1693483015084] [32m[OPENAI] Embedding created successfully.[39m
[1693483015138] --- Observations received -- 
[1693483015138] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees Tree (485) at X: 53.93, Y: 9.11",
  "time": 168.0012
}
[1693483015138] [Character] Getting character: A4
[1693483015174] {
  "id": "chatcmpl-7taa6RqFSfMs8HOMVQ4Xy75pb7kg0",
  "object": "chat.completion",
  "created": 1693483014,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693483015174] {
  "role": "assistant",
  "content": "2"
}
[1693483015174] [36m[OPENAI] Chat completion took 412.4383339881897ms[39m
[1693483015174] [36m[OPENAI] Tokens per second: 2.4246048865783543tps[39m
[1693483015174] [32m[OPENAI] Chat completion created successfully.[39m
[1693483015203] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483015203] [33m[OPENAI] Creating embedding...[39m
[1693483015232] {
  "id": "chatcmpl-7taa6lzTUb2eDDADA4YsKdD2S0kht",
  "object": "chat.completion",
  "created": 1693483014,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 2,
    "total_tokens": 106
  }
}
[1693483015232] {
  "role": "assistant",
  "content": "4."
}
[1693483015232] [36m[OPENAI] Chat completion took 322.0233750343323ms[39m
[1693483015232] [36m[OPENAI] Tokens per second: 6.210729267050168tps[39m
[1693483015232] [32m[OPENAI] Chat completion created successfully.[39m
[1693483015300] [33m[OPENAI] Creating embedding...[39m
[1693483015339] [32m[OPENAI] Embedding created successfully.[39m
[1693483015456] [33m[OPENAI] Creating embedding...[39m
[1693483015465] [32m[OPENAI] Embedding created successfully.[39m
[1693483015466] {
  "id": "chatcmpl-7taa7r9gOrGx1BmC3vBs9ELAzC7iE",
  "object": "chat.completion",
  "created": 1693483015,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693483015466] {
  "role": "assistant",
  "content": "2"
}
[1693483015466] [36m[OPENAI] Chat completion took 263.27212500572205ms[39m
[1693483015466] [36m[OPENAI] Tokens per second: 3.7983512306069835tps[39m
[1693483015466] [32m[OPENAI] Chat completion created successfully.[39m
[1693483015634] [32m[OPENAI] Embedding created successfully.[39m
[1693483015935] --- Observations received -- 
[1693483015935] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Tree at X: 50.12, Y: 6.280001.",
  "time": 168.800552
}
[1693483015935] [Character] Getting character: A4
[1693483015999] [33m[OPENAI] Creating embedding...[39m
[1693483016000] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483016000] [33m[OPENAI] Creating embedding...[39m
[1693483016095] [33m[OPENAI] Creating embedding...[39m
[1693483016183] [32m[OPENAI] Embedding created successfully.[39m
[1693483016194] --- Observations received -- 
[1693483016194] {
  "observerId": "A2",
  "observation": "George Brown no longer sees Human (3) at X: 48.12225, Y: 10.79779",
  "time": 169.06
}
[1693483016194] [Character] Getting character: A2
[1693483016241] [32m[OPENAI] Embedding created successfully.[39m
[1693483016260] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483016261] [33m[OPENAI] Creating embedding...[39m
[1693483016277] {
  "id": "chatcmpl-7taa8cfTVj5W56NnXDvQgvBu9sXKD",
  "object": "chat.completion",
  "created": 1693483016,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 2,
    "total_tokens": 104
  }
}
[1693483016277] {
  "role": "assistant",
  "content": "5."
}
[1693483016277] [36m[OPENAI] Chat completion took 276.8698329925537ms[39m
[1693483016277] [36m[OPENAI] Tokens per second: 7.223611104116891tps[39m
[1693483016277] [32m[OPENAI] Chat completion created successfully.[39m
[1693483016278] [32m[OPENAI] Embedding created successfully.[39m
[1693483016319] --- Observations received -- 
[1693483016319] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 47.72001, Y: 10.21.",
  "time": 169.179947
}
[1693483016319] [Character] Getting character: A4
[1693483016319] [Character] Getting character: A4
[1693483016356] [33m[OPENAI] Creating embedding...[39m
[1693483016393] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483016394] [33m[OPENAI] Creating embedding...[39m
[1693483016442] [32m[OPENAI] Embedding created successfully.[39m
[1693483016557] [32m[OPENAI] Embedding created successfully.[39m
[1693483016569] [32m[OPENAI] Embedding created successfully.[39m
[1693483016662] {
  "id": "chatcmpl-7taa8CJbiAamfFfiW55aYLNL4iDCF",
  "object": "chat.completion",
  "created": 1693483016,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 107,
    "completion_tokens": 1,
    "total_tokens": 108
  }
}
[1693483016662] {
  "role": "assistant",
  "content": "1"
}
[1693483016662] [36m[OPENAI] Chat completion took 401.74029195308685ms[39m
[1693483016662] [36m[OPENAI] Tokens per second: 2.4891702924255723tps[39m
[1693483016662] [32m[OPENAI] Chat completion created successfully.[39m
[1693483016676] {
  "id": "chatcmpl-7taa86H1RbpIs9gVgRV5EKX4dZpNV",
  "object": "chat.completion",
  "created": 1693483016,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693483016676] {
  "role": "assistant",
  "content": "2"
}
[1693483016676] [36m[OPENAI] Chat completion took 282.4316670894623ms[39m
[1693483016676] [36m[OPENAI] Tokens per second: 3.540679451087341tps[39m
[1693483016676] [32m[OPENAI] Chat completion created successfully.[39m
[1693483016741] [33m[OPENAI] Creating embedding...[39m
[1693483016873] [33m[OPENAI] Creating embedding...[39m
[1693483017030] [32m[OPENAI] Embedding created successfully.[39m
[1693483017103] [33m[OPENAI] Creating embedding...[39m
[1693483017104] [32m[OPENAI] Embedding created successfully.[39m
[1693483017313] [32m[OPENAI] Embedding created successfully.[39m
[1693483017438] [33m[OPENAI] Creating embedding...[39m
[1693483017602] [33m[OPENAI] Creating embedding...[39m
[1693483017656] [32m[OPENAI] Embedding created successfully.[39m
[1693483017770] [33m[OPENAI] Creating embedding...[39m
[1693483017795] [32m[OPENAI] Embedding created successfully.[39m
[1693483018038] [32m[OPENAI] Embedding created successfully.[39m
[1693483018161] [33m[OPENAI] Creating embedding...[39m
[1693483018312] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693483018332] [32m[OPENAI] Embedding created successfully.[39m
[1693483018517] [33m[OPENAI] Creating embedding...[39m
[1693483018679] [32m[OPENAI] Embedding created successfully.[39m
[1693483018729] [33m[OPENAI] Creating embedding...[39m
[1693483019098] [33m[OPENAI] Creating embedding...[39m
[1693483019231] [32m[OPENAI] Embedding created successfully.[39m
[1693483019353] [32m[OPENAI] Embedding created successfully.[39m
[1693483019641] [33m[OPENAI] Creating embedding...[39m
[1693483019762] [33m[OPENAI] Creating embedding...[39m
[1693483019825] [32m[OPENAI] Embedding created successfully.[39m
[1693483019948] [32m[OPENAI] Embedding created successfully.[39m
[1693483020348] [33m[OPENAI] Creating embedding...[39m
[1693483020384] [33m[OPENAI] Creating embedding...[39m
[1693483020567] [32m[OPENAI] Embedding created successfully.[39m
[1693483020593] [32m[OPENAI] Embedding created successfully.[39m
[1693483020899] [33m[OPENAI] Creating embedding...[39m
[1693483021081] [32m[OPENAI] Embedding created successfully.[39m
[1693483021147] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693483021509] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693483023450] {
  "id": "chatcmpl-7taaAX5qLqzRfkRlqVA1usZEUE4Pv",
  "object": "chat.completion",
  "created": 1693483018,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "drop_wood",
          "arguments": "{\n  \"characterId\": \"A3\",\n  \"itemId\": \"c50fe28c-c875-46c8-8e06-aa1d64eaff29\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2471,
    "completion_tokens": 47,
    "total_tokens": 2518
  }
}
[1693483023450] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "drop_wood",
    "arguments": "{\n  \"characterId\": \"A3\",\n  \"itemId\": \"c50fe28c-c875-46c8-8e06-aa1d64eaff29\"\n}"
  }
}
[1693483023450] [36m[OPENAI] Chat completion took 5138.198166012764ms[39m
[1693483023451] [36m[OPENAI] Tokens per second: 9.147175426375576tps[39m
[1693483023451] [32m[OPENAI] Chat completion created successfully.[39m
[1693483023474] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693483023697] {
  "id": "chatcmpl-7taaDRaj4kdCZVNp7Eu2v5uocRbqK",
  "object": "chat.completion",
  "created": 1693483021,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_axe",
          "arguments": "{\n  \"characterId\": \"A5\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1924,
    "completion_tokens": 18,
    "total_tokens": 1942
  }
}
[1693483023697] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_axe",
    "arguments": "{\n  \"characterId\": \"A5\"\n}"
  }
}
[1693483023697] [36m[OPENAI] Chat completion took 2188.0852080583572ms[39m
[1693483023697] [36m[OPENAI] Tokens per second: 8.226370679582754tps[39m
[1693483023697] [32m[OPENAI] Chat completion created successfully.[39m
[1693483024575] {
  "id": "chatcmpl-7taaDbLF8x6BeWOsfSzCEIEEfPgQR",
  "object": "chat.completion",
  "created": 1693483021,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n\"characterId\": \"A4\",\n\"x\": 45.24001,\n\"y\": 10.2\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1796,
    "completion_tokens": 32,
    "total_tokens": 1828
  }
}
[1693483024576] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n\"characterId\": \"A4\",\n\"x\": 45.24001,\n\"y\": 10.2\n}"
  }
}
[1693483024576] [36m[OPENAI] Chat completion took 3428.0591670274734ms[39m
[1693483024576] [36m[OPENAI] Tokens per second: 9.334728031473192tps[39m
[1693483024576] [32m[OPENAI] Chat completion created successfully.[39m
[1693483024592] --- Observations received -- 
[1693483024593] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 45.24001, Y: 10.2.",
  "time": 177.4528
}
[1693483024593] [Character] Getting character: A4
[1693483024659] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483024659] [33m[OPENAI] Creating embedding...[39m
[1693483024721] [Character] Getting character: A5
[1693483024748] [33m[OPENAI] Creating embedding...[39m
[1693483024817] [32m[OPENAI] Embedding created successfully.[39m
[1693483024901] {
  "id": "chatcmpl-7taaGapxcGszHh0ogR9Hp1kb7tDRt",
  "object": "chat.completion",
  "created": 1693483024,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693483024901] {
  "role": "assistant",
  "content": "2"
}
[1693483024901] [36m[OPENAI] Chat completion took 241.707750082016ms[39m
[1693483024901] [36m[OPENAI] Tokens per second: 4.137227704368938tps[39m
[1693483024901] [32m[OPENAI] Chat completion created successfully.[39m
[1693483024911] [32m[OPENAI] Embedding created successfully.[39m
[1693483025099] --- Observations received -- 
[1693483025099] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees Human (1) at X: 51.1129, Y: 14.6129",
  "time": 177.961578
}
[1693483025099] [Character] Getting character: A4
[1693483025165] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483025165] [33m[OPENAI] Creating embedding...[39m
[1693483025216] --- Observations received -- 
[1693483025216] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees Tree (533) at X: 50.12, Y: 6.280001",
  "time": 178.081329
}
[1693483025216] [Character] Getting character: A4
[1693483025276] --- Observations received -- 
[1693483025277] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees Stump(Clone) at X: 52.41, Y: 11.03",
  "time": 178.141525
}
[1693483025277] [Character] Getting character: A4
[1693483025285] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483025285] [33m[OPENAI] Creating embedding...[39m
[1693483025334] [32m[OPENAI] Embedding created successfully.[39m
[1693483025348] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693483025349] [33m[OPENAI] Creating embedding...[39m
[1693483025379] [33m[OPENAI] Creating embedding...[39m
[1693483025452] {
  "id": "chatcmpl-7taaHpwUkZ5iHU4Qwk98BV3H54ihT",
  "object": "chat.completion",
  "created": 1693483025,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 107,
    "completion_tokens": 1,
    "total_tokens": 108
  }
}
[1693483025452] {
  "role": "assistant",
  "content": "4"
}
[1693483025452] [36m[OPENAI] Chat completion took 286.13929200172424ms[39m
[1693483025452] [36m[OPENAI] Tokens per second: 3.494801406001851tps[39m
[1693483025452] [32m[OPENAI] Chat completion created successfully.[39m
[1693483025481] [32m[OPENAI] Embedding created successfully.[39m
[1693483025615] [32m[OPENAI] Embedding created successfully.[39m
[1693483025619] {
  "id": "chatcmpl-7taaHkbrEzMGpsEbsfVRzhMvutvK0",
  "object": "chat.completion",
  "created": 1693483025,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693483025619] {
  "role": "assistant",
  "content": "2"
}
[1693483025619] [36m[OPENAI] Chat completion took 270.54095792770386ms[39m
[1693483025619] [36m[OPENAI] Tokens per second: 3.6962979936931695tps[39m
[1693483025619] [32m[OPENAI] Chat completion created successfully.[39m
[1693483025656] --- Observations received -- 
[1693483025657] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees Chest (1) at X: 50.52, Y: 14.5",
  "time": 178.5206
}
[1693483025657] [Character] Getting character: A4
