[1693633789891] [Character] Creating Thomas's logger
[1693633789891] [Character] Creating George's logger
[1693633789891] [Character] Creating Will's logger
[1693633789891] [Character] Creating Lucy's logger
[1693633789891] [Character] Creating Eli's logger
[1693633789899] [Main] WebSocket server listening on port 8082
[1693633790114] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790120] [33m[OPENAI] Creating embedding...[39m
[1693633790120] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790120] [33m[OPENAI] Creating embedding...[39m
[1693633790120] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790120] [33m[OPENAI] Creating embedding...[39m
[1693633790121] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790121] [33m[OPENAI] Creating embedding...[39m
[1693633790121] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790121] [33m[OPENAI] Creating embedding...[39m
[1693633790121] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790123] [33m[OPENAI] Creating embedding...[39m
[1693633790123] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790124] [33m[OPENAI] Creating embedding...[39m
[1693633790124] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790124] [33m[OPENAI] Creating embedding...[39m
[1693633790124] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790124] [33m[OPENAI] Creating embedding...[39m
[1693633790124] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790124] [33m[OPENAI] Creating embedding...[39m
[1693633790125] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790125] [33m[OPENAI] Creating embedding...[39m
[1693633790125] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790125] [33m[OPENAI] Creating embedding...[39m
[1693633790127] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790127] [33m[OPENAI] Creating embedding...[39m
[1693633790127] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790127] [33m[OPENAI] Creating embedding...[39m
[1693633790127] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790128] [33m[OPENAI] Creating embedding...[39m
[1693633790288] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790288] [33m[OPENAI] Creating embedding...[39m
[1693633790288] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790288] [33m[OPENAI] Creating embedding...[39m
[1693633790288] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790288] [33m[OPENAI] Creating embedding...[39m
[1693633790288] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790288] [33m[OPENAI] Creating embedding...[39m
[1693633790288] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790288] [33m[OPENAI] Creating embedding...[39m
[1693633790288] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790288] [33m[OPENAI] Creating embedding...[39m
[1693633790288] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790288] [33m[OPENAI] Creating embedding...[39m
[1693633790289] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790289] [33m[OPENAI] Creating embedding...[39m
[1693633790289] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790289] [33m[OPENAI] Creating embedding...[39m
[1693633790289] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790289] [33m[OPENAI] Creating embedding...[39m
[1693633790289] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790289] [33m[OPENAI] Creating embedding...[39m
[1693633790289] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790289] [33m[OPENAI] Creating embedding...[39m
[1693633790289] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790289] [33m[OPENAI] Creating embedding...[39m
[1693633790289] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790289] [33m[OPENAI] Creating embedding...[39m
[1693633790289] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790289] [33m[OPENAI] Creating embedding...[39m
[1693633790317] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790317] [33m[OPENAI] Creating embedding...[39m
[1693633790317] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790317] [33m[OPENAI] Creating embedding...[39m
[1693633790317] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790317] [33m[OPENAI] Creating embedding...[39m
[1693633790317] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790317] [33m[OPENAI] Creating embedding...[39m
[1693633790317] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790317] [33m[OPENAI] Creating embedding...[39m
[1693633790318] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790318] [33m[OPENAI] Creating embedding...[39m
[1693633790318] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790318] [33m[OPENAI] Creating embedding...[39m
[1693633790318] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790318] [33m[OPENAI] Creating embedding...[39m
[1693633790318] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790318] [33m[OPENAI] Creating embedding...[39m
[1693633790318] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790318] [33m[OPENAI] Creating embedding...[39m
[1693633790318] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790318] [33m[OPENAI] Creating embedding...[39m
[1693633790318] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790318] [33m[OPENAI] Creating embedding...[39m
[1693633790318] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790318] [33m[OPENAI] Creating embedding...[39m
[1693633790318] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790318] [33m[OPENAI] Creating embedding...[39m
[1693633790318] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790318] [33m[OPENAI] Creating embedding...[39m
[1693633790326] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790326] [33m[OPENAI] Creating embedding...[39m
[1693633790326] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790326] [33m[OPENAI] Creating embedding...[39m
[1693633790326] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790326] [33m[OPENAI] Creating embedding...[39m
[1693633790326] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790326] [33m[OPENAI] Creating embedding...[39m
[1693633790326] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790326] [33m[OPENAI] Creating embedding...[39m
[1693633790326] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790326] [33m[OPENAI] Creating embedding...[39m
[1693633790327] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790327] [33m[OPENAI] Creating embedding...[39m
[1693633790327] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790327] [33m[OPENAI] Creating embedding...[39m
[1693633790327] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790327] [33m[OPENAI] Creating embedding...[39m
[1693633790327] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790327] [33m[OPENAI] Creating embedding...[39m
[1693633790327] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790327] [33m[OPENAI] Creating embedding...[39m
[1693633790327] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790327] [33m[OPENAI] Creating embedding...[39m
[1693633790327] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790327] [33m[OPENAI] Creating embedding...[39m
[1693633790327] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790327] [33m[OPENAI] Creating embedding...[39m
[1693633790327] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790327] [33m[OPENAI] Creating embedding...[39m
[1693633790327] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790327] [33m[OPENAI] Creating embedding...[39m
[1693633790346] [32m[OPENAI] Embedding created successfully.[39m
[1693633790346] [32m[OPENAI] Embedding created successfully.[39m
[1693633790346] [32m[OPENAI] Embedding created successfully.[39m
[1693633790348] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790348] [33m[OPENAI] Creating embedding...[39m
[1693633790349] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790349] [33m[OPENAI] Creating embedding...[39m
[1693633790349] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790349] [33m[OPENAI] Creating embedding...[39m
[1693633790349] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790349] [33m[OPENAI] Creating embedding...[39m
[1693633790349] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790349] [33m[OPENAI] Creating embedding...[39m
[1693633790349] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790349] [33m[OPENAI] Creating embedding...[39m
[1693633790349] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790349] [33m[OPENAI] Creating embedding...[39m
[1693633790349] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790349] [33m[OPENAI] Creating embedding...[39m
[1693633790349] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790349] [33m[OPENAI] Creating embedding...[39m
[1693633790349] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790349] [33m[OPENAI] Creating embedding...[39m
[1693633790349] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790349] [33m[OPENAI] Creating embedding...[39m
[1693633790349] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790349] [33m[OPENAI] Creating embedding...[39m
[1693633790349] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790349] [33m[OPENAI] Creating embedding...[39m
[1693633790349] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790349] [33m[OPENAI] Creating embedding...[39m
[1693633790350] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633790350] [33m[OPENAI] Creating embedding...[39m
[1693633790375] [32m[OPENAI] Embedding created successfully.[39m
[1693633790375] [32m[OPENAI] Embedding created successfully.[39m
[1693633790375] [32m[OPENAI] Embedding created successfully.[39m
[1693633790375] [32m[OPENAI] Embedding created successfully.[39m
[1693633790376] [32m[OPENAI] Embedding created successfully.[39m
[1693633790382] [32m[OPENAI] Embedding created successfully.[39m
[1693633790416] [32m[OPENAI] Embedding created successfully.[39m
[1693633790442] {
  "id": "chatcmpl-7uDny04HcRlQI2M3v3IU3TDjRz25J",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693633790442] {
  "role": "assistant",
  "content": "5"
}
[1693633790442] [36m[OPENAI] Chat completion took 315.72062492370605ms[39m
[1693633790442] [36m[OPENAI] Global tokens per second: 0.46360686138154844tps[39m
[1693633790442] [36m[OPENAI] Tokens per second: 3.1673572172918707tps[39m
[1693633790442] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790442] {
  "id": "chatcmpl-7uDnyf5jde3lK5EbsZ5avr5OURpG7",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 96,
    "completion_tokens": 1,
    "total_tokens": 97
  }
}
[1693633790442] {
  "role": "assistant",
  "content": "2"
}
[1693633790442] [36m[OPENAI] Chat completion took 315.1875ms[39m
[1693633790442] [36m[OPENAI] Global tokens per second: 0.9272137227630969tps[39m
[1693633790442] [36m[OPENAI] Tokens per second: 3.1727146539758078tps[39m
[1693633790442] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790457] {
  "id": "chatcmpl-7uDnySs0IHn3YQU09OSOKOJnVPW3v",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693633790457] {
  "role": "assistant",
  "content": "6"
}
[1693633790458] [36m[OPENAI] Chat completion took 329.94145798683167ms[39m
[1693633790458] [36m[OPENAI] Global tokens per second: 1.3805798435342844tps[39m
[1693633790458] [36m[OPENAI] Tokens per second: 3.0308407015644305tps[39m
[1693633790458] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790462] {
  "id": "chatcmpl-7uDnyYLgUimGC5JdNJ65Ju5Xspl8f",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 90,
    "completion_tokens": 1,
    "total_tokens": 91
  }
}
[1693633790462] {
  "role": "assistant",
  "content": "2"
}
[1693633790462] [36m[OPENAI] Chat completion took 340.00850009918213ms[39m
[1693633790462] [36m[OPENAI] Global tokens per second: 1.8373909049150206tps[39m
[1693633790462] [36m[OPENAI] Tokens per second: 2.941102942156726tps[39m
[1693633790462] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790466] {
  "id": "chatcmpl-7uDnyGavDnIbpdwC9pkyI0nw7lM8G",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693633790466] {
  "role": "assistant",
  "content": "4"
}
[1693633790466] [36m[OPENAI] Chat completion took 350.6388750076294ms[39m
[1693633790466] [36m[OPENAI] Global tokens per second: 2.2925263640531868tps[39m
[1693633790466] [36m[OPENAI] Tokens per second: 2.8519370534092703tps[39m
[1693633790466] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790486] [32m[OPENAI] Embedding created successfully.[39m
[1693633790486] [32m[OPENAI] Embedding created successfully.[39m
[1693633790490] {
  "id": "chatcmpl-7uDnykY6eOlkhj3FzrPVXEquEoURz",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693633790490] {
  "role": "assistant",
  "content": "5"
}
[1693633790490] [36m[OPENAI] Chat completion took 369.26295804977417ms[39m
[1693633790490] [36m[OPENAI] Global tokens per second: 2.7210884353741496tps[39m
[1693633790490] [36m[OPENAI] Tokens per second: 2.7080972466921707tps[39m
[1693633790490] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790493] [32m[OPENAI] Embedding created successfully.[39m
[1693633790496] {
  "id": "chatcmpl-7uDny8e9cz9nIkNTQkZsCileXC9Jb",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 96,
    "completion_tokens": 1,
    "total_tokens": 97
  }
}
[1693633790496] {
  "role": "assistant",
  "content": "3"
}
[1693633790496] [36m[OPENAI] Chat completion took 375.1023750305176ms[39m
[1693633790496] [36m[OPENAI] Global tokens per second: 3.1659882406151065tps[39m
[1693633790496] [36m[OPENAI] Tokens per second: 2.665938865139529tps[39m
[1693633790496] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790505] [32m[OPENAI] Embedding created successfully.[39m
[1693633790507] [32m[OPENAI] Embedding created successfully.[39m
[1693633790507] {
  "id": "chatcmpl-7uDnyQM8PoWxzK0ORhYbVkPt7Ckq0",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693633790507] {
  "role": "assistant",
  "content": "4"
}
[1693633790507] [36m[OPENAI] Chat completion took 383.3905830383301ms[39m
[1693633790507] [36m[OPENAI] Global tokens per second: 3.6003600360036003tps[39m
[1693633790507] [36m[OPENAI] Tokens per second: 2.6083061093339985tps[39m
[1693633790507] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790508] {
  "id": "chatcmpl-7uDnyNnWcPxDkZnmpzIBAVm48EUw9",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693633790508] {
  "role": "assistant",
  "content": "4"
}
[1693633790508] [36m[OPENAI] Chat completion took 384.33112502098083ms[39m
[1693633790508] [36m[OPENAI] Global tokens per second: 4.048582995951417tps[39m
[1693633790508] [36m[OPENAI] Tokens per second: 2.601923016111197tps[39m
[1693633790508] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790509] [32m[OPENAI] Embedding created successfully.[39m
[1693633790515] [32m[OPENAI] Embedding created successfully.[39m
[1693633790518] [32m[OPENAI] Embedding created successfully.[39m
[1693633790520] [32m[OPENAI] Embedding created successfully.[39m
[1693633790521] [32m[OPENAI] Embedding created successfully.[39m
[1693633790525] [32m[OPENAI] Embedding created successfully.[39m
[1693633790532] [32m[OPENAI] Embedding created successfully.[39m
[1693633790534] [32m[OPENAI] Embedding created successfully.[39m
[1693633790535] [32m[OPENAI] Embedding created successfully.[39m
[1693633790537] [32m[OPENAI] Embedding created successfully.[39m
[1693633790538] [32m[OPENAI] Embedding created successfully.[39m
[1693633790544] [32m[OPENAI] Embedding created successfully.[39m
[1693633790545] [32m[OPENAI] Embedding created successfully.[39m
[1693633790545] [32m[OPENAI] Embedding created successfully.[39m
[1693633790545] [32m[OPENAI] Embedding created successfully.[39m
[1693633790552] [32m[OPENAI] Embedding created successfully.[39m
[1693633790552] [32m[OPENAI] Embedding created successfully.[39m
[1693633790555] [32m[OPENAI] Embedding created successfully.[39m
[1693633790555] [32m[OPENAI] Embedding created successfully.[39m
[1693633790556] {
  "id": "chatcmpl-7uDnydHIa2Sz6qJhSNXHzA8p4JhTc",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693633790556] {
  "role": "assistant",
  "content": "2"
}
[1693633790556] [36m[OPENAI] Chat completion took 268.1904170513153ms[39m
[1693633790556] [36m[OPENAI] Global tokens per second: 4.4033465433729635tps[39m
[1693633790556] [36m[OPENAI] Tokens per second: 3.728694004039156tps[39m
[1693633790556] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790558] [32m[OPENAI] Embedding created successfully.[39m
[1693633790559] [32m[OPENAI] Embedding created successfully.[39m
[1693633790564] [32m[OPENAI] Embedding created successfully.[39m
[1693633790566] [32m[OPENAI] Embedding created successfully.[39m
[1693633790574] [32m[OPENAI] Embedding created successfully.[39m
[1693633790575] [32m[OPENAI] Embedding created successfully.[39m
[1693633790580] [32m[OPENAI] Embedding created successfully.[39m
[1693633790581] {
  "id": "chatcmpl-7uDnyqIYYoWrSHNqEOMAAU4LOCRwg",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 2,
    "total_tokens": 93
  }
}
[1693633790581] {
  "role": "assistant",
  "content": "5."
}
[1693633790581] [36m[OPENAI] Chat completion took 263.1831660270691ms[39m
[1693633790581] [36m[OPENAI] Global tokens per second: 5.226480836236934tps[39m
[1693633790581] [36m[OPENAI] Tokens per second: 7.599270235218215tps[39m
[1693633790581] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790581] [32m[OPENAI] Embedding created successfully.[39m
[1693633790583] [32m[OPENAI] Embedding created successfully.[39m
[1693633790586] {
  "id": "chatcmpl-7uDnyruifwb8z8ackzjrKBdClMbI9",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693633790586] {
  "role": "assistant",
  "content": "5"
}
[1693633790586] [36m[OPENAI] Chat completion took 296.31962513923645ms[39m
[1693633790586] [36m[OPENAI] Global tokens per second: 5.649717514124293tps[39m
[1693633790586] [36m[OPENAI] Tokens per second: 3.374734290818956tps[39m
[1693633790586] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790587] [32m[OPENAI] Embedding created successfully.[39m
[1693633790587] [32m[OPENAI] Embedding created successfully.[39m
[1693633790595] {
  "id": "chatcmpl-7uDnyComPcSwTvuM4lNCOxLwVnNjn",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1693633790595] {
  "role": "assistant",
  "content": "1"
}
[1693633790595] [36m[OPENAI] Chat completion took 305.52758407592773ms[39m
[1693633790595] [36m[OPENAI] Global tokens per second: 6.0606060606060606tps[39m
[1693633790595] [36m[OPENAI] Tokens per second: 3.273026895507695tps[39m
[1693633790595] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790596] [32m[OPENAI] Embedding created successfully.[39m
[1693633790597] [32m[OPENAI] Embedding created successfully.[39m
[1693633790597] [32m[OPENAI] Embedding created successfully.[39m
[1693633790600] [32m[OPENAI] Embedding created successfully.[39m
[1693633790604] {
  "id": "chatcmpl-7uDnyAJeYvqFQtvgSH3h0hrHg0xi0",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693633790604] {
  "role": "assistant",
  "content": "2"
}
[1693633790604] [36m[OPENAI] Chat completion took 479.35720896720886ms[39m
[1693633790604] [36m[OPENAI] Global tokens per second: 6.468305304010349tps[39m
[1693633790604] [36m[OPENAI] Tokens per second: 2.0861269660563435tps[39m
[1693633790604] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790605] [32m[OPENAI] Embedding created successfully.[39m
[1693633790606] {
  "id": "chatcmpl-7uDnyfNpz0N0HFyLfFCEG3NePPt8G",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 86,
    "completion_tokens": 1,
    "total_tokens": 87
  }
}
[1693633790606] {
  "role": "assistant",
  "content": "1"
}
[1693633790606] [36m[OPENAI] Chat completion took 317.12029099464417ms[39m
[1693633790606] [36m[OPENAI] Global tokens per second: 6.8935803532959925tps[39m
[1693633790606] [36m[OPENAI] Tokens per second: 3.1533775302220852tps[39m
[1693633790606] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790606] [32m[OPENAI] Embedding created successfully.[39m
[1693633790608] {
  "id": "chatcmpl-7uDnyAsrs5gqYjvRLFzofLPMYUTTs",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 92,
    "completion_tokens": 1,
    "total_tokens": 93
  }
}
[1693633790608] {
  "role": "assistant",
  "content": "2"
}
[1693633790608] [36m[OPENAI] Chat completion took 319.1056671142578ms[39m
[1693633790608] [36m[OPENAI] Global tokens per second: 7.318123116659492tps[39m
[1693633790608] [36m[OPENAI] Tokens per second: 3.1337581969108173tps[39m
[1693633790608] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790609] [32m[OPENAI] Embedding created successfully.[39m
[1693633790613] {
  "id": "chatcmpl-7uDnydHemcAtVYWtxf9JzPNtFES7F",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693633790613] {
  "role": "assistant",
  "content": "3"
}
[1693633790613] [36m[OPENAI] Chat completion took 264.8857500553131ms[39m
[1693633790613] [36m[OPENAI] Global tokens per second: 7.731958762886598tps[39m
[1693633790613] [36m[OPENAI] Tokens per second: 3.7752125200815114tps[39m
[1693633790613] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790636] {
  "id": "chatcmpl-7uDnyxXpu2pzoc1ZLq2hNNM5ZGVlE",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693633790636] {
  "role": "assistant",
  "content": "7"
}
[1693633790636] [36m[OPENAI] Chat completion took 347.4953329563141ms[39m
[1693633790636] [36m[OPENAI] Global tokens per second: 8.081667375584857tps[39m
[1693633790636] [36m[OPENAI] Tokens per second: 2.8777364907105576tps[39m
[1693633790636] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790639] {
  "id": "chatcmpl-7uDnywFZGgxtFGBknVwJsLpbyiImO",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 114,
    "completion_tokens": 1,
    "total_tokens": 115
  }
}
[1693633790639] {
  "role": "assistant",
  "content": "4"
}
[1693633790639] [36m[OPENAI] Chat completion took 313.14712500572205ms[39m
[1693633790639] [36m[OPENAI] Global tokens per second: 8.496176720475786tps[39m
[1693633790639] [36m[OPENAI] Tokens per second: 3.19338713386472tps[39m
[1693633790639] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790640] [32m[OPENAI] Embedding created successfully.[39m
[1693633790640] [32m[OPENAI] Embedding created successfully.[39m
[1693633790647] {
  "id": "chatcmpl-7uDnym6qXq1bxz4guIqorMPFByJtz",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1693633790647] {
  "role": "assistant",
  "content": "7"
}
[1693633790647] [36m[OPENAI] Chat completion took 296.92987513542175ms[39m
[1693633790647] [36m[OPENAI] Global tokens per second: 8.890770533446231tps[39m
[1693633790647] [36m[OPENAI] Tokens per second: 3.367798540123074tps[39m
[1693633790647] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790647] [32m[OPENAI] Embedding created successfully.[39m
[1693633790648] {
  "id": "chatcmpl-7uDnyRF2H8jz3vISlKJ8mZ8dqyfOs",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693633790648] {
  "role": "assistant",
  "content": "4"
}
[1693633790648] [36m[OPENAI] Chat completion took 320.8472499847412ms[39m
[1693633790648] [36m[OPENAI] Global tokens per second: 9.310198899703767tps[39m
[1693633790648] [36m[OPENAI] Tokens per second: 3.1167479230305317tps[39m
[1693633790648] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790650] [32m[OPENAI] Embedding created successfully.[39m
[1693633790657] [32m[OPENAI] Embedding created successfully.[39m
[1693633790659] {
  "id": "chatcmpl-7uDnyRMNeqf3Y9VgACnP8hf0rWlVC",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1693633790659] {
  "role": "assistant",
  "content": "5"
}
[1693633790659] [36m[OPENAI] Chat completion took 332.44745802879333ms[39m
[1693633790659] [36m[OPENAI] Global tokens per second: 9.688289806234204tps[39m
[1693633790659] [36m[OPENAI] Tokens per second: 3.007994123129646tps[39m
[1693633790659] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790660] [32m[OPENAI] Embedding created successfully.[39m
[1693633790662] {
  "id": "chatcmpl-7uDnyvIOmi9eFUbCSW7LBnoYXzmgQ",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693633790662] {
  "role": "assistant",
  "content": "5"
}
[1693633790662] [36m[OPENAI] Chat completion took 334.7586250305176ms[39m
[1693633790662] [36m[OPENAI] Global tokens per second: 10.096760622633573tps[39m
[1693633790662] [36m[OPENAI] Tokens per second: 2.9872269905184283tps[39m
[1693633790662] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790662] {
  "id": "chatcmpl-7uDny1OdVHk9O0BKqwcyHi9lztxNT",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693633790662] {
  "role": "assistant",
  "content": "5"
}
[1693633790662] [36m[OPENAI] Chat completion took 373.5135841369629ms[39m
[1693633790662] [36m[OPENAI] Global tokens per second: 10.517458981909972tps[39m
[1693633790662] [36m[OPENAI] Tokens per second: 2.6772787991381652tps[39m
[1693633790662] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790665] {
  "id": "chatcmpl-7uDnyDCKe7g6sWQ2npXhZNWXxpzsD",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "8"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633790665] {
  "role": "assistant",
  "content": "8"
}
[1693633790665] [36m[OPENAI] Chat completion took 338.10491704940796ms[39m
[1693633790665] [36m[OPENAI] Global tokens per second: 10.92436974789916tps[39m
[1693633790665] [36m[OPENAI] Tokens per second: 2.9576618072486296tps[39m
[1693633790665] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790665] {
  "id": "chatcmpl-7uDnyV94r4AzKe40KQ1m1xY5sDQfm",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693633790665] {
  "role": "assistant",
  "content": "5"
}
[1693633790665] [36m[OPENAI] Chat completion took 338.5367910861969ms[39m
[1693633790665] [36m[OPENAI] Global tokens per second: 11.344537815126051tps[39m
[1693633790665] [36m[OPENAI] Tokens per second: 2.9538886949081524tps[39m
[1693633790665] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790666] [32m[OPENAI] Embedding created successfully.[39m
[1693633790671] {
  "id": "chatcmpl-7uDnycizsuVvl1OB0Bp4gXeuZHxq0",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 92,
    "completion_tokens": 1,
    "total_tokens": 93
  }
}
[1693633790671] {
  "role": "assistant",
  "content": "5"
}
[1693633790671] [36m[OPENAI] Chat completion took 353.5912079811096ms[39m
[1693633790671] [36m[OPENAI] Global tokens per second: 11.735121542330258tps[39m
[1693633790671] [36m[OPENAI] Tokens per second: 2.8281246180007518tps[39m
[1693633790671] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790672] [32m[OPENAI] Embedding created successfully.[39m
[1693633790673] {
  "id": "chatcmpl-7uDny2ILTURIjdfwSjlKwQl0hah0D",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693633790673] {
  "role": "assistant",
  "content": "4"
}
[1693633790673] [36m[OPENAI] Chat completion took 354.93008399009705ms[39m
[1693633790673] [36m[OPENAI] Global tokens per second: 12.144053601340033tps[39m
[1693633790673] [36m[OPENAI] Tokens per second: 2.8174562966262986tps[39m
[1693633790673] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790673] {
  "id": "chatcmpl-7uDnyFe0t7Kw6FwU4t5uD3YRGscEQ",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633790673] {
  "role": "assistant",
  "content": "6"
}
[1693633790673] [36m[OPENAI] Chat completion took 323.55629205703735ms[39m
[1693633790673] [36m[OPENAI] Global tokens per second: 12.56281407035176tps[39m
[1693633790673] [36m[OPENAI] Tokens per second: 3.0906523054841952tps[39m
[1693633790673] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790674] [32m[OPENAI] Embedding created successfully.[39m
[1693633790675] [32m[OPENAI] Embedding created successfully.[39m
[1693633790676] [32m[OPENAI] Embedding created successfully.[39m
[1693633790681] {
  "id": "chatcmpl-7uDnyMwnxl3J1I8DWUElpNXbfKRBL",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1693633790681] {
  "role": "assistant",
  "content": "4"
}
[1693633790681] [36m[OPENAI] Chat completion took 331.7384159564972ms[39m
[1693633790681] [36m[OPENAI] Global tokens per second: 12.93823038397329tps[39m
[1693633790681] [36m[OPENAI] Tokens per second: 3.014423268154557tps[39m
[1693633790681] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790682] {
  "id": "chatcmpl-7uDnykbBGnDv9mfXxUhbBC71m1m78",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 90,
    "completion_tokens": 1,
    "total_tokens": 91
  }
}
[1693633790682] {
  "role": "assistant",
  "content": "3"
}
[1693633790682] [36m[OPENAI] Chat completion took 364.05308413505554ms[39m
[1693633790682] [36m[OPENAI] Global tokens per second: 13.350020859407595tps[39m
[1693633790682] [36m[OPENAI] Tokens per second: 2.7468521585962513tps[39m
[1693633790682] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790682] {
  "id": "chatcmpl-7uDny4C6hqXlhlWZObBSkVuezpFvF",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693633790682] {
  "role": "assistant",
  "content": "7"
}
[1693633790682] [36m[OPENAI] Chat completion took 332.92604088783264ms[39m
[1693633790682] [36m[OPENAI] Global tokens per second: 13.76720901126408tps[39m
[1693633790682] [36m[OPENAI] Tokens per second: 3.003670116441609tps[39m
[1693633790682] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790683] {
  "id": "chatcmpl-7uDnyizo7AjrrN3fn4BbbLwsxUVHQ",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693633790683] {
  "role": "assistant",
  "content": "2"
}
[1693633790683] [36m[OPENAI] Chat completion took 393.8504161834717ms[39m
[1693633790683] [36m[OPENAI] Global tokens per second: 14.178482068390325tps[39m
[1693633790683] [36m[OPENAI] Tokens per second: 2.539035021697575tps[39m
[1693633790683] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790684] [32m[OPENAI] Embedding created successfully.[39m
[1693633790690] {
  "id": "chatcmpl-7uDnyNMSKU02SczEraeSHgyY7Ux6b",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 2,
    "total_tokens": 100
  }
}
[1693633790690] {
  "role": "assistant",
  "content": "6."
}
[1693633790690] [36m[OPENAI] Chat completion took 340.74033403396606ms[39m
[1693633790690] [36m[OPENAI] Global tokens per second: 14.96881496881497tps[39m
[1693633790690] [36m[OPENAI] Tokens per second: 5.86957222328905tps[39m
[1693633790690] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790690] {
  "id": "chatcmpl-7uDnyd5yghrfIH21gmmFYmHioK491",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693633790690] {
  "role": "assistant",
  "content": "5"
}
[1693633790690] [36m[OPENAI] Chat completion took 363.09154081344604ms[39m
[1693633790690] [36m[OPENAI] Global tokens per second: 15.384615384615385tps[39m
[1693633790690] [36m[OPENAI] Tokens per second: 2.754126405037327tps[39m
[1693633790690] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790690] [32m[OPENAI] Embedding created successfully.[39m
[1693633790692] {
  "id": "chatcmpl-7uDnySavyPyrN0ghKnXVOWGwn1gvk",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693633790692] {
  "role": "assistant",
  "content": "6"
}
[1693633790692] [36m[OPENAI] Chat completion took 568.2436249256134ms[39m
[1693633790692] [36m[OPENAI] Global tokens per second: 15.78728707935189tps[39m
[1693633790692] [36m[OPENAI] Tokens per second: 1.75980856825434tps[39m
[1693633790692] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790693] {
  "id": "chatcmpl-7uDnyJBKvaa6f0n0PwGRqtAuwWVTm",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633790693] {
  "role": "assistant",
  "content": "6"
}
[1693633790693] [36m[OPENAI] Chat completion took 365.97408294677734ms[39m
[1693633790693] [36m[OPENAI] Global tokens per second: 16.196013289036546tps[39m
[1693633790693] [36m[OPENAI] Tokens per second: 2.732433925233518tps[39m
[1693633790693] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790694] {
  "id": "chatcmpl-7uDnynPkP3rWqP5VGijrXHzX19oQL",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693633790694] {
  "role": "assistant",
  "content": "1"
}
[1693633790694] [36m[OPENAI] Chat completion took 344.78166699409485ms[39m
[1693633790694] [36m[OPENAI] Global tokens per second: 16.604400166044tps[39m
[1693633790694] [36m[OPENAI] Tokens per second: 2.9003862320125253tps[39m
[1693633790694] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790696] {
  "id": "chatcmpl-7uDnydd5hUhln45DoZtfgk3zVdfXA",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 2,
    "total_tokens": 96
  }
}
[1693633790696] {
  "role": "assistant",
  "content": "5."
}
[1693633790696] [36m[OPENAI] Chat completion took 406.5928330421448ms[39m
[1693633790696] [36m[OPENAI] Global tokens per second: 17.420157610949815tps[39m
[1693633790696] [36m[OPENAI] Tokens per second: 4.918925857684002tps[39m
[1693633790696] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790696] [32m[OPENAI] Embedding created successfully.[39m
[1693633790697] {
  "id": "chatcmpl-7uDnyRiJJkx0pZIdhIBm6PFzIipbk",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693633790697] {
  "role": "assistant",
  "content": "6"
}
[1693633790697] [36m[OPENAI] Chat completion took 348.5055000782013ms[39m
[1693633790697] [36m[OPENAI] Global tokens per second: 17.827529021558874tps[39m
[1693633790697] [36m[OPENAI] Tokens per second: 2.86939517389427tps[39m
[1693633790697] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790699] {
  "id": "chatcmpl-7uDnyB6qgKnNiQGoOY2NuiEu7cLXM",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "8."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 2,
    "total_tokens": 102
  }
}
[1693633790699] {
  "role": "assistant",
  "content": "8."
}
[1693633790699] [36m[OPENAI] Chat completion took 372.3833749294281ms[39m
[1693633790699] [36m[OPENAI] Global tokens per second: 18.641259320629658tps[39m
[1693633790699] [36m[OPENAI] Tokens per second: 5.370809049622659tps[39m
[1693633790699] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790700] {
  "id": "chatcmpl-7uDnyBZ9oOTBPvHK1Fiy8hAUsTZdE",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693633790700] {
  "role": "assistant",
  "content": "4"
}
[1693633790700] [36m[OPENAI] Chat completion took 350.9757921695709ms[39m
[1693633790700] [36m[OPENAI] Global tokens per second: 19.047619047619047tps[39m
[1693633790700] [36m[OPENAI] Tokens per second: 2.8491993530905932tps[39m
[1693633790700] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790700] {
  "id": "chatcmpl-7uDnytM5NcPzo4pNWyjr0ZfWBpqJa",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693633790700] {
  "role": "assistant",
  "content": "4"
}
[1693633790700] [36m[OPENAI] Chat completion took 351.54120898246765ms[39m
[1693633790700] [36m[OPENAI] Global tokens per second: 19.461697722567287tps[39m
[1693633790700] [36m[OPENAI] Tokens per second: 2.844616717608981tps[39m
[1693633790700] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790701] [32m[OPENAI] Embedding created successfully.[39m
[1693633790706] {
  "id": "chatcmpl-7uDnyQY4gNtuudejuMdamDFheyNl7",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633790706] {
  "role": "assistant",
  "content": "7"
}
[1693633790706] [36m[OPENAI] Chat completion took 356.77854084968567ms[39m
[1693633790706] [36m[OPENAI] Global tokens per second: 19.82651796778191tps[39m
[1693633790706] [36m[OPENAI] Tokens per second: 2.8028591563227168tps[39m
[1693633790706] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790707] {
  "id": "chatcmpl-7uDnyrBBApnXRgVEpIVBHSBcBggOj",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693633790707] {
  "role": "assistant",
  "content": "4"
}
[1693633790707] [36m[OPENAI] Chat completion took 388.8579170703888ms[39m
[1693633790707] [36m[OPENAI] Global tokens per second: 20.23121387283237tps[39m
[1693633790707] [36m[OPENAI] Tokens per second: 2.571633380988835tps[39m
[1693633790707] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790708] {
  "id": "chatcmpl-7uDnyCp4mtCqXnABsKAXQ8NrcPbuq",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633790708] {
  "role": "assistant",
  "content": "4"
}
[1693633790708] [36m[OPENAI] Chat completion took 381.35816621780396ms[39m
[1693633790708] [36m[OPENAI] Global tokens per second: 20.635575732562938tps[39m
[1693633790708] [36m[OPENAI] Tokens per second: 2.6222068611187757tps[39m
[1693633790708] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790708] {
  "id": "chatcmpl-7uDnyRoLJ7VCLXMQJJF8YPx6gixlJ",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693633790708] {
  "role": "assistant",
  "content": "6"
}
[1693633790708] [36m[OPENAI] Chat completion took 359.2560839653015ms[39m
[1693633790708] [36m[OPENAI] Global tokens per second: 21.048287247214198tps[39m
[1693633790708] [36m[OPENAI] Tokens per second: 2.783529756719678tps[39m
[1693633790708] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790718] {
  "id": "chatcmpl-7uDnyYmY8h5HpWSXBufe15bEr8va5",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693633790718] {
  "role": "assistant",
  "content": "4"
}
[1693633790718] [36m[OPENAI] Chat completion took 400.58604097366333ms[39m
[1693633790718] [36m[OPENAI] Global tokens per second: 21.37279079325935tps[39m
[1693633790718] [36m[OPENAI] Tokens per second: 2.4963426023767648tps[39m
[1693633790718] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790719] {
  "id": "chatcmpl-7uDnyUk0RVJUdMjdpuM1cLF9m8z4k",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 96,
    "completion_tokens": 1,
    "total_tokens": 97
  }
}
[1693633790719] {
  "role": "assistant",
  "content": "5"
}
[1693633790719] [36m[OPENAI] Chat completion took 401.00712513923645ms[39m
[1693633790719] [36m[OPENAI] Global tokens per second: 21.774856203779784tps[39m
[1693633790719] [36m[OPENAI] Tokens per second: 2.4937212765303935tps[39m
[1693633790719] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790740] {
  "id": "chatcmpl-7uDny6xk6FUFGyIZeW88w8VVyhtqQ",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "8"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693633790740] {
  "role": "assistant",
  "content": "8"
}
[1693633790740] [36m[OPENAI] Chat completion took 413.5767080783844ms[39m
[1693633790740] [36m[OPENAI] Global tokens per second: 21.9959266802444tps[39m
[1693633790740] [36m[OPENAI] Tokens per second: 2.417931136998343tps[39m
[1693633790740] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790745] {
  "id": "chatcmpl-7uDnyOQUpZqQvyyzRTo3XCHZgGBte",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633790745] {
  "role": "assistant",
  "content": "5"
}
[1693633790745] [36m[OPENAI] Chat completion took 396.1982500553131ms[39m
[1693633790745] [36m[OPENAI] Global tokens per second: 22.357723577235774tps[39m
[1693633790745] [36m[OPENAI] Tokens per second: 2.5239889370041144tps[39m
[1693633790745] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790752] {
  "id": "chatcmpl-7uDnyXoGwlZIHMoorOL9XFbzzjBke",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 89,
    "completion_tokens": 2,
    "total_tokens": 91
  }
}
[1693633790752] {
  "role": "assistant",
  "content": "5."
}
[1693633790752] [36m[OPENAI] Chat completion took 463.2006251811981ms[39m
[1693633790752] [36m[OPENAI] Global tokens per second: 23.10498581272801tps[39m
[1693633790752] [36m[OPENAI] Tokens per second: 4.31778346416874tps[39m
[1693633790752] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790758] {
  "id": "chatcmpl-7uDnyV5wL8VHF5Wv9OoX8LMnp73B3",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633790758] {
  "role": "assistant",
  "content": "6"
}
[1693633790758] [36m[OPENAI] Chat completion took 431.4123749732971ms[39m
[1693633790758] [36m[OPENAI] Global tokens per second: 23.4532955923979tps[39m
[1693633790758] [36m[OPENAI] Tokens per second: 2.3179678145808786tps[39m
[1693633790758] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790762] {
  "id": "chatcmpl-7uDny48GgWrkT7EafxxWLYhBswmxc",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 2,
    "total_tokens": 101
  }
}
[1693633790762] {
  "role": "assistant",
  "content": "6."
}
[1693633790762] [36m[OPENAI] Chat completion took 435.99612498283386ms[39m
[1693633790762] [36m[OPENAI] Global tokens per second: 24.222850222042794tps[39m
[1693633790762] [36m[OPENAI] Tokens per second: 4.5871967327203755tps[39m
[1693633790762] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790813] [32m[OPENAI] Embedding created successfully.[39m
[1693633790819] [32m[OPENAI] Embedding created successfully.[39m
[1693633790831] [32m[OPENAI] Embedding created successfully.[39m
[1693633790884] {
  "id": "chatcmpl-7uDnySwIH45qliNuZvRFWOV2qxkPf",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693633790884] {
  "role": "assistant",
  "content": "2"
}
[1693633790884] [36m[OPENAI] Chat completion took 566.0861251354218ms[39m
[1693633790884] [36m[OPENAI] Global tokens per second: 23.47056560215467tps[39m
[1693633790884] [36m[OPENAI] Tokens per second: 1.7665156512373013tps[39m
[1693633790884] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790894] {
  "id": "chatcmpl-7uDnybfgap2QtwjQURBfPEM4iQM3b",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 92,
    "completion_tokens": 1,
    "total_tokens": 93
  }
}
[1693633790894] {
  "role": "assistant",
  "content": "6"
}
[1693633790894] [36m[OPENAI] Chat completion took 575.9184579849243ms[39m
[1693633790894] [36m[OPENAI] Global tokens per second: 23.763894212341892tps[39m
[1693633790894] [36m[OPENAI] Tokens per second: 1.7363569202120914tps[39m
[1693633790894] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790895] {
  "id": "chatcmpl-7uDnyOyID5UpVchSkAGT42pi5ykLm",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693633790895] {
  "role": "assistant",
  "content": "5"
}
[1693633790895] [36m[OPENAI] Chat completion took 576.6676251888275ms[39m
[1693633790895] [36m[OPENAI] Global tokens per second: 24.137931034482758tps[39m
[1693633790895] [36m[OPENAI] Tokens per second: 1.734101163859431tps[39m
[1693633790895] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790924] {
  "id": "chatcmpl-7uDnyoxMRCLsUGBPAR9e0Y58Aa2mF",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693633790924] {
  "role": "assistant",
  "content": "2"
}
[1693633790924] [36m[OPENAI] Chat completion took 797.180999994278ms[39m
[1693633790924] [36m[OPENAI] Global tokens per second: 24.251610458507013tps[39m
[1693633790924] [36m[OPENAI] Tokens per second: 1.254420263412171tps[39m
[1693633790924] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790933] [32m[OPENAI] Embedding created successfully.[39m
[1693633790938] {
  "id": "chatcmpl-7uDnyGi5vBeBjH49nTYy67Bau2kur",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693633790938] {
  "role": "assistant",
  "content": "5"
}
[1693633790938] [36m[OPENAI] Chat completion took 814.0909161567688ms[39m
[1693633790938] [36m[OPENAI] Global tokens per second: 24.500565397663024tps[39m
[1693633790938] [36m[OPENAI] Tokens per second: 1.2283640317728726tps[39m
[1693633790938] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790940] [32m[OPENAI] Embedding created successfully.[39m
[1693633790941] {
  "id": "chatcmpl-7uDnyN0PJz2lf2mWtsjKO0Y7UfqZL",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633790941] {
  "role": "assistant",
  "content": "5"
}
[1693633790941] [36m[OPENAI] Chat completion took 614.3745839595795ms[39m
[1693633790941] [36m[OPENAI] Global tokens per second: 24.849397590361445tps[39m
[1693633790941] [36m[OPENAI] Tokens per second: 1.6276714989658352tps[39m
[1693633790941] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790944] {
  "id": "chatcmpl-7uDnyzpsYPLMtVfybIDwGizyvRwan",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693633790944] {
  "role": "assistant",
  "content": "4"
}
[1693633790944] [36m[OPENAI] Chat completion took 822.6802921295166ms[39m
[1693633790944] [36m[OPENAI] Global tokens per second: 25.197442647611886tps[39m
[1693633790944] [36m[OPENAI] Tokens per second: 1.2155390247789812tps[39m
[1693633790944] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790946] {
  "id": "chatcmpl-7uDnynPT1myB4Z5OuGzWFUyn3oG22",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633790946] {
  "role": "assistant",
  "content": "4"
}
[1693633790946] [36m[OPENAI] Chat completion took 597.4579169750214ms[39m
[1693633790946] [36m[OPENAI] Global tokens per second: 25.554302893649005tps[39m
[1693633790946] [36m[OPENAI] Tokens per second: 1.6737580532250411tps[39m
[1693633790946] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790952] {
  "id": "chatcmpl-7uDnygsgMUjg3doEoxBj72RnLTvEm",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693633790952] {
  "role": "assistant",
  "content": "4"
}
[1693633790952] [36m[OPENAI] Chat completion took 634.7239999771118ms[39m
[1693633790952] [36m[OPENAI] Global tokens per second: 25.871766029246345tps[39m
[1693633790952] [36m[OPENAI] Tokens per second: 1.5754879286683032tps[39m
[1693633790952] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790957] [32m[OPENAI] Embedding created successfully.[39m
[1693633790960] {
  "id": "chatcmpl-7uDny2HUqkM9ieuvCGmH1TOnr3RYz",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 2,
    "total_tokens": 96
  }
}
[1693633790960] {
  "role": "assistant",
  "content": "3."
}
[1693633790960] [36m[OPENAI] Chat completion took 641.996416091919ms[39m
[1693633790960] [36m[OPENAI] Global tokens per second: 26.542056074766357tps[39m
[1693633790960] [36m[OPENAI] Tokens per second: 3.1152821882944073tps[39m
[1693633790960] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790991] {
  "id": "chatcmpl-7uDnyvogKSFpYidJ2z1KDon2YGSXf",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693633790991] {
  "role": "assistant",
  "content": "3"
}
[1693633790991] [36m[OPENAI] Chat completion took 870.6567499637604ms[39m
[1693633790991] [36m[OPENAI] Global tokens per second: 26.607538802660756tps[39m
[1693633790991] [36m[OPENAI] Tokens per second: 1.1485582579376123tps[39m
[1693633790991] [32m[OPENAI] Chat completion created successfully.[39m
[1693633790993] {
  "id": "chatcmpl-7uDnyJwbN0Igarzr0FJF4WK8C6vt4",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693633790993] {
  "role": "assistant",
  "content": "5"
}
[1693633790993] [36m[OPENAI] Chat completion took 643.6773328781128ms[39m
[1693633790993] [36m[OPENAI] Global tokens per second: 26.95716395864106tps[39m
[1693633790993] [36m[OPENAI] Tokens per second: 1.5535734271216923tps[39m
[1693633790993] [32m[OPENAI] Chat completion created successfully.[39m
[1693633791010] {
  "id": "chatcmpl-7uDnyacpagakmlysRb114sRWHWmrQ",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693633791011] {
  "role": "assistant",
  "content": "3"
}
[1693633791011] [36m[OPENAI] Chat completion took 722.1676669120789ms[39m
[1693633791011] [36m[OPENAI] Global tokens per second: 27.146001467351432tps[39m
[1693633791011] [36m[OPENAI] Tokens per second: 1.3847199837620896tps[39m
[1693633791011] [32m[OPENAI] Chat completion created successfully.[39m
[1693633791028] {
  "id": "chatcmpl-7uDnyLdscswixbmS09oMf11Qkb3yg",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693633791028] {
  "role": "assistant",
  "content": "1"
}
[1693633791028] [36m[OPENAI] Chat completion took 739.4976251125336ms[39m
[1693633791028] [36m[OPENAI] Global tokens per second: 27.342325920524974tps[39m
[1693633791028] [36m[OPENAI] Tokens per second: 1.3522693867310585tps[39m
[1693633791028] [32m[OPENAI] Chat completion created successfully.[39m
[1693633791037] [32m[OPENAI] Embedding created successfully.[39m
[1693633791041] {
  "id": "chatcmpl-7uDnyU8MvgtkOSBfiPf1NgSaUfK3v",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633791041] {
  "role": "assistant",
  "content": "3"
}
[1693633791041] [36m[OPENAI] Chat completion took 714.0603330135345ms[39m
[1693633791041] [36m[OPENAI] Global tokens per second: 27.576197387518146tps[39m
[1693633791041] [36m[OPENAI] Tokens per second: 1.400441886723661tps[39m
[1693633791041] [32m[OPENAI] Chat completion created successfully.[39m
[1693633791042] [32m[OPENAI] Embedding created successfully.[39m
[1693633791044] {
  "id": "chatcmpl-7uDnyly9bQuuV9V9pNg5erbpxGoUg",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "8"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1693633791044] {
  "role": "assistant",
  "content": "8"
}
[1693633791044] [36m[OPENAI] Chat completion took 717.419291973114ms[39m
[1693633791044] [36m[OPENAI] Global tokens per second: 27.908662558898154tps[39m
[1693633791044] [36m[OPENAI] Tokens per second: 1.3938850142288561tps[39m
[1693633791044] [32m[OPENAI] Chat completion created successfully.[39m
[1693633791068] {
  "id": "chatcmpl-7uDny6c8spvPBj0EsEQaTybDcWhg6",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693633791068] {
  "role": "assistant",
  "content": "2"
}
[1693633791068] [36m[OPENAI] Chat completion took 778.8611249923706ms[39m
[1693633791068] [36m[OPENAI] Global tokens per second: 28.02730865971973tps[39m
[1693633791068] [36m[OPENAI] Tokens per second: 1.2839259373868424tps[39m
[1693633791068] [32m[OPENAI] Chat completion created successfully.[39m
[1693633791075] {
  "id": "chatcmpl-7uDny4D1m5tZa1WgPU0KRU47cPtym",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 2,
    "total_tokens": 93
  }
}
[1693633791075] {
  "role": "assistant",
  "content": "6."
}
[1693633791075] [36m[OPENAI] Chat completion took 786.8498330116272ms[39m
[1693633791075] [36m[OPENAI] Global tokens per second: 28.67383512544803tps[39m
[1693633791075] [36m[OPENAI] Tokens per second: 2.5417810566790147tps[39m
[1693633791075] [32m[OPENAI] Chat completion created successfully.[39m
[1693633791154] {
  "id": "chatcmpl-7uDnyD1zX17TZIM0r1GqQElymRFDm",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 90,
    "completion_tokens": 1,
    "total_tokens": 91
  }
}
[1693633791154] {
  "role": "assistant",
  "content": "7"
}
[1693633791154] [36m[OPENAI] Chat completion took 836.3592500686646ms[39m
[1693633791154] [36m[OPENAI] Global tokens per second: 28.232833739979085tps[39m
[1693633791154] [36m[OPENAI] Tokens per second: 1.1956584445235714tps[39m
[1693633791154] [32m[OPENAI] Chat completion created successfully.[39m
[1693633791287] [32m[OPENAI] Embedding created successfully.[39m
[1693633791305] {
  "id": "chatcmpl-7uDnzG4xbnVX2DCWTHb3YG2mqBAyJ",
  "object": "chat.completion",
  "created": 1693633791,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693633791305] {
  "role": "assistant",
  "content": "3"
}
[1693633791305] [36m[OPENAI] Chat completion took 986.8022918701172ms[39m
[1693633791305] [36m[OPENAI] Global tokens per second: 27.1523178807947tps[39m
[1693633791305] [36m[OPENAI] Tokens per second: 1.013374217144218tps[39m
[1693633791305] [32m[OPENAI] Chat completion created successfully.[39m
[1693633791319] {
  "id": "chatcmpl-7uDnygsHlC4ze9QSLgK2RbwJlfDSX",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693633791320] {
  "role": "assistant",
  "content": "3"
}
[1693633791320] [36m[OPENAI] Chat completion took 999.2639579772949ms[39m
[1693633791320] [36m[OPENAI] Global tokens per second: 27.347611202635914tps[39m
[1693633791320] [36m[OPENAI] Tokens per second: 1.0007365841796145tps[39m
[1693633791320] [32m[OPENAI] Chat completion created successfully.[39m
[1693633791454] {
  "id": "chatcmpl-7uDnyxZbr0XmoVLz4Y8GnMkmfeodF",
  "object": "chat.completion",
  "created": 1693633790,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 2,
    "total_tokens": 96
  }
}
[1693633791454] {
  "role": "assistant",
  "content": "1."
}
[1693633791454] [36m[OPENAI] Chat completion took 1164.3948330879211ms[39m
[1693633791454] [36m[OPENAI] Global tokens per second: 26.82234143262859tps[39m
[1693633791454] [36m[OPENAI] Tokens per second: 1.717630431849386tps[39m
[1693633791454] [32m[OPENAI] Chat completion created successfully.[39m
[1693633796045] [Main] WebSocket connection established
[1693633796072] [Character] Getting character: A5
[1693633796073] --- Observations received -- 
[1693633796073] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 42.12, Y: 5.77.",
  "time": 0
}
[1693633796073] [Character] Getting character: A5
[1693633796073] --- Observations received -- 
[1693633796074] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Small) at X: 41.33658, Y: 13.99647.",
  "time": 0
}
[1693633796074] [Character] Getting character: A5
[1693633796074] [Character] Getting character: A2
[1693633796074] --- Observations received -- 
[1693633796074] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Small) at X: 62.25, Y: 15.1.",
  "time": 0
}
[1693633796074] [Character] Getting character: A2
[1693633796075] --- Observations received -- 
[1693633796075] {
  "observerId": "A2",
  "observation": "George Brown sees Tree at X: 67.61, Y: 9.619999.",
  "time": 0
}
[1693633796075] [Character] Getting character: A2
[1693633796075] --- Observations received -- 
[1693633796076] {
  "observerId": "A2",
  "observation": "George Brown sees Iron Ore Deposit (Large) at X: 65.22, Y: 18.37.",
  "time": 0
}
[1693633796076] [Character] Getting character: A2
[1693633796076] [Character] Getting character: A4
[1693633796077] --- Observations received -- 
[1693633796077] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Medium) at X: 53.76, Y: 21.7.",
  "time": 0
}
[1693633796077] [Character] Getting character: A4
[1693633796077] --- Observations received -- 
[1693633796077] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Medium) at X: 52.01, Y: 23.05.",
  "time": 0
}
[1693633796077] [Character] Getting character: A4
[1693633796077] --- Observations received -- 
[1693633796077] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Large) at X: 50.38, Y: 26.11.",
  "time": 0
}
[1693633796077] [Character] Getting character: A4
[1693633796078] --- Observations received -- 
[1693633796078] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Large) at X: 53.13, Y: 26.69.",
  "time": 0
}
[1693633796078] [Character] Getting character: A4
[1693633796078] --- Observations received -- 
[1693633796078] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Medium) at X: 54.06, Y: 24.46.",
  "time": 0
}
[1693633796078] [Character] Getting character: A4
[1693633796079] --- Observations received -- 
[1693633796079] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Diamond Ore Deposit (Large) at X: 58.32, Y: 26.61.",
  "time": 0
}
[1693633796079] [Character] Getting character: A4
[1693633796079] --- Observations received -- 
[1693633796079] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Small) at X: 57.1, Y: 24.45.",
  "time": 0
}
[1693633796080] [Character] Getting character: A4
[1693633796080] --- Observations received -- 
[1693633796080] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Large) at X: 55.12, Y: 28.15.",
  "time": 0
}
[1693633796080] [Character] Getting character: A4
[1693633796082] --- Observations received -- 
[1693633796082] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Diamond Ore Deposit (Small) at X: 58.32, Y: 22.87.",
  "time": 0
}
[1693633796082] [Character] Getting character: A4
[1693633796082] --- Observations received -- 
[1693633796082] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Diamond Ore Deposit (Large) at X: 60.38, Y: 24.68.",
  "time": 0
}
[1693633796082] [Character] Getting character: A4
[1693633796082] --- Observations received -- 
[1693633796082] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Diamond Ore Deposit (Large) at X: 61.07, Y: 27.32.",
  "time": 0
}
[1693633796082] [Character] Getting character: A4
[1693633796135] [33m[OPENAI] Creating embedding...[39m
[1693633796140] [33m[OPENAI] Creating embedding...[39m
[1693633796142] [33m[OPENAI] Creating embedding...[39m
[1693633796167] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633796167] [33m[OPENAI] Creating embedding...[39m
[1693633796175] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633796175] [33m[OPENAI] Creating embedding...[39m
[1693633796175] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633796176] [33m[OPENAI] Creating embedding...[39m
[1693633796176] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633796176] [33m[OPENAI] Creating embedding...[39m
[1693633796190] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633796190] [33m[OPENAI] Creating embedding...[39m
[1693633796190] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633796190] [33m[OPENAI] Creating embedding...[39m
[1693633796202] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633796202] [33m[OPENAI] Creating embedding...[39m
[1693633796202] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633796202] [33m[OPENAI] Creating embedding...[39m
[1693633796202] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633796202] [33m[OPENAI] Creating embedding...[39m
[1693633796204] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633796204] [33m[OPENAI] Creating embedding...[39m
[1693633796204] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633796204] [33m[OPENAI] Creating embedding...[39m
[1693633796204] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633796204] [33m[OPENAI] Creating embedding...[39m
[1693633796204] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633796204] [33m[OPENAI] Creating embedding...[39m
[1693633796204] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633796204] [33m[OPENAI] Creating embedding...[39m
[1693633796207] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633796207] [33m[OPENAI] Creating embedding...[39m
[1693633796207] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633796207] [33m[OPENAI] Creating embedding...[39m
[1693633796326] [32m[OPENAI] Embedding created successfully.[39m
[1693633796380] [32m[OPENAI] Embedding created successfully.[39m
[1693633796386] [32m[OPENAI] Embedding created successfully.[39m
[1693633796389] [32m[OPENAI] Embedding created successfully.[39m
[1693633796391] [32m[OPENAI] Embedding created successfully.[39m
[1693633796391] [32m[OPENAI] Embedding created successfully.[39m
[1693633796397] [32m[OPENAI] Embedding created successfully.[39m
[1693633796397] [32m[OPENAI] Embedding created successfully.[39m
[1693633796406] [32m[OPENAI] Embedding created successfully.[39m
[1693633796429] [32m[OPENAI] Embedding created successfully.[39m
[1693633796430] [32m[OPENAI] Embedding created successfully.[39m
[1693633796444] [32m[OPENAI] Embedding created successfully.[39m
[1693633796448] [32m[OPENAI] Embedding created successfully.[39m
[1693633796448] [32m[OPENAI] Embedding created successfully.[39m
[1693633796449] [32m[OPENAI] Embedding created successfully.[39m
[1693633796469] {
  "id": "chatcmpl-7uDo4TWelJpzg5UoawjS3uTyBbVye",
  "object": "chat.completion",
  "created": 1693633796,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633796469] {
  "role": "assistant",
  "content": "1"
}
[1693633796469] [36m[OPENAI] Chat completion took 293.44487500190735ms[39m
[1693633796469] [36m[OPENAI] Global tokens per second: 10.508308895405671tps[39m
[1693633796469] [36m[OPENAI] Tokens per second: 3.4077950756287705tps[39m
[1693633796469] [32m[OPENAI] Chat completion created successfully.[39m
[1693633796470] [32m[OPENAI] Embedding created successfully.[39m
[1693633796471] [32m[OPENAI] Embedding created successfully.[39m
[1693633796475] {
  "id": "chatcmpl-7uDo49MrPgKEEYoRklcu1zuSJ4SCR",
  "object": "chat.completion",
  "created": 1693633796,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633796475] {
  "role": "assistant",
  "content": "4"
}
[1693633796475] [36m[OPENAI] Chat completion took 299.7797501087189ms[39m
[1693633796475] [36m[OPENAI] Global tokens per second: 10.622710622710624tps[39m
[1693633796475] [36m[OPENAI] Tokens per second: 3.3357823523347974tps[39m
[1693633796475] [32m[OPENAI] Chat completion created successfully.[39m
[1693633796503] {
  "id": "chatcmpl-7uDo4VDBqq4jRlrQY83yVewj7LPWI",
  "object": "chat.completion",
  "created": 1693633796,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633796503] {
  "role": "assistant",
  "content": "1"
}
[1693633796503] [36m[OPENAI] Chat completion took 300.64304208755493ms[39m
[1693633796503] [36m[OPENAI] Global tokens per second: 10.70820150888294tps[39m
[1693633796503] [36m[OPENAI] Tokens per second: 3.32620370342306tps[39m
[1693633796503] [32m[OPENAI] Chat completion created successfully.[39m
[1693633796505] {
  "id": "chatcmpl-7uDo4F7YjQhLwpX8iGxtH6RvOUaNa",
  "object": "chat.completion",
  "created": 1693633796,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693633796505] {
  "role": "assistant",
  "content": "1"
}
[1693633796505] [36m[OPENAI] Chat completion took 314.5686671733856ms[39m
[1693633796505] [36m[OPENAI] Global tokens per second: 10.827250608272506tps[39m
[1693633796505] [36m[OPENAI] Tokens per second: 3.1789561528351924tps[39m
[1693633796505] [32m[OPENAI] Chat completion created successfully.[39m
[1693633796506] {
  "id": "chatcmpl-7uDo4SR86SoaVqBAGM7hkLSzUjwc9",
  "object": "chat.completion",
  "created": 1693633796,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633796506] {
  "role": "assistant",
  "content": "3"
}
[1693633796506] [36m[OPENAI] Chat completion took 301.86183309555054ms[39m
[1693633796506] [36m[OPENAI] Global tokens per second: 10.947573287921177tps[39m
[1693633796506] [36m[OPENAI] Tokens per second: 3.3127738930925483tps[39m
[1693633796506] [32m[OPENAI] Chat completion created successfully.[39m
[1693633796523] {
  "id": "chatcmpl-7uDo4bmphBVFMzYu9UGO3lo1MPRsr",
  "object": "chat.completion",
  "created": 1693633796,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633796523] {
  "role": "assistant",
  "content": "1"
}
[1693633796523] [36m[OPENAI] Chat completion took 321.04587507247925ms[39m
[1693633796523] [36m[OPENAI] Global tokens per second: 11.046370478271426tps[39m
[1693633796523] [36m[OPENAI] Tokens per second: 3.1148196492923024tps[39m
[1693633796524] [32m[OPENAI] Chat completion created successfully.[39m
[1693633796549] {
  "id": "chatcmpl-7uDo4XbuiU8JbB3KXS6b9IKgt722s",
  "object": "chat.completion",
  "created": 1693633796,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633796549] {
  "role": "assistant",
  "content": "3"
}
[1693633796549] [36m[OPENAI] Chat completion took 374.189416885376ms[39m
[1693633796549] [36m[OPENAI] Global tokens per second: 11.132623426911907tps[39m
[1693633796549] [36m[OPENAI] Tokens per second: 2.6724432997695553tps[39m
[1693633796549] [32m[OPENAI] Chat completion created successfully.[39m
[1693633796550] {
  "id": "chatcmpl-7uDo4x2cw2RTUL4TOj8PPWmkHcNJv",
  "object": "chat.completion",
  "created": 1693633796,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693633796550] {
  "role": "assistant",
  "content": "5"
}
[1693633796550] [36m[OPENAI] Chat completion took 343.2603750228882ms[39m
[1693633796550] [36m[OPENAI] Global tokens per second: 11.252268602540834tps[39m
[1693633796550] [36m[OPENAI] Tokens per second: 2.9132404226188973tps[39m
[1693633796550] [32m[OPENAI] Chat completion created successfully.[39m
[1693633796552] {
  "id": "chatcmpl-7uDo4qLKQH3PlE2HCOUDFAwy7TDfj",
  "object": "chat.completion",
  "created": 1693633796,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633796552] {
  "role": "assistant",
  "content": "2"
}
[1693633796552] [36m[OPENAI] Chat completion took 385.1096661090851ms[39m
[1693633796552] [36m[OPENAI] Global tokens per second: 11.370509253659128tps[39m
[1693633796552] [36m[OPENAI] Tokens per second: 2.596662945657518tps[39m
[1693633796552] [32m[OPENAI] Chat completion created successfully.[39m
[1693633796556] {
  "id": "chatcmpl-7uDo4MJpSF7tJnArvhxmYBPvy623G",
  "object": "chat.completion",
  "created": 1693633796,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633796557] {
  "role": "assistant",
  "content": "1"
}
[1693633796557] [36m[OPENAI] Chat completion took 366.1563329696655ms[39m
[1693633796557] [36m[OPENAI] Global tokens per second: 11.484526112185687tps[39m
[1693633796557] [36m[OPENAI] Tokens per second: 2.7310738882750543tps[39m
[1693633796557] [32m[OPENAI] Chat completion created successfully.[39m
[1693633796560] {
  "id": "chatcmpl-7uDo4CLbhnqjAYI1wWWHDTJKQMo1g",
  "object": "chat.completion",
  "created": 1693633796,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 2,
    "total_tokens": 108
  }
}
[1693633796560] {
  "role": "assistant",
  "content": "2."
}
[1693633796560] [36m[OPENAI] Chat completion took 355.77016592025757ms[39m
[1693633796560] [36m[OPENAI] Global tokens per second: 11.722054380664652tps[39m
[1693633796560] [36m[OPENAI] Tokens per second: 5.621606845044676tps[39m
[1693633796560] [32m[OPENAI] Chat completion created successfully.[39m
[1693633796566] [32m[OPENAI] Embedding created successfully.[39m
[1693633796582] {
  "id": "chatcmpl-7uDo4lyQSL7YG9bq3staGTu1u7PC7",
  "object": "chat.completion",
  "created": 1693633796,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633796582] {
  "role": "assistant",
  "content": "2"
}
[1693633796582] [36m[OPENAI] Chat completion took 377.66129088401794ms[39m
[1693633796582] [36m[OPENAI] Global tokens per second: 11.811498131854886tps[39m
[1693633796582] [36m[OPENAI] Tokens per second: 2.6478752896788302tps[39m
[1693633796582] [32m[OPENAI] Chat completion created successfully.[39m
[1693633796603] {
  "id": "chatcmpl-7uDo45NZssNyCLApooGHijbtfK7Jk",
  "object": "chat.completion",
  "created": 1693633796,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633796603] {
  "role": "assistant",
  "content": "3"
}
[1693633796603] [36m[OPENAI] Chat completion took 398.7300410270691ms[39m
[1693633796603] [36m[OPENAI] Global tokens per second: 11.90189949507093tps[39m
[1693633796603] [36m[OPENAI] Tokens per second: 2.507962523777113tps[39m
[1693633796603] [32m[OPENAI] Chat completion created successfully.[39m
[1693633796604] {
  "id": "chatcmpl-7uDo4SO1Hu9wdCKFN8BHalkUQ1MYK",
  "object": "chat.completion",
  "created": 1693633796,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633796604] {
  "role": "assistant",
  "content": "3"
}
[1693633796604] [36m[OPENAI] Chat completion took 396.8382079601288ms[39m
[1693633796604] [36m[OPENAI] Global tokens per second: 12.02067556196658tps[39m
[1693633796604] [36m[OPENAI] Tokens per second: 2.51991864679641tps[39m
[1693633796604] [32m[OPENAI] Chat completion created successfully.[39m
[1693633796643] [32m[OPENAI] Embedding created successfully.[39m
[1693633796645] {
  "id": "chatcmpl-7uDo4nIyhxkWwVn9nrYH1QZKZ6oHl",
  "object": "chat.completion",
  "created": 1693633796,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633796645] {
  "role": "assistant",
  "content": "2"
}
[1693633796645] [36m[OPENAI] Chat completion took 442.7919578552246ms[39m
[1693633796645] [36m[OPENAI] Global tokens per second: 12.08133971291866tps[39m
[1693633796645] [36m[OPENAI] Tokens per second: 2.258396933954614tps[39m
[1693633796645] [32m[OPENAI] Chat completion created successfully.[39m
[1693633796772] {
  "id": "chatcmpl-7uDo42Asoe5Y4qFVuHUHXpRP9uMYc",
  "object": "chat.completion",
  "created": 1693633796,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633796772] {
  "role": "assistant",
  "content": "2"
}
[1693633796772] [36m[OPENAI] Chat completion took 567.7565841674805ms[39m
[1693633796772] [36m[OPENAI] Global tokens per second: 12.018381053375752tps[39m
[1693633796772] [36m[OPENAI] Tokens per second: 1.7613181914329217tps[39m
[1693633796772] [32m[OPENAI] Chat completion created successfully.[39m
[1693633796844] [33m[OPENAI] Creating embedding...[39m
[1693633797075] [33m[OPENAI] Creating embedding...[39m
[1693633797113] [32m[OPENAI] Embedding created successfully.[39m
[1693633797187] [33m[OPENAI] Creating embedding...[39m
[1693633797220] [32m[OPENAI] Embedding created successfully.[39m
[1693633797389] [32m[OPENAI] Embedding created successfully.[39m
[1693633797548] [33m[OPENAI] Creating embedding...[39m
[1693633797679] [33m[OPENAI] Creating embedding...[39m
[1693633797701] [32m[OPENAI] Embedding created successfully.[39m
[1693633797824] [33m[OPENAI] Creating embedding...[39m
[1693633797942] [32m[OPENAI] Embedding created successfully.[39m
[1693633797986] [32m[OPENAI] Embedding created successfully.[39m
[1693633798121] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633798220] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633798344] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633804964] {
  "id": "chatcmpl-7uDo6e7D8qYrFEAYQC8B74qVuA3AR",
  "object": "chat.completion",
  "created": 1693633798,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "[\n  {\n    \"task\": \"eat\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"move_to: Copper Ore Deposit\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Carry out your daily duties\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Catch up with other villagers\",\n    \"priority\": 4\n  },\n  {\n    \"task\": \"Maintain a healthy lifestyle\",\n    \"priority\": 5\n  }\n]"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 1286,
    "completion_tokens": 110,
    "total_tokens": 1396
  }
}
[1693633804965] {
  "role": "assistant",
  "content": "[\n  {\n    \"task\": \"eat\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"move_to: Copper Ore Deposit\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Carry out your daily duties\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Catch up with other villagers\",\n    \"priority\": 4\n  },\n  {\n    \"task\": \"Maintain a healthy lifestyle\",\n    \"priority\": 5\n  }\n]"
}
[1693633804965] [36m[OPENAI] Chat completion took 6842.194540977478ms[39m
[1693633804965] [36m[OPENAI] Global tokens per second: 12.709832134292567tps[39m
[1693633804965] [36m[OPENAI] Tokens per second: 16.076713303197803tps[39m
[1693633804965] [32m[OPENAI] Chat completion created successfully.[39m
[1693633804965] [Character] Getting character: A4
[1693633804999] [33m[OPENAI] Creating embedding...[39m
[1693633805787] [32m[OPENAI] Embedding created successfully.[39m
[1693633806301] [33m[OPENAI] Creating embedding...[39m
[1693633806432] [32m[OPENAI] Embedding created successfully.[39m
[1693633806835] [33m[OPENAI] Creating embedding...[39m
[1693633806963] [32m[OPENAI] Embedding created successfully.[39m
[1693633807401] [33m[OPENAI] Creating embedding...[39m
[1693633807533] [32m[OPENAI] Embedding created successfully.[39m
[1693633807930] [33m[OPENAI] Creating embedding...[39m
[1693633808070] [32m[OPENAI] Embedding created successfully.[39m
[1693633808451] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633809386] {
  "id": "chatcmpl-7uDo6TVIfC9HQlrU24igdGbW5GoA0",
  "object": "chat.completion",
  "created": 1693633798,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "[\n  {\n    \"task\": \"Eat the berries to stave off hunger\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Collect resources from the closest Stone Ore Deposit\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Chop down a tree for firewood\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Carry out your daily duties\",\n    \"priority\": 4\n  },\n  {\n    \"task\": \"Catch up with fellow explorers in the evening\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Keep an eye out for new trees or stones to log onto your map\",\n    \"priority\": 6\n  },\n  {\n    \"task\": \"Maintain a healthy lifestyle by ensuring to rest after a day's work\",\n    \"priority\": 7\n  }\n]"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 958,
    "completion_tokens": 188,
    "total_tokens": 1146
  }
}
[1693633809387] {
  "role": "assistant",
  "content": "[\n  {\n    \"task\": \"Eat the berries to stave off hunger\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Collect resources from the closest Stone Ore Deposit\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Chop down a tree for firewood\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Carry out your daily duties\",\n    \"priority\": 4\n  },\n  {\n    \"task\": \"Catch up with fellow explorers in the evening\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Keep an eye out for new trees or stones to log onto your map\",\n    \"priority\": 6\n  },\n  {\n    \"task\": \"Maintain a healthy lifestyle by ensuring to rest after a day's work\",\n    \"priority\": 7\n  }\n]"
}
[1693633809387] [36m[OPENAI] Chat completion took 11041.179874897003ms[39m
[1693633809387] [36m[OPENAI] Global tokens per second: 18.955549237039143tps[39m
[1693633809387] [36m[OPENAI] Tokens per second: 17.02716576762171tps[39m
[1693633809387] [32m[OPENAI] Chat completion created successfully.[39m
[1693633809389] [Character] Getting character: A5
[1693633809447] [33m[OPENAI] Creating embedding...[39m
[1693633809606] [32m[OPENAI] Embedding created successfully.[39m
[1693633809999] [33m[OPENAI] Creating embedding...[39m
[1693633810139] [32m[OPENAI] Embedding created successfully.[39m
[1693633810510] [33m[OPENAI] Creating embedding...[39m
[1693633810602] {
  "id": "chatcmpl-7uDoGBq2B8qsYtrVRp5m5ucvQYMw3",
  "object": "chat.completion",
  "created": 1693633808,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "eat",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"foodId\": \"berries\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1607,
    "completion_tokens": 25,
    "total_tokens": 1632
  }
}
[1693633810602] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "eat",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"foodId\": \"berries\"\n}"
  }
}
[1693633810602] [36m[OPENAI] Chat completion took 2149.9505829811096ms[39m
[1693633810602] [36m[OPENAI] Global tokens per second: 19.043778285611864tps[39m
[1693633810602] [36m[OPENAI] Tokens per second: 11.628174246375067tps[39m
[1693633810602] [32m[OPENAI] Chat completion created successfully.[39m
[1693633810631] [Character] Getting character: A4
[1693633810652] [32m[OPENAI] Embedding created successfully.[39m
[1693633810692] [33m[OPENAI] Creating embedding...[39m
[1693633810909] [32m[OPENAI] Embedding created successfully.[39m
[1693633811028] [33m[OPENAI] Creating embedding...[39m
[1693633811261] [32m[OPENAI] Embedding created successfully.[39m
[1693633811267] [33m[OPENAI] Creating embedding...[39m
[1693633811447] [32m[OPENAI] Embedding created successfully.[39m
[1693633811587] [33m[OPENAI] Creating embedding...[39m
[1693633811745] [32m[OPENAI] Embedding created successfully.[39m
[1693633811829] [33m[OPENAI] Creating embedding...[39m
[1693633811982] [32m[OPENAI] Embedding created successfully.[39m
[1693633812041] [33m[OPENAI] Creating embedding...[39m
[1693633812237] [33m[OPENAI] Creating embedding...[39m
[1693633812248] [32m[OPENAI] Embedding created successfully.[39m
[1693633812414] [32m[OPENAI] Embedding created successfully.[39m
[1693633812851] [33m[OPENAI] Creating embedding...[39m
[1693633813008] [32m[OPENAI] Embedding created successfully.[39m
[1693633813151] [33m[OPENAI] Creating embedding...[39m
[1693633813302] [32m[OPENAI] Embedding created successfully.[39m
[1693633813352] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633813636] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633815794] {
  "id": "chatcmpl-7uDoLfFynJX1N326f59Dku0G7A0sl",
  "object": "chat.completion",
  "created": 1693633813,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "eat>xpath.Bounds",
          "arguments": "{ \"characterId\": \"A5\", \"foodId\": \"berries\" }"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1355,
    "completion_tokens": 25,
    "total_tokens": 1380
  }
}
[1693633815794] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "eat>xpath.Bounds",
    "arguments": "{ \"characterId\": \"A5\", \"foodId\": \"berries\" }"
  }
}
[1693633815794] [36m[OPENAI] Chat completion took 2157.1875ms[39m
[1693633815794] [36m[OPENAI] Global tokens per second: 16.358282743829292tps[39m
[1693633815794] [36m[OPENAI] Tokens per second: 11.589164131537013tps[39m
[1693633815794] [32m[OPENAI] Chat completion created successfully.[39m
[1693633815810] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633817290] {
  "id": "chatcmpl-7uDoLKLwNQliwahlvumPqzT4zt60G",
  "object": "chat.completion",
  "created": 1693633813,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 55.12,\n  \"y\": 28.15\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1519,
    "completion_tokens": 35,
    "total_tokens": 1554
  }
}
[1693633817291] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 55.12,\n  \"y\": 28.15\n}"
  }
}
[1693633817291] [36m[OPENAI] Chat completion took 3937.0268330574036ms[39m
[1693633817291] [36m[OPENAI] Global tokens per second: 16.72067848031442tps[39m
[1693633817291] [36m[OPENAI] Tokens per second: 8.889957189552558tps[39m
[1693633817291] [32m[OPENAI] Chat completion created successfully.[39m
[1693633817307] --- Observations received -- 
[1693633817307] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 55.12, Y: 28.15.",
  "time": 20.8872414
}
[1693633817307] [Character] Getting character: A4
[1693633817403] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633817404] [33m[OPENAI] Creating embedding...[39m
[1693633817557] --- Observations received -- 
[1693633817557] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees DiamondOreLarge (1) at X: 61.07, Y: 27.32",
  "time": 21.14013
}
[1693633817557] [Character] Getting character: A4
[1693633817607] {
  "id": "chatcmpl-7uDoNXCKXUD4u8hFYa9xli2RkgZOg",
  "object": "chat.completion",
  "created": 1693633815,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "eat",
          "arguments": "{\n  \"characterId\": \"A5\",\n  \"foodId\": \"berries\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1355,
    "completion_tokens": 25,
    "total_tokens": 1380
  }
}
[1693633817607] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "eat",
    "arguments": "{\n  \"characterId\": \"A5\",\n  \"foodId\": \"berries\"\n}"
  }
}
[1693633817607] [36m[OPENAI] Chat completion took 1796.645625114441ms[39m
[1693633817607] [36m[OPENAI] Global tokens per second: 17.393083691426234tps[39m
[1693633817607] [36m[OPENAI] Tokens per second: 13.91481973436335tps[39m
[1693633817607] [32m[OPENAI] Chat completion created successfully.[39m
[1693633817609] [32m[OPENAI] Embedding created successfully.[39m
[1693633817617] [Character] Getting character: A5
[1693633817621] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633817621] [33m[OPENAI] Creating embedding...[39m
[1693633817648] [33m[OPENAI] Creating embedding...[39m
[1693633817753] {
  "id": "chatcmpl-7uDoPBn7hniCbq2EiPC9U9C7mBVF5",
  "object": "chat.completion",
  "created": 1693633817,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633817753] {
  "role": "assistant",
  "content": "1"
}
[1693633817753] [36m[OPENAI] Chat completion took 349.18545794487ms[39m
[1693633817753] [36m[OPENAI] Global tokens per second: 17.340844305687526tps[39m
[1693633817753] [36m[OPENAI] Tokens per second: 2.863807690862893tps[39m
[1693633817753] [32m[OPENAI] Chat completion created successfully.[39m
[1693633817779] [32m[OPENAI] Embedding created successfully.[39m
[1693633817876] [32m[OPENAI] Embedding created successfully.[39m
[1693633817887] {
  "id": "chatcmpl-7uDoPOXQEnII2bPF3yOeaPZeBsHju",
  "object": "chat.completion",
  "created": 1693633817,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633817887] {
  "role": "assistant",
  "content": "1"
}
[1693633817887] [36m[OPENAI] Chat completion took 265.90179109573364ms[39m
[1693633817887] [36m[OPENAI] Global tokens per second: 17.29612863995676tps[39m
[1693633817887] [36m[OPENAI] Tokens per second: 3.7607870028974952tps[39m
[1693633817887] [32m[OPENAI] Chat completion created successfully.[39m
[1693633817997] --- Observations received -- 
[1693633818002] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees CopperOreMedium (2) at X: 53.76, Y: 21.7",
  "time": 21.5802441
}
[1693633818002] [Character] Getting character: A4
[1693633818070] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633818070] [33m[OPENAI] Creating embedding...[39m
[1693633818087] --- Observations received -- 
[1693633818087] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 55.12, Y: 28.15.",
  "time": 21.6599922
}
[1693633818087] [Character] Getting character: A4
[1693633818087] [Character] Getting character: A4
[1693633818177] [33m[OPENAI] Creating embedding...[39m
[1693633818239] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633818239] [33m[OPENAI] Creating embedding...[39m
[1693633818282] [32m[OPENAI] Embedding created successfully.[39m
[1693633818305] [33m[OPENAI] Creating embedding...[39m
[1693633818345] [32m[OPENAI] Embedding created successfully.[39m
[1693633818452] {
  "id": "chatcmpl-7uDoQufQFhH22QbrsJUBYYYv7FBiI",
  "object": "chat.completion",
  "created": 1693633818,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633818452] {
  "role": "assistant",
  "content": "3"
}
[1693633818452] [36m[OPENAI] Chat completion took 381.7878749370575ms[39m
[1693633818452] [36m[OPENAI] Global tokens per second: 17.005336957602676tps[39m
[1693633818452] [36m[OPENAI] Tokens per second: 2.619255522886531tps[39m
[1693633818452] [32m[OPENAI] Chat completion created successfully.[39m
[1693633818460] [32m[OPENAI] Embedding created successfully.[39m
[1693633818477] [32m[OPENAI] Embedding created successfully.[39m
[1693633818567] {
  "id": "chatcmpl-7uDoQU8zCQhUJAYcC7HJnB85SXwB6",
  "object": "chat.completion",
  "created": 1693633818,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633818567] {
  "role": "assistant",
  "content": "1"
}
[1693633818567] [36m[OPENAI] Chat completion took 327.24558305740356ms[39m
[1693633818567] [36m[OPENAI] Global tokens per second: 16.973779803183408tps[39m
[1693633818567] [36m[OPENAI] Tokens per second: 3.0558090063650627tps[39m
[1693633818567] [32m[OPENAI] Chat completion created successfully.[39m
[1693633818768] [33m[OPENAI] Creating embedding...[39m
[1693633818864] [33m[OPENAI] Creating embedding...[39m
[1693633818892] [32m[OPENAI] Embedding created successfully.[39m
[1693633818988] [32m[OPENAI] Embedding created successfully.[39m
[1693633819272] [33m[OPENAI] Creating embedding...[39m
[1693633819340] [33m[OPENAI] Creating embedding...[39m
[1693633819434] [32m[OPENAI] Embedding created successfully.[39m
[1693633819494] [32m[OPENAI] Embedding created successfully.[39m
[1693633819823] [33m[OPENAI] Creating embedding...[39m
[1693633819861] [33m[OPENAI] Creating embedding...[39m
[1693633820130] [32m[OPENAI] Embedding created successfully.[39m
[1693633820148] [32m[OPENAI] Embedding created successfully.[39m
[1693633820365] {
  "id": "chatcmpl-7uDo6nz2cQeuF6Bg33hI9BElz1iBu",
  "object": "chat.completion",
  "created": 1693633798,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "[\n  {\n    \"task\": \"Find Food\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Eat\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Harvest Coal from deposit at X: 62.25, Y: 15.1\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Harvest Iron from deposit at X: 65.22, Y: 18.37\",\n    \"priority\": 4\n  },\n  {\n    \"task\": \"Carry out your daily duties\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Drink water to stay healthy\",\n    \"priority\": 6\n  },\n  {\n    \"task\": \"Catch up with other villagers\",\n    \"priority\": 7\n  },\n  {\n    \"task\": \"Maintain weapons and tools\",\n    \"priority\": 8\n  },\n  {\n    \"task\": \"Chop trees at X: 61.49, Y: 9.35 for firewood\",\n    \"priority\": 9\n  },\n  {\n    \"task\": \"Maintain a healthy lifestyle\",\n    \"priority\": 10\n  }\n]"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 971,
    "completion_tokens": 259,
    "total_tokens": 1230
  }
}
[1693633820368] {
  "role": "assistant",
  "content": "[\n  {\n    \"task\": \"Find Food\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Eat\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Harvest Coal from deposit at X: 62.25, Y: 15.1\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Harvest Iron from deposit at X: 65.22, Y: 18.37\",\n    \"priority\": 4\n  },\n  {\n    \"task\": \"Carry out your daily duties\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Drink water to stay healthy\",\n    \"priority\": 6\n  },\n  {\n    \"task\": \"Catch up with other villagers\",\n    \"priority\": 7\n  },\n  {\n    \"task\": \"Maintain weapons and tools\",\n    \"priority\": 8\n  },\n  {\n    \"task\": \"Chop trees at X: 61.49, Y: 9.35 for firewood\",\n    \"priority\": 9\n  },\n  {\n    \"task\": \"Maintain a healthy lifestyle\",\n    \"priority\": 10\n  }\n]"
}
[1693633820368] [36m[OPENAI] Chat completion took 22144.29337501526ms[39m
[1693633820368] [36m[OPENAI] Global tokens per second: 24.093756818252658tps[39m
[1693633820368] [36m[OPENAI] Tokens per second: 11.69601556544685tps[39m
[1693633820368] [32m[OPENAI] Chat completion created successfully.[39m
[1693633820369] [Character] Getting character: A2
[1693633820422] [33m[OPENAI] Creating embedding...[39m
[1693633820496] [33m[OPENAI] Creating embedding...[39m
[1693633820575] [33m[OPENAI] Creating embedding...[39m
[1693633820626] [32m[OPENAI] Embedding created successfully.[39m
[1693633820658] [32m[OPENAI] Embedding created successfully.[39m
[1693633820728] [32m[OPENAI] Embedding created successfully.[39m
[1693633820986] [33m[OPENAI] Creating embedding...[39m
[1693633821055] [33m[OPENAI] Creating embedding...[39m
[1693633821137] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633821170] [32m[OPENAI] Embedding created successfully.[39m
[1693633821270] [32m[OPENAI] Embedding created successfully.[39m
[1693633821530] [33m[OPENAI] Creating embedding...[39m
[1693633821666] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633821697] [32m[OPENAI] Embedding created successfully.[39m
[1693633822029] [33m[OPENAI] Creating embedding...[39m
[1693633822193] [32m[OPENAI] Embedding created successfully.[39m
[1693633822545] [33m[OPENAI] Creating embedding...[39m
[1693633822712] [32m[OPENAI] Embedding created successfully.[39m
[1693633822998] {
  "id": "chatcmpl-7uDoTPSh0DqGubNdw9tA7il0D1SEP",
  "object": "chat.completion",
  "created": 1693633821,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_pickaxe",
          "arguments": "{\n  \"characterId\": \"A4\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1630,
    "completion_tokens": 18,
    "total_tokens": 1648
  }
}
[1693633822998] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_pickaxe",
    "arguments": "{\n  \"characterId\": \"A4\"\n}"
  }
}
[1693633822998] [36m[OPENAI] Chat completion took 1860.4793329238892ms[39m
[1693633822998] [36m[OPENAI] Global tokens per second: 22.786852187941115tps[39m
[1693633822998] [36m[OPENAI] Tokens per second: 9.674926069569173tps[39m
[1693633822998] [32m[OPENAI] Chat completion created successfully.[39m
[1693633823035] [33m[OPENAI] Creating embedding...[39m
[1693633823161] [32m[OPENAI] Embedding created successfully.[39m
[1693633823482] [33m[OPENAI] Creating embedding...[39m
[1693633823669] [32m[OPENAI] Embedding created successfully.[39m
[1693633823969] [33m[OPENAI] Creating embedding...[39m
[1693633824009] [Character] Getting character: A4
[1693633824040] [33m[OPENAI] Creating embedding...[39m
[1693633824124] [32m[OPENAI] Embedding created successfully.[39m
[1693633824198] [32m[OPENAI] Embedding created successfully.[39m
[1693633824329] {
  "id": "chatcmpl-7uDoTHkB49KngDYtevuHGqZvKnL5p",
  "object": "chat.completion",
  "created": 1693633821,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 41.33658,\n  \"y\": 13.99647\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1267,
    "completion_tokens": 37,
    "total_tokens": 1304
  }
}
[1693633824329] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 41.33658,\n  \"y\": 13.99647\n}"
  }
}
[1693633824329] [36m[OPENAI] Chat completion took 2661.8730409145355ms[39m
[1693633824329] [36m[OPENAI] Global tokens per second: 22.971923204971702tps[39m
[1693633824329] [36m[OPENAI] Tokens per second: 13.899986750415401tps[39m
[1693633824329] [32m[OPENAI] Chat completion created successfully.[39m
[1693633824333] --- Observations received -- 
[1693633824333] {
  "observerId": "A5",
  "observation": "Eli Green has started walking to 41.33658, Y: 13.99647.",
  "time": 27.9173183
}
[1693633824333] [Character] Getting character: A5
[1693633824401] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633824401] [33m[OPENAI] Creating embedding...[39m
[1693633824428] [33m[OPENAI] Creating embedding...[39m
[1693633824537] --- Observations received -- 
[1693633824537] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Small) at X: 38.24, Y: 15.93.",
  "time": 28.120615
}
[1693633824537] [Character] Getting character: A5
[1693633824563] [32m[OPENAI] Embedding created successfully.[39m
[1693633824600] [32m[OPENAI] Embedding created successfully.[39m
[1693633824624] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633824624] [33m[OPENAI] Creating embedding...[39m
[1693633824628] [33m[OPENAI] Creating embedding...[39m
[1693633824719] --- Observations received -- 
[1693633824719] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 45.24001, Y: 10.2.",
  "time": 28.3015671
}
[1693633824719] [Character] Getting character: A5
[1693633824727] --- Observations received -- 
[1693633824727] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees Tree (205) at X: 42.12, Y: 5.77",
  "time": 28.3015671
}
[1693633824727] [Character] Getting character: A5
[1693633824729] {
  "id": "chatcmpl-7uDoWzAqGXzCja1WzkUc5eI4nhTmq",
  "object": "chat.completion",
  "created": 1693633824,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693633824729] {
  "role": "assistant",
  "content": "1"
}
[1693633824729] [36m[OPENAI] Chat completion took 328.01900005340576ms[39m
[1693633824729] [36m[OPENAI] Global tokens per second: 22.747228624739325tps[39m
[1693633824729] [36m[OPENAI] Tokens per second: 3.0486038913513758tps[39m
[1693633824729] [32m[OPENAI] Chat completion created successfully.[39m
[1693633824759] [32m[OPENAI] Embedding created successfully.[39m
[1693633824827] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633824827] [33m[OPENAI] Creating embedding...[39m
[1693633824827] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633824827] [33m[OPENAI] Creating embedding...[39m
[1693633824848] [32m[OPENAI] Embedding created successfully.[39m
[1693633824888] [33m[OPENAI] Creating embedding...[39m
[1693633824900] {
  "id": "chatcmpl-7uDoWZ9lQjZlbI6aweXyBWTP2C9wz",
  "object": "chat.completion",
  "created": 1693633824,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633824900] {
  "role": "assistant",
  "content": "3"
}
[1693633824900] [36m[OPENAI] Chat completion took 275.953250169754ms[39m
[1693633824900] [36m[OPENAI] Global tokens per second: 22.6683053393418tps[39m
[1693633824900] [36m[OPENAI] Tokens per second: 3.62380221789323tps[39m
[1693633824900] [32m[OPENAI] Chat completion created successfully.[39m
[1693633825003] [32m[OPENAI] Embedding created successfully.[39m
[1693633825037] [32m[OPENAI] Embedding created successfully.[39m
[1693633825037] [32m[OPENAI] Embedding created successfully.[39m
[1693633825155] {
  "id": "chatcmpl-7uDoW1KPWEhmIuRQNPOM2N7G3XjqD",
  "object": "chat.completion",
  "created": 1693633824,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693633825155] {
  "role": "assistant",
  "content": "5"
}
[1693633825155] [36m[OPENAI] Chat completion took 326.575875043869ms[39m
[1693633825155] [36m[OPENAI] Global tokens per second: 22.538649308380798tps[39m
[1693633825155] [36m[OPENAI] Tokens per second: 3.0620755432888904tps[39m
[1693633825155] [32m[OPENAI] Chat completion created successfully.[39m
[1693633825169] {
  "id": "chatcmpl-7uDoWr0kUGIZ4zMP04UTfaZMQQmK9",
  "object": "chat.completion",
  "created": 1693633824,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693633825169] {
  "role": "assistant",
  "content": "2"
}
[1693633825169] [36m[OPENAI] Chat completion took 341.3923752307892ms[39m
[1693633825169] [36m[OPENAI] Global tokens per second: 22.557206376748727tps[39m
[1693633825169] [36m[OPENAI] Tokens per second: 2.9291808269706574tps[39m
[1693633825169] [32m[OPENAI] Chat completion created successfully.[39m
[1693633825206] [33m[OPENAI] Creating embedding...[39m
[1693633825337] [32m[OPENAI] Embedding created successfully.[39m
[1693633825350] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633825477] --- Observations received -- 
[1693633825478] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Medium) at X: 42.53862, Y: 17.00157.",
  "time": 29.0613441
}
[1693633825478] [Character] Getting character: A5
[1693633825564] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633825564] [33m[OPENAI] Creating embedding...[39m
[1693633825762] [32m[OPENAI] Embedding created successfully.[39m
[1693633825852] [33m[OPENAI] Creating embedding...[39m
[1693633826006] {
  "id": "chatcmpl-7uDoXsb1jI3A4ELTYyo44VSCHATws",
  "object": "chat.completion",
  "created": 1693633825,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633826006] {
  "role": "assistant",
  "content": "4"
}
[1693633826006] [36m[OPENAI] Chat completion took 441.27583408355713ms[39m
[1693633826006] [36m[OPENAI] Global tokens per second: 22.083189735160786tps[39m
[1693633826006] [36m[OPENAI] Tokens per second: 2.2661562740611045tps[39m
[1693633826006] [32m[OPENAI] Chat completion created successfully.[39m
[1693633826018] [32m[OPENAI] Embedding created successfully.[39m
[1693633826216] --- Observations received -- 
[1693633826216] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees Tree (479) at X: 45.24001, Y: 10.2",
  "time": 29.8000183
}
[1693633826216] [Character] Getting character: A5
[1693633826289] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633826289] [33m[OPENAI] Creating embedding...[39m
[1693633826420] [33m[OPENAI] Creating embedding...[39m
[1693633826459] --- Observations received -- 
[1693633826459] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Medium) at X: 38.03, Y: 18.78.",
  "time": 30.0415173
}
[1693633826459] [Character] Getting character: A5
[1693633826476] [32m[OPENAI] Embedding created successfully.[39m
[1693633826551] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633826551] [33m[OPENAI] Creating embedding...[39m
[1693633826579] [32m[OPENAI] Embedding created successfully.[39m
[1693633826586] {
  "id": "chatcmpl-7uDoYuGNX2iN55i15IZ3kzYLAE8ci",
  "object": "chat.completion",
  "created": 1693633826,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633826587] {
  "role": "assistant",
  "content": "1"
}
[1693633826587] [36m[OPENAI] Chat completion took 296.80254101753235ms[39m
[1693633826587] [36m[OPENAI] Global tokens per second: 21.7743198788575tps[39m
[1693633826587] [36m[OPENAI] Tokens per second: 3.369243391824362tps[39m
[1693633826587] [32m[OPENAI] Chat completion created successfully.[39m
[1693633826772] [32m[OPENAI] Embedding created successfully.[39m
[1693633826837] --- Observations received -- 
[1693633826837] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Large) at X: 40.75, Y: 19.74.",
  "time": 30.4205875
}
[1693633826837] [Character] Getting character: A5
[1693633826838] --- Observations received -- 
[1693633826838] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Small) at X: 45.73, Y: 15.31.",
  "time": 30.4205875
}
[1693633826838] [Character] Getting character: A5
[1693633826848] {
  "id": "chatcmpl-7uDoY8RbmrH2bNo6zbslhR0xDboHD",
  "object": "chat.completion",
  "created": 1693633826,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633826848] {
  "role": "assistant",
  "content": "1"
}
[1693633826848] [36m[OPENAI] Chat completion took 296.37454104423523ms[39m
[1693633826848] [36m[OPENAI] Global tokens per second: 21.65287970334258tps[39m
[1693633826848] [36m[OPENAI] Tokens per second: 3.3741089787153666tps[39m
[1693633826848] [32m[OPENAI] Chat completion created successfully.[39m
[1693633826904] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633826904] [33m[OPENAI] Creating embedding...[39m
[1693633826907] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633826907] [33m[OPENAI] Creating embedding...[39m
[1693633826931] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633827061] [32m[OPENAI] Embedding created successfully.[39m
[1693633827090] [32m[OPENAI] Embedding created successfully.[39m
[1693633827250] {
  "id": "chatcmpl-7uDoZl1uG6JKuPatZwEKMf0Rktk68",
  "object": "chat.completion",
  "created": 1693633827,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633827252] {
  "role": "assistant",
  "content": "2"
}
[1693633827252] [36m[OPENAI] Chat completion took 342.37866592407227ms[39m
[1693633827253] [36m[OPENAI] Global tokens per second: 21.45405086355121tps[39m
[1693633827253] [36m[OPENAI] Tokens per second: 2.92074273173833tps[39m
[1693633827253] [32m[OPENAI] Chat completion created successfully.[39m
[1693633827288] {
  "id": "chatcmpl-7uDoYnGL0wSeUibtEcYy6RpQmUajg",
  "object": "chat.completion",
  "created": 1693633826,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633827288] {
  "role": "assistant",
  "content": "2"
}
[1693633827288] [36m[OPENAI] Chat completion took 383.62891697883606ms[39m
[1693633827288] [36m[OPENAI] Global tokens per second: 21.45988770094608tps[39m
[1693633827289] [36m[OPENAI] Tokens per second: 2.606685668732234tps[39m
[1693633827291] [32m[OPENAI] Chat completion created successfully.[39m
[1693633827537] --- Observations received -- 
[1693633827538] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Medium) at X: 46.05, Y: 17.85.",
  "time": 31.1213589
}
[1693633827538] [Character] Getting character: A5
[1693633827608] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633827608] [33m[OPENAI] Creating embedding...[39m
[1693633827619] --- Observations received -- 
[1693633827619] {
  "observerId": "A5",
  "observation": "Eli Green finished walking to 41.33658, Y: 13.99647.",
  "time": 31.19999
}
[1693633827619] [Character] Getting character: A5
[1693633827620] [Character] Getting character: A5
[1693633827667] [33m[OPENAI] Creating embedding...[39m
[1693633827679] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633827679] [33m[OPENAI] Creating embedding...[39m
[1693633827755] [32m[OPENAI] Embedding created successfully.[39m
[1693633827874] {
  "id": "chatcmpl-7uDoZfmFBbHcUfCp6auOLyo8FXEUs",
  "object": "chat.completion",
  "created": 1693633827,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633827874] {
  "role": "assistant",
  "content": "4"
}
[1693633827874] [36m[OPENAI] Chat completion took 265.50537514686584ms[39m
[1693633827874] [36m[OPENAI] Global tokens per second: 21.167496021622167tps[39m
[1693633827874] [36m[OPENAI] Tokens per second: 3.7664020905295956tps[39m
[1693633827874] [32m[OPENAI] Chat completion created successfully.[39m
[1693633827895] {
  "id": "chatcmpl-7uDoXcyTlRd5yWYnyUZNLU5dsgIHl",
  "object": "chat.completion",
  "created": 1693633825,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "eat",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"foodId\": \"berries\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1422,
    "completion_tokens": 25,
    "total_tokens": 1447
  }
}
[1693633827895] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "eat",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"foodId\": \"berries\"\n}"
  }
}
[1693633827895] [36m[OPENAI] Chat completion took 2541.5087089538574ms[39m
[1693633827895] [36m[OPENAI] Global tokens per second: 21.78742741731886tps[39m
[1693633827895] [36m[OPENAI] Tokens per second: 9.836676896649537tps[39m
[1693633827895] [32m[OPENAI] Chat completion created successfully.[39m
[1693633827897] [32m[OPENAI] Embedding created successfully.[39m
[1693633827897] [32m[OPENAI] Embedding created successfully.[39m
[1693633827907] [Character] Getting character: A2
[1693633827919] {
  "id": "chatcmpl-7uDoZeu5kX5YiGfu28THqi9SSbsH6",
  "object": "chat.completion",
  "created": 1693633827,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693633827919] {
  "role": "assistant",
  "content": "2"
}
[1693633827919] [36m[OPENAI] Chat completion took 239.89983296394348ms[39m
[1693633827919] [36m[OPENAI] Global tokens per second: 21.799465105717314tps[39m
[1693633827920] [36m[OPENAI] Tokens per second: 4.16840640381062tps[39m
[1693633827920] [32m[OPENAI] Chat completion created successfully.[39m
[1693633827944] [33m[OPENAI] Creating embedding...[39m
[1693633828121] [32m[OPENAI] Embedding created successfully.[39m
[1693633828253] [33m[OPENAI] Creating embedding...[39m
[1693633828466] [33m[OPENAI] Creating embedding...[39m
[1693633828582] [32m[OPENAI] Embedding created successfully.[39m
[1693633828636] [32m[OPENAI] Embedding created successfully.[39m
[1693633828931] [33m[OPENAI] Creating embedding...[39m
[1693633829019] [33m[OPENAI] Creating embedding...[39m
[1693633829103] [32m[OPENAI] Embedding created successfully.[39m
[1693633829191] [32m[OPENAI] Embedding created successfully.[39m
[1693633829512] [33m[OPENAI] Creating embedding...[39m
[1693633829524] [33m[OPENAI] Creating embedding...[39m
[1693633829691] [32m[OPENAI] Embedding created successfully.[39m
[1693633829738] [32m[OPENAI] Embedding created successfully.[39m
[1693633829916] {
  "id": "chatcmpl-7uDoZjYipEZIhSeQpYcE2IpigyDuu",
  "object": "chat.completion",
  "created": 1693633827,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.13,\n  \"y\": 26.69\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1672,
    "completion_tokens": 35,
    "total_tokens": 1707
  }
}
[1693633829916] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.13,\n  \"y\": 26.69\n}"
  }
}
[1693633829916] [36m[OPENAI] Chat completion took 2984.052083015442ms[39m
[1693633829916] [36m[OPENAI] Global tokens per second: 21.594484879056473tps[39m
[1693633829916] [36m[OPENAI] Tokens per second: 11.72901780073216tps[39m
[1693633829916] [32m[OPENAI] Chat completion created successfully.[39m
[1693633829924] --- Observations received -- 
[1693633829924] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 53.13, Y: 26.69.",
  "time": 33.50779
}
[1693633829924] [Character] Getting character: A4
[1693633830021] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633830022] [33m[OPENAI] Creating embedding...[39m
[1693633830037] --- Observations received -- 
[1693633830037] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Medium) at X: 53.76, Y: 21.7.",
  "time": 33.62087
}
[1693633830038] [Character] Getting character: A4
[1693633830045] [33m[OPENAI] Creating embedding...[39m
[1693633830075] [33m[OPENAI] Creating embedding...[39m
[1693633830119] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633830119] [33m[OPENAI] Creating embedding...[39m
[1693633830186] [32m[OPENAI] Embedding created successfully.[39m
[1693633830219] [32m[OPENAI] Embedding created successfully.[39m
[1693633830253] [32m[OPENAI] Embedding created successfully.[39m
[1693633830277] --- Observations received -- 
[1693633830278] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees DiamondOreLarge (2) at X: 60.38, Y: 24.68",
  "time": 33.8614464
}
[1693633830278] [Character] Getting character: A4
[1693633830287] [32m[OPENAI] Embedding created successfully.[39m
[1693633830302] {
  "id": "chatcmpl-7uDocBc11h5i7REwF7KhycIuQO0Nu",
  "object": "chat.completion",
  "created": 1693633830,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633830302] {
  "role": "assistant",
  "content": "2"
}
[1693633830302] [36m[OPENAI] Chat completion took 279.99433279037476ms[39m
[1693633830302] [36m[OPENAI] Global tokens per second: 21.419901468453244tps[39m
[1693633830302] [36m[OPENAI] Tokens per second: 3.5715008587287254tps[39m
[1693633830302] [32m[OPENAI] Chat completion created successfully.[39m
[1693633830360] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633830360] [33m[OPENAI] Creating embedding...[39m
[1693633830436] --- Observations received -- 
[1693633830437] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Large) at X: 49.04, Y: 28.68.",
  "time": 34.02014
}
[1693633830437] [Character] Getting character: A4
[1693633830507] [33m[OPENAI] Creating embedding...[39m
[1693633830512] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633830512] [33m[OPENAI] Creating embedding...[39m
[1693633830516] {
  "id": "chatcmpl-7uDocOquVUbr1avgefWNs2KT2iwiZ",
  "object": "chat.completion",
  "created": 1693633830,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633830516] {
  "role": "assistant",
  "content": "2"
}
[1693633830516] [36m[OPENAI] Chat completion took 396.50404119491577ms[39m
[1693633830516] [36m[OPENAI] Global tokens per second: 21.335038242049677tps[39m
[1693633830516] [36m[OPENAI] Tokens per second: 2.522042390756906tps[39m
[1693633830516] [32m[OPENAI] Chat completion created successfully.[39m
[1693633830517] [32m[OPENAI] Embedding created successfully.[39m
[1693633830646] {
  "id": "chatcmpl-7uDoctT5ELwiXYeDvkBEIAsT0Ujai",
  "object": "chat.completion",
  "created": 1693633830,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633830646] {
  "role": "assistant",
  "content": "2"
}
[1693633830646] [36m[OPENAI] Chat completion took 285.9972081184387ms[39m
[1693633830646] [36m[OPENAI] Global tokens per second: 21.293170605037655tps[39m
[1693633830646] [36m[OPENAI] Tokens per second: 3.4965376290871855tps[39m
[1693633830646] [32m[OPENAI] Chat completion created successfully.[39m
[1693633830671] [33m[OPENAI] Creating embedding...[39m
[1693633830683] [32m[OPENAI] Embedding created successfully.[39m
[1693633830707] [32m[OPENAI] Embedding created successfully.[39m
[1693633830818] [32m[OPENAI] Embedding created successfully.[39m
[1693633830821] {
  "id": "chatcmpl-7uDocWeOupPxSpbzREVy3U75ZBdr0",
  "object": "chat.completion",
  "created": 1693633830,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633830821] {
  "role": "assistant",
  "content": "1"
}
[1693633830821] [36m[OPENAI] Chat completion took 309.247750043869ms[39m
[1693633830821] [36m[OPENAI] Global tokens per second: 21.229076546924958tps[39m
[1693633830821] [36m[OPENAI] Tokens per second: 3.2336532759192034tps[39m
[1693633830821] [32m[OPENAI] Chat completion created successfully.[39m
[1693633830990] [33m[OPENAI] Creating embedding...[39m
[1693633830991] --- Observations received -- 
[1693633830991] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Small) at X: 49.03, Y: 23.52.",
  "time": 34.56105
}
[1693633830991] [Character] Getting character: A4
[1693633831080] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633831081] [33m[OPENAI] Creating embedding...[39m
[1693633831135] [32m[OPENAI] Embedding created successfully.[39m
[1693633831150] [33m[OPENAI] Creating embedding...[39m
[1693633831264] [32m[OPENAI] Embedding created successfully.[39m
[1693633831288] [32m[OPENAI] Embedding created successfully.[39m
[1693633831317] {
  "id": "chatcmpl-7uDodlNkhOHrlh9kp4BzvmffZyw4e",
  "object": "chat.completion",
  "created": 1693633831,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633831317] {
  "role": "assistant",
  "content": "1"
}
[1693633831317] [36m[OPENAI] Chat completion took 236.17016696929932ms[39m
[1693633831317] [36m[OPENAI] Global tokens per second: 21.0076222346161tps[39m
[1693633831317] [36m[OPENAI] Tokens per second: 4.234235055310749tps[39m
[1693633831317] [32m[OPENAI] Chat completion created successfully.[39m
[1693633831378] [33m[OPENAI] Creating embedding...[39m
[1693633831425] --- Observations received -- 
[1693633831426] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees DiamondOreSmall at X: 58.32, Y: 22.87",
  "time": 35.00101
}
[1693633831426] [Character] Getting character: A4
[1693633831462] --- Observations received -- 
[1693633831463] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 53.13, Y: 26.69.",
  "time": 35.01999
}
[1693633831463] [Character] Getting character: A4
[1693633831463] [Character] Getting character: A4
[1693633831493] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633831493] [33m[OPENAI] Creating embedding...[39m
[1693633831522] [33m[OPENAI] Creating embedding...[39m
[1693633831560] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633831560] [33m[OPENAI] Creating embedding...[39m
[1693633831591] [32m[OPENAI] Embedding created successfully.[39m
[1693633831620] [32m[OPENAI] Embedding created successfully.[39m
[1693633831631] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633831694] [32m[OPENAI] Embedding created successfully.[39m
[1693633831828] {
  "id": "chatcmpl-7uDodnL1z8DEYQ7ldR22jsA8Od3Hw",
  "object": "chat.completion",
  "created": 1693633831,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633831828] {
  "role": "assistant",
  "content": "1"
}
[1693633831828] [36m[OPENAI] Chat completion took 268.24762511253357ms[39m
[1693633831828] [36m[OPENAI] Global tokens per second: 20.784052545759366tps[39m
[1693633831828] [36m[OPENAI] Tokens per second: 3.727898800895203tps[39m
[1693633831828] [32m[OPENAI] Chat completion created successfully.[39m
[1693633831833] {
  "id": "chatcmpl-7uDodtAdkMTJVZvW9w9f31CAvRi93",
  "object": "chat.completion",
  "created": 1693633831,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693633831833] {
  "role": "assistant",
  "content": "2"
}
[1693633831833] [36m[OPENAI] Chat completion took 339.819167137146ms[39m
[1693633831833] [36m[OPENAI] Global tokens per second: 20.804629374483326tps[39m
[1693633831833] [36m[OPENAI] Tokens per second: 2.9427416011422767tps[39m
[1693633831833] [32m[OPENAI] Chat completion created successfully.[39m
[1693633831920] [33m[OPENAI] Creating embedding...[39m
[1693633832050] [33m[OPENAI] Creating embedding...[39m
[1693633832087] [32m[OPENAI] Embedding created successfully.[39m
[1693633832393] [33m[OPENAI] Creating embedding...[39m
[1693633833441] {
  "id": "chatcmpl-7uDodBBvFBuKSbMEiT2TgczoTwSUx",
  "object": "chat.completion",
  "created": 1693633831,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_pickaxe",
          "arguments": "{\n  \"characterId\": \"A5\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1625,
    "completion_tokens": 18,
    "total_tokens": 1643
  }
}
[1693633833441] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_pickaxe",
    "arguments": "{\n  \"characterId\": \"A5\"\n}"
  }
}
[1693633833441] [36m[OPENAI] Chat completion took 1810.449375152588ms[39m
[1693633833441] [36m[OPENAI] Global tokens per second: 20.46239702365134tps[39m
[1693633833441] [36m[OPENAI] Tokens per second: 9.942282975177324tps[39m
[1693633833442] [32m[OPENAI] Chat completion created successfully.[39m
[1693633834069] --- Observations received -- 
[1693633834069] {
  "observerId": "A5",
  "observation": "Eli Green picked up Stone at X: 41.20406, Y: 14.52373",
  "time": 37.6524467
}
[1693633834069] [Character] Getting character: A5
[1693633834198] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633834198] [33m[OPENAI] Creating embedding...[39m
[1693633834439] {
  "id": "chatcmpl-7uDogVrBGe0Y8X6Q00wa55PKkVqOK",
  "object": "chat.completion",
  "created": 1693633834,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693633834439] {
  "role": "assistant",
  "content": "5"
}
[1693633834439] [36m[OPENAI] Chat completion took 241.15387511253357ms[39m
[1693633834439] [36m[OPENAI] Global tokens per second: 20.041599861333793tps[39m
[1693633834439] [36m[OPENAI] Tokens per second: 4.146729964564549tps[39m
[1693633834439] [32m[OPENAI] Chat completion created successfully.[39m
[1693633834459] [Character] Getting character: A5
[1693633834496] [33m[OPENAI] Creating embedding...[39m
[1693633834919] [32m[OPENAI] Embedding created successfully.[39m
[1693633834929] [32m[OPENAI] Embedding created successfully.[39m
[1693633834985] [32m[OPENAI] Embedding created successfully.[39m
[1693633835301] [32m[OPENAI] Embedding created successfully.[39m
[1693633835337] [32m[OPENAI] Embedding created successfully.[39m
[1693633835428] [33m[OPENAI] Creating embedding...[39m
[1693633835660] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633835662] [32m[OPENAI] Embedding created successfully.[39m
[1693633835747] [33m[OPENAI] Creating embedding...[39m
[1693633835960] [32m[OPENAI] Embedding created successfully.[39m
[1693633835999] [33m[OPENAI] Creating embedding...[39m
[1693633836248] [32m[OPENAI] Embedding created successfully.[39m
[1693633836293] [33m[OPENAI] Creating embedding...[39m
[1693633836480] [32m[OPENAI] Embedding created successfully.[39m
[1693633836611] [33m[OPENAI] Creating embedding...[39m
[1693633836788] [32m[OPENAI] Embedding created successfully.[39m
[1693633836860] [33m[OPENAI] Creating embedding...[39m
[1693633837060] [32m[OPENAI] Embedding created successfully.[39m
[1693633837160] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633837403] [33m[OPENAI] Creating embedding...[39m
[1693633837585] [32m[OPENAI] Embedding created successfully.[39m
[1693633837969] [33m[OPENAI] Creating embedding...[39m
[1693633838094] [32m[OPENAI] Embedding created successfully.[39m
[1693633838434] [33m[OPENAI] Creating embedding...[39m
[1693633838518] {
  "id": "chatcmpl-7uDohuwG8DlXOjxr58rTspXlppuzH",
  "object": "chat.completion",
  "created": 1693633835,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 62.25,\n  \"y\": 15.1\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1334,
    "completion_tokens": 35,
    "total_tokens": 1369
  }
}
[1693633838518] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 62.25,\n  \"y\": 15.1\n}"
  }
}
[1693633838518] [36m[OPENAI] Chat completion took 2857.167541027069ms[39m
[1693633838518] [36m[OPENAI] Global tokens per second: 19.110943005593935tps[39m
[1693633838518] [36m[OPENAI] Tokens per second: 12.249894168760756tps[39m
[1693633838518] [32m[OPENAI] Chat completion created successfully.[39m
[1693633838525] --- Observations received -- 
[1693633838525] {
  "observerId": "A2",
  "observation": "George Brown has started walking to 62.25, Y: 15.1.",
  "time": 42.10825
}
[1693633838525] [Character] Getting character: A2
[1693633838585] [32m[OPENAI] Embedding created successfully.[39m
[1693633838592] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633838592] [33m[OPENAI] Creating embedding...[39m
[1693633838717] --- Observations received -- 
[1693633838717] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Medium) at X: 61.66, Y: 18.02.",
  "time": 42.3000679
}
[1693633838717] [Character] Getting character: A2
[1693633838798] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633838798] [33m[OPENAI] Creating embedding...[39m
[1693633838817] [32m[OPENAI] Embedding created successfully.[39m
[1693633838855] {
  "id": "chatcmpl-7uDojYOkysg5rKKWAEutP0pRegUfS",
  "object": "chat.completion",
  "created": 1693633837,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_pickaxe",
          "arguments": "{\n  \"characterId\": \"A4\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1794,
    "completion_tokens": 18,
    "total_tokens": 1812
  }
}
[1693633838855] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_pickaxe",
    "arguments": "{\n  \"characterId\": \"A4\"\n}"
  }
}
[1693633838855] [36m[OPENAI] Chat completion took 1694.7521250247955ms[39m
[1693633838855] [36m[OPENAI] Global tokens per second: 19.339529365236306tps[39m
[1693633838855] [36m[OPENAI] Tokens per second: 10.621022233405753tps[39m
[1693633838855] [32m[OPENAI] Chat completion created successfully.[39m
[1693633838922] {
  "id": "chatcmpl-7uDokLu7DizGdsc2oz6EF1zkulQI9",
  "object": "chat.completion",
  "created": 1693633838,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633838922] {
  "role": "assistant",
  "content": "1"
}
[1693633838922] [36m[OPENAI] Chat completion took 329.8993330001831ms[39m
[1693633838922] [36m[OPENAI] Global tokens per second: 19.333688804629027tps[39m
[1693633838922] [36m[OPENAI] Tokens per second: 3.0312277109073302tps[39m
[1693633838922] [32m[OPENAI] Chat completion created successfully.[39m
[1693633838930] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633838977] --- Observations received -- 
[1693633838977] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Medium) at X: 59.9, Y: 16.03.",
  "time": 42.5604935
}
[1693633838977] [Character] Getting character: A2
[1693633839027] [32m[OPENAI] Embedding created successfully.[39m
[1693633839040] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633839040] [33m[OPENAI] Creating embedding...[39m
[1693633839074] {
  "id": "chatcmpl-7uDokKthastqvRZNjjhT3nL8jGIpM",
  "object": "chat.completion",
  "created": 1693633838,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 2,
    "total_tokens": 108
  }
}
[1693633839074] {
  "role": "assistant",
  "content": "5."
}
[1693633839074] [36m[OPENAI] Chat completion took 275.92812490463257ms[39m
[1693633839074] [36m[OPENAI] Global tokens per second: 19.31520604855382tps[39m
[1693633839074] [36m[OPENAI] Tokens per second: 7.248264382948451tps[39m
[1693633839074] [32m[OPENAI] Chat completion created successfully.[39m
[1693633839180] [32m[OPENAI] Embedding created successfully.[39m
[1693633839377] --- Observations received -- 
[1693633839377] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Small) at X: 59.32, Y: 14.11.",
  "time": 42.9609642
}
[1693633839377] [Character] Getting character: A2
[1693633839440] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633839441] [33m[OPENAI] Creating embedding...[39m
[1693633839497] --- Observations received -- 
[1693633839497] {
  "observerId": "A2",
  "observation": "George Brown no longer sees Tree (1056) at X: 67.61, Y: 9.619999",
  "time": 43.0805435
}
[1693633839497] [Character] Getting character: A2
[1693633839551] {
  "id": "chatcmpl-7uDolf4kOXhz0mh65GvdhZz54IMvl",
  "object": "chat.completion",
  "created": 1693633839,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633839551] {
  "role": "assistant",
  "content": "2"
}
[1693633839551] [36m[OPENAI] Chat completion took 510.8136250972748ms[39m
[1693633839551] [36m[OPENAI] Global tokens per second: 19.154995513595757tps[39m
[1693633839551] [36m[OPENAI] Tokens per second: 1.9576611720362176tps[39m
[1693633839551] [32m[OPENAI] Chat completion created successfully.[39m
[1693633839566] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633839566] [33m[OPENAI] Creating embedding...[39m
[1693633839623] [32m[OPENAI] Embedding created successfully.[39m
[1693633839747] [32m[OPENAI] Embedding created successfully.[39m
[1693633839769] {
  "id": "chatcmpl-7uDolo9G9m34Cjbxke4thvbqBLIbE",
  "object": "chat.completion",
  "created": 1693633839,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633839769] {
  "role": "assistant",
  "content": "3"
}
[1693633839769] [36m[OPENAI] Chat completion took 328.1950418949127ms[39m
[1693633839769] [36m[OPENAI] Global tokens per second: 19.093310543081344tps[39m
[1693633839769] [36m[OPENAI] Tokens per second: 3.0469686386066663tps[39m
[1693633839769] [32m[OPENAI] Chat completion created successfully.[39m
[1693633839778] --- Observations received -- 
[1693633839778] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Small) at X: 62.95, Y: 20.13.",
  "time": 43.3620377
}
[1693633839779] [Character] Getting character: A2
[1693633839846] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633839846] [33m[OPENAI] Creating embedding...[39m
[1693633839867] [Character] Getting character: A4
[1693633839887] {
  "id": "chatcmpl-7uDoliIHVemG9wLDlIbY2hbAHDt38",
  "object": "chat.completion",
  "created": 1693633839,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 107,
    "completion_tokens": 1,
    "total_tokens": 108
  }
}
[1693633839887] {
  "role": "assistant",
  "content": "5"
}
[1693633839887] [36m[OPENAI] Chat completion took 320.5237500667572ms[39m
[1693633839887] [36m[OPENAI] Global tokens per second: 19.069028332235185tps[39m
[1693633839887] [36m[OPENAI] Tokens per second: 3.1198936109780466tps[39m
[1693633839887] [32m[OPENAI] Chat completion created successfully.[39m
[1693633839899] [33m[OPENAI] Creating embedding...[39m
[1693633840036] [32m[OPENAI] Embedding created successfully.[39m
[1693633840067] [32m[OPENAI] Embedding created successfully.[39m
[1693633840111] {
  "id": "chatcmpl-7uDolC7YzjMUplPubbt4e5neouet9",
  "object": "chat.completion",
  "created": 1693633839,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633840111] {
  "role": "assistant",
  "content": "1"
}
[1693633840111] [36m[OPENAI] Chat completion took 264.40720796585083ms[39m
[1693633840111] [36m[OPENAI] Global tokens per second: 19.00590437232277tps[39m
[1693633840111] [36m[OPENAI] Tokens per second: 3.782045155626596tps[39m
[1693633840111] [32m[OPENAI] Chat completion created successfully.[39m
[1693633840499] --- Observations received -- 
[1693633840499] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Large) at X: 58.91, Y: 19.37.",
  "time": 44.081398
}
[1693633840499] [Character] Getting character: A2
[1693633840551] [33m[OPENAI] Creating embedding...[39m
[1693633840585] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633840585] [33m[OPENAI] Creating embedding...[39m
[1693633840687] [32m[OPENAI] Embedding created successfully.[39m
[1693633840738] --- Observations received -- 
[1693633840738] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Medium) at X: 57.27, Y: 17.32.",
  "time": 44.3214569
}
[1693633840738] [Character] Getting character: A2
[1693633840746] [32m[OPENAI] Embedding created successfully.[39m
[1693633840803] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633840803] [33m[OPENAI] Creating embedding...[39m
[1693633840862] {
  "id": "chatcmpl-7uDomPkR8uWH9QJ4GvUyRixbXj1nl",
  "object": "chat.completion",
  "created": 1693633840,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633840862] {
  "role": "assistant",
  "content": "1"
}
[1693633840862] [36m[OPENAI] Chat completion took 277.03891587257385ms[39m
[1693633840862] [36m[OPENAI] Global tokens per second: 18.753447324875896tps[39m
[1693633840862] [36m[OPENAI] Tokens per second: 3.609601188520235tps[39m
[1693633840862] [32m[OPENAI] Chat completion created successfully.[39m
[1693633840921] --- Observations received -- 
[1693633840921] {
  "observerId": "A2",
  "observation": "George Brown finished walking to 62.25, Y: 15.1.",
  "time": 44.4999847
}
[1693633840922] [Character] Getting character: A2
[1693633840922] [Character] Getting character: A2
[1693633840950] [32m[OPENAI] Embedding created successfully.[39m
[1693633840989] [33m[OPENAI] Creating embedding...[39m
[1693633841023] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633841024] [33m[OPENAI] Creating embedding...[39m
[1693633841053] {
  "id": "chatcmpl-7uDomkpRx6nsblJalrrvVg0s0CGAx",
  "object": "chat.completion",
  "created": 1693633840,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633841053] {
  "role": "assistant",
  "content": "3"
}
[1693633841053] [36m[OPENAI] Chat completion took 249.3831250667572ms[39m
[1693633841053] [36m[OPENAI] Global tokens per second: 18.70451788963008tps[39m
[1693633841053] [36m[OPENAI] Tokens per second: 4.009894413394293tps[39m
[1693633841053] [32m[OPENAI] Chat completion created successfully.[39m
[1693633841116] [32m[OPENAI] Embedding created successfully.[39m
[1693633841132] [33m[OPENAI] Creating embedding...[39m
[1693633841201] [32m[OPENAI] Embedding created successfully.[39m
[1693633841265] {
  "id": "chatcmpl-7uDonhm97JuopoYkvx5CQHWJpFulz",
  "object": "chat.completion",
  "created": 1693633841,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633841266] {
  "role": "assistant",
  "content": "3"
}
[1693633841266] [36m[OPENAI] Chat completion took 241.87654089927673ms[39m
[1693633841266] [36m[OPENAI] Global tokens per second: 18.64819463581284tps[39m
[1693633841266] [36m[OPENAI] Tokens per second: 4.134340586656663tps[39m
[1693633841266] [32m[OPENAI] Chat completion created successfully.[39m
[1693633841352] [32m[OPENAI] Embedding created successfully.[39m
[1693633841455] [33m[OPENAI] Creating embedding...[39m
[1693633841617] [32m[OPENAI] Embedding created successfully.[39m
[1693633841786] [33m[OPENAI] Creating embedding...[39m
[1693633841972] [33m[OPENAI] Creating embedding...[39m
[1693633841990] [32m[OPENAI] Embedding created successfully.[39m
[1693633842118] [32m[OPENAI] Embedding created successfully.[39m
[1693633842178] {
  "id": "chatcmpl-7uDol1QX7Vax1ZMunnVjbnL35rAnq",
  "object": "chat.completion",
  "created": 1693633839,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 42.53862,\n  \"y\": 17.00157\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1572,
    "completion_tokens": 37,
    "total_tokens": 1609
  }
}
[1693633842178] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 42.53862,\n  \"y\": 17.00157\n}"
  }
}
[1693633842178] [36m[OPENAI] Chat completion took 3248.0102088451385ms[39m
[1693633842178] [36m[OPENAI] Global tokens per second: 19.019167609893678tps[39m
[1693633842178] [36m[OPENAI] Tokens per second: 11.391589810660019tps[39m
[1693633842178] [32m[OPENAI] Chat completion created successfully.[39m
[1693633842186] --- Observations received -- 
[1693633842187] {
  "observerId": "A5",
  "observation": "Eli Green has started walking to 42.53862, Y: 17.00157.",
  "time": 45.7694931
}
[1693633842187] [Character] Getting character: A5
[1693633842250] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633842252] [33m[OPENAI] Creating embedding...[39m
[1693633842376] [33m[OPENAI] Creating embedding...[39m
[1693633842432] [32m[OPENAI] Embedding created successfully.[39m
[1693633842486] {
  "id": "chatcmpl-7uDooE82fDQmKJSQExyuYsY9dXbvV",
  "object": "chat.completion",
  "created": 1693633842,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693633842486] {
  "role": "assistant",
  "content": "5"
}
[1693633842486] [36m[OPENAI] Chat completion took 234.14883279800415ms[39m
[1693633842486] [36m[OPENAI] Global tokens per second: 18.929540045386616tps[39m
[1693633842486] [36m[OPENAI] Tokens per second: 4.270787891830669tps[39m
[1693633842486] [32m[OPENAI] Chat completion created successfully.[39m
[1693633842503] [33m[OPENAI] Creating embedding...[39m
[1693633842522] [32m[OPENAI] Embedding created successfully.[39m
[1693633842577] --- Observations received -- 
[1693633842578] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Large) at X: 44.3, Y: 20.36.",
  "time": 46.1602
}
[1693633842578] [Character] Getting character: A5
[1693633842663] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633842664] [33m[OPENAI] Creating embedding...[39m
[1693633842671] [32m[OPENAI] Embedding created successfully.[39m
[1693633842826] [32m[OPENAI] Embedding created successfully.[39m
[1693633842951] {
  "id": "chatcmpl-7uDooTydDebfZY1JP30CG6OGcqd5t",
  "object": "chat.completion",
  "created": 1693633842,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633842951] {
  "role": "assistant",
  "content": "2"
}
[1693633842951] [36m[OPENAI] Chat completion took 287.33662486076355ms[39m
[1693633842951] [36m[OPENAI] Global tokens per second: 18.78681447334724tps[39m
[1693633842951] [36m[OPENAI] Tokens per second: 3.4802385546380523tps[39m
[1693633842951] [32m[OPENAI] Chat completion created successfully.[39m
[1693633842978] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633843061] [33m[OPENAI] Creating embedding...[39m
[1693633843237] [32m[OPENAI] Embedding created successfully.[39m
[1693633843478] --- Observations received -- 
[1693633843478] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Large) at X: 41.29, Y: 22.52.",
  "time": 47.06026
}
[1693633843478] [Character] Getting character: A5
[1693633843543] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633843543] [33m[OPENAI] Creating embedding...[39m
[1693633843615] [33m[OPENAI] Creating embedding...[39m
[1693633843709] [32m[OPENAI] Embedding created successfully.[39m
[1693633843783] {
  "id": "chatcmpl-7uDop75kVYul4eipeUACIEDr2JmA0",
  "object": "chat.completion",
  "created": 1693633843,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633843783] {
  "role": "assistant",
  "content": "3"
}
[1693633843783] [36m[OPENAI] Chat completion took 239.6741659641266ms[39m
[1693633843784] [36m[OPENAI] Global tokens per second: 18.523190024865762tps[39m
[1693633843785] [36m[OPENAI] Tokens per second: 4.172331197971816tps[39m
[1693633843785] [32m[OPENAI] Chat completion created successfully.[39m
[1693633843864] [32m[OPENAI] Embedding created successfully.[39m
[1693633844244] [33m[OPENAI] Creating embedding...[39m
[1693633844339] --- Observations received -- 
[1693633844339] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Small) at X: 47.58, Y: 19.17.",
  "time": 47.92181
}
[1693633844339] [Character] Getting character: A5
[1693633844395] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633844395] [33m[OPENAI] Creating embedding...[39m
[1693633844437] [32m[OPENAI] Embedding created successfully.[39m
[1693633844482] --- Observations received -- 
[1693633844482] {
  "observerId": "A5",
  "observation": "Eli Green finished walking to 42.53862, Y: 17.00157.",
  "time": 48.0599823
}
[1693633844482] [Character] Getting character: A5
[1693633844483] [Character] Getting character: A5
[1693633844521] [33m[OPENAI] Creating embedding...[39m
[1693633844552] [32m[OPENAI] Embedding created successfully.[39m
[1693633844562] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633844562] [33m[OPENAI] Creating embedding...[39m
[1693633844658] {
  "id": "chatcmpl-7uDoqlSLBBKNPpzMuipFgthpt65gK",
  "object": "chat.completion",
  "created": 1693633844,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633844658] {
  "role": "assistant",
  "content": "1"
}
[1693633844658] [36m[OPENAI] Chat completion took 262.6202919483185ms[39m
[1693633844658] [36m[OPENAI] Global tokens per second: 18.253419190037786tps[39m
[1693633844658] [36m[OPENAI] Tokens per second: 3.807778875658214tps[39m
[1693633844658] [32m[OPENAI] Chat completion created successfully.[39m
[1693633844685] [32m[OPENAI] Embedding created successfully.[39m
[1693633844724] [32m[OPENAI] Embedding created successfully.[39m
[1693633844756] [33m[OPENAI] Creating embedding...[39m
[1693633844833] {
  "id": "chatcmpl-7uDoqltzLFcUIrLw1E0YiNdVC3KTz",
  "object": "chat.completion",
  "created": 1693633844,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693633844833] {
  "role": "assistant",
  "content": "4"
}
[1693633844834] [36m[OPENAI] Chat completion took 270.8081669807434ms[39m
[1693633844835] [36m[OPENAI] Global tokens per second: 18.214292029920955tps[39m
[1693633844835] [36m[OPENAI] Tokens per second: 3.692650820501687tps[39m
[1693633844835] [32m[OPENAI] Chat completion created successfully.[39m
[1693633844935] [32m[OPENAI] Embedding created successfully.[39m
[1693633845109] [33m[OPENAI] Creating embedding...[39m
[1693633845243] [33m[OPENAI] Creating embedding...[39m
[1693633845278] [32m[OPENAI] Embedding created successfully.[39m
[1693633845381] [32m[OPENAI] Embedding created successfully.[39m
[1693633845681] [33m[OPENAI] Creating embedding...[39m
[1693633845818] [33m[OPENAI] Creating embedding...[39m
[1693633845858] [32m[OPENAI] Embedding created successfully.[39m
[1693633846033] [32m[OPENAI] Embedding created successfully.[39m
[1693633846312] [33m[OPENAI] Creating embedding...[39m
[1693633846429] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633846433] {
  "id": "chatcmpl-7uDopLQcwTbGwERDehivQO5srJbFA",
  "object": "chat.completion",
  "created": 1693633843,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 54.06,\n  \"y\": 24.46\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1828,
    "completion_tokens": 35,
    "total_tokens": 1863
  }
}
[1693633846433] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 54.06,\n  \"y\": 24.46\n}"
  }
}
[1693633846433] [36m[OPENAI] Chat completion took 3454.365541934967ms[39m
[1693633846433] [36m[OPENAI] Global tokens per second: 18.315333287473344tps[39m
[1693633846433] [36m[OPENAI] Tokens per second: 10.132106627139033tps[39m
[1693633846433] [32m[OPENAI] Chat completion created successfully.[39m
[1693633846439] --- Observations received -- 
[1693633846439] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 54.06, Y: 24.46.",
  "time": 50.0230064
}
[1693633846439] [Character] Getting character: A4
[1693633846456] [32m[OPENAI] Embedding created successfully.[39m
[1693633846477] --- Observations received -- 
[1693633846477] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Diamond Ore Deposit (Small) at X: 58.32, Y: 22.87.",
  "time": 50.06049
}
[1693633846477] [Character] Getting character: A4
[1693633846501] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633846502] [33m[OPENAI] Creating embedding...[39m
[1693633846538] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633846538] [33m[OPENAI] Creating embedding...[39m
[1693633846635] [32m[OPENAI] Embedding created successfully.[39m
[1693633846703] [32m[OPENAI] Embedding created successfully.[39m
[1693633846822] {
  "id": "chatcmpl-7uDosb0qtvsYsNcE9RPZkbYG4H29h",
  "object": "chat.completion",
  "created": 1693633846,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633846822] {
  "role": "assistant",
  "content": "3"
}
[1693633846822] [36m[OPENAI] Chat completion took 283.8672499656677ms[39m
[1693633846822] [36m[OPENAI] Global tokens per second: 18.210704340844252tps[39m
[1693633846822] [36m[OPENAI] Tokens per second: 3.522773409475538tps[39m
[1693633846822] [32m[OPENAI] Chat completion created successfully.[39m
[1693633846827] [33m[OPENAI] Creating embedding...[39m
[1693633846848] {
  "id": "chatcmpl-7uDosZBizK6lEjvJPNVrMLUTsQop3",
  "object": "chat.completion",
  "created": 1693633846,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633846848] {
  "role": "assistant",
  "content": "2"
}
[1693633846848] [36m[OPENAI] Chat completion took 346.7020001411438ms[39m
[1693633846848] [36m[OPENAI] Global tokens per second: 18.2196950292847tps[39m
[1693633846848] [36m[OPENAI] Tokens per second: 2.8843214045286616tps[39m
[1693633846848] [32m[OPENAI] Chat completion created successfully.[39m
[1693633846983] [32m[OPENAI] Embedding created successfully.[39m
[1693633847098] --- Observations received -- 
[1693633847098] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees CopperOreLarge (1) at X: 49.04, Y: 28.68",
  "time": 50.6816368
}
[1693633847098] [Character] Getting character: A4
[1693633847119] --- Observations received -- 
[1693633847119] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 54.06, Y: 24.46.",
  "time": 50.69998
}
[1693633847119] [Character] Getting character: A4
[1693633847122] [Character] Getting character: A4
[1693633847167] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633847167] [33m[OPENAI] Creating embedding...[39m
[1693633847168] [33m[OPENAI] Creating embedding...[39m
[1693633847211] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633847212] [33m[OPENAI] Creating embedding...[39m
[1693633847331] [32m[OPENAI] Embedding created successfully.[39m
[1693633847341] [32m[OPENAI] Embedding created successfully.[39m
[1693633847343] [33m[OPENAI] Creating embedding...[39m
[1693633847436] [32m[OPENAI] Embedding created successfully.[39m
[1693633847470] {
  "id": "chatcmpl-7uDotHEQV8vtFXkocxO1Bq14rLBXp",
  "object": "chat.completion",
  "created": 1693633847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633847470] {
  "role": "assistant",
  "content": "3"
}
[1693633847470] [36m[OPENAI] Chat completion took 302.267874956131ms[39m
[1693633847470] [36m[OPENAI] Global tokens per second: 18.045112781954888tps[39m
[1693633847470] [36m[OPENAI] Tokens per second: 3.308323784474724tps[39m
[1693633847470] [32m[OPENAI] Chat completion created successfully.[39m
[1693633847510] [32m[OPENAI] Embedding created successfully.[39m
[1693633847513] {
  "id": "chatcmpl-7uDot5EuvloIZ2SJfmGfH3OZD3XjV",
  "object": "chat.completion",
  "created": 1693633847,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633847513] {
  "role": "assistant",
  "content": "5"
}
[1693633847513] [36m[OPENAI] Chat completion took 301.8567500114441ms[39m
[1693633847513] [36m[OPENAI] Global tokens per second: 18.04889579253056tps[39m
[1693633847513] [36m[OPENAI] Tokens per second: 3.3128296781903592tps[39m
[1693633847513] [32m[OPENAI] Chat completion created successfully.[39m
[1693633847732] [33m[OPENAI] Creating embedding...[39m
[1693633847869] [32m[OPENAI] Embedding created successfully.[39m
[1693633847886] [33m[OPENAI] Creating embedding...[39m
[1693633848074] [32m[OPENAI] Embedding created successfully.[39m
[1693633848113] {
  "id": "chatcmpl-7uDosIg6FEB8xiTr4ocylceXkc8gl",
  "object": "chat.completion",
  "created": 1693633846,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_pickaxe",
          "arguments": "{\n  \"characterId\": \"A2\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1820,
    "completion_tokens": 18,
    "total_tokens": 1838
  }
}
[1693633848113] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_pickaxe",
    "arguments": "{\n  \"characterId\": \"A2\"\n}"
  }
}
[1693633848113] [36m[OPENAI] Chat completion took 1683.8385000228882ms[39m
[1693633848113] [36m[OPENAI] Global tokens per second: 18.168750417864544tps[39m
[1693633848113] [36m[OPENAI] Tokens per second: 10.689861289996237tps[39m
[1693633848113] [32m[OPENAI] Chat completion created successfully.[39m
[1693633848312] [33m[OPENAI] Creating embedding...[39m
[1693633848359] --- Observations received -- 
[1693633848359] {
  "observerId": "A5",
  "observation": "Eli Green sees Thomas Smith at X: 45.39852, Y: 13.77648.",
  "time": 51.94203
}
[1693633848359] [Character] Getting character: A5
[1693633848416] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633848418] [33m[OPENAI] Creating embedding...[39m
[1693633848468] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633848489] [32m[OPENAI] Embedding created successfully.[39m
[1693633848598] [32m[OPENAI] Embedding created successfully.[39m
[1693633848712] {
  "id": "chatcmpl-7uDouSfM3RvuTHP7Xn6j2eY55POfe",
  "object": "chat.completion",
  "created": 1693633848,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1693633848712] {
  "role": "assistant",
  "content": "2"
}
[1693633848712] [36m[OPENAI] Chat completion took 295.47466707229614ms[39m
[1693633848712] [36m[OPENAI] Global tokens per second: 18.005196352623827tps[39m
[1693633848712] [36m[OPENAI] Tokens per second: 3.3843848946797257tps[39m
[1693633848712] [32m[OPENAI] Chat completion created successfully.[39m
[1693633848742] --- Observations received -- 
[1693633848742] {
  "observerId": "A2",
  "observation": "George Brown picked up Coal at X: 62.6383, Y: 15.4435",
  "time": 52.3254776
}
[1693633848742] [Character] Getting character: A2
[1693633848818] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633848818] [33m[OPENAI] Creating embedding...[39m
[1693633848861] [33m[OPENAI] Creating embedding...[39m
[1693633848982] [32m[OPENAI] Embedding created successfully.[39m
[1693633849027] [32m[OPENAI] Embedding created successfully.[39m
[1693633849124] {
  "id": "chatcmpl-7uDouSdREiJlYQJnYWQapp5ZMN7pw",
  "object": "chat.completion",
  "created": 1693633848,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693633849124] {
  "role": "assistant",
  "content": "1"
}
[1693633849124] [36m[OPENAI] Chat completion took 306.1881251335144ms[39m
[1693633849124] [36m[OPENAI] Global tokens per second: 17.89970249346636tps[39m
[1693633849124] [36m[OPENAI] Tokens per second: 3.265965979457716tps[39m
[1693633849124] [32m[OPENAI] Chat completion created successfully.[39m
[1693633849137] [Character] Getting character: A2
[1693633849173] [33m[OPENAI] Creating embedding...[39m
[1693633849308] [32m[OPENAI] Embedding created successfully.[39m
[1693633849422] [33m[OPENAI] Creating embedding...[39m
[1693633849626] [32m[OPENAI] Embedding created successfully.[39m
[1693633849681] [33m[OPENAI] Creating embedding...[39m
[1693633849903] [32m[OPENAI] Embedding created successfully.[39m
[1693633850007] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633850310] [33m[OPENAI] Creating embedding...[39m
[1693633850504] [32m[OPENAI] Embedding created successfully.[39m
[1693633850906] [33m[OPENAI] Creating embedding...[39m
[1693633851084] {
  "id": "chatcmpl-7uDouglFTtv5iE96agcaOSMdMVhuy",
  "object": "chat.completion",
  "created": 1693633848,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 42.53862,\n  \"y\": 17.00157\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1807,
    "completion_tokens": 37,
    "total_tokens": 1844
  }
}
[1693633851084] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 42.53862,\n  \"y\": 17.00157\n}"
  }
}
[1693633851084] [36m[OPENAI] Chat completion took 2615.333125114441ms[39m
[1693633851084] [36m[OPENAI] Global tokens per second: 17.930221818818772tps[39m
[1693633851084] [36m[OPENAI] Tokens per second: 14.147337348614421tps[39m
[1693633851084] [32m[OPENAI] Chat completion created successfully.[39m
[1693633851085] [32m[OPENAI] Embedding created successfully.[39m
[1693633851089] --- Observations received -- 
[1693633851089] {
  "observerId": "A5",
  "observation": "Eli Green has started walking to 42.53862, Y: 17.00157.",
  "time": 54.6727676
}
[1693633851089] [Character] Getting character: A5
[1693633851116] --- Observations received -- 
[1693633851116] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Small) at X: 46.53, Y: 21.65.",
  "time": 54.7000961
}
[1693633851116] [Character] Getting character: A5
[1693633851137] --- Observations received -- 
[1693633851137] {
  "observerId": "A5",
  "observation": "Eli Green finished walking to 42.53862, Y: 17.00157.",
  "time": 54.7199821
}
[1693633851137] [Character] Getting character: A5
[1693633851139] [Character] Getting character: A5
[1693633851152] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633851152] [33m[OPENAI] Creating embedding...[39m
[1693633851175] [33m[OPENAI] Creating embedding...[39m
[1693633851187] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633851187] [33m[OPENAI] Creating embedding...[39m
[1693633851225] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633851225] [33m[OPENAI] Creating embedding...[39m
[1693633851418] [33m[OPENAI] Creating embedding...[39m
[1693633851432] {
  "id": "chatcmpl-7uDoxvLESADo0msU7FY2NFtoiyEbx",
  "object": "chat.completion",
  "created": 1693633851,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693633851432] {
  "role": "assistant",
  "content": "1"
}
[1693633851432] [36m[OPENAI] Chat completion took 280.3125829696655ms[39m
[1693633851433] [36m[OPENAI] Global tokens per second: 17.84724531648376tps[39m
[1693633851433] [36m[OPENAI] Tokens per second: 3.5674459897799755tps[39m
[1693633851433] [32m[OPENAI] Chat completion created successfully.[39m
[1693633851443] {
  "id": "chatcmpl-7uDoxmZQTRL5OoEY5vvsRGaLhX2C9",
  "object": "chat.completion",
  "created": 1693633851,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633851443] {
  "role": "assistant",
  "content": "3"
}
[1693633851443] [36m[OPENAI] Chat completion took 256.00566697120667ms[39m
[1693633851443] [36m[OPENAI] Global tokens per second: 17.859970233382946tps[39m
[1693633851443] [36m[OPENAI] Tokens per second: 3.9061635307958684tps[39m
[1693633851443] [32m[OPENAI] Chat completion created successfully.[39m
[1693633851452] [32m[OPENAI] Embedding created successfully.[39m
[1693633851482] [32m[OPENAI] Embedding created successfully.[39m
[1693633851498] [32m[OPENAI] Embedding created successfully.[39m
[1693633851626] [32m[OPENAI] Embedding created successfully.[39m
[1693633851765] {
  "id": "chatcmpl-7uDoxyLs815UqGq9GQlgA2sqBlCiq",
  "object": "chat.completion",
  "created": 1693633851,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693633851765] {
  "role": "assistant",
  "content": "1"
}
[1693633851765] [36m[OPENAI] Chat completion took 539.6166250705719ms[39m
[1693633851765] [36m[OPENAI] Global tokens per second: 17.785129174543165tps[39m
[1693633851765] [36m[OPENAI] Tokens per second: 1.853167514750344tps[39m
[1693633851765] [32m[OPENAI] Chat completion created successfully.[39m
[1693633851869] [32m[OPENAI] Embedding created successfully.[39m
[1693633851967] {
  "id": "chatcmpl-7uDow5AE3BvvhsCB74yIGmoD8SHEU",
  "object": "chat.completion",
  "created": 1693633850,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_pickaxe",
          "arguments": "{\n  \"characterId\": \"A4\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1904,
    "completion_tokens": 18,
    "total_tokens": 1922
  }
}
[1693633851968] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_pickaxe",
    "arguments": "{\n  \"characterId\": \"A4\"\n}"
  }
}
[1693633851968] [36m[OPENAI] Chat completion took 1959.526792049408ms[39m
[1693633851968] [36m[OPENAI] Global tokens per second: 18.011086161141908tps[39m
[1693633851968] [36m[OPENAI] Tokens per second: 9.185891243249786tps[39m
[1693633851968] [32m[OPENAI] Chat completion created successfully.[39m
[1693633851994] [33m[OPENAI] Creating embedding...[39m
[1693633852077] [33m[OPENAI] Creating embedding...[39m
[1693633852175] [32m[OPENAI] Embedding created successfully.[39m
[1693633852207] [32m[OPENAI] Embedding created successfully.[39m
[1693633852592] [33m[OPENAI] Creating embedding...[39m
[1693633852603] [33m[OPENAI] Creating embedding...[39m
[1693633852785] [32m[OPENAI] Embedding created successfully.[39m
[1693633852820] [32m[OPENAI] Embedding created successfully.[39m
[1693633852982] [Character] Getting character: A4
[1693633853045] [33m[OPENAI] Creating embedding...[39m
[1693633853181] [32m[OPENAI] Embedding created successfully.[39m
[1693633853183] [33m[OPENAI] Creating embedding...[39m
[1693633853267] [33m[OPENAI] Creating embedding...[39m
[1693633853328] [32m[OPENAI] Embedding created successfully.[39m
[1693633853489] [33m[OPENAI] Creating embedding...[39m
[1693633853508] [32m[OPENAI] Embedding created successfully.[39m
[1693633853648] [32m[OPENAI] Embedding created successfully.[39m
[1693633853668] [33m[OPENAI] Creating embedding...[39m
[1693633853804] [32m[OPENAI] Embedding created successfully.[39m
[1693633853906] [33m[OPENAI] Creating embedding...[39m
[1693633854034] [33m[OPENAI] Creating embedding...[39m
[1693633854080] [32m[OPENAI] Embedding created successfully.[39m
[1693633854128] [33m[OPENAI] Creating embedding...[39m
[1693633854191] [32m[OPENAI] Embedding created successfully.[39m
[1693633854312] [32m[OPENAI] Embedding created successfully.[39m
[1693633854449] [33m[OPENAI] Creating embedding...[39m
[1693633854535] [33m[OPENAI] Creating embedding...[39m
[1693633854690] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633854705] [32m[OPENAI] Embedding created successfully.[39m
[1693633854982] [32m[OPENAI] Embedding created successfully.[39m
[1693633855180] [33m[OPENAI] Creating embedding...[39m
[1693633855338] [32m[OPENAI] Embedding created successfully.[39m
[1693633855345] [33m[OPENAI] Creating embedding...[39m
[1693633855480] [32m[OPENAI] Embedding created successfully.[39m
[1693633855708] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633855866] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633857503] {
  "id": "chatcmpl-7uDp0ihmk5BO18PH00Utyl1mPszLK",
  "object": "chat.completion",
  "created": 1693633854,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 65.22,\n  \"y\": 18.37\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1766,
    "completion_tokens": 35,
    "total_tokens": 1801
  }
}
[1693633857503] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 65.22,\n  \"y\": 18.37\n}"
  }
}
[1693633857503] [36m[OPENAI] Chat completion took 2812.147625207901ms[39m
[1693633857503] [36m[OPENAI] Global tokens per second: 17.07648299575255tps[39m
[1693633857503] [36m[OPENAI] Tokens per second: 12.446003789510327tps[39m
[1693633857503] [32m[OPENAI] Chat completion created successfully.[39m
[1693633857514] --- Observations received -- 
[1693633857514] {
  "observerId": "A2",
  "observation": "George Brown has started walking to 65.22, Y: 18.37.",
  "time": 61.0977364
}
[1693633857514] [Character] Getting character: A2
[1693633857575] {
  "id": "chatcmpl-7uDp1z3iwDeS1aG0EKyljzbA3xW6O",
  "object": "chat.completion",
  "created": 1693633855,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_pickaxe",
          "arguments": "{\n  \"characterId\": \"A4\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1948,
    "completion_tokens": 18,
    "total_tokens": 1966
  }
}
[1693633857576] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_pickaxe",
    "arguments": "{\n  \"characterId\": \"A4\"\n}"
  }
}
[1693633857579] [36m[OPENAI] Chat completion took 1867.3280420303345ms[39m
[1693633857579] [36m[OPENAI] Global tokens per second: 17.317516668109793tps[39m
[1693633857579] [36m[OPENAI] Tokens per second: 9.639441809286337tps[39m
[1693633857579] [32m[OPENAI] Chat completion created successfully.[39m
[1693633857584] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633857585] [33m[OPENAI] Creating embedding...[39m
[1693633857688] {
  "id": "chatcmpl-7uDp1YXwUWRDIaPGOF4Mb1bQwjqZC",
  "object": "chat.completion",
  "created": 1693633855,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_pickaxe",
          "arguments": "{\n  \"characterId\": \"A5\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1922,
    "completion_tokens": 18,
    "total_tokens": 1940
  }
}
[1693633857688] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_pickaxe",
    "arguments": "{\n  \"characterId\": \"A5\"\n}"
  }
}
[1693633857688] [36m[OPENAI] Chat completion took 1821.4151668548584ms[39m
[1693633857688] [36m[OPENAI] Global tokens per second: 17.549673645231472tps[39m
[1693633857688] [36m[OPENAI] Tokens per second: 9.882425669641057tps[39m
[1693633857688] [32m[OPENAI] Chat completion created successfully.[39m
[1693633857742] [32m[OPENAI] Embedding created successfully.[39m
[1693633857879] --- Observations received -- 
[1693633857879] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CoalOreMedium (1) at X: 57.27, Y: 17.32",
  "time": 61.46138
}
[1693633857879] [Character] Getting character: A2
[1693633857946] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633857946] [33m[OPENAI] Creating embedding...[39m
[1693633858037] --- Observations received -- 
[1693633858037] {
  "observerId": "A2",
  "observation": "George Brown sees Iron Ore Deposit (Medium) at X: 66.39, Y: 21.18.",
  "time": 61.6201439
}
[1693633858037] [Character] Getting character: A2
[1693633858078] --- Observations received -- 
[1693633858078] {
  "observerId": "A2",
  "observation": "George Brown sees Iron Ore Deposit (Large) at X: 68.08, Y: 19.36.",
  "time": 61.66154
}
[1693633858078] [Character] Getting character: A2
[1693633858093] [32m[OPENAI] Embedding created successfully.[39m
[1693633858114] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633858114] [33m[OPENAI] Creating embedding...[39m
[1693633858116] {
  "id": "chatcmpl-7uDp3uHLLKB6tM4exno1DLCTdSxEi",
  "object": "chat.completion",
  "created": 1693633857,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633858116] {
  "role": "assistant",
  "content": "3"
}
[1693633858117] [36m[OPENAI] Chat completion took 531.8966670036316ms[39m
[1693633858117] [36m[OPENAI] Global tokens per second: 17.456180547599956tps[39m
[1693633858117] [36m[OPENAI] Tokens per second: 1.8800644223498628tps[39m
[1693633858117] [32m[OPENAI] Chat completion created successfully.[39m
[1693633858148] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633858148] [33m[OPENAI] Creating embedding...[39m
[1693633858196] {
  "id": "chatcmpl-7uDp40Xna5mE0lhsl4Js4Dt93Ma0j",
  "object": "chat.completion",
  "created": 1693633858,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633858197] {
  "role": "assistant",
  "content": "7"
}
[1693633858197] [36m[OPENAI] Chat completion took 249.290207862854ms[39m
[1693633858197] [36m[OPENAI] Global tokens per second: 17.450509211580272tps[39m
[1693633858197] [36m[OPENAI] Tokens per second: 4.011389009511942tps[39m
[1693633858197] [32m[OPENAI] Chat completion created successfully.[39m
[1693633858199] --- Observations received -- 
[1693633858199] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Small) at X: 54.06, Y: 24.46.",
  "time": 61.7809677
}
[1693633858208] [Character] Getting character: A4
[1693633858208] --- Observations received -- 
[1693633858208] {
  "observerId": "A4",
  "observation": "Lucy Wilde picked up Copper at X: 53.95826, Y: 25.09559",
  "time": 61.7809677
}
[1693633858208] [Character] Getting character: A4
[1693633858251] [32m[OPENAI] Embedding created successfully.[39m
[1693633858275] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633858275] [33m[OPENAI] Creating embedding...[39m
[1693633858275] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633858276] [33m[OPENAI] Creating embedding...[39m
[1693633858299] --- Observations received -- 
[1693633858299] {
  "observerId": "A2",
  "observation": "George Brown sees Iron Ore Deposit (Large) at X: 64.4, Y: 22.23.",
  "time": 61.88168
}
[1693633858299] [Character] Getting character: A2
[1693633858369] [32m[OPENAI] Embedding created successfully.[39m
[1693633858371] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633858371] [33m[OPENAI] Creating embedding...[39m
[1693633858383] {
  "id": "chatcmpl-7uDp4UGJQjzPGSwxdgaO7j3XduRn6",
  "object": "chat.completion",
  "created": 1693633858,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633858383] {
  "role": "assistant",
  "content": "3"
}
[1693633858383] [36m[OPENAI] Chat completion took 268.46658301353455ms[39m
[1693633858383] [36m[OPENAI] Global tokens per second: 17.418471283060857tps[39m
[1693633858383] [36m[OPENAI] Tokens per second: 3.724858374457672tps[39m
[1693633858383] [32m[OPENAI] Chat completion created successfully.[39m
[1693633858490] [32m[OPENAI] Embedding created successfully.[39m
[1693633858529] [32m[OPENAI] Embedding created successfully.[39m
[1693633858545] {
  "id": "chatcmpl-7uDp48IkNq4BnRzm4Ndx8yVQuIxCk",
  "object": "chat.completion",
  "created": 1693633858,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633858545] {
  "role": "assistant",
  "content": "2"
}
[1693633858545] [36m[OPENAI] Chat completion took 270.2176671028137ms[39m
[1693633858545] [36m[OPENAI] Global tokens per second: 17.392541986905776tps[39m
[1693633858545] [36m[OPENAI] Tokens per second: 3.700720277551339tps[39m
[1693633858545] [32m[OPENAI] Chat completion created successfully.[39m
[1693633858556] [32m[OPENAI] Embedding created successfully.[39m
[1693633858573] {
  "id": "chatcmpl-7uDp4xXsxD9NWWVLd6Ah4t7gjjIlh",
  "object": "chat.completion",
  "created": 1693633858,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693633858573] {
  "role": "assistant",
  "content": "1"
}
[1693633858574] [36m[OPENAI] Chat completion took 298.0683329105377ms[39m
[1693633858574] [36m[OPENAI] Global tokens per second: 17.399593108452247tps[39m
[1693633858574] [36m[OPENAI] Tokens per second: 3.3549353942947717tps[39m
[1693633858574] [32m[OPENAI] Chat completion created successfully.[39m
[1693633858593] [Character] Getting character: A4
[1693633858619] {
  "id": "chatcmpl-7uDp4Zpog8TL1ew5qLFpRMpItxmph",
  "object": "chat.completion",
  "created": 1693633858,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633858619] {
  "role": "assistant",
  "content": "2"
}
[1693633858619] [36m[OPENAI] Chat completion took 247.7135419845581ms[39m
[1693633858619] [36m[OPENAI] Global tokens per second: 17.402678647595756tps[39m
[1693633858619] [36m[OPENAI] Tokens per second: 4.036921001526585tps[39m
[1693633858619] [32m[OPENAI] Chat completion created successfully.[39m
[1693633858630] [33m[OPENAI] Creating embedding...[39m
[1693633858687] {
  "id": "chatcmpl-7uDp4j0Q7U9gERabm6c8PgTbluUJm",
  "object": "chat.completion",
  "created": 1693633858,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633858687] {
  "role": "assistant",
  "content": "2"
}
[1693633858687] [36m[OPENAI] Chat completion took 538.6690418720245ms[39m
[1693633858687] [36m[OPENAI] Global tokens per second: 17.400073861538026tps[39m
[1693633858687] [36m[OPENAI] Tokens per second: 1.8564274578036306tps[39m
[1693633858688] [32m[OPENAI] Chat completion created successfully.[39m
[1693633858698] [Character] Getting character: A5
[1693633858717] --- Observations received -- 
[1693633858717] {
  "observerId": "A2",
  "observation": "George Brown sees Diamond Ore Deposit (Medium) at X: 60.84, Y: 22.05.",
  "time": 62.30033
}
[1693633858717] [Character] Getting character: A2
[1693633858727] [33m[OPENAI] Creating embedding...[39m
[1693633858774] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633858774] [33m[OPENAI] Creating embedding...[39m
[1693633858780] --- Observations received -- 
[1693633858781] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CoalOreSmall (2) at X: 59.32, Y: 14.11",
  "time": 62.3611336
}
[1693633858781] [Character] Getting character: A2
[1693633858843] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633858843] [33m[OPENAI] Creating embedding...[39m
[1693633858859] [32m[OPENAI] Embedding created successfully.[39m
[1693633858871] [32m[OPENAI] Embedding created successfully.[39m
[1693633858991] [32m[OPENAI] Embedding created successfully.[39m
[1693633859014] [32m[OPENAI] Embedding created successfully.[39m
[1693633859066] {
  "id": "chatcmpl-7uDp4UhGjKoTrccU22CMDaOHzEPGK",
  "object": "chat.completion",
  "created": 1693633858,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633859066] {
  "role": "assistant",
  "content": "3"
}
[1693633859066] [36m[OPENAI] Chat completion took 291.47362518310547ms[39m
[1693633859066] [36m[OPENAI] Global tokens per second: 17.32103248046792tps[39m
[1693633859067] [36m[OPENAI] Tokens per second: 3.430842153803089tps[39m
[1693633859067] [32m[OPENAI] Chat completion created successfully.[39m
[1693633859167] {
  "id": "chatcmpl-7uDp4xMR0J2ZPXDOtM6ZS1zq9r2Xs",
  "object": "chat.completion",
  "created": 1693633858,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633859167] {
  "role": "assistant",
  "content": "2"
}
[1693633859167] [36m[OPENAI] Chat completion took 323.6709578037262ms[39m
[1693633859167] [36m[OPENAI] Global tokens per second: 17.31045963714342tps[39m
[1693633859167] [36m[OPENAI] Tokens per second: 3.089557391202207tps[39m
[1693633859167] [32m[OPENAI] Chat completion created successfully.[39m
[1693633859311] [33m[OPENAI] Creating embedding...[39m
[1693633859351] [33m[OPENAI] Creating embedding...[39m
[1693633859378] --- Observations received -- 
[1693633859379] {
  "observerId": "A2",
  "observation": "George Brown sees Iron Ore Deposit (Large) at X: 65.92, Y: 23.75.",
  "time": 62.9616661
}
[1693633859379] [Character] Getting character: A2
[1693633859444] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633859445] [33m[OPENAI] Creating embedding...[39m
[1693633859450] [32m[OPENAI] Embedding created successfully.[39m
[1693633859542] [32m[OPENAI] Embedding created successfully.[39m
[1693633859652] [32m[OPENAI] Embedding created successfully.[39m
[1693633859664] --- Observations received -- 
[1693633859664] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CoalOreLarge (1) at X: 58.91, Y: 19.37",
  "time": 63.2409744
}
[1693633859664] [Character] Getting character: A2
[1693633859730] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633859730] [33m[OPENAI] Creating embedding...[39m
[1693633859754] {
  "id": "chatcmpl-7uDp5XGflw5aoyroplKXG59IH4lzB",
  "object": "chat.completion",
  "created": 1693633859,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633859754] {
  "role": "assistant",
  "content": "1"
}
[1693633859754] [36m[OPENAI] Chat completion took 309.60554218292236ms[39m
[1693633859754] [36m[OPENAI] Global tokens per second: 17.182274832444836tps[39m
[1693633859754] [36m[OPENAI] Tokens per second: 3.2299163411266587tps[39m
[1693633859755] [32m[OPENAI] Chat completion created successfully.[39m
[1693633859778] --- Observations received -- 
[1693633859778] {
  "observerId": "A2",
  "observation": "George Brown sees Iron Ore Deposit (Large) at X: 69.37, Y: 22.11.",
  "time": 63.3617363
}
[1693633859778] [Character] Getting character: A2
[1693633859779] --- Observations received -- 
[1693633859779] {
  "observerId": "A2",
  "observation": "George Brown sees Iron Ore Deposit (Large) at X: 69.37, Y: 22.11.",
  "time": 63.3617363
}
[1693633859779] [Character] Getting character: A2
[1693633859798] --- Observations received -- 
[1693633859798] {
  "observerId": "A2",
  "observation": "George Brown finished walking to 65.22, Y: 18.37.",
  "time": 63.37998
}
[1693633859799] [Character] Getting character: A2
[1693633859800] [Character] Getting character: A2
[1693633859834] [33m[OPENAI] Creating embedding...[39m
[1693633859860] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633859860] [33m[OPENAI] Creating embedding...[39m
[1693633859860] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633859860] [33m[OPENAI] Creating embedding...[39m
[1693633859861] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633859861] [33m[OPENAI] Creating embedding...[39m
[1693633859862] [33m[OPENAI] Creating embedding...[39m
[1693633859883] [32m[OPENAI] Embedding created successfully.[39m
[1693633859892] [33m[OPENAI] Creating embedding...[39m
[1693633859976] {
  "id": "chatcmpl-7uDp5JPU98NMlxch2scyFLxf7ix1o",
  "object": "chat.completion",
  "created": 1693633859,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633859976] {
  "role": "assistant",
  "content": "1"
}
[1693633859976] [36m[OPENAI] Chat completion took 245.95991706848145ms[39m
[1693633859976] [36m[OPENAI] Global tokens per second: 17.14301655716896tps[39m
[1693633859976] [36m[OPENAI] Tokens per second: 4.065703110973057tps[39m
[1693633859976] [32m[OPENAI] Chat completion created successfully.[39m
[1693633860009] [32m[OPENAI] Embedding created successfully.[39m
[1693633860022] [32m[OPENAI] Embedding created successfully.[39m
[1693633860031] [32m[OPENAI] Embedding created successfully.[39m
[1693633860041] [32m[OPENAI] Embedding created successfully.[39m
[1693633860057] [32m[OPENAI] Embedding created successfully.[39m
[1693633860075] [32m[OPENAI] Embedding created successfully.[39m
[1693633860116] {
  "id": "chatcmpl-7uDp5DpXWYFfcJ40pXWIEkv27iFhy",
  "object": "chat.completion",
  "created": 1693633859,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633860116] {
  "role": "assistant",
  "content": "2"
}
[1693633860116] [36m[OPENAI] Chat completion took 255.63612508773804ms[39m
[1693633860116] [36m[OPENAI] Global tokens per second: 17.123526054210576tps[39m
[1693633860116] [36m[OPENAI] Tokens per second: 3.9118101937149357tps[39m
[1693633860116] [32m[OPENAI] Chat completion created successfully.[39m
[1693633860120] {
  "id": "chatcmpl-7uDp54sUARJaf7BWARQZzOvxPvH2F",
  "object": "chat.completion",
  "created": 1693633859,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633860121] {
  "role": "assistant",
  "content": "1"
}
[1693633860121] [36m[OPENAI] Chat completion took 259.5163748264313ms[39m
[1693633860121] [36m[OPENAI] Global tokens per second: 17.136254802605936tps[39m
[1693633860121] [36m[OPENAI] Tokens per second: 3.8533213970363764tps[39m
[1693633860121] [32m[OPENAI] Chat completion created successfully.[39m
[1693633860207] {
  "id": "chatcmpl-7uDp52RQcHkgMzLd4pnGfjhODdCC1",
  "object": "chat.completion",
  "created": 1693633859,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633860207] {
  "role": "assistant",
  "content": "2"
}
[1693633860208] [36m[OPENAI] Chat completion took 347.22116589546204ms[39m
[1693633860208] [36m[OPENAI] Global tokens per second: 17.129430084951963tps[39m
[1693633860208] [36m[OPENAI] Tokens per second: 2.8800087616233343tps[39m
[1693633860208] [32m[OPENAI] Chat completion created successfully.[39m
[1693633860457] [33m[OPENAI] Creating embedding...[39m
[1693633860505] [33m[OPENAI] Creating embedding...[39m
[1693633860591] [33m[OPENAI] Creating embedding...[39m
[1693633860597] [32m[OPENAI] Embedding created successfully.[39m
[1693633860663] [32m[OPENAI] Embedding created successfully.[39m
[1693633860799] [32m[OPENAI] Embedding created successfully.[39m
[1693633860981] [33m[OPENAI] Creating embedding...[39m
[1693633860998] [33m[OPENAI] Creating embedding...[39m
[1693633861208] [33m[OPENAI] Creating embedding...[39m
[1693633861241] [32m[OPENAI] Embedding created successfully.[39m
[1693633861265] [32m[OPENAI] Embedding created successfully.[39m
[1693633861402] [32m[OPENAI] Embedding created successfully.[39m
[1693633861634] [33m[OPENAI] Creating embedding...[39m
[1693633861694] [33m[OPENAI] Creating embedding...[39m
[1693633861774] [32m[OPENAI] Embedding created successfully.[39m
[1693633861859] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633861881] [32m[OPENAI] Embedding created successfully.[39m
[1693633862112] [33m[OPENAI] Creating embedding...[39m
[1693633862292] [33m[OPENAI] Creating embedding...[39m
[1693633862341] [32m[OPENAI] Embedding created successfully.[39m
[1693633862443] [32m[OPENAI] Embedding created successfully.[39m
[1693633862715] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633862830] [33m[OPENAI] Creating embedding...[39m
[1693633862965] [32m[OPENAI] Embedding created successfully.[39m
[1693633863407] [33m[OPENAI] Creating embedding...[39m
[1693633863619] [32m[OPENAI] Embedding created successfully.[39m
[1693633864041] [33m[OPENAI] Creating embedding...[39m
[1693633864205] [32m[OPENAI] Embedding created successfully.[39m
[1693633864604] [33m[OPENAI] Creating embedding...[39m
[1693633864764] [32m[OPENAI] Embedding created successfully.[39m
[1693633865101] [33m[OPENAI] Creating embedding...[39m
[1693633865145] {
  "id": "chatcmpl-7uDp84MAhsEVklg0o3PvIfqKzNnEd",
  "object": "chat.completion",
  "created": 1693633862,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 42.53862,\n  \"y\": 17.00157\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1964,
    "completion_tokens": 37,
    "total_tokens": 2001
  }
}
[1693633865145] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 42.53862,\n  \"y\": 17.00157\n}"
  }
}
[1693633865145] [36m[OPENAI] Chat completion took 2429.9869577884674ms[39m
[1693633865145] [36m[OPENAI] Global tokens per second: 16.510538641686182tps[39m
[1693633865145] [36m[OPENAI] Tokens per second: 15.226419171267372tps[39m
[1693633865145] [32m[OPENAI] Chat completion created successfully.[39m
[1693633865155] --- Observations received -- 
[1693633865155] {
  "observerId": "A5",
  "observation": "Eli Green has started walking to 42.53862, Y: 17.00157.",
  "time": 68.73815
}
[1693633865155] [Character] Getting character: A5
[1693633865213] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633865214] [33m[OPENAI] Creating embedding...[39m
[1693633865218] --- Observations received -- 
[1693633865218] {
  "observerId": "A5",
  "observation": "Eli Green finished walking to 42.53862, Y: 17.00157.",
  "time": 68.79997
}
[1693633865218] [Character] Getting character: A5
[1693633865220] [Character] Getting character: A5
[1693633865227] [32m[OPENAI] Embedding created successfully.[39m
[1693633865254] [33m[OPENAI] Creating embedding...[39m
[1693633865276] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633865276] [33m[OPENAI] Creating embedding...[39m
[1693633865514] [32m[OPENAI] Embedding created successfully.[39m
[1693633865522] [32m[OPENAI] Embedding created successfully.[39m
[1693633865523] [32m[OPENAI] Embedding created successfully.[39m
[1693633865532] {
  "id": "chatcmpl-7uDpBde4j7hdj2SzO4OiAJnTD5KhG",
  "object": "chat.completion",
  "created": 1693633865,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693633865533] {
  "role": "assistant",
  "content": "2"
}
[1693633865533] [36m[OPENAI] Chat completion took 318.93504190444946ms[39m
[1693633865533] [36m[OPENAI] Global tokens per second: 16.440555095277546tps[39m
[1693633865533] [36m[OPENAI] Tokens per second: 3.1354347080481433tps[39m
[1693633865533] [32m[OPENAI] Chat completion created successfully.[39m
[1693633865617] {
  "id": "chatcmpl-7uDpBTxH1LD7G9dHGgEuCfzyrq4fn",
  "object": "chat.completion",
  "created": 1693633865,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693633865617] {
  "role": "assistant",
  "content": "3"
}
[1693633865617] [36m[OPENAI] Chat completion took 341.24462485313416ms[39m
[1693633865617] [36m[OPENAI] Global tokens per second: 16.435628200486217tps[39m
[1693633865617] [36m[OPENAI] Tokens per second: 2.9304490889208377tps[39m
[1693633865617] [32m[OPENAI] Chat completion created successfully.[39m
[1693633865700] --- Observations received -- 
[1693633865701] {
  "observerId": "A5",
  "observation": "Thomas Smith started a conversation with me.",
  "time": 69.2775955
}
[1693633865701] [Character] Getting character: A5
[1693633865775] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633865775] [33m[OPENAI] Creating embedding...[39m
[1693633865803] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633865921] [32m[OPENAI] Embedding created successfully.[39m
[1693633865971] [33m[OPENAI] Creating embedding...[39m
[1693633866126] [32m[OPENAI] Embedding created successfully.[39m
[1693633866177] {
  "id": "chatcmpl-7uDpBLEJyUK5b9hsgwvyhZXudRC5N",
  "object": "chat.completion",
  "created": 1693633865,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 90,
    "completion_tokens": 1,
    "total_tokens": 91
  }
}
[1693633866177] {
  "role": "assistant",
  "content": "3"
}
[1693633866177] [36m[OPENAI] Chat completion took 402.3882908821106ms[39m
[1693633866177] [36m[OPENAI] Global tokens per second: 16.330303497149902tps[39m
[1693633866177] [36m[OPENAI] Tokens per second: 2.4851617769687397tps[39m
[1693633866177] [32m[OPENAI] Chat completion created successfully.[39m
[1693633866592] [33m[OPENAI] Creating embedding...[39m
[1693633866769] [32m[OPENAI] Embedding created successfully.[39m
[1693633867242] [33m[OPENAI] Creating embedding...[39m
[1693633867389] [32m[OPENAI] Embedding created successfully.[39m
[1693633867812] {
  "id": "chatcmpl-7uDpBFzCEyWmA9IIR77jvTExuwZ8z",
  "object": "chat.completion",
  "created": 1693633865,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.13,\n  \"y\": 26.69\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1977,
    "completion_tokens": 35,
    "total_tokens": 2012
  }
}
[1693633867812] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.13,\n  \"y\": 26.69\n}"
  }
}
[1693633867812] [36m[OPENAI] Chat completion took 5952.115791082382ms[39m
[1693633867812] [36m[OPENAI] Global tokens per second: 16.43466998629396tps[39m
[1693633867812] [36m[OPENAI] Tokens per second: 5.88026194860623tps[39m
[1693633867812] [32m[OPENAI] Chat completion created successfully.[39m
[1693633867820] --- Observations received -- 
[1693633867820] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 53.13, Y: 26.69.",
  "time": 71.40099
}
[1693633867820] [Character] Getting character: A4
[1693633867820] [33m[OPENAI] Creating embedding...[39m
[1693633867856] --- Observations received -- 
[1693633867857] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Large) at X: 49.04, Y: 28.68.",
  "time": 71.44029
}
[1693633867857] [Character] Getting character: A4
[1693633867880] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633867880] [33m[OPENAI] Creating embedding...[39m
[1693633867892] {
  "id": "chatcmpl-7uDpB79n3GPzL3lnNDcHrLJlxX7XS",
  "object": "chat.completion",
  "created": 1693633865,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_pickaxe",
          "arguments": "{\n  \"characterId\": \"A2\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1985,
    "completion_tokens": 18,
    "total_tokens": 2003
  }
}
[1693633867892] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_pickaxe",
    "arguments": "{\n  \"characterId\": \"A2\"\n}"
  }
}
[1693633867893] [36m[OPENAI] Chat completion took 2088.9895000457764ms[39m
[1693633867893] [36m[OPENAI] Global tokens per second: 16.64405587378153tps[39m
[1693633867893] [36m[OPENAI] Tokens per second: 8.616606258483138tps[39m
[1693633867893] [32m[OPENAI] Chat completion created successfully.[39m
[1693633867915] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633867915] [33m[OPENAI] Creating embedding...[39m
[1693633867980] [32m[OPENAI] Embedding created successfully.[39m
[1693633868073] [32m[OPENAI] Embedding created successfully.[39m
[1693633868097] [32m[OPENAI] Embedding created successfully.[39m
[1693633868202] {
  "id": "chatcmpl-7uDpDBU9Pxv9qogv7unEAqYFYiXa2",
  "object": "chat.completion",
  "created": 1693633867,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633868202] {
  "role": "assistant",
  "content": "2"
}
[1693633868202] [36m[OPENAI] Chat completion took 322.0480420589447ms[39m
[1693633868202] [36m[OPENAI] Global tokens per second: 16.592214422463304tps[39m
[1693633868202] [36m[OPENAI] Tokens per second: 3.1051267804850347tps[39m
[1693633868202] [32m[OPENAI] Chat completion created successfully.[39m
[1693633868271] {
  "id": "chatcmpl-7uDpElkBbTiqQhI9SjXSsDJbN8D65",
  "object": "chat.completion",
  "created": 1693633868,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633868271] {
  "role": "assistant",
  "content": "2"
}
[1693633868271] [36m[OPENAI] Chat completion took 356.23916697502136ms[39m
[1693633868271] [36m[OPENAI] Global tokens per second: 16.5904033205811tps[39m
[1693633868271] [36m[OPENAI] Tokens per second: 2.8071029036235022tps[39m
[1693633868271] [32m[OPENAI] Chat completion created successfully.[39m
[1693633868453] [33m[OPENAI] Creating embedding...[39m
[1693633868458] --- Observations received -- 
[1693633868458] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees DiamondOreSmall at X: 58.32, Y: 22.87",
  "time": 72.0404
}
[1693633868458] [Character] Getting character: A4
[1693633868479] --- Observations received -- 
[1693633868479] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 53.13, Y: 26.69.",
  "time": 72.0599747
}
[1693633868479] [Character] Getting character: A4
[1693633868481] [Character] Getting character: A4
[1693633868512] [33m[OPENAI] Creating embedding...[39m
[1693633868520] --- Observations received -- 
[1693633868520] {
  "observerId": "A2",
  "observation": "George Brown sees Iron Ore Deposit (Medium) at X: 65.22, Y: 18.37.",
  "time": 72.10082
}
[1693633868520] [Character] Getting character: A2
[1693633868520] --- Observations received -- 
[1693633868520] {
  "observerId": "A2",
  "observation": "George Brown picked up Iron at X: 64.86655, Y: 18.43103",
  "time": 72.10082
}
[1693633868520] [Character] Getting character: A2
[1693633868524] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633868524] [33m[OPENAI] Creating embedding...[39m
[1693633868565] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633868566] [33m[OPENAI] Creating embedding...[39m
[1693633868582] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633868585] [33m[OPENAI] Creating embedding...[39m
[1693633868585] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633868585] [33m[OPENAI] Creating embedding...[39m
[1693633868599] [32m[OPENAI] Embedding created successfully.[39m
[1693633868682] [32m[OPENAI] Embedding created successfully.[39m
[1693633868687] [32m[OPENAI] Embedding created successfully.[39m
[1693633868806] [32m[OPENAI] Embedding created successfully.[39m
[1693633868820] {
  "id": "chatcmpl-7uDpEysxkTwP31loPAz0tyKKvgXYz",
  "object": "chat.completion",
  "created": 1693633868,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693633868820] {
  "role": "assistant",
  "content": "6"
}
[1693633868820] [36m[OPENAI] Chat completion took 295.9687080383301ms[39m
[1693633868820] [36m[OPENAI] Global tokens per second: 16.489724964301235tps[39m
[1693633868820] [36m[OPENAI] Tokens per second: 3.3787355650803894tps[39m
[1693633868820] [32m[OPENAI] Chat completion created successfully.[39m
[1693633868848] [32m[OPENAI] Embedding created successfully.[39m
[1693633868848] {
  "id": "chatcmpl-7uDpEaVybwLOLt5Nmb2nv81Lrpy2l",
  "object": "chat.completion",
  "created": 1693633868,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693633868848] {
  "role": "assistant",
  "content": "1"
}
[1693633868848] [36m[OPENAI] Chat completion took 263.59016704559326ms[39m
[1693633868848] [36m[OPENAI] Global tokens per second: 16.496406538981915tps[39m
[1693633868848] [36m[OPENAI] Tokens per second: 3.7937682243929447tps[39m
[1693633868848] [32m[OPENAI] Chat completion created successfully.[39m
[1693633868867] {
  "id": "chatcmpl-7uDpECNSbAmjFYq9PO2aBlbbH6mtp",
  "object": "chat.completion",
  "created": 1693633868,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633868867] {
  "role": "assistant",
  "content": "4"
}
[1693633868867] [36m[OPENAI] Chat completion took 301.1426658630371ms[39m
[1693633868867] [36m[OPENAI] Global tokens per second: 16.504926658558986tps[39m
[1693633868867] [36m[OPENAI] Tokens per second: 3.3206852211861957tps[39m
[1693633868867] [32m[OPENAI] Chat completion created successfully.[39m
[1693633868902] [Character] Getting character: A2
[1693633868959] [33m[OPENAI] Creating embedding...[39m
[1693633869025] [33m[OPENAI] Creating embedding...[39m
[1693633869052] {
  "id": "chatcmpl-7uDpEaa1tQh2XMaJXi91mGnEYlYCM",
  "object": "chat.completion",
  "created": 1693633868,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633869052] {
  "role": "assistant",
  "content": "4"
}
[1693633869052] [36m[OPENAI] Chat completion took 468.02091693878174ms[39m
[1693633869053] [36m[OPENAI] Global tokens per second: 16.479502767219287tps[39m
[1693633869053] [36m[OPENAI] Tokens per second: 2.13665664035012tps[39m
[1693633869053] [32m[OPENAI] Chat completion created successfully.[39m
[1693633869097] [32m[OPENAI] Embedding created successfully.[39m
[1693633869120] [32m[OPENAI] Embedding created successfully.[39m
[1693633869141] [33m[OPENAI] Creating embedding...[39m
[1693633869246] [32m[OPENAI] Embedding created successfully.[39m
[1693633869277] [32m[OPENAI] Embedding created successfully.[39m
[1693633869438] [33m[OPENAI] Creating embedding...[39m
[1693633869571] [33m[CONVERSATION] Starting conversation as player ...[39m
[1693633869571] [33m[CONVERSATION] Starting conversation...[39m
[1693633869571] [33m[CONVERSATION] Player: A1[39m
[1693633869571] [33m[CONVERSATION] Character: A5[39m
[1693633869632] [33m[OPENAI] Creating embedding...[39m
[1693633869678] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633869684] [32m[OPENAI] Embedding created successfully.[39m
[1693633869717] [33m[OPENAI] Creating embedding...[39m
[1693633869806] [32m[OPENAI] Embedding created successfully.[39m
[1693633869912] [32m[OPENAI] Embedding created successfully.[39m
[1693633870077] [33m[OPENAI] Creating embedding...[39m
[1693633870250] [32m[OPENAI] Embedding created successfully.[39m
[1693633870356] [33m[OPENAI] Creating embedding...[39m
[1693633870524] [32m[OPENAI] Embedding created successfully.[39m
[1693633870635] [33m[OPENAI] Creating embedding...[39m
[1693633870803] [32m[OPENAI] Embedding created successfully.[39m
[1693633870944] [33m[OPENAI] Creating embedding...[39m
[1693633871148] [33m[OPENAI] Creating embedding...[39m
[1693633871231] [32m[OPENAI] Embedding created successfully.[39m
[1693633871371] [32m[OPENAI] Embedding created successfully.[39m
[1693633871602] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633871744] [33m[OPENAI] Creating embedding...[39m
[1693633871999] [32m[OPENAI] Embedding created successfully.[39m
[1693633872366] [33m[OPENAI] Creating embedding...[39m
[1693633872597] {
  "id": "chatcmpl-7uDpFsExAxoeAXJ8OtJYTJc6GMqY8",
  "object": "chat.completion",
  "created": 1693633869,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 42.53862,\n  \"y\": 17.00157\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2028,
    "completion_tokens": 37,
    "total_tokens": 2065
  }
}
[1693633872597] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 42.53862,\n  \"y\": 17.00157\n}"
  }
}
[1693633872597] [36m[OPENAI] Chat completion took 2918.268082857132ms[39m
[1693633872597] [36m[OPENAI] Global tokens per second: 16.225448334756617tps[39m
[1693633872597] [36m[OPENAI] Tokens per second: 12.678752927926734tps[39m
[1693633872597] [32m[OPENAI] Chat completion created successfully.[39m
[1693633872597] [32m[OPENAI] Embedding created successfully.[39m
[1693633872980] [33m[OPENAI] Creating embedding...[39m
[1693633873205] [32m[OPENAI] Embedding created successfully.[39m
[1693633873575] [33m[OPENAI] Creating embedding...[39m
[1693633873695] [32m[OPENAI] Embedding created successfully.[39m
[1693633873993] [33m[OPENAI] Creating embedding...[39m
[1693633874115] [32m[OPENAI] Embedding created successfully.[39m
[1693633874430] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633875100] {
  "id": "chatcmpl-7uDpHhSW5jeZFT5EJv5fUITYlEf09",
  "object": "chat.completion",
  "created": 1693633871,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "{ \"function\": \"functions.move_to\", \"arguments\": { \"characterId\": \"A4\", \"x\": 53.13, \"y\": 26.69 } }"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 2058,
    "completion_tokens": 39,
    "total_tokens": 2097
  }
}
[1693633875101] {
  "role": "assistant",
  "content": "{ \"function\": \"functions.move_to\", \"arguments\": { \"characterId\": \"A4\", \"x\": 53.13, \"y\": 26.69 } }"
}
[1693633875101] [36m[OPENAI] Chat completion took 3497.7861659526825ms[39m
[1693633875101] [36m[OPENAI] Global tokens per second: 16.20669001105787tps[39m
[1693633875101] [36m[OPENAI] Tokens per second: 11.149909728508998tps[39m
[1693633875101] [32m[OPENAI] Chat completion created successfully.[39m
[1693633875105] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633877283] {
  "id": "chatcmpl-7uDpKsB40mp5tRgcnFSMCHsaDdeFq",
  "object": "chat.completion",
  "created": 1693633874,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 62.95,\n  \"y\": 20.13\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2012,
    "completion_tokens": 35,
    "total_tokens": 2047
  }
}
[1693633877283] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 62.95,\n  \"y\": 20.13\n}"
  }
}
[1693633877283] [36m[OPENAI] Chat completion took 2851.9747500419617ms[39m
[1693633877283] [36m[OPENAI] Global tokens per second: 16.202611294635833tps[39m
[1693633877283] [36m[OPENAI] Tokens per second: 12.272198412515761tps[39m
[1693633877283] [32m[OPENAI] Chat completion created successfully.[39m
[1693633877292] --- Observations received -- 
[1693633877292] {
  "observerId": "A2",
  "observation": "George Brown has started walking to 62.95, Y: 20.13.",
  "time": 80.87383
}
[1693633877292] [Character] Getting character: A2
[1693633877351] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633877351] [33m[OPENAI] Creating embedding...[39m
[1693633877500] --- Observations received -- 
[1693633877501] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Large) at X: 58.91, Y: 19.37.",
  "time": 81.08022
}
[1693633877501] [Character] Getting character: A2
[1693633877564] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633877564] [33m[OPENAI] Creating embedding...[39m
[1693633877596] --- Observations received -- 
[1693633877596] {
  "observerId": "A2",
  "observation": "George Brown no longer sees IronOreSmall (4) at X: 69.37, Y: 22.11",
  "time": 81.1801147
}
[1693633877596] [Character] Getting character: A2
[1693633877597] --- Observations received -- 
[1693633877597] {
  "observerId": "A2",
  "observation": "George Brown no longer sees IronOreSmall (2) at X: 69.37, Y: 22.11",
  "time": 81.1801147
}
[1693633877597] [Character] Getting character: A2
[1693633877611] [32m[OPENAI] Embedding created successfully.[39m
[1693633877655] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633877655] [33m[OPENAI] Creating embedding...[39m
[1693633877664] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633877664] [33m[OPENAI] Creating embedding...[39m
[1693633877748] {
  "id": "chatcmpl-7uDpL7fUOXuyACwF6opH27YcBwh2Z",
  "object": "chat.completion",
  "created": 1693633875,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.13,\n  \"y\": 26.69\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2058,
    "completion_tokens": 35,
    "total_tokens": 2093
  }
}
[1693633877748] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.13,\n  \"y\": 26.69\n}"
  }
}
[1693633877748] [36m[OPENAI] Chat completion took 2642.611209154129ms[39m
[1693633877748] [36m[OPENAI] Global tokens per second: 16.509618501503414tps[39m
[1693633877748] [36m[OPENAI] Tokens per second: 13.244475721119459tps[39m
[1693633877748] [32m[OPENAI] Chat completion created successfully.[39m
[1693633877753] --- Observations received -- 
[1693633877753] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 53.13, Y: 26.69.",
  "time": 81.33694
}
[1693633877753] [Character] Getting character: A4
[1693633877776] --- Observations received -- 
[1693633877776] {
  "observerId": "A2",
  "observation": "George Brown sees Iron Ore Deposit (Large) at X: 63.58, Y: 24.8.",
  "time": 81.3601
}
[1693633877776] [Character] Getting character: A2
[1693633877788] [32m[OPENAI] Embedding created successfully.[39m
[1693633877798] --- Observations received -- 
[1693633877798] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 53.13, Y: 26.69.",
  "time": 81.3799744
}
[1693633877798] [Character] Getting character: A4
[1693633877799] [Character] Getting character: A4
[1693633877810] {
  "id": "chatcmpl-7uDpNHhKhNErTBh1wwyvEjWhtUzwi",
  "object": "chat.completion",
  "created": 1693633877,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633877810] {
  "role": "assistant",
  "content": "5"
}
[1693633877810] [36m[OPENAI] Chat completion took 458.74349999427795ms[39m
[1693633877810] [36m[OPENAI] Global tokens per second: 16.509354928790838tps[39m
[1693633877810] [36m[OPENAI] Tokens per second: 2.1798673986933292tps[39m
[1693633877810] [32m[OPENAI] Chat completion created successfully.[39m
[1693633877817] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633877818] [33m[OPENAI] Creating embedding...[39m
[1693633877830] [33m[OPENAI] Creating embedding...[39m
[1693633877832] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633877832] [33m[OPENAI] Creating embedding...[39m
[1693633877857] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633877857] [33m[OPENAI] Creating embedding...[39m
[1693633877875] {
  "id": "chatcmpl-7uDpN1oDQt6ie2AfTRlbw5bBBTzEM",
  "object": "chat.completion",
  "created": 1693633877,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633877875] {
  "role": "assistant",
  "content": "3"
}
[1693633877876] [36m[OPENAI] Chat completion took 311.5826668739319ms[39m
[1693633877876] [36m[OPENAI] Global tokens per second: 16.50835463383599tps[39m
[1693633877876] [36m[OPENAI] Tokens per second: 3.2094211466666906tps[39m
[1693633877876] [32m[OPENAI] Chat completion created successfully.[39m
[1693633877886] [32m[OPENAI] Embedding created successfully.[39m
[1693633877961] {
  "id": "chatcmpl-7uDpNmVRsYKphdnpaMbQg5VmhXspH",
  "object": "chat.completion",
  "created": 1693633877,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633877962] {
  "role": "assistant",
  "content": "3"
}
[1693633877962] [36m[OPENAI] Chat completion took 306.0557918548584ms[39m
[1693633877962] [36m[OPENAI] Global tokens per second: 16.503674297757506tps[39m
[1693633877962] [36m[OPENAI] Tokens per second: 3.2673781271691555tps[39m
[1693633877962] [32m[OPENAI] Chat completion created successfully.[39m
[1693633877983] [32m[OPENAI] Embedding created successfully.[39m
[1693633878027] [32m[OPENAI] Embedding created successfully.[39m
[1693633878028] {
  "id": "chatcmpl-7uDpNHfCEDA4U6q9SFNbUHoNBW9db",
  "object": "chat.completion",
  "created": 1693633877,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 2,
    "total_tokens": 110
  }
}
[1693633878028] {
  "role": "assistant",
  "content": "2."
}
[1693633878028] [36m[OPENAI] Chat completion took 363.95875000953674ms[39m
[1693633878028] [36m[OPENAI] Global tokens per second: 16.513822805121293tps[39m
[1693633878028] [36m[OPENAI] Tokens per second: 5.495128225238696tps[39m
[1693633878028] [32m[OPENAI] Chat completion created successfully.[39m
[1693633878034] [32m[OPENAI] Embedding created successfully.[39m
[1693633878104] {
  "id": "chatcmpl-7uDpNrBjNFyasBg2toWdQyoZoVHyP",
  "object": "chat.completion",
  "created": 1693633877,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633878104] {
  "role": "assistant",
  "content": "1"
}
[1693633878104] [36m[OPENAI] Chat completion took 286.03804206848145ms[39m
[1693633878104] [36m[OPENAI] Global tokens per second: 16.510983199545752tps[39m
[1693633878104] [36m[OPENAI] Tokens per second: 3.4960384736537464tps[39m
[1693633878104] [32m[OPENAI] Chat completion created successfully.[39m
[1693633878212] {
  "id": "chatcmpl-7uDpNYTnJ7SIPpAUqxAU5cmRY89KV",
  "object": "chat.completion",
  "created": 1693633877,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633878212] {
  "role": "assistant",
  "content": "2"
}
[1693633878212] [36m[OPENAI] Chat completion took 379.850417137146ms[39m
[1693633878212] [36m[OPENAI] Global tokens per second: 16.502274066743023tps[39m
[1693633878212] [36m[OPENAI] Tokens per second: 2.6326152476987996tps[39m
[1693633878212] [32m[OPENAI] Chat completion created successfully.[39m
[1693633878238] --- Observations received -- 
[1693633878238] {
  "observerId": "A2",
  "observation": "George Brown sees Diamond Ore Deposit (Large) at X: 60.38, Y: 24.68.",
  "time": 81.82114
}
[1693633878239] [Character] Getting character: A2
[1693633878314] {
  "id": "chatcmpl-7uDpOq62srCSO0mwpY2mYYKYJmvig",
  "object": "chat.completion",
  "created": 1693633878,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633878314] {
  "role": "assistant",
  "content": "2"
}
[1693633878314] [36m[OPENAI] Chat completion took 456.73029088974ms[39m
[1693633878314] [36m[OPENAI] Global tokens per second: 16.494685045929646tps[39m
[1693633878314] [36m[OPENAI] Tokens per second: 2.1894759772817687tps[39m
[1693633878314] [32m[OPENAI] Chat completion created successfully.[39m
[1693633878341] [32m[OPENAI] Embedding created successfully.[39m
[1693633878347] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633878348] [33m[OPENAI] Creating embedding...[39m
[1693633878470] [33m[OPENAI] Creating embedding...[39m
[1693633878540] [32m[OPENAI] Embedding created successfully.[39m
[1693633878577] --- Observations received -- 
[1693633878577] {
  "observerId": "A2",
  "observation": "George Brown sees Diamond Ore Deposit (Small) at X: 58.32, Y: 22.87.",
  "time": 82.16069
}
[1693633878577] [Character] Getting character: A2
[1693633878641] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633878643] [33m[OPENAI] Creating embedding...[39m
[1693633878649] [32m[OPENAI] Embedding created successfully.[39m
[1693633878654] [32m[OPENAI] Embedding created successfully.[39m
[1693633878778] [32m[OPENAI] Embedding created successfully.[39m
[1693633878803] {
  "id": "chatcmpl-7uDpOLUxIpE2B5A9fcmiMYtSl41CL",
  "object": "chat.completion",
  "created": 1693633878,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633878803] {
  "role": "assistant",
  "content": "1"
}
[1693633878803] [36m[OPENAI] Chat completion took 455.12716698646545ms[39m
[1693633878803] [36m[OPENAI] Global tokens per second: 16.41662431781524tps[39m
[1693633878803] [36m[OPENAI] Tokens per second: 2.19718811035013tps[39m
[1693633878803] [32m[OPENAI] Chat completion created successfully.[39m
[1693633878897] --- Observations received -- 
[1693633878897] {
  "observerId": "A2",
  "observation": "George Brown finished walking to 62.95, Y: 20.13.",
  "time": 82.47997
}
[1693633878897] [Character] Getting character: A2
[1693633878899] [Character] Getting character: A2
[1693633878923] [33m[OPENAI] Creating embedding...[39m
[1693633878938] {
  "id": "chatcmpl-7uDpOv6XBTKx7q5wVtjqYqSyNV6sa",
  "object": "chat.completion",
  "created": 1693633878,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633878938] {
  "role": "assistant",
  "content": "1"
}
[1693633878938] [36m[OPENAI] Chat completion took 295.5222499370575ms[39m
[1693633878938] [36m[OPENAI] Global tokens per second: 16.40320783647535tps[39m
[1693633878938] [36m[OPENAI] Tokens per second: 3.3838399653934257tps[39m
[1693633878938] [32m[OPENAI] Chat completion created successfully.[39m
[1693633878947] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633878947] [33m[OPENAI] Creating embedding...[39m
[1693633879091] [33m[OPENAI] Creating embedding...[39m
[1693633879110] [32m[OPENAI] Embedding created successfully.[39m
[1693633879180] [32m[OPENAI] Embedding created successfully.[39m
[1693633879226] {
  "id": "chatcmpl-7uDpPzC9volxvT0zY7ezvgsrnFboy",
  "object": "chat.completion",
  "created": 1693633879,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633879226] {
  "role": "assistant",
  "content": "1"
}
[1693633879226] [36m[OPENAI] Chat completion took 277.7862079143524ms[39m
[1693633879227] [36m[OPENAI] Global tokens per second: 16.362256847846407tps[39m
[1693633879227] [36m[OPENAI] Tokens per second: 3.599890748745603tps[39m
[1693633879227] [32m[OPENAI] Chat completion created successfully.[39m
[1693633879315] [32m[OPENAI] Embedding created successfully.[39m
[1693633879604] [33m[OPENAI] Creating embedding...[39m
[1693633879759] [32m[OPENAI] Embedding created successfully.[39m
[1693633879790] [33m[OPENAI] Creating embedding...[39m
[1693633879957] [32m[OPENAI] Embedding created successfully.[39m
[1693633880264] [33m[OPENAI] Creating embedding...[39m
[1693633880427] [32m[OPENAI] Embedding created successfully.[39m
[1693633880450] [33m[OPENAI] Creating embedding...[39m
[1693633880635] [32m[OPENAI] Embedding created successfully.[39m
[1693633880813] [33m[OPENAI] Creating embedding...[39m
[1693633881035] [32m[OPENAI] Embedding created successfully.[39m
[1693633881073] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633881412] [33m[OPENAI] Creating embedding...[39m
[1693633881589] [32m[OPENAI] Embedding created successfully.[39m
[1693633881975] [33m[OPENAI] Creating embedding...[39m
[1693633882218] [32m[OPENAI] Embedding created successfully.[39m
[1693633882690] [33m[OPENAI] Creating embedding...[39m
[1693633882698] {
  "id": "chatcmpl-7uDpRwEyxsCqXIVm2ZIklNmkZ3wnq",
  "object": "chat.completion",
  "created": 1693633881,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_pickaxe",
          "arguments": "{\n\"characterId\": \"A4\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2086,
    "completion_tokens": 17,
    "total_tokens": 2103
  }
}
[1693633882698] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_pickaxe",
    "arguments": "{\n\"characterId\": \"A4\"\n}"
  }
}
[1693633882699] [36m[OPENAI] Chat completion took 1624.6791660785675ms[39m
[1693633882699] [36m[OPENAI] Global tokens per second: 15.940432562967356tps[39m
[1693633882699] [36m[OPENAI] Tokens per second: 10.463604356441843tps[39m
[1693633882699] [32m[OPENAI] Chat completion created successfully.[39m
[1693633882894] [32m[OPENAI] Embedding created successfully.[39m
[1693633883375] [33m[OPENAI] Creating embedding...[39m
[1693633883531] [32m[OPENAI] Embedding created successfully.[39m
[1693633883715] [Character] Getting character: A4
[1693633883747] [33m[OPENAI] Creating embedding...[39m
[1693633883975] [33m[OPENAI] Creating embedding...[39m
[1693633884552] [32m[OPENAI] Embedding created successfully.[39m
[1693633884990] [32m[OPENAI] Embedding created successfully.[39m
[1693633885030] [33m[OPENAI] Creating embedding...[39m
[1693633885214] [32m[OPENAI] Embedding created successfully.[39m
[1693633885365] [33m[OPENAI] Creating embedding...[39m
[1693633885538] [32m[OPENAI] Embedding created successfully.[39m
[1693633885804] [33m[OPENAI] Creating embedding...[39m
[1693633885848] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633885965] [32m[OPENAI] Embedding created successfully.[39m
[1693633886302] [33m[OPENAI] Creating embedding...[39m
[1693633886459] [32m[OPENAI] Embedding created successfully.[39m
[1693633886930] [33m[OPENAI] Creating embedding...[39m
[1693633887099] [32m[OPENAI] Embedding created successfully.[39m
[1693633887545] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633887625] {
  "id": "chatcmpl-7uDpVUVhx7zaJuom4Z1Rv4Fm8v3R4",
  "object": "chat.completion",
  "created": 1693633885,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_pickaxe",
          "arguments": "{\n  \"characterId\": \"A2\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2293,
    "completion_tokens": 18,
    "total_tokens": 2311
  }
}
[1693633887625] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_pickaxe",
    "arguments": "{\n  \"characterId\": \"A2\"\n}"
  }
}
[1693633887625] [36m[OPENAI] Chat completion took 1776.047166109085ms[39m
[1693633887625] [36m[OPENAI] Global tokens per second: 15.3311858264546tps[39m
[1693633887625] [36m[OPENAI] Tokens per second: 10.134865978494197tps[39m
[1693633887625] [32m[OPENAI] Chat completion created successfully.[39m
[1693633888257] --- Observations received -- 
[1693633888257] {
  "observerId": "A2",
  "observation": "George Brown picked up Coal at X: 63.11706, Y: 20.44167",
  "time": 91.84105
}
[1693633888257] [Character] Getting character: A2
[1693633888319] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633888319] [33m[OPENAI] Creating embedding...[39m
[1693633888535] [32m[OPENAI] Embedding created successfully.[39m
[1693633888594] {
  "id": "chatcmpl-7uDpYdyavuNsNKPawd5ceNJB43kmj",
  "object": "chat.completion",
  "created": 1693633888,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693633888595] {
  "role": "assistant",
  "content": "1"
}
[1693633888595] [36m[OPENAI] Chat completion took 275.532958984375ms[39m
[1693633888595] [36m[OPENAI] Global tokens per second: 15.192902003788257tps[39m
[1693633888595] [36m[OPENAI] Tokens per second: 3.6293298764911395tps[39m
[1693633888595] [32m[OPENAI] Chat completion created successfully.[39m
[1693633888643] [Character] Getting character: A2
[1693633888671] [33m[OPENAI] Creating embedding...[39m
[1693633888845] [32m[OPENAI] Embedding created successfully.[39m
[1693633889374] [33m[OPENAI] Creating embedding...[39m
[1693633889540] [32m[OPENAI] Embedding created successfully.[39m
[1693633889972] [33m[OPENAI] Creating embedding...[39m
[1693633890205] {
  "id": "chatcmpl-7uDpXQUztfPuBWzjkdtfiszcZZidw",
  "object": "chat.completion",
  "created": 1693633887,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n\"characterId\": \"A4\",\n\"x\": 53.13,\n\"y\": 26.69\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2106,
    "completion_tokens": 31,
    "total_tokens": 2137
  }
}
[1693633890205] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n\"characterId\": \"A4\",\n\"x\": 53.13,\n\"y\": 26.69\n}"
  }
}
[1693633890205] [36m[OPENAI] Chat completion took 2659.4769580364227ms[39m
[1693633890205] [36m[OPENAI] Global tokens per second: 15.25706436420722tps[39m
[1693633890205] [36m[OPENAI] Tokens per second: 11.656427368668874tps[39m
[1693633890205] [32m[OPENAI] Chat completion created successfully.[39m
[1693633890210] [32m[OPENAI] Embedding created successfully.[39m
[1693633890211] --- Observations received -- 
[1693633890211] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 53.13, Y: 26.69.",
  "time": 93.79403
}
[1693633890211] [Character] Getting character: A4
[1693633890257] --- Observations received -- 
[1693633890257] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 53.13, Y: 26.69.",
  "time": 93.8399658
}
[1693633890257] [Character] Getting character: A4
[1693633890260] [Character] Getting character: A4
[1693633890283] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633890284] [33m[OPENAI] Creating embedding...[39m
[1693633890289] [33m[OPENAI] Creating embedding...[39m
[1693633890321] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633890322] [33m[OPENAI] Creating embedding...[39m
[1693633890448] [32m[OPENAI] Embedding created successfully.[39m
[1693633890466] [32m[OPENAI] Embedding created successfully.[39m
[1693633890533] [32m[OPENAI] Embedding created successfully.[39m
[1693633890543] {
  "id": "chatcmpl-7uDpaGH8lYzfjlnwb12t5olbGgvOD",
  "object": "chat.completion",
  "created": 1693633890,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633890544] {
  "role": "assistant",
  "content": "2"
}
[1693633890544] [36m[OPENAI] Chat completion took 259.83662509918213ms[39m
[1693633890544] [36m[OPENAI] Global tokens per second: 15.216264583068483tps[39m
[1693633890544] [36m[OPENAI] Tokens per second: 3.848572154207631tps[39m
[1693633890544] [32m[OPENAI] Chat completion created successfully.[39m
[1693633890716] [33m[OPENAI] Creating embedding...[39m
[1693633890720] {
  "id": "chatcmpl-7uDpazbUtOZiO4oaXepRphDkrrliu",
  "object": "chat.completion",
  "created": 1693633890,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633890720] {
  "role": "assistant",
  "content": "3"
}
[1693633890720] [36m[OPENAI] Chat completion took 398.35837507247925ms[39m
[1693633890720] [36m[OPENAI] Global tokens per second: 15.199882852540636tps[39m
[1693633890720] [36m[OPENAI] Tokens per second: 2.5103024376431278tps[39m
[1693633890720] [32m[OPENAI] Chat completion created successfully.[39m
[1693633890877] [33m[OPENAI] Creating embedding...[39m
[1693633890960] [32m[OPENAI] Embedding created successfully.[39m
[1693633891044] [32m[OPENAI] Embedding created successfully.[39m
[1693633891402] [33m[OPENAI] Creating embedding...[39m
[1693633891532] [33m[OPENAI] Creating embedding...[39m
[1693633891533] [32m[OPENAI] Embedding created successfully.[39m
[1693633891704] [32m[OPENAI] Embedding created successfully.[39m
[1693633892038] [33m[OPENAI] Creating embedding...[39m
[1693633892164] [33m[OPENAI] Creating embedding...[39m
[1693633892303] [32m[OPENAI] Embedding created successfully.[39m
[1693633892457] [32m[OPENAI] Embedding created successfully.[39m
[1693633892795] [33m[OPENAI] Creating embedding...[39m
[1693633892921] [33m[OPENAI] Creating embedding...[39m
[1693633892949] [32m[OPENAI] Embedding created successfully.[39m
[1693633893086] [32m[OPENAI] Embedding created successfully.[39m
[1693633893348] [33m[OPENAI] Creating embedding...[39m
[1693633893507] [32m[OPENAI] Embedding created successfully.[39m
[1693633893609] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633893935] [33m[OPENAI] Creating embedding...[39m
[1693633894073] [32m[OPENAI] Embedding created successfully.[39m
[1693633894399] [33m[OPENAI] Creating embedding...[39m
[1693633894637] [32m[OPENAI] Embedding created successfully.[39m
[1693633894981] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633895556] {
  "id": "chatcmpl-7uDpd4rkK288DkcO36vYteDzMeARk",
  "object": "chat.completion",
  "created": 1693633893,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_pickaxe",
          "arguments": "{\n  \"characterId\": \"A4\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2106,
    "completion_tokens": 18,
    "total_tokens": 2124
  }
}
[1693633895556] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "swing_pickaxe",
    "arguments": "{\n  \"characterId\": \"A4\"\n}"
  }
}
[1693633895556] [36m[OPENAI] Chat completion took 1947.180291891098ms[39m
[1693633895556] [36m[OPENAI] Global tokens per second: 14.682439801996813tps[39m
[1693633895556] [36m[OPENAI] Tokens per second: 9.244136290285905tps[39m
[1693633895556] [32m[OPENAI] Chat completion created successfully.[39m
[1693633896178] --- Observations received -- 
[1693633896178] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Medium) at X: 53.13, Y: 26.69.",
  "time": 99.76154
}
[1693633896178] [Character] Getting character: A4
[1693633896236] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633896236] [33m[OPENAI] Creating embedding...[39m
[1693633896537] {
  "id": "chatcmpl-7uDpgCp564VML6w0L9mTcNbydYW1S",
  "object": "chat.completion",
  "created": 1693633896,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633896537] {
  "role": "assistant",
  "content": "4"
}
[1693633896537] [36m[OPENAI] Chat completion took 301.2031660079956ms[39m
[1693633896537] [36m[OPENAI] Global tokens per second: 14.55862247348779tps[39m
[1693633896537] [36m[OPENAI] Tokens per second: 3.3200182230934927tps[39m
[1693633896537] [32m[OPENAI] Chat completion created successfully.[39m
[1693633896566] [Character] Getting character: A4
[1693633896595] [33m[OPENAI] Creating embedding...[39m
[1693633896603] [32m[OPENAI] Embedding created successfully.[39m
[1693633896744] [32m[OPENAI] Embedding created successfully.[39m
[1693633897299] [33m[OPENAI] Creating embedding...[39m
[1693633897472] [32m[OPENAI] Embedding created successfully.[39m
[1693633897632] {
  "id": "chatcmpl-7uDpfExZnF9hLhIUm1fElG17etfqo",
  "object": "chat.completion",
  "created": 1693633895,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 62.25,\n  \"y\": 15.1\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2183,
    "completion_tokens": 35,
    "total_tokens": 2218
  }
}
[1693633897632] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 62.25,\n  \"y\": 15.1\n}"
  }
}
[1693633897632] [36m[OPENAI] Chat completion took 2649.700833082199ms[39m
[1693633897632] [36m[OPENAI] Global tokens per second: 14.73291448325057tps[39m
[1693633897632] [36m[OPENAI] Tokens per second: 13.209038380112942tps[39m
[1693633897632] [32m[OPENAI] Chat completion created successfully.[39m
[1693633897639] --- Observations received -- 
[1693633897639] {
  "observerId": "A2",
  "observation": "George Brown has started walking to 62.25, Y: 15.1.",
  "time": 101.222847
}
[1693633897639] [Character] Getting character: A2
[1693633897705] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633897706] [33m[OPENAI] Creating embedding...[39m
[1693633897856] [32m[OPENAI] Embedding created successfully.[39m
[1693633897977] [33m[OPENAI] Creating embedding...[39m
[1693633898019] --- Observations received -- 
[1693633898019] {
  "observerId": "A2",
  "observation": "George Brown no longer sees DiamondOreSmall at X: 58.32, Y: 22.87",
  "time": 101.602043
}
[1693633898019] [Character] Getting character: A2
[1693633898053] {
  "id": "chatcmpl-7uDph3rskP29dljIwtMhrYZn5qoHt",
  "object": "chat.completion",
  "created": 1693633897,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633898053] {
  "role": "assistant",
  "content": "2"
}
[1693633898053] [36m[OPENAI] Chat completion took 347.77016711235046ms[39m
[1693633898054] [36m[OPENAI] Global tokens per second: 14.685518548210771tps[39m
[1693633898054] [36m[OPENAI] Tokens per second: 2.875462286783617tps[39m
[1693633898054] [32m[OPENAI] Chat completion created successfully.[39m
[1693633898087] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633898087] [33m[OPENAI] Creating embedding...[39m
[1693633898139] [32m[OPENAI] Embedding created successfully.[39m
[1693633898263] [32m[OPENAI] Embedding created successfully.[39m
[1693633898356] --- Observations received -- 
[1693633898357] {
  "observerId": "A2",
  "observation": "George Brown no longer sees DiamondOreLarge (2) at X: 60.38, Y: 24.68",
  "time": 101.940224
}
[1693633898357] [Character] Getting character: A2
[1693633898439] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633898439] [33m[OPENAI] Creating embedding...[39m
[1693633898446] {
  "id": "chatcmpl-7uDpin9ZsD1h73QyMmitXT6PXwdWp",
  "object": "chat.completion",
  "created": 1693633898,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693633898446] {
  "role": "assistant",
  "content": "3"
}
[1693633898446] [36m[OPENAI] Chat completion took 358.3767499923706ms[39m
[1693633898446] [36m[OPENAI] Global tokens per second: 14.642205499223863tps[39m
[1693633898446] [36m[OPENAI] Tokens per second: 2.7903595867234374tps[39m
[1693633898446] [32m[OPENAI] Chat completion created successfully.[39m
[1693633898598] [33m[OPENAI] Creating embedding...[39m
[1693633898603] [32m[OPENAI] Embedding created successfully.[39m
[1693633898657] --- Observations received -- 
[1693633898657] {
  "observerId": "A2",
  "observation": "George Brown no longer sees IronOreSmall (3) at X: 63.58, Y: 24.8",
  "time": 102.240921
}
[1693633898658] [Character] Getting character: A2
[1693633898722] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633898722] [33m[OPENAI] Creating embedding...[39m
[1693633898736] [32m[OPENAI] Embedding created successfully.[39m
[1693633898834] {
  "id": "chatcmpl-7uDpiVtvZRKOq8bYvnDCgQfRMYO77",
  "object": "chat.completion",
  "created": 1693633898,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633898834] {
  "role": "assistant",
  "content": "4"
}
[1693633898834] [36m[OPENAI] Chat completion took 394.026624917984ms[39m
[1693633898834] [36m[OPENAI] Global tokens per second: 14.599860695257306tps[39m
[1693633898834] [36m[OPENAI] Tokens per second: 2.537899565056418tps[39m
[1693633898834] [32m[OPENAI] Chat completion created successfully.[39m
[1693633898897] [32m[OPENAI] Embedding created successfully.[39m
[1693633898994] {
  "id": "chatcmpl-7uDpi01gVGbyQ6PixrRTthLIhBOTT",
  "object": "chat.completion",
  "created": 1693633898,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633898994] {
  "role": "assistant",
  "content": "2"
}
[1693633898995] [36m[OPENAI] Chat completion took 272.3390419483185ms[39m
[1693633898995] [36m[OPENAI] Global tokens per second: 14.587661457862886tps[39m
[1693633898995] [36m[OPENAI] Tokens per second: 3.6718936544903062tps[39m
[1693633898995] [32m[OPENAI] Chat completion created successfully.[39m
[1693633899162] [33m[OPENAI] Creating embedding...[39m
[1693633899178] --- Observations received -- 
[1693633899178] {
  "observerId": "A2",
  "observation": "George Brown no longer sees IronOreLarge at X: 65.92, Y: 23.75",
  "time": 102.761467
}
[1693633899178] [Character] Getting character: A2
[1693633899232] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633899233] [33m[OPENAI] Creating embedding...[39m
[1693633899370] [32m[OPENAI] Embedding created successfully.[39m
[1693633899382] [32m[OPENAI] Embedding created successfully.[39m
[1693633899417] --- Observations received -- 
[1693633899423] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Small) at X: 59.32, Y: 14.11.",
  "time": 103.000168
}
[1693633899423] [Character] Getting character: A2
[1693633899490] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633899491] [33m[OPENAI] Creating embedding...[39m
[1693633899495] {
  "id": "chatcmpl-7uDpjAQZOqiNafHlJkCNH9u6ZajBY",
  "object": "chat.completion",
  "created": 1693633899,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693633899496] {
  "role": "assistant",
  "content": "2"
}
[1693633899496] [36m[OPENAI] Chat completion took 260.59212493896484ms[39m
[1693633899496] [36m[OPENAI] Global tokens per second: 14.530936687917562tps[39m
[1693633899496] [36m[OPENAI] Tokens per second: 3.8374145045028403tps[39m
[1693633899496] [32m[OPENAI] Chat completion created successfully.[39m
[1693633899661] [32m[OPENAI] Embedding created successfully.[39m
[1693633899727] {
  "id": "chatcmpl-7uDpjd8gRZoqEywlxNauKQ1V5wLKa",
  "object": "chat.completion",
  "created": 1693633899,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633899727] {
  "role": "assistant",
  "content": "2"
}
[1693633899727] [36m[OPENAI] Chat completion took 236.4102499485016ms[39m
[1693633899727] [36m[OPENAI] Global tokens per second: 14.509789845839093tps[39m
[1693633899727] [36m[OPENAI] Tokens per second: 4.22993503969407tps[39m
[1693633899727] [32m[OPENAI] Chat completion created successfully.[39m
[1693633899810] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633899938] --- Observations received -- 
[1693633899938] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Medium) at X: 57.27, Y: 17.32.",
  "time": 103.521454
}
[1693633899938] [Character] Getting character: A2
[1693633900004] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633900005] [33m[OPENAI] Creating embedding...[39m
[1693633900077] --- Observations received -- 
[1693633900080] {
  "observerId": "A2",
  "observation": "George Brown no longer sees IronOreSmall (1) at X: 68.08, Y: 19.36",
  "time": 103.660881
}
[1693633900080] [Character] Getting character: A2
[1693633900148] [32m[OPENAI] Embedding created successfully.[39m
[1693633900149] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633900154] [33m[OPENAI] Creating embedding...[39m
[1693633900297] --- Observations received -- 
[1693633900297] {
  "observerId": "A2",
  "observation": "George Brown no longer sees IronOreLarge (1) at X: 64.4, Y: 22.23",
  "time": 103.880737
}
[1693633900297] [Character] Getting character: A2
[1693633900319] --- Observations received -- 
[1693633900319] {
  "observerId": "A2",
  "observation": "George Brown no longer sees DiamondOreMedium at X: 60.84, Y: 22.05",
  "time": 103.90213
}
[1693633900319] [Character] Getting character: A2
[1693633900357] --- Observations received -- 
[1693633900358] {
  "observerId": "A2",
  "observation": "George Brown no longer sees IronOreMedium at X: 66.39, Y: 21.18",
  "time": 103.94017
}
[1693633900358] [Character] Getting character: A2
[1693633900368] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633900368] [33m[OPENAI] Creating embedding...[39m
[1693633900391] {
  "id": "chatcmpl-7uDpkiBeHIqLX7lD76bhx69csMBcX",
  "object": "chat.completion",
  "created": 1693633900,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633900391] {
  "role": "assistant",
  "content": "3"
}
[1693633900391] [36m[OPENAI] Chat completion took 386.5754590034485ms[39m
[1693633900391] [36m[OPENAI] Global tokens per second: 14.432768986494926tps[39m
[1693633900391] [36m[OPENAI] Tokens per second: 2.5868170798474805tps[39m
[1693633900391] [32m[OPENAI] Chat completion created successfully.[39m
[1693633900417] {
  "id": "chatcmpl-7uDpkTkrOUoHn1nYI3R2U9bhz75Zf",
  "object": "chat.completion",
  "created": 1693633900,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633900418] {
  "role": "assistant",
  "content": "3"
}
[1693633900418] [36m[OPENAI] Chat completion took 267.93537521362305ms[39m
[1693633900418] [36m[OPENAI] Global tokens per second: 14.438211766384562tps[39m
[1693633900418] [36m[OPENAI] Tokens per second: 3.7322432665067344tps[39m
[1693633900418] [32m[OPENAI] Chat completion created successfully.[39m
[1693633900421] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633900421] [33m[OPENAI] Creating embedding...[39m
[1693633900452] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633900452] [33m[OPENAI] Creating embedding...[39m
[1693633900563] [32m[OPENAI] Embedding created successfully.[39m
[1693633900582] [32m[OPENAI] Embedding created successfully.[39m
[1693633900663] [32m[OPENAI] Embedding created successfully.[39m
[1693633900664] [32m[OPENAI] Embedding created successfully.[39m
[1693633900683] {
  "id": "chatcmpl-7uDpkJxz0DpnzNXKovYGoq3E0bRvh",
  "object": "chat.completion",
  "created": 1693633900,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693633900683] {
  "role": "assistant",
  "content": "2"
}
[1693633900683] [36m[OPENAI] Chat completion took 262.0274999141693ms[39m
[1693633900683] [36m[OPENAI] Global tokens per second: 14.413067848182353tps[39m
[1693633900683] [36m[OPENAI] Tokens per second: 3.8163933187454133tps[39m
[1693633900686] [32m[OPENAI] Chat completion created successfully.[39m
[1693633900715] {
  "id": "chatcmpl-7uDpkSZtaAziNuF7JtC1Zng0UHd87",
  "object": "chat.completion",
  "created": 1693633900,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633900715] {
  "role": "assistant",
  "content": "2"
}
[1693633900715] [36m[OPENAI] Chat completion took 346.46570801734924ms[39m
[1693633900715] [36m[OPENAI] Global tokens per second: 14.417860001778884tps[39m
[1693633900715] [36m[OPENAI] Tokens per second: 2.8862885326299743tps[39m
[1693633900715] [32m[OPENAI] Chat completion created successfully.[39m
[1693633900747] {
  "id": "chatcmpl-7uDpkkuuouicoHH03rylOV9zI89IG",
  "object": "chat.completion",
  "created": 1693633900,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693633900747] {
  "role": "assistant",
  "content": "2"
}
[1693633900747] [36m[OPENAI] Chat completion took 295.02787494659424ms[39m
[1693633900747] [36m[OPENAI] Global tokens per second: 14.42264942825132tps[39m
[1693633900747] [36m[OPENAI] Tokens per second: 3.389510229096215tps[39m
[1693633900747] [32m[OPENAI] Chat completion created successfully.[39m
[1693633900897] --- Observations received -- 
[1693633900897] {
  "observerId": "A2",
  "observation": "George Brown finished walking to 62.25, Y: 15.1.",
  "time": 104.479965
}
[1693633900897] [Character] Getting character: A2
[1693633900901] [Character] Getting character: A2
[1693633900956] [33m[OPENAI] Creating embedding...[39m
[1693633900958] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633900958] [33m[OPENAI] Creating embedding...[39m
[1693633901122] [32m[OPENAI] Embedding created successfully.[39m
[1693633901129] [32m[OPENAI] Embedding created successfully.[39m
[1693633901358] {
  "id": "chatcmpl-7uDplWPdfSlMvPYDWhBRMvy9tgtVT",
  "object": "chat.completion",
  "created": 1693633901,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633901359] {
  "role": "assistant",
  "content": "1"
}
[1693633901359] [36m[OPENAI] Chat completion took 400.064334154129ms[39m
[1693633901359] [36m[OPENAI] Global tokens per second: 14.353432265595982tps[39m
[1693633901359] [36m[OPENAI] Tokens per second: 2.499597976196347tps[39m
[1693633901359] [32m[OPENAI] Chat completion created successfully.[39m
[1693633901608] [33m[OPENAI] Creating embedding...[39m
[1693633901755] [32m[OPENAI] Embedding created successfully.[39m
[1693633902196] [33m[OPENAI] Creating embedding...[39m
[1693633902350] [32m[OPENAI] Embedding created successfully.[39m
[1693633902835] [33m[OPENAI] Creating embedding...[39m
[1693633902998] {
  "id": "chatcmpl-7uDpky3fSLuUzZVGdH1U7GvIFLVMK",
  "object": "chat.completion",
  "created": 1693633900,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 54.06,\n  \"y\": 24.46\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2088,
    "completion_tokens": 35,
    "total_tokens": 2123
  }
}
[1693633902999] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 54.06,\n  \"y\": 24.46\n}"
  }
}
[1693633902999] [36m[OPENAI] Chat completion took 3187.7342500686646ms[39m
[1693633902999] [36m[OPENAI] Global tokens per second: 14.45333612287951tps[39m
[1693633902999] [36m[OPENAI] Tokens per second: 10.979585264752258tps[39m
[1693633902999] [32m[OPENAI] Chat completion created successfully.[39m
[1693633903004] --- Observations received -- 
[1693633903004] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 54.06, Y: 24.46.",
  "time": 106.587563
}
[1693633903004] [Character] Getting character: A4
[1693633903014] [32m[OPENAI] Embedding created successfully.[39m
[1693633903070] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633903070] [33m[OPENAI] Creating embedding...[39m
[1693633903097] --- Observations received -- 
[1693633903098] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Diamond Ore Deposit (Small) at X: 58.32, Y: 22.87.",
  "time": 106.680786
}
[1693633903098] [Character] Getting character: A4
[1693633903166] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633903167] [33m[OPENAI] Creating embedding...[39m
[1693633903219] [32m[OPENAI] Embedding created successfully.[39m
[1693633903335] [32m[OPENAI] Embedding created successfully.[39m
[1693633903358] {
  "id": "chatcmpl-7uDpn1xSPLn4AwDiXTjRmT3GBFSY3",
  "object": "chat.completion",
  "created": 1693633903,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633903358] {
  "role": "assistant",
  "content": "1"
}
[1693633903358] [36m[OPENAI] Chat completion took 288.2341248989105ms[39m
[1693633903358] [36m[OPENAI] Global tokens per second: 14.416935336699314tps[39m
[1693633903358] [36m[OPENAI] Tokens per second: 3.469401828637466tps[39m
[1693633903358] [32m[OPENAI] Chat completion created successfully.[39m
[1693633903434] {
  "id": "chatcmpl-7uDpnyy10ca05EJ5jsJr5RAkaFhs4",
  "object": "chat.completion",
  "created": 1693633903,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633903435] {
  "role": "assistant",
  "content": "2"
}
[1693633903435] [36m[OPENAI] Chat completion took 267.95625019073486ms[39m
[1693633903435] [36m[OPENAI] Global tokens per second: 14.415979157620495tps[39m
[1693633903435] [36m[OPENAI] Tokens per second: 3.7319525082478444tps[39m
[1693633903435] [32m[OPENAI] Chat completion created successfully.[39m
[1693633903462] [33m[OPENAI] Creating embedding...[39m
[1693633903639] [32m[OPENAI] Embedding created successfully.[39m
[1693633903678] --- Observations received -- 
[1693633903678] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees CopperOreLarge (1) at X: 49.04, Y: 28.68",
  "time": 107.2612
}
[1693633903678] [Character] Getting character: A4
[1693633903697] --- Observations received -- 
[1693633903697] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 54.06, Y: 24.46.",
  "time": 107.279961
}
[1693633903697] [Character] Getting character: A4
[1693633903699] [Character] Getting character: A4
[1693633903729] [33m[OPENAI] Creating embedding...[39m
[1693633903730] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633903730] [33m[OPENAI] Creating embedding...[39m
[1693633903762] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633903762] [33m[OPENAI] Creating embedding...[39m
[1693633903924] [32m[OPENAI] Embedding created successfully.[39m
[1693633903929] [32m[OPENAI] Embedding created successfully.[39m
[1693633903986] {
  "id": "chatcmpl-7uDpnPc67XRBydWlYeCB0AL5BDbSS",
  "object": "chat.completion",
  "created": 1693633903,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633903986] {
  "role": "assistant",
  "content": "4"
}
[1693633903986] [36m[OPENAI] Chat completion took 256.07658290863037ms[39m
[1693633903986] [36m[OPENAI] Global tokens per second: 14.35596926560704tps[39m
[1693633903986] [36m[OPENAI] Tokens per second: 3.9050817870246486tps[39m
[1693633903986] [32m[OPENAI] Chat completion created successfully.[39m
[1693633904049] {
  "id": "chatcmpl-7uDpnHmCXncNTNw9cPeJCwHhTbziF",
  "object": "chat.completion",
  "created": 1693633903,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633904049] {
  "role": "assistant",
  "content": "4"
}
[1693633904049] [36m[OPENAI] Chat completion took 286.52704191207886ms[39m
[1693633904049] [36m[OPENAI] Global tokens per second: 14.356794858505236tps[39m
[1693633904049] [36m[OPENAI] Tokens per second: 3.4900719782911493tps[39m
[1693633904049] [32m[OPENAI] Chat completion created successfully.[39m
[1693633904050] [32m[OPENAI] Embedding created successfully.[39m
[1693633904092] [33m[OPENAI] Creating embedding...[39m
[1693633904236] [32m[OPENAI] Embedding created successfully.[39m
[1693633904415] [33m[OPENAI] Creating embedding...[39m
[1693633904558] [32m[OPENAI] Embedding created successfully.[39m
[1693633904727] [33m[OPENAI] Creating embedding...[39m
[1693633904907] [32m[OPENAI] Embedding created successfully.[39m
[1693633904994] [33m[OPENAI] Creating embedding...[39m
[1693633905187] [32m[OPENAI] Embedding created successfully.[39m
[1693633905586] [33m[OPENAI] Creating embedding...[39m
[1693633905744] [33m[OPENAI] Creating embedding...[39m
[1693633905758] [32m[OPENAI] Embedding created successfully.[39m
[1693633905943] [32m[OPENAI] Embedding created successfully.[39m
[1693633906246] [33m[OPENAI] Creating embedding...[39m
[1693633906427] [33m[OPENAI] Creating embedding...[39m
[1693633906429] [32m[OPENAI] Embedding created successfully.[39m
[1693633906603] [32m[OPENAI] Embedding created successfully.[39m
[1693633906887] [33m[OPENAI] Creating embedding...[39m
[1693633907044] [32m[OPENAI] Embedding created successfully.[39m
[1693633907055] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633907401] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633908813] [33m[CONVERSATION] Continuing conversation as player...[39m
[1693633908813] [33m[CONVERSATION] Continuing conversation...[39m
[1693633908813] [33m[CONVERSATION] Player: A1[39m
[1693633908813] [33m[CONVERSATION] Character: A5[39m
[1693633909848] {
  "id": "chatcmpl-7uDprF3R4Ya6n7Q0fbw6qw2seTGSz",
  "object": "chat.completion",
  "created": 1693633907,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 62.25,\n  \"y\": 15.1\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2015,
    "completion_tokens": 35,
    "total_tokens": 2050
  }
}
[1693633909848] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 62.25,\n  \"y\": 15.1\n}"
  }
}
[1693633909848] [36m[OPENAI] Chat completion took 2446.7655420303345ms[39m
[1693633909848] [36m[OPENAI] Global tokens per second: 13.959839753872478tps[39m
[1693633909849] [36m[OPENAI] Tokens per second: 14.304599030341452tps[39m
[1693633909849] [32m[OPENAI] Chat completion created successfully.[39m
[1693633909857] --- Observations received -- 
[1693633909857] {
  "observerId": "A2",
  "observation": "George Brown has started walking to 62.25, Y: 15.1.",
  "time": 113.438828
}
[1693633909857] [Character] Getting character: A2
[1693633909911] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633909911] [33m[OPENAI] Creating embedding...[39m
[1693633909918] --- Observations received -- 
[1693633909918] {
  "observerId": "A2",
  "observation": "George Brown finished walking to 62.25, Y: 15.1.",
  "time": 113.499962
}
[1693633909918] [Character] Getting character: A2
[1693633909920] [Character] Getting character: A2
[1693633909947] [33m[OPENAI] Creating embedding...[39m
[1693633909965] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633909965] [33m[OPENAI] Creating embedding...[39m
[1693633910079] [32m[OPENAI] Embedding created successfully.[39m
[1693633910153] {
  "id": "chatcmpl-7uDpt7WG17Z0dgqPUo2zZKvjcfAzn",
  "object": "chat.completion",
  "created": 1693633909,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633910154] {
  "role": "assistant",
  "content": "1"
}
[1693633910154] [36m[OPENAI] Chat completion took 241.73683404922485ms[39m
[1693633910154] [36m[OPENAI] Global tokens per second: 13.932993624301504tps[39m
[1693633910154] [36m[OPENAI] Tokens per second: 4.136729944086097tps[39m
[1693633910154] [32m[OPENAI] Chat completion created successfully.[39m
[1693633910186] [32m[OPENAI] Embedding created successfully.[39m
[1693633910203] [32m[OPENAI] Embedding created successfully.[39m
[1693633910364] {
  "id": "chatcmpl-7uDpuBgKE7YPOmvZqXHu9jn5ONDBg",
  "object": "chat.completion",
  "created": 1693633910,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633910364] {
  "role": "assistant",
  "content": "3"
}
[1693633910364] [36m[OPENAI] Chat completion took 399.21404099464417ms[39m
[1693633910364] [36m[OPENAI] Global tokens per second: 13.917217539462152tps[39m
[1693633910364] [36m[OPENAI] Tokens per second: 2.5049219148417072tps[39m
[1693633910364] [32m[OPENAI] Chat completion created successfully.[39m
[1693633910674] [33m[OPENAI] Creating embedding...[39m
[1693633910865] [32m[OPENAI] Embedding created successfully.[39m
[1693633911301] {
  "id": "chatcmpl-7uDpr6qJCk8B6tTYPyi2WxcLL0ztV",
  "object": "chat.completion",
  "created": 1693633907,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 54.06,\n  \"y\": 24.46\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2129,
    "completion_tokens": 35,
    "total_tokens": 2164
  }
}
[1693633911301] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 54.06,\n  \"y\": 24.46\n}"
  }
}
[1693633911301] [36m[OPENAI] Chat completion took 4244.382292032242ms[39m
[1693633911301] [36m[OPENAI] Global tokens per second: 14.095727385055602tps[39m
[1693633911301] [36m[OPENAI] Tokens per second: 8.246194049415314tps[39m
[1693633911301] [32m[OPENAI] Chat completion created successfully.[39m
[1693633911308] --- Observations received -- 
[1693633911309] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 54.06, Y: 24.46.",
  "time": 114.890221
}
[1693633911309] [Character] Getting character: A4
[1693633911357] --- Observations received -- 
[1693633911357] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 54.06, Y: 24.46.",
  "time": 114.939957
}
[1693633911357] [Character] Getting character: A4
[1693633911360] [Character] Getting character: A4
[1693633911364] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633911364] [33m[OPENAI] Creating embedding...[39m
[1693633911391] [33m[OPENAI] Creating embedding...[39m
[1693633911406] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633911406] [33m[OPENAI] Creating embedding...[39m
[1693633911418] [33m[OPENAI] Creating embedding...[39m
[1693633911498] [32m[OPENAI] Embedding created successfully.[39m
[1693633911573] [32m[OPENAI] Embedding created successfully.[39m
[1693633911589] [32m[OPENAI] Embedding created successfully.[39m
[1693633911603] [32m[OPENAI] Embedding created successfully.[39m
[1693633911608] {
  "id": "chatcmpl-7uDpvD5aqbUt0eGlegQeGK7Do5xto",
  "object": "chat.completion",
  "created": 1693633911,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633911608] {
  "role": "assistant",
  "content": "1"
}
[1693633911608] [36m[OPENAI] Chat completion took 244.07862496376038ms[39m
[1693633911608] [36m[OPENAI] Global tokens per second: 14.068746300365707tps[39m
[1693633911611] [36m[OPENAI] Tokens per second: 4.097040452225078tps[39m
[1693633911611] [32m[OPENAI] Chat completion created successfully.[39m
[1693633911737] {
  "id": "chatcmpl-7uDpvcy5GAK2bJdFEI8sBqnXgWIhQ",
  "object": "chat.completion",
  "created": 1693633911,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633911737] {
  "role": "assistant",
  "content": "4"
}
[1693633911737] [36m[OPENAI] Chat completion took 330.76166701316833ms[39m
[1693633911737] [36m[OPENAI] Global tokens per second: 14.062145611249717tps[39m
[1693633911737] [36m[OPENAI] Tokens per second: 3.0233249488375202tps[39m
[1693633911737] [32m[OPENAI] Chat completion created successfully.[39m
[1693633912087] [33m[OPENAI] Creating embedding...[39m
[1693633912112] [33m[OPENAI] Creating embedding...[39m
[1693633912248] [32m[OPENAI] Embedding created successfully.[39m
[1693633912258] [32m[OPENAI] Embedding created successfully.[39m
[1693633912752] [33m[OPENAI] Creating embedding...[39m
[1693633912773] [33m[OPENAI] Creating embedding...[39m
[1693633912894] [32m[OPENAI] Embedding created successfully.[39m
[1693633912947] [32m[OPENAI] Embedding created successfully.[39m
[1693633913373] [33m[OPENAI] Creating embedding...[39m
[1693633913398] [33m[OPENAI] Creating embedding...[39m
[1693633913566] [32m[OPENAI] Embedding created successfully.[39m
[1693633913646] [32m[OPENAI] Embedding created successfully.[39m
[1693633914090] [33m[OPENAI] Creating embedding...[39m
[1693633914094] [33m[OPENAI] Creating embedding...[39m
[1693633914219] [32m[OPENAI] Embedding created successfully.[39m
[1693633914252] [32m[OPENAI] Embedding created successfully.[39m
[1693633914736] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633914745] [33m[OPENAI] Creating embedding...[39m
[1693633914914] [32m[OPENAI] Embedding created successfully.[39m
[1693633915288] [33m[OPENAI] Creating embedding...[39m
[1693633915500] [32m[OPENAI] Embedding created successfully.[39m
[1693633915831] [33m[OPENAI] Creating embedding...[39m
[1693633915984] [32m[OPENAI] Embedding created successfully.[39m
[1693633916286] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633917543] {
  "id": "chatcmpl-7uDpyPZfyvm4Kw2auQyCayF6TXEY0",
  "object": "chat.completion",
  "created": 1693633914,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 54.06,\n  \"y\": 24.46\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2115,
    "completion_tokens": 35,
    "total_tokens": 2150
  }
}
[1693633917543] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 54.06,\n  \"y\": 24.46\n}"
  }
}
[1693633917543] [36m[OPENAI] Chat completion took 2805.9202501773834ms[39m
[1693633917543] [36m[OPENAI] Global tokens per second: 13.701279611319995tps[39m
[1693633917543] [36m[OPENAI] Tokens per second: 12.47362607607518tps[39m
[1693633917543] [32m[OPENAI] Chat completion created successfully.[39m
[1693633917548] --- Observations received -- 
[1693633917548] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 54.06, Y: 24.46.",
  "time": 121.131218
}
[1693633917548] [Character] Getting character: A4
[1693633917598] --- Observations received -- 
[1693633917598] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 54.06, Y: 24.46.",
  "time": 121.179955
}
[1693633917598] [Character] Getting character: A4
[1693633917602] [Character] Getting character: A4
[1693633917606] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633917606] [33m[OPENAI] Creating embedding...[39m
[1693633917628] [33m[OPENAI] Creating embedding...[39m
[1693633917666] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633917667] [33m[OPENAI] Creating embedding...[39m
[1693633917781] [32m[OPENAI] Embedding created successfully.[39m
[1693633917797] [32m[OPENAI] Embedding created successfully.[39m
[1693633917851] [32m[OPENAI] Embedding created successfully.[39m
[1693633917928] {
  "id": "chatcmpl-7uDq1SKpdWow3vJ9C9uyVn3zvXdzU",
  "object": "chat.completion",
  "created": 1693633917,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633917928] {
  "role": "assistant",
  "content": "2"
}
[1693633917928] [36m[OPENAI] Chat completion took 321.38587498664856ms[39m
[1693633917928] [36m[OPENAI] Global tokens per second: 13.668304497736091tps[39m
[1693633917928] [36m[OPENAI] Tokens per second: 3.111524425401531tps[39m
[1693633917928] [32m[OPENAI] Chat completion created successfully.[39m
[1693633918236] {
  "id": "chatcmpl-7uDq1xuuK5lFSBt6etUApUsmdQWTZ",
  "object": "chat.completion",
  "created": 1693633917,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633918236] {
  "role": "assistant",
  "content": "3"
}
[1693633918236] [36m[OPENAI] Chat completion took 568.8492498397827ms[39m
[1693633918236] [36m[OPENAI] Global tokens per second: 13.643604127709676tps[39m
[1693633918236] [36m[OPENAI] Tokens per second: 1.7579349894223322tps[39m
[1693633918236] [32m[OPENAI] Chat completion created successfully.[39m
[1693633918334] [33m[OPENAI] Creating embedding...[39m
[1693633918473] [32m[OPENAI] Embedding created successfully.[39m
[1693633918639] {
  "id": "chatcmpl-7uDq0p0WJzJqUUqaeOKNyozXBgzbb",
  "object": "chat.completion",
  "created": 1693633916,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 65.22,\n  \"y\": 18.37\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2043,
    "completion_tokens": 35,
    "total_tokens": 2078
  }
}
[1693633918639] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 65.22,\n  \"y\": 18.37\n}"
  }
}
[1693633918639] [36m[OPENAI] Chat completion took 2352.7359158992767ms[39m
[1693633918639] [36m[OPENAI] Global tokens per second: 13.86992343925004tps[39m
[1693633918639] [36m[OPENAI] Tokens per second: 14.876297744883997tps[39m
[1693633918639] [32m[OPENAI] Chat completion created successfully.[39m
[1693633918647] --- Observations received -- 
[1693633918647] {
  "observerId": "A2",
  "observation": "George Brown has started walking to 65.22, Y: 18.37.",
  "time": 122.231018
}
[1693633918647] [Character] Getting character: A2
[1693633918715] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633918715] [33m[OPENAI] Creating embedding...[39m
[1693633918887] [32m[OPENAI] Embedding created successfully.[39m
[1693633919008] [33m[OPENAI] Creating embedding...[39m
[1693633919011] {
  "id": "chatcmpl-7uDq2oC28pBZFY71Moi9nVognMaSj",
  "object": "chat.completion",
  "created": 1693633918,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633919011] {
  "role": "assistant",
  "content": "4"
}
[1693633919011] [36m[OPENAI] Chat completion took 296.24983310699463ms[39m
[1693633919011] [36m[OPENAI] Global tokens per second: 13.838104126187599tps[39m
[1693633919011] [36m[OPENAI] Tokens per second: 3.3755293277712544tps[39m
[1693633919011] [32m[OPENAI] Chat completion created successfully.[39m
[1693633919154] [32m[OPENAI] Embedding created successfully.[39m
[1693633919217] --- Observations received -- 
[1693633919217] {
  "observerId": "A2",
  "observation": "George Brown sees Iron Ore Deposit (Medium) at X: 66.39, Y: 21.18.",
  "time": 122.800156
}
[1693633919217] [Character] Getting character: A2
[1693633919293] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633919293] [33m[OPENAI] Creating embedding...[39m
[1693633919339] --- Observations received -- 
[1693633919339] {
  "observerId": "A2",
  "observation": "George Brown sees Iron Ore Deposit (Large) at X: 64.4, Y: 22.23.",
  "time": 122.921738
}
[1693633919339] [Character] Getting character: A2
[1693633919339] --- Observations received -- 
[1693633919339] {
  "observerId": "A2",
  "observation": "George Brown sees Iron Ore Deposit (Large) at X: 68.08, Y: 19.36.",
  "time": 122.921738
}
[1693633919339] [Character] Getting character: A2
[1693633919339] --- Observations received -- 
[1693633919339] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CoalOreMedium (1) at X: 57.27, Y: 17.32",
  "time": 122.921738
}
[1693633919339] [Character] Getting character: A2
[1693633919402] --- Observations received -- 
[1693633919402] {
  "observerId": "A2",
  "observation": "George Brown sees Diamond Ore Deposit (Medium) at X: 60.84, Y: 22.05.",
  "time": 122.980545
}
[1693633919402] [Character] Getting character: A2
[1693633919428] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633919428] [33m[OPENAI] Creating embedding...[39m
[1693633919452] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633919452] [33m[OPENAI] Creating embedding...[39m
[1693633919452] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633919452] [33m[OPENAI] Creating embedding...[39m
[1693633919454] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633919454] [33m[OPENAI] Creating embedding...[39m
[1693633919455] [32m[OPENAI] Embedding created successfully.[39m
[1693633919558] [32m[OPENAI] Embedding created successfully.[39m
[1693633919578] [33m[OPENAI] Creating embedding...[39m
[1693633919579] {
  "id": "chatcmpl-7uDq3qIvlm8UmYrMtqG74ZtNF7T7l",
  "object": "chat.completion",
  "created": 1693633919,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 2,
    "total_tokens": 108
  }
}
[1693633919579] {
  "role": "assistant",
  "content": "4."
}
[1693633919579] [36m[OPENAI] Chat completion took 286.2704999446869ms[39m
[1693633919579] [36m[OPENAI] Global tokens per second: 13.793471141103172tps[39m
[1693633919580] [36m[OPENAI] Tokens per second: 6.986399228654156tps[39m
[1693633919580] [32m[OPENAI] Chat completion created successfully.[39m
[1693633919624] [32m[OPENAI] Embedding created successfully.[39m
[1693633919663] [32m[OPENAI] Embedding created successfully.[39m
[1693633919700] {
  "id": "chatcmpl-7uDq3IaporLgMnllnZ6njo2WAFOgx",
  "object": "chat.completion",
  "created": 1693633919,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633919700] {
  "role": "assistant",
  "content": "2"
}
[1693633919700] [36m[OPENAI] Chat completion took 247.17087483406067ms[39m
[1693633919700] [36m[OPENAI] Global tokens per second: 13.788380321881064tps[39m
[1693633919700] [36m[OPENAI] Tokens per second: 4.045784118664283tps[39m
[1693633919700] [32m[OPENAI] Chat completion created successfully.[39m
[1693633919722] {
  "id": "chatcmpl-7uDq3ypX1s3kh1KdjNdfPv6rDYdzr",
  "object": "chat.completion",
  "created": 1693633919,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633919722] {
  "role": "assistant",
  "content": "4"
}
[1693633919722] [36m[OPENAI] Chat completion took 269.04704213142395ms[39m
[1693633919722] [36m[OPENAI] Global tokens per second: 13.79368062265572tps[39m
[1693633919722] [36m[OPENAI] Tokens per second: 3.7168221292376096tps[39m
[1693633919722] [32m[OPENAI] Chat completion created successfully.[39m
[1693633919742] [32m[OPENAI] Embedding created successfully.[39m
[1693633919767] [32m[OPENAI] Embedding created successfully.[39m
[1693633919773] {
  "id": "chatcmpl-7uDq3M4V8hKAzLiB1qvCgidQsTJ8B",
  "object": "chat.completion",
  "created": 1693633919,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633919773] {
  "role": "assistant",
  "content": "2"
}
[1693633919773] [36m[OPENAI] Chat completion took 344.8391251564026ms[39m
[1693633919773] [36m[OPENAI] Global tokens per second: 13.795935750790946tps[39m
[1693633919774] [36m[OPENAI] Tokens per second: 2.8999029606818767tps[39m
[1693633919774] [32m[OPENAI] Chat completion created successfully.[39m
[1693633919821] {
  "id": "chatcmpl-7uDq3KKUTo8g2gqD42CS9p6uEDpr4",
  "object": "chat.completion",
  "created": 1693633919,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633919822] {
  "role": "assistant",
  "content": "2"
}
[1693633919822] [36m[OPENAI] Chat completion took 367.52066707611084ms[39m
[1693633919822] [36m[OPENAI] Global tokens per second: 13.798398929578749tps[39m
[1693633919822] [36m[OPENAI] Tokens per second: 2.7209354182873944tps[39m
[1693633919822] [32m[OPENAI] Chat completion created successfully.[39m
[1693633920017] --- Observations received -- 
[1693633920017] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CoalOreSmall (2) at X: 59.32, Y: 14.11",
  "time": 123.601036
}
[1693633920017] [Character] Getting character: A2
[1693633920066] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633920066] [33m[OPENAI] Creating embedding...[39m
[1693633920196] [33m[OPENAI] Creating embedding...[39m
[1693633920218] [32m[OPENAI] Embedding created successfully.[39m
[1693633920373] [32m[OPENAI] Embedding created successfully.[39m
[1693633920490] {
  "id": "chatcmpl-7uDq4vbR7iixYA1Bb72QAme0RzkJl",
  "object": "chat.completion",
  "created": 1693633920,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633920490] {
  "role": "assistant",
  "content": "4"
}
[1693633920490] [36m[OPENAI] Chat completion took 423.4094579219818ms[39m
[1693633920490] [36m[OPENAI] Global tokens per second: 13.736242956015278tps[39m
[1693633920490] [36m[OPENAI] Tokens per second: 2.3617800247255265tps[39m
[1693633920490] [32m[OPENAI] Chat completion created successfully.[39m
[1693633920498] --- Observations received -- 
[1693633920498] {
  "observerId": "A2",
  "observation": "George Brown sees Iron Ore Deposit (Large) at X: 65.92, Y: 23.75.",
  "time": 124.081635
}
[1693633920498] [Character] Getting character: A2
[1693633920565] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633920565] [33m[OPENAI] Creating embedding...[39m
[1693633920798] --- Observations received -- 
[1693633920798] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CoalOreLarge (1) at X: 58.91, Y: 19.37",
  "time": 124.381058
}
[1693633920798] [Character] Getting character: A2
[1693633920806] [32m[OPENAI] Embedding created successfully.[39m
[1693633920837] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633920876] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633920876] [33m[OPENAI] Creating embedding...[39m
[1693633920906] {
  "id": "chatcmpl-7uDq44cz1zJIpXThiXSO1cojBmCz7",
  "object": "chat.completion",
  "created": 1693633920,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633920906] {
  "role": "assistant",
  "content": "2"
}
[1693633920906] [36m[OPENAI] Chat completion took 341.0818748474121ms[39m
[1693633920906] [36m[OPENAI] Global tokens per second: 13.700695968210162tps[39m
[1693633920906] [36m[OPENAI] Tokens per second: 2.9318473766668616tps[39m
[1693633920906] [32m[OPENAI] Chat completion created successfully.[39m
[1693633920918] --- Observations received -- 
[1693633920918] {
  "observerId": "A2",
  "observation": "George Brown sees Iron Ore Deposit (Large) at X: 69.37, Y: 22.11.",
  "time": 124.50161
}
[1693633920918] [Character] Getting character: A2
[1693633920918] --- Observations received -- 
[1693633920918] {
  "observerId": "A2",
  "observation": "George Brown sees Iron Ore Deposit (Large) at X: 69.37, Y: 22.11.",
  "time": 124.50161
}
[1693633920918] [Character] Getting character: A2
[1693633920937] --- Observations received -- 
[1693633920937] {
  "observerId": "A2",
  "observation": "George Brown finished walking to 65.22, Y: 18.37.",
  "time": 124.519958
}
[1693633920937] [Character] Getting character: A2
[1693633920939] [Character] Getting character: A2
[1693633920972] [33m[OPENAI] Creating embedding...[39m
[1693633920978] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633920987] [33m[OPENAI] Creating embedding...[39m
[1693633920990] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633920990] [33m[OPENAI] Creating embedding...[39m
[1693633920990] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633920990] [33m[OPENAI] Creating embedding...[39m
[1693633921041] [32m[OPENAI] Embedding created successfully.[39m
[1693633921143] [32m[OPENAI] Embedding created successfully.[39m
[1693633921148] [32m[OPENAI] Embedding created successfully.[39m
[1693633921170] [32m[OPENAI] Embedding created successfully.[39m
[1693633921318] {
  "id": "chatcmpl-7uDq5oPL0Ar1CYeTSFSfK0miGSI2d",
  "object": "chat.completion",
  "created": 1693633921,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633921318] {
  "role": "assistant",
  "content": "2"
}
[1693633921318] [36m[OPENAI] Chat completion took 328.5187921524048ms[39m
[1693633921318] [36m[OPENAI] Global tokens per second: 13.66578217434772tps[39m
[1693633921318] [36m[OPENAI] Tokens per second: 3.043965897500576tps[39m
[1693633921318] [32m[OPENAI] Chat completion created successfully.[39m
[1693633921399] {
  "id": "chatcmpl-7uDq5kKSdQbTP2aysMAGY7DL7Y1ZO",
  "object": "chat.completion",
  "created": 1693633921,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633921399] {
  "role": "assistant",
  "content": "1"
}
[1693633921399] [36m[OPENAI] Chat completion took 408.43504190444946ms[39m
[1693633921399] [36m[OPENAI] Global tokens per second: 13.6649788902745tps[39m
[1693633921399] [36m[OPENAI] Tokens per second: 2.4483697464771965tps[39m
[1693633921399] [32m[OPENAI] Chat completion created successfully.[39m
[1693633921449] [32m[OPENAI] Embedding created successfully.[39m
[1693633921467] {
  "id": "chatcmpl-7uDq5iqx8ftv7nBmDNwNuP7r6c6b0",
  "object": "chat.completion",
  "created": 1693633921,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633921467] {
  "role": "assistant",
  "content": "2"
}
[1693633921467] [36m[OPENAI] Chat completion took 488.84879207611084ms[39m
[1693633921467] [36m[OPENAI] Global tokens per second: 13.665510354252078tps[39m
[1693633921467] [36m[OPENAI] Tokens per second: 2.0456223196401107tps[39m
[1693633921467] [32m[OPENAI] Chat completion created successfully.[39m
[1693633921541] {
  "id": "chatcmpl-7uDq4iyUhx5yD8o3R9qTNqXHkX4BY",
  "object": "chat.completion",
  "created": 1693633920,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633921541] {
  "role": "assistant",
  "content": "2"
}
[1693633921541] [36m[OPENAI] Chat completion took 664.4153339862823ms[39m
[1693633921541] [36m[OPENAI] Global tokens per second: 13.665425947049288tps[39m
[1693633921541] [36m[OPENAI] Tokens per second: 1.5050826626777494tps[39m
[1693633921541] [32m[OPENAI] Chat completion created successfully.[39m
[1693633921755] [33m[OPENAI] Creating embedding...[39m
[1693633921911] [32m[OPENAI] Embedding created successfully.[39m
[1693633922451] [33m[OPENAI] Creating embedding...[39m
[1693633922731] [32m[OPENAI] Embedding created successfully.[39m
[1693633923244] [33m[OPENAI] Creating embedding...[39m
[1693633923363] {
  "id": "chatcmpl-7uDq45CGg1VQYGUoRapYM4GyJDgHf",
  "object": "chat.completion",
  "created": 1693633920,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 54.06,\n  \"y\": 24.46\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2115,
    "completion_tokens": 35,
    "total_tokens": 2150
  }
}
[1693633923363] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 54.06,\n  \"y\": 24.46\n}"
  }
}
[1693633923363] [36m[OPENAI] Chat completion took 2525.4772911071777ms[39m
[1693633923363] [36m[OPENAI] Global tokens per second: 13.740209360517627tps[39m
[1693633923364] [36m[OPENAI] Tokens per second: 13.858766468914032tps[39m
[1693633923364] [32m[OPENAI] Chat completion created successfully.[39m
[1693633923376] --- Observations received -- 
[1693633923376] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 54.06, Y: 24.46.",
  "time": 126.960136
}
[1693633923376] [Character] Getting character: A4
[1693633923415] [32m[OPENAI] Embedding created successfully.[39m
[1693633923425] --- Observations received -- 
[1693633923425] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Small) at X: 53.88, Y: 19.83.",
  "time": 127.000137
}
[1693633923425] [Character] Getting character: A4
[1693633923437] --- Observations received -- 
[1693633923438] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 54.06, Y: 24.46.",
  "time": 127.019958
}
[1693633923438] [Character] Getting character: A4
[1693633923440] [Character] Getting character: A4
[1693633923444] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633923444] [33m[OPENAI] Creating embedding...[39m
[1693633923468] [33m[OPENAI] Creating embedding...[39m
[1693633923488] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633923489] [33m[OPENAI] Creating embedding...[39m
[1693633923507] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633923507] [33m[OPENAI] Creating embedding...[39m
[1693633923631] [32m[OPENAI] Embedding created successfully.[39m
[1693633923641] [32m[OPENAI] Embedding created successfully.[39m
[1693633923667] [32m[OPENAI] Embedding created successfully.[39m
[1693633923726] {
  "id": "chatcmpl-7uDq7VYTm4CW9XE7jOEFeIGaWjHIl",
  "object": "chat.completion",
  "created": 1693633923,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633923726] {
  "role": "assistant",
  "content": "1"
}
[1693633923726] [36m[OPENAI] Chat completion took 281.6830840110779ms[39m
[1693633923726] [36m[OPENAI] Global tokens per second: 13.710767049859347tps[39m
[1693633923726] [36m[OPENAI] Tokens per second: 3.5500889359783936tps[39m
[1693633923726] [32m[OPENAI] Chat completion created successfully.[39m
[1693633923769] {
  "id": "chatcmpl-7uDq73yGqjutBr52OlISEmUUgw2y4",
  "object": "chat.completion",
  "created": 1693633923,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633923769] {
  "role": "assistant",
  "content": "2"
}
[1693633923769] [36m[OPENAI] Chat completion took 280.4257080554962ms[39m
[1693633923769] [36m[OPENAI] Global tokens per second: 13.713796463050986tps[39m
[1693633923769] [36m[OPENAI] Tokens per second: 3.566006864827458tps[39m
[1693633923769] [32m[OPENAI] Chat completion created successfully.[39m
[1693633923804] {
  "id": "chatcmpl-7uDq76HHpddYcBaRwGiIQH7aviobu",
  "object": "chat.completion",
  "created": 1693633923,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633923804] {
  "role": "assistant",
  "content": "2"
}
[1693633923804] [36m[OPENAI] Chat completion took 297.66733407974243ms[39m
[1693633923804] [36m[OPENAI] Global tokens per second: 13.717633689740921tps[39m
[1693633923804] [36m[OPENAI] Tokens per second: 3.3594549536030343tps[39m
[1693633923804] [32m[OPENAI] Chat completion created successfully.[39m
[1693633923828] [35m[CORTEX] Eli Green - New Goal: Find out Thomas's intention behind starting the conversation.}[39m
[1693633923862] [32m[OPENAI] Embedding created successfully.[39m
[1693633924000] [33m[OPENAI] Creating embedding...[39m
[1693633924107] [33m[OPENAI] Creating embedding...[39m
[1693633924265] [32m[OPENAI] Embedding created successfully.[39m
[1693633924283] [32m[OPENAI] Embedding created successfully.[39m
[1693633924764] [33m[OPENAI] Creating embedding...[39m
[1693633924784] [33m[OPENAI] Creating embedding...[39m
[1693633924935] [32m[OPENAI] Embedding created successfully.[39m
[1693633924958] [32m[OPENAI] Embedding created successfully.[39m
[1693633925514] [33m[OPENAI] Creating embedding...[39m
[1693633925524] [33m[OPENAI] Creating embedding...[39m
[1693633925678] [32m[OPENAI] Embedding created successfully.[39m
[1693633925684] [32m[OPENAI] Embedding created successfully.[39m
[1693633926164] [33m[OPENAI] Creating embedding...[39m
[1693633926218] [33m[OPENAI] Creating embedding...[39m
[1693633926327] [32m[OPENAI] Embedding created successfully.[39m
[1693633926409] [32m[OPENAI] Embedding created successfully.[39m
[1693633926809] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633926928] [33m[OPENAI] Creating embedding...[39m
[1693633927064] [32m[OPENAI] Embedding created successfully.[39m
[1693633927420] [33m[OPENAI] Creating embedding...[39m
[1693633927598] [32m[OPENAI] Embedding created successfully.[39m
[1693633927924] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633929532] {
  "id": "chatcmpl-7uDqAYOSgAE20cwSHxKEc26LqcZWy",
  "object": "chat.completion",
  "created": 1693633926,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 54.06,\n  \"y\": 24.46\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2111,
    "completion_tokens": 35,
    "total_tokens": 2146
  }
}
[1693633929532] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 54.06,\n  \"y\": 24.46\n}"
  }
}
[1693633929532] [36m[OPENAI] Chat completion took 2721.8539578914642ms[39m
[1693633929532] [36m[OPENAI] Global tokens per second: 13.409134353295999tps[39m
[1693633929532] [36m[OPENAI] Tokens per second: 12.85888241671622tps[39m
[1693633929532] [32m[OPENAI] Chat completion created successfully.[39m
[1693633929538] --- Observations received -- 
[1693633929538] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 54.06, Y: 24.46.",
  "time": 133.120377
}
[1693633929538] [Character] Getting character: A4
[1693633929599] --- Observations received -- 
[1693633929599] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 54.06, Y: 24.46.",
  "time": 133.179947
}
[1693633929599] [Character] Getting character: A4
[1693633929601] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633929601] [33m[OPENAI] Creating embedding...[39m
[1693633929604] [Character] Getting character: A4
[1693633929656] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633929656] [33m[OPENAI] Creating embedding...[39m
[1693633929664] [33m[OPENAI] Creating embedding...[39m
[1693633929843] [32m[OPENAI] Embedding created successfully.[39m
[1693633929858] [32m[OPENAI] Embedding created successfully.[39m
[1693633929949] {
  "id": "chatcmpl-7uDqDrOpnrACAErbNUVcIDUSeiQgI",
  "object": "chat.completion",
  "created": 1693633929,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633929949] {
  "role": "assistant",
  "content": "1"
}
[1693633929949] [36m[OPENAI] Chat completion took 347.6394579410553ms[39m
[1693633929949] [36m[OPENAI] Global tokens per second: 13.37672238536255tps[39m
[1693633929949] [36m[OPENAI] Tokens per second: 2.876543433598257tps[39m
[1693633929949] [32m[OPENAI] Chat completion created successfully.[39m
[1693633929964] [32m[OPENAI] Embedding created successfully.[39m
[1693633929992] {
  "id": "chatcmpl-7uDqDQ7JgKdWTOS1nyPrjtNr1kh4i",
  "object": "chat.completion",
  "created": 1693633929,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633929992] {
  "role": "assistant",
  "content": "2"
}
[1693633929992] [36m[OPENAI] Chat completion took 335.47175002098083ms[39m
[1693633929992] [36m[OPENAI] Global tokens per second: 13.379720126740388tps[39m
[1693633929992] [36m[OPENAI] Tokens per second: 2.980876929093012tps[39m
[1693633929992] [32m[OPENAI] Chat completion created successfully.[39m
[1693633930465] [33m[OPENAI] Creating embedding...[39m
[1693633930629] [32m[OPENAI] Embedding created successfully.[39m
[1693633930995] {
  "id": "chatcmpl-7uDqCgdM5rWIjeDLzwYZGhTlC2PB6",
  "object": "chat.completion",
  "created": 1693633928,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 65.22,\n  \"y\": 18.37\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2151,
    "completion_tokens": 35,
    "total_tokens": 2186
  }
}
[1693633930995] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 65.22,\n  \"y\": 18.37\n}"
  }
}
[1693633930995] [36m[OPENAI] Chat completion took 3070.4300408363342ms[39m
[1693633930995] [36m[OPENAI] Global tokens per second: 13.530936864970919tps[39m
[1693633930995] [36m[OPENAI] Tokens per second: 11.399054703902838tps[39m
[1693633930995] [32m[OPENAI] Chat completion created successfully.[39m
[1693633930999] --- Observations received -- 
[1693633930999] {
  "observerId": "A2",
  "observation": "George Brown has started walking to 65.22, Y: 18.37.",
  "time": 134.582748
}
[1693633930999] [Character] Getting character: A2
[1693633931046] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633931047] [33m[OPENAI] Creating embedding...[39m
[1693633931057] --- Observations received -- 
[1693633931058] {
  "observerId": "A2",
  "observation": "George Brown finished walking to 65.22, Y: 18.37.",
  "time": 134.639954
}
[1693633931058] [Character] Getting character: A2
[1693633931058] [Character] Getting character: A2
[1693633931086] [33m[OPENAI] Creating embedding...[39m
[1693633931107] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633931108] [33m[OPENAI] Creating embedding...[39m
[1693633931169] [33m[OPENAI] Creating embedding...[39m
[1693633931189] [32m[OPENAI] Embedding created successfully.[39m
[1693633931216] [32m[OPENAI] Embedding created successfully.[39m
[1693633931247] [32m[OPENAI] Embedding created successfully.[39m
[1693633931332] [32m[OPENAI] Embedding created successfully.[39m
[1693633931387] {
  "id": "chatcmpl-7uDqF1USz0yiTNnpgudwYI4fMRZUH",
  "object": "chat.completion",
  "created": 1693633931,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 2,
    "total_tokens": 102
  }
}
[1693633931387] {
  "role": "assistant",
  "content": "3."
}
[1693633931387] [36m[OPENAI] Chat completion took 333.6949999332428ms[39m
[1693633931387] [36m[OPENAI] Global tokens per second: 13.507847549300498tps[39m
[1693633931387] [36m[OPENAI] Tokens per second: 5.993497056893598tps[39m
[1693633931387] [32m[OPENAI] Chat completion created successfully.[39m
[1693633931389] {
  "id": "chatcmpl-7uDqFuRE6HmAw0536lHx5ZlcVFxEL",
  "object": "chat.completion",
  "created": 1693633931,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633931389] {
  "role": "assistant",
  "content": "1"
}
[1693633931389] [36m[OPENAI] Chat completion took 281.93499994277954ms[39m
[1693633931389] [36m[OPENAI] Global tokens per second: 13.514646690518783tps[39m
[1693633931389] [36m[OPENAI] Tokens per second: 3.5469168432544955tps[39m
[1693633931389] [32m[OPENAI] Chat completion created successfully.[39m
[1693633931773] [33m[OPENAI] Creating embedding...[39m
[1693633931832] [33m[OPENAI] Creating embedding...[39m
[1693633931910] [32m[OPENAI] Embedding created successfully.[39m
[1693633932016] [32m[OPENAI] Embedding created successfully.[39m
[1693633932470] [33m[OPENAI] Creating embedding...[39m
[1693633932656] [33m[OPENAI] Creating embedding...[39m
[1693633932759] [32m[OPENAI] Embedding created successfully.[39m
[1693633932781] [32m[OPENAI] Embedding created successfully.[39m
[1693633933289] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633933361] [33m[OPENAI] Creating embedding...[39m
[1693633933501] [32m[OPENAI] Embedding created successfully.[39m
[1693633934022] [33m[OPENAI] Creating embedding...[39m
[1693633934158] [32m[OPENAI] Embedding created successfully.[39m
[1693633934643] [33m[OPENAI] Creating embedding...[39m
[1693633934810] [32m[OPENAI] Embedding created successfully.[39m
[1693633935253] [33m[OPENAI] Creating embedding...[39m
[1693633935402] [32m[OPENAI] Embedding created successfully.[39m
[1693633935985] [33m[OPENAI] Creating embedding...[39m
[1693633936111] [32m[OPENAI] Embedding created successfully.[39m
[1693633936460] {
  "id": "chatcmpl-7uDqHuHddvPqr7ZaVGUgymqhx5zNl",
  "object": "chat.completion",
  "created": 1693633933,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 54.06,\n  \"y\": 24.46\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2097,
    "completion_tokens": 35,
    "total_tokens": 2132
  }
}
[1693633936460] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 54.06,\n  \"y\": 24.46\n}"
  }
}
[1693633936460] [36m[OPENAI] Chat completion took 3169.690999984741ms[39m
[1693633936460] [36m[OPENAI] Global tokens per second: 13.28834148810528tps[39m
[1693633936460] [36m[OPENAI] Tokens per second: 11.042085805893535tps[39m
[1693633936460] [32m[OPENAI] Chat completion created successfully.[39m
[1693633936466] --- Observations received -- 
[1693633936466] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 54.06, Y: 24.46.",
  "time": 140.04895
}
[1693633936467] [Character] Getting character: A4
[1693633936518] --- Observations received -- 
[1693633936519] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 54.06, Y: 24.46.",
  "time": 140.099945
}
[1693633936519] [Character] Getting character: A4
[1693633936521] [Character] Getting character: A4
[1693633936525] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633936526] [33m[OPENAI] Creating embedding...[39m
[1693633936555] [33m[OPENAI] Creating embedding...[39m
[1693633936562] [33m[OPENAI] Creating embedding...[39m
[1693633936583] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633936583] [33m[OPENAI] Creating embedding...[39m
[1693633936725] [32m[OPENAI] Embedding created successfully.[39m
[1693633936765] [32m[OPENAI] Embedding created successfully.[39m
[1693633936772] [32m[OPENAI] Embedding created successfully.[39m
[1693633936815] {
  "id": "chatcmpl-7uDqKhogfPHAG4EvKnPLlkZTbN53X",
  "object": "chat.completion",
  "created": 1693633936,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633936816] {
  "role": "assistant",
  "content": "1"
}
[1693633936816] [36m[OPENAI] Chat completion took 289.9794590473175ms[39m
[1693633936816] [36m[OPENAI] Global tokens per second: 13.263224512054721tps[39m
[1693633936816] [36m[OPENAI] Tokens per second: 3.448520123754092tps[39m
[1693633936816] [32m[OPENAI] Chat completion created successfully.[39m
[1693633936944] [32m[OPENAI] Embedding created successfully.[39m
[1693633936944] {
  "id": "chatcmpl-7uDqKYgCpSawa5j4NsfGLKgU5oi1B",
  "object": "chat.completion",
  "created": 1693633936,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633936944] {
  "role": "assistant",
  "content": "4"
}
[1693633936944] [36m[OPENAI] Chat completion took 361.55883407592773ms[39m
[1693633936944] [36m[OPENAI] Global tokens per second: 13.258531269549776tps[39m
[1693633936944] [36m[OPENAI] Tokens per second: 2.7658015950731794tps[39m
[1693633936944] [32m[OPENAI] Chat completion created successfully.[39m
[1693633937171] [33m[OPENAI] Creating embedding...[39m
[1693633937239] [33m[OPENAI] Creating embedding...[39m
[1693633937361] [32m[OPENAI] Embedding created successfully.[39m
[1693633937481] [32m[OPENAI] Embedding created successfully.[39m
[1693633937913] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633938098] [33m[OPENAI] Creating embedding...[39m
[1693633938264] [32m[OPENAI] Embedding created successfully.[39m
[1693633938771] [33m[OPENAI] Creating embedding...[39m
[1693633938901] [32m[OPENAI] Embedding created successfully.[39m
[1693633939405] [33m[OPENAI] Creating embedding...[39m
[1693633939570] [32m[OPENAI] Embedding created successfully.[39m
[1693633940074] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633941631] {
  "id": "chatcmpl-7uDqMYcMIs1IPV04MQ7lAOkd0iYBw",
  "object": "chat.completion",
  "created": 1693633938,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 62.25,\n  \"y\": 15.1\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2146,
    "completion_tokens": 35,
    "total_tokens": 2181
  }
}
[1693633941631] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 62.25,\n  \"y\": 15.1\n}"
  }
}
[1693633941631] [36m[OPENAI] Chat completion took 3717.3358750343323ms[39m
[1693633941631] [36m[OPENAI] Global tokens per second: 13.081528047683017tps[39m
[1693633941631] [36m[OPENAI] Tokens per second: 9.415345068779061tps[39m
[1693633941631] [32m[OPENAI] Chat completion created successfully.[39m
[1693633941643] --- Observations received -- 
[1693633941643] {
  "observerId": "A2",
  "observation": "George Brown has started walking to 62.25, Y: 15.1.",
  "time": 145.226654
}
[1693633941643] [Character] Getting character: A2
[1693633941706] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633941706] [33m[OPENAI] Creating embedding...[39m
[1693633941738] --- Observations received -- 
[1693633941739] {
  "observerId": "A2",
  "observation": "George Brown no longer sees IronOreSmall (4) at X: 69.37, Y: 22.11",
  "time": 145.321335
}
[1693633941739] [Character] Getting character: A2
[1693633941739] --- Observations received -- 
[1693633941739] {
  "observerId": "A2",
  "observation": "George Brown no longer sees IronOreSmall (2) at X: 69.37, Y: 22.11",
  "time": 145.321335
}
[1693633941739] [Character] Getting character: A2
[1693633941802] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633941802] [33m[OPENAI] Creating embedding...[39m
[1693633941806] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633941806] [33m[OPENAI] Creating embedding...[39m
[1693633941819] --- Observations received -- 
[1693633941819] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Large) at X: 58.91, Y: 19.37.",
  "time": 145.40155
}
[1693633941819] [Character] Getting character: A2
[1693633941890] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633941890] [33m[OPENAI] Creating embedding...[39m
[1693633941977] [32m[OPENAI] Embedding created successfully.[39m
[1693633941986] [32m[OPENAI] Embedding created successfully.[39m
[1693633941989] [32m[OPENAI] Embedding created successfully.[39m
[1693633942004] {
  "id": "chatcmpl-7uDqPEMaqAdq6kr852FGzSK2HRZ3F",
  "object": "chat.completion",
  "created": 1693633941,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633942004] {
  "role": "assistant",
  "content": "2"
}
[1693633942004] [36m[OPENAI] Chat completion took 297.53974986076355ms[39m
[1693633942004] [36m[OPENAI] Global tokens per second: 13.056291024531776tps[39m
[1693633942004] [36m[OPENAI] Tokens per second: 3.3608954785636516tps[39m
[1693633942004] [32m[OPENAI] Chat completion created successfully.[39m
[1693633942119] {
  "id": "chatcmpl-7uDqPkb3MfUPyMDltsc0XLeZa0zAj",
  "object": "chat.completion",
  "created": 1693633941,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633942119] {
  "role": "assistant",
  "content": "1"
}
[1693633942119] [36m[OPENAI] Chat completion took 313.2818751335144ms[39m
[1693633942119] [36m[OPENAI] Global tokens per second: 13.053031189463967tps[39m
[1693633942119] [36m[OPENAI] Tokens per second: 3.1920135806574197tps[39m
[1693633942119] [32m[OPENAI] Chat completion created successfully.[39m
[1693633942143] {
  "id": "chatcmpl-7uDqPl3khjJlwjyBg2cLyEgwFq6mz",
  "object": "chat.completion",
  "created": 1693633941,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633942143] {
  "role": "assistant",
  "content": "2"
}
[1693633942143] [36m[OPENAI] Chat completion took 340.0969579219818ms[39m
[1693633942143] [36m[OPENAI] Global tokens per second: 13.057494572917886tps[39m
[1693633942143] [36m[OPENAI] Tokens per second: 2.940337973353469tps[39m
[1693633942143] [32m[OPENAI] Chat completion created successfully.[39m
[1693633942150] [32m[OPENAI] Embedding created successfully.[39m
[1693633942178] --- Observations received -- 
[1693633942178] {
  "observerId": "A2",
  "observation": "George Brown no longer sees IronOreLarge at X: 65.92, Y: 23.75",
  "time": 145.761292
}
[1693633942178] [Character] Getting character: A2
[1693633942195] {
  "id": "chatcmpl-7uDqQ0fehCrFhNJ1U2UTUI2SowICq",
  "object": "chat.completion",
  "created": 1693633942,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633942195] {
  "role": "assistant",
  "content": "2"
}
[1693633942195] [36m[OPENAI] Chat completion took 304.5427918434143ms[39m
[1693633942195] [36m[OPENAI] Global tokens per second: 13.059580274186214tps[39m
[1693633942195] [36m[OPENAI] Tokens per second: 3.283610798820569tps[39m
[1693633942195] [32m[OPENAI] Chat completion created successfully.[39m
[1693633942235] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633942235] [33m[OPENAI] Creating embedding...[39m
[1693633942444] [32m[OPENAI] Embedding created successfully.[39m
[1693633942510] {
  "id": "chatcmpl-7uDqQgtN5OtpMWA0fmPhhiYEcQCng",
  "object": "chat.completion",
  "created": 1693633942,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693633942510] {
  "role": "assistant",
  "content": "2"
}
[1693633942510] [36m[OPENAI] Chat completion took 275.4597911834717ms[39m
[1693633942510] [36m[OPENAI] Global tokens per second: 13.039390500891555tps[39m
[1693633942510] [36m[OPENAI] Tokens per second: 3.6302939013481783tps[39m
[1693633942510] [32m[OPENAI] Chat completion created successfully.[39m
[1693633942557] --- Observations received -- 
[1693633942557] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Small) at X: 59.32, Y: 14.11.",
  "time": 146.140228
}
[1693633942557] [Character] Getting character: A2
[1693633942628] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633942629] [33m[OPENAI] Creating embedding...[39m
[1693633942784] [32m[OPENAI] Embedding created successfully.[39m
[1693633942928] {
  "id": "chatcmpl-7uDqOjQPM6xcc7b5Qq0mmZuJXmF3d",
  "object": "chat.completion",
  "created": 1693633940,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.13,\n  \"y\": 26.69\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2098,
    "completion_tokens": 35,
    "total_tokens": 2133
  }
}
[1693633942929] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.13,\n  \"y\": 26.69\n}"
  }
}
[1693633942929] [36m[OPENAI] Chat completion took 2853.6612088680267ms[39m
[1693633942929] [36m[OPENAI] Global tokens per second: 13.230387211918988tps[39m
[1693633942929] [36m[OPENAI] Tokens per second: 12.264945779560003tps[39m
[1693633942929] [32m[OPENAI] Chat completion created successfully.[39m
[1693633942939] --- Observations received -- 
[1693633942939] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 53.13, Y: 26.69.",
  "time": 146.520126
}
[1693633942939] [Character] Getting character: A4
[1693633942977] --- Observations received -- 
[1693633942977] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees CopperOreSmall (3) at X: 53.88, Y: 19.83",
  "time": 146.560944
}
[1693633942977] [Character] Getting character: A4
[1693633942993] {
  "id": "chatcmpl-7uDqQ3GgB8W0TPJYFjl2FVldi1LoP",
  "object": "chat.completion",
  "created": 1693633942,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633942993] {
  "role": "assistant",
  "content": "2"
}
[1693633942993] [36m[OPENAI] Chat completion took 362.67229104042053ms[39m
[1693633942993] [36m[OPENAI] Global tokens per second: 13.23137782144427tps[39m
[1693633942993] [36m[OPENAI] Tokens per second: 2.75731017975274tps[39m
[1693633942993] [32m[OPENAI] Chat completion created successfully.[39m
[1693633943001] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633943001] [33m[OPENAI] Creating embedding...[39m
[1693633943042] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633943042] [33m[OPENAI] Creating embedding...[39m
[1693633943057] --- Observations received -- 
[1693633943058] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Medium) at X: 57.27, Y: 17.32.",
  "time": 146.640823
}
[1693633943058] [Character] Getting character: A2
[1693633943097] --- Observations received -- 
[1693633943098] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Copper Ore Deposit (Large) at X: 49.04, Y: 28.68.",
  "time": 146.6807
}
[1693633943098] [Character] Getting character: A4
[1693633943121] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633943122] [33m[OPENAI] Creating embedding...[39m
[1693633943137] [32m[OPENAI] Embedding created successfully.[39m
[1693633943168] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633943169] [33m[OPENAI] Creating embedding...[39m
[1693633943178] --- Observations received -- 
[1693633943178] {
  "observerId": "A2",
  "observation": "George Brown no longer sees IronOreSmall (1) at X: 68.08, Y: 19.36",
  "time": 146.761566
}
[1693633943178] [Character] Getting character: A2
[1693633943187] [32m[OPENAI] Embedding created successfully.[39m
[1693633943238] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633943239] [33m[OPENAI] Creating embedding...[39m
[1693633943282] {
  "id": "chatcmpl-7uDqRnt05sU39sgjDaKBNdnVp78c4",
  "object": "chat.completion",
  "created": 1693633943,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633943282] {
  "role": "assistant",
  "content": "3"
}
[1693633943282] [36m[OPENAI] Chat completion took 239.23770785331726ms[39m
[1693633943282] [36m[OPENAI] Global tokens per second: 13.213158964367052tps[39m
[1693633943282] [36m[OPENAI] Tokens per second: 4.179943074078963tps[39m
[1693633943282] [32m[OPENAI] Chat completion created successfully.[39m
[1693633943307] {
  "id": "chatcmpl-7uDqRHacrOi1xr96XurpYM4boTOYS",
  "object": "chat.completion",
  "created": 1693633943,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633943307] {
  "role": "assistant",
  "content": "1"
}
[1693633943307] [36m[OPENAI] Chat completion took 306.2774169445038ms[39m
[1693633943307] [36m[OPENAI] Global tokens per second: 13.217478809459303tps[39m
[1693633943307] [36m[OPENAI] Tokens per second: 3.2650138230112993tps[39m
[1693633943307] [32m[OPENAI] Chat completion created successfully.[39m
[1693633943321] [32m[OPENAI] Embedding created successfully.[39m
[1693633943370] {
  "id": "chatcmpl-7uDqRYlOByZZAUh8rrLBn3KUK8q06",
  "object": "chat.completion",
  "created": 1693633943,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633943370] {
  "role": "assistant",
  "content": "4"
}
[1693633943370] [36m[OPENAI] Chat completion took 248.75354194641113ms[39m
[1693633943370] [36m[OPENAI] Global tokens per second: 13.218557565206176tps[39m
[1693633943370] [36m[OPENAI] Tokens per second: 4.020043261194767tps[39m
[1693633943370] [32m[OPENAI] Chat completion created successfully.[39m
[1693633943378] --- Observations received -- 
[1693633943378] {
  "observerId": "A2",
  "observation": "George Brown no longer sees IronOreLarge (1) at X: 64.4, Y: 22.23",
  "time": 146.9616
}
[1693633943378] [Character] Getting character: A2
[1693633943380] [32m[OPENAI] Embedding created successfully.[39m
[1693633943397] --- Observations received -- 
[1693633943398] {
  "observerId": "A2",
  "observation": "George Brown no longer sees DiamondOreMedium at X: 60.84, Y: 22.05",
  "time": 146.980957
}
[1693633943398] [Character] Getting character: A2
[1693633943434] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633943435] [33m[OPENAI] Creating embedding...[39m
[1693633943438] --- Observations received -- 
[1693633943438] {
  "observerId": "A2",
  "observation": "George Brown no longer sees IronOreMedium at X: 66.39, Y: 21.18",
  "time": 147.0215
}
[1693633943438] [Character] Getting character: A2
[1693633943462] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633943462] [33m[OPENAI] Creating embedding...[39m
[1693633943463] [32m[OPENAI] Embedding created successfully.[39m
[1693633943473] {
  "id": "chatcmpl-7uDqRbMvg3ZhX3EagSqS5zccadEpW",
  "object": "chat.completion",
  "created": 1693633943,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633943473] {
  "role": "assistant",
  "content": "3"
}
[1693633943473] [36m[OPENAI] Chat completion took 234.26887488365173ms[39m
[1693633943473] [36m[OPENAI] Global tokens per second: 13.216228058870533tps[39m
[1693633943473] [36m[OPENAI] Tokens per second: 4.268599490635041tps[39m
[1693633943473] [32m[OPENAI] Chat completion created successfully.[39m
[1693633943491] {
  "id": "chatcmpl-7uDqREw9uksrNbQrvuowhleupxafi",
  "object": "chat.completion",
  "created": 1693633943,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633943491] {
  "role": "assistant",
  "content": "1"
}
[1693633943491] [36m[OPENAI] Chat completion took 321.11445808410645ms[39m
[1693633943491] [36m[OPENAI] Global tokens per second: 13.22113835805317tps[39m
[1693633943491] [36m[OPENAI] Tokens per second: 3.114154392070629tps[39m
[1693633943491] [32m[OPENAI] Chat completion created successfully.[39m
[1693633943503] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633943504] [33m[OPENAI] Creating embedding...[39m
[1693633943563] [32m[OPENAI] Embedding created successfully.[39m
[1693633943591] [32m[OPENAI] Embedding created successfully.[39m
[1693633943682] [32m[OPENAI] Embedding created successfully.[39m
[1693633943698] --- Observations received -- 
[1693633943698] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees DiamondOreSmall at X: 58.32, Y: 22.87",
  "time": 147.281235
}
[1693633943698] [Character] Getting character: A4
[1693633943719] --- Observations received -- 
[1693633943719] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 53.13, Y: 26.69.",
  "time": 147.299942
}
[1693633943719] [Character] Getting character: A4
[1693633943724] [Character] Getting character: A4
[1693633943752] [33m[OPENAI] Creating embedding...[39m
[1693633943769] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633943769] [33m[OPENAI] Creating embedding...[39m
[1693633943777] {
  "id": "chatcmpl-7uDqR5IxsJQmgA3J3btdxW8z5rq6o",
  "object": "chat.completion",
  "created": 1693633943,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693633943777] {
  "role": "assistant",
  "content": "3"
}
[1693633943777] [36m[OPENAI] Chat completion took 315.2114579677582ms[39m
[1693633943777] [36m[OPENAI] Global tokens per second: 13.203251614230958tps[39m
[1693633943777] [36m[OPENAI] Tokens per second: 3.1724735085686078tps[39m
[1693633943777] [32m[OPENAI] Chat completion created successfully.[39m
[1693633943778] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633943778] [33m[OPENAI] Creating embedding...[39m
[1693633943902] [32m[OPENAI] Embedding created successfully.[39m
[1693633943917] --- Observations received -- 
[1693633943917] {
  "observerId": "A2",
  "observation": "George Brown finished walking to 62.25, Y: 15.1.",
  "time": 147.499954
}
[1693633943917] [Character] Getting character: A2
[1693633943919] [Character] Getting character: A2
[1693633943929] [32m[OPENAI] Embedding created successfully.[39m
[1693633943944] [32m[OPENAI] Embedding created successfully.[39m
[1693633943964] [33m[OPENAI] Creating embedding...[39m
[1693633943965] {
  "id": "chatcmpl-7uDqR3O0WNlkM8cbTmrp4GBRNHpc2",
  "object": "chat.completion",
  "created": 1693633943,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633943965] {
  "role": "assistant",
  "content": "2"
}
[1693633943965] [36m[OPENAI] Chat completion took 529.8804998397827ms[39m
[1693633943965] [36m[OPENAI] Global tokens per second: 13.193730729701953tps[39m
[1693633943965] [36m[OPENAI] Tokens per second: 1.8872179676405623tps[39m
[1693633943965] [32m[OPENAI] Chat completion created successfully.[39m
[1693633943979] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633943979] [33m[OPENAI] Creating embedding...[39m
[1693633944073] {
  "id": "chatcmpl-7uDqRrzNO3aPA63dEvxj0LZrTxkRf",
  "object": "chat.completion",
  "created": 1693633943,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633944073] {
  "role": "assistant",
  "content": "2"
}
[1693633944073] [36m[OPENAI] Chat completion took 294.5277919769287ms[39m
[1693633944073] [36m[OPENAI] Global tokens per second: 13.191003158137981tps[39m
[1693633944073] [36m[OPENAI] Tokens per second: 3.395265327213444tps[39m
[1693633944073] [32m[OPENAI] Chat completion created successfully.[39m
[1693633944137] [32m[OPENAI] Embedding created successfully.[39m
[1693633944138] {
  "id": "chatcmpl-7uDqRB5TCfHnma3LZHlJXYL2pR9Fh",
  "object": "chat.completion",
  "created": 1693633943,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693633944138] {
  "role": "assistant",
  "content": "2"
}
[1693633944138] [36m[OPENAI] Chat completion took 369.04150009155273ms[39m
[1693633944138] [36m[OPENAI] Global tokens per second: 13.19191802531873tps[39m
[1693633944138] [36m[OPENAI] Tokens per second: 2.7097223476273467tps[39m
[1693633944138] [32m[OPENAI] Chat completion created successfully.[39m
[1693633944197] [32m[OPENAI] Embedding created successfully.[39m
[1693633944238] {
  "id": "chatcmpl-7uDqS727xcvLFpUSdNZiz0LIZGj32",
  "object": "chat.completion",
  "created": 1693633944,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633944238] {
  "role": "assistant",
  "content": "2"
}
[1693633944238] [36m[OPENAI] Chat completion took 259.7114579677582ms[39m
[1693633944239] [36m[OPENAI] Global tokens per second: 13.18987130738107tps[39m
[1693633944239] [36m[OPENAI] Tokens per second: 3.850426961617322tps[39m
[1693633944239] [32m[OPENAI] Chat completion created successfully.[39m
[1693633944369] {
  "id": "chatcmpl-7uDqRXg2FUbVs6Wmrpw9WbSUgwZSB",
  "object": "chat.completion",
  "created": 1693633943,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 2,
    "total_tokens": 107
  }
}
[1693633944369] {
  "role": "assistant",
  "content": "2."
}
[1693633944369] [36m[OPENAI] Chat completion took 865.4211249351501ms[39m
[1693633944369] [36m[OPENAI] Global tokens per second: 13.191614771533276tps[39m
[1693633944369] [36m[OPENAI] Tokens per second: 2.3110136121877876tps[39m
[1693633944369] [32m[OPENAI] Chat completion created successfully.[39m
[1693633944502] [33m[OPENAI] Creating embedding...[39m
[1693633944696] [32m[OPENAI] Embedding created successfully.[39m
[1693633944827] [33m[OPENAI] Creating embedding...[39m
[1693633945036] [32m[OPENAI] Embedding created successfully.[39m
[1693633945130] [33m[OPENAI] Creating embedding...[39m
[1693633945289] [32m[OPENAI] Embedding created successfully.[39m
[1693633945690] [33m[OPENAI] Creating embedding...[39m
[1693633945803] [33m[OPENAI] Creating embedding...[39m
[1693633945848] [32m[OPENAI] Embedding created successfully.[39m
[1693633945979] [32m[OPENAI] Embedding created successfully.[39m
[1693633946373] [33m[OPENAI] Creating embedding...[39m
[1693633946495] [33m[OPENAI] Creating embedding...[39m
[1693633946543] [32m[OPENAI] Embedding created successfully.[39m
[1693633946703] [32m[OPENAI] Embedding created successfully.[39m
[1693633947068] [33m[OPENAI] Creating embedding...[39m
[1693633947127] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633947247] [32m[OPENAI] Embedding created successfully.[39m
[1693633947830] [33m[OPENAI] Creating embedding...[39m
[1693633948034] [32m[OPENAI] Embedding created successfully.[39m
[1693633948660] [33m[OPENAI] Creating embedding...[39m
[1693633948893] [32m[OPENAI] Embedding created successfully.[39m
[1693633949507] [33m[OPENAI] Creating embedding...[39m
[1693633949654] [32m[OPENAI] Embedding created successfully.[39m
[1693633949762] {
  "id": "chatcmpl-7uDqVutPx67WHtJmSj02EddoMJRQG",
  "object": "chat.completion",
  "created": 1693633947,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.13,\n  \"y\": 26.69\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2059,
    "completion_tokens": 35,
    "total_tokens": 2094
  }
}
[1693633949762] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.13,\n  \"y\": 26.69\n}"
  }
}
[1693633949762] [36m[OPENAI] Chat completion took 2631.647332906723ms[39m
[1693633949762] [36m[OPENAI] Global tokens per second: 12.967791078605622tps[39m
[1693633949762] [36m[OPENAI] Tokens per second: 13.299654388470657tps[39m
[1693633949762] [32m[OPENAI] Chat completion created successfully.[39m
[1693633949771] --- Observations received -- 
[1693633949771] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 53.13, Y: 26.69.",
  "time": 153.354324
}
[1693633949771] [Character] Getting character: A4
[1693633949820] --- Observations received -- 
[1693633949820] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 53.13, Y: 26.69.",
  "time": 153.399948
}
[1693633949820] [Character] Getting character: A4
[1693633949820] [Character] Getting character: A4
[1693633949854] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633949855] [33m[OPENAI] Creating embedding...[39m
[1693633949856] [33m[OPENAI] Creating embedding...[39m
[1693633949894] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633949894] [33m[OPENAI] Creating embedding...[39m
[1693633950000] [32m[OPENAI] Embedding created successfully.[39m
[1693633950082] [32m[OPENAI] Embedding created successfully.[39m
[1693633950095] [32m[OPENAI] Embedding created successfully.[39m
[1693633950127] {
  "id": "chatcmpl-7uDqXtSofKja83T8wfdlly4RYwTVC",
  "object": "chat.completion",
  "created": 1693633949,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633950127] {
  "role": "assistant",
  "content": "5"
}
[1693633950127] [36m[OPENAI] Chat completion took 272.15750002861023ms[39m
[1693633950127] [36m[OPENAI] Global tokens per second: 12.944723866487067tps[39m
[1693633950127] [36m[OPENAI] Tokens per second: 3.6743429811593518tps[39m
[1693633950127] [32m[OPENAI] Chat completion created successfully.[39m
[1693633950136] [33m[OPENAI] Creating embedding...[39m
[1693633950245] {
  "id": "chatcmpl-7uDqYRjpIaETuZ93pZPjImd9Qt3yI",
  "object": "chat.completion",
  "created": 1693633950,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633950245] {
  "role": "assistant",
  "content": "3"
}
[1693633950245] [36m[OPENAI] Chat completion took 350.4279580116272ms[39m
[1693633950245] [36m[OPENAI] Global tokens per second: 12.941467028896023tps[39m
[1693633950245] [36m[OPENAI] Tokens per second: 2.8536535888121692tps[39m
[1693633950245] [32m[OPENAI] Chat completion created successfully.[39m
[1693633950357] [32m[OPENAI] Embedding created successfully.[39m
[1693633950699] [33m[OPENAI] Creating embedding...[39m
[1693633950754] [33m[OPENAI] Creating embedding...[39m
[1693633950859] [32m[OPENAI] Embedding created successfully.[39m
[1693633950949] [32m[OPENAI] Embedding created successfully.[39m
[1693633951250] [33m[OPENAI] Creating embedding...[39m
[1693633951430] [32m[OPENAI] Embedding created successfully.[39m
[1693633951546] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633951887] [33m[OPENAI] Creating embedding...[39m
[1693633952040] [32m[OPENAI] Embedding created successfully.[39m
[1693633952583] [33m[OPENAI] Creating embedding...[39m
[1693633952736] [32m[OPENAI] Embedding created successfully.[39m
[1693633953204] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633955730] {
  "id": "chatcmpl-7uDqZHqkMA5NrTXdcDRy2Y6HX8Uaq",
  "object": "chat.completion",
  "created": 1693633951,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 62.25,\n  \"y\": 15.1\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2065,
    "completion_tokens": 35,
    "total_tokens": 2100
  }
}
[1693633955730] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 62.25,\n  \"y\": 15.1\n}"
  }
}
[1693633955730] [36m[OPENAI] Chat completion took 4183.376042127609ms[39m
[1693633955730] [36m[OPENAI] Global tokens per second: 12.726566932425573tps[39m
[1693633955730] [36m[OPENAI] Tokens per second: 8.366448449181123tps[39m
[1693633955730] [32m[OPENAI] Chat completion created successfully.[39m
[1693633955739] --- Observations received -- 
[1693633955739] {
  "observerId": "A2",
  "observation": "George Brown has started walking to 62.25, Y: 15.1.",
  "time": 159.320816
}
[1693633955739] [Character] Getting character: A2
[1693633955792] {
  "id": "chatcmpl-7uDqbwl9E1fWOQXzy7h7XH7NkHnky",
  "object": "chat.completion",
  "created": 1693633953,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.13,\n  \"y\": 26.69\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2045,
    "completion_tokens": 35,
    "total_tokens": 2080
  }
}
[1693633955792] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.13,\n  \"y\": 26.69\n}"
  }
}
[1693633955792] [36m[OPENAI] Chat completion took 2587.7102921009064ms[39m
[1693633955792] [36m[OPENAI] Global tokens per second: 12.930802891819447tps[39m
[1693633955792] [36m[OPENAI] Tokens per second: 13.525470802059628tps[39m
[1693633955792] [32m[OPENAI] Chat completion created successfully.[39m
[1693633955799] --- Observations received -- 
[1693633955799] {
  "observerId": "A2",
  "observation": "George Brown finished walking to 62.25, Y: 15.1.",
  "time": 159.379944
}
[1693633955799] [Character] Getting character: A2
[1693633955802] [Character] Getting character: A2
[1693633955802] --- Observations received -- 
[1693633955802] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 53.13, Y: 26.69.",
  "time": 159.380035
}
[1693633955802] [Character] Getting character: A4
[1693633955802] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633955802] [33m[OPENAI] Creating embedding...[39m
[1693633955830] [33m[OPENAI] Creating embedding...[39m
[1693633955858] --- Observations received -- 
[1693633955858] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 53.13, Y: 26.69.",
  "time": 159.439941
}
[1693633955858] [Character] Getting character: A4
[1693633955859] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633955860] [33m[OPENAI] Creating embedding...[39m
[1693633955866] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633955866] [33m[OPENAI] Creating embedding...[39m
[1693633955871] [Character] Getting character: A4
[1693633955904] [33m[OPENAI] Creating embedding...[39m
[1693633955916] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633955916] [33m[OPENAI] Creating embedding...[39m
[1693633955970] [32m[OPENAI] Embedding created successfully.[39m
[1693633956035] [32m[OPENAI] Embedding created successfully.[39m
[1693633956070] {
  "id": "chatcmpl-7uDqddwlS1HVVm5Gy2Lggkmh3HaSy",
  "object": "chat.completion",
  "created": 1693633955,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633956070] {
  "role": "assistant",
  "content": "1"
}
[1693633956070] [36m[OPENAI] Chat completion took 267.4948329925537ms[39m
[1693633956070] [36m[OPENAI] Global tokens per second: 12.915338081473314tps[39m
[1693633956070] [36m[OPENAI] Tokens per second: 3.738389967434762tps[39m
[1693633956070] [32m[OPENAI] Chat completion created successfully.[39m
[1693633956081] [32m[OPENAI] Embedding created successfully.[39m
[1693633956081] [32m[OPENAI] Embedding created successfully.[39m
[1693633956101] [32m[OPENAI] Embedding created successfully.[39m
[1693633956144] {
  "id": "chatcmpl-7uDqdAo23KpBfYLPtqwd4urF8bWUx",
  "object": "chat.completion",
  "created": 1693633955,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633956144] {
  "role": "assistant",
  "content": "1"
}
[1693633956144] [36m[OPENAI] Chat completion took 284.5436670780182ms[39m
[1693633956144] [36m[OPENAI] Global tokens per second: 12.915601784831317tps[39m
[1693633956144] [36m[OPENAI] Tokens per second: 3.5143990736782516tps[39m
[1693633956144] [32m[OPENAI] Chat completion created successfully.[39m
[1693633956289] {
  "id": "chatcmpl-7uDqed4LjRZgEnUpgC1C7BAw6jVeh",
  "object": "chat.completion",
  "created": 1693633956,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633956289] {
  "role": "assistant",
  "content": "2"
}
[1693633956289] [36m[OPENAI] Chat completion took 373.31462502479553ms[39m
[1693633956289] [36m[OPENAI] Global tokens per second: 12.910406895073928tps[39m
[1693633956289] [36m[OPENAI] Tokens per second: 2.6787056626393357tps[39m
[1693633956289] [32m[OPENAI] Chat completion created successfully.[39m
[1693633956358] {
  "id": "chatcmpl-7uDqe7DkXvk57d6fKgZ24nkIghE59",
  "object": "chat.completion",
  "created": 1693633956,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633956358] {
  "role": "assistant",
  "content": "4"
}
[1693633956358] [36m[OPENAI] Chat completion took 491.8110830783844ms[39m
[1693633956358] [36m[OPENAI] Global tokens per second: 12.911056505209045tps[39m
[1693633956358] [36m[OPENAI] Tokens per second: 2.033301067029067tps[39m
[1693633956358] [32m[OPENAI] Chat completion created successfully.[39m
[1693633956396] [32m[OPENAI] Embedding created successfully.[39m
[1693633956662] [33m[OPENAI] Creating embedding...[39m
[1693633956769] [33m[OPENAI] Creating embedding...[39m
[1693633956828] [32m[OPENAI] Embedding created successfully.[39m
[1693633956947] [32m[OPENAI] Embedding created successfully.[39m
[1693633957389] [33m[OPENAI] Creating embedding...[39m
[1693633957530] [32m[OPENAI] Embedding created successfully.[39m
[1693633957537] [33m[OPENAI] Creating embedding...[39m
[1693633957710] [32m[OPENAI] Embedding created successfully.[39m
[1693633958030] [33m[OPENAI] Creating embedding...[39m
[1693633958184] [33m[OPENAI] Creating embedding...[39m
[1693633958186] [32m[OPENAI] Embedding created successfully.[39m
[1693633958349] [32m[OPENAI] Embedding created successfully.[39m
[1693633958726] [33m[OPENAI] Creating embedding...[39m
[1693633958841] [33m[OPENAI] Creating embedding...[39m
[1693633958861] [32m[OPENAI] Embedding created successfully.[39m
[1693633958978] [32m[OPENAI] Embedding created successfully.[39m
[1693633959346] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633959634] [33m[OPENAI] Creating embedding...[39m
[1693633959771] [32m[OPENAI] Embedding created successfully.[39m
[1693633960367] [33m[OPENAI] Creating embedding...[39m
[1693633960552] [32m[OPENAI] Embedding created successfully.[39m
[1693633961165] [33m[OPENAI] Creating embedding...[39m
[1693633961373] [32m[OPENAI] Embedding created successfully.[39m
[1693633961912] [33m[OPENAI] Creating embedding...[39m
[1693633961999] {
  "id": "chatcmpl-7uDqhdhLMOB0mQtHF9GWZRHgWu5Zj",
  "object": "chat.completion",
  "created": 1693633959,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.13,\n  \"y\": 26.69\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2045,
    "completion_tokens": 35,
    "total_tokens": 2080
  }
}
[1693633962000] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.13,\n  \"y\": 26.69\n}"
  }
}
[1693633962000] [36m[OPENAI] Chat completion took 2653.6094579696655ms[39m
[1693633962000] [36m[OPENAI] Global tokens per second: 12.693204386495122tps[39m
[1693633962000] [36m[OPENAI] Tokens per second: 13.189582172645428tps[39m
[1693633962000] [32m[OPENAI] Chat completion created successfully.[39m
[1693633962006] --- Observations received -- 
[1693633962006] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 53.13, Y: 26.69.",
  "time": 165.589661
}
[1693633962006] [Character] Getting character: A4
[1693633962058] --- Observations received -- 
[1693633962058] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 53.13, Y: 26.69.",
  "time": 165.639938
}
[1693633962058] [Character] Getting character: A4
[1693633962059] [Character] Getting character: A4
[1693633962070] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633962071] [33m[OPENAI] Creating embedding...[39m
[1693633962073] [32m[OPENAI] Embedding created successfully.[39m
[1693633962086] [33m[OPENAI] Creating embedding...[39m
[1693633962167] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633962167] [33m[OPENAI] Creating embedding...[39m
[1693633962230] [32m[OPENAI] Embedding created successfully.[39m
[1693633962284] [32m[OPENAI] Embedding created successfully.[39m
[1693633962364] {
  "id": "chatcmpl-7uDqk3STccYZHVFL5FTiXurDL5ffV",
  "object": "chat.completion",
  "created": 1693633962,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633962364] {
  "role": "assistant",
  "content": "3"
}
[1693633962364] [36m[OPENAI] Chat completion took 293.60895800590515ms[39m
[1693633962364] [36m[OPENAI] Global tokens per second: 12.672407355281223tps[39m
[1693633962364] [36m[OPENAI] Tokens per second: 3.40589063355447tps[39m
[1693633962364] [32m[OPENAI] Chat completion created successfully.[39m
[1693633962398] [32m[OPENAI] Embedding created successfully.[39m
[1693633962536] [33m[OPENAI] Creating embedding...[39m
[1693633962583] {
  "id": "chatcmpl-7uDqk6d7O0OcngPR5A5wV8y5ThWoF",
  "object": "chat.completion",
  "created": 1693633962,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633962583] {
  "role": "assistant",
  "content": "1"
}
[1693633962583] [36m[OPENAI] Chat completion took 415.3745000362396ms[39m
[1693633962583] [36m[OPENAI] Global tokens per second: 12.662222171223995tps[39m
[1693633962583] [36m[OPENAI] Tokens per second: 2.4074660334535567tps[39m
[1693633962583] [32m[OPENAI] Chat completion created successfully.[39m
[1693633962663] [32m[OPENAI] Embedding created successfully.[39m
[1693633962864] [33m[OPENAI] Creating embedding...[39m
[1693633963004] [32m[OPENAI] Embedding created successfully.[39m
[1693633963155] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633963444] [33m[CONVERSATION] Continuing conversation as player...[39m
[1693633963444] [33m[CONVERSATION] Continuing conversation...[39m
[1693633963445] [33m[CONVERSATION] Player: A1[39m
[1693633963445] [33m[CONVERSATION] Character: A5[39m
[1693633963540] [33m[OPENAI] Creating embedding...[39m
[1693633963689] [32m[OPENAI] Embedding created successfully.[39m
[1693633964173] [33m[OPENAI] Creating embedding...[39m
[1693633964336] [32m[OPENAI] Embedding created successfully.[39m
[1693633964937] [33m[OPENAI] Creating embedding...[39m
[1693633965100] [32m[OPENAI] Embedding created successfully.[39m
[1693633965601] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633965902] {
  "id": "chatcmpl-7uDqlQRaWM0k0HmynvmNgbKWzjuyu",
  "object": "chat.completion",
  "created": 1693633963,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 62.25,\n  \"y\": 15.1\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2051,
    "completion_tokens": 35,
    "total_tokens": 2086
  }
}
[1693633965902] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 62.25,\n  \"y\": 15.1\n}"
  }
}
[1693633965902] [36m[OPENAI] Chat completion took 2746.9468750953674ms[39m
[1693633965902] [36m[OPENAI] Global tokens per second: 12.622665623223003tps[39m
[1693633965902] [36m[OPENAI] Tokens per second: 12.741418597250767tps[39m
[1693633965902] [32m[OPENAI] Chat completion created successfully.[39m
[1693633965908] --- Observations received -- 
[1693633965908] {
  "observerId": "A2",
  "observation": "George Brown has started walking to 62.25, Y: 15.1.",
  "time": 169.491623
}
[1693633965908] [Character] Getting character: A2
[1693633965960] --- Observations received -- 
[1693633965960] {
  "observerId": "A2",
  "observation": "George Brown finished walking to 62.25, Y: 15.1.",
  "time": 169.539948
}
[1693633965960] [Character] Getting character: A2
[1693633965962] [Character] Getting character: A2
[1693633965975] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633965975] [33m[OPENAI] Creating embedding...[39m
[1693633965991] [33m[OPENAI] Creating embedding...[39m
[1693633966021] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633966021] [33m[OPENAI] Creating embedding...[39m
[1693633966133] [32m[OPENAI] Embedding created successfully.[39m
[1693633966197] [32m[OPENAI] Embedding created successfully.[39m
[1693633966245] [32m[OPENAI] Embedding created successfully.[39m
[1693633966304] {
  "id": "chatcmpl-7uDqojw4ekAFfuGZGXZ4DGvSgHggk",
  "object": "chat.completion",
  "created": 1693633966,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633966304] {
  "role": "assistant",
  "content": "1"
}
[1693633966304] [36m[OPENAI] Chat completion took 327.88087487220764ms[39m
[1693633966304] [36m[OPENAI] Global tokens per second: 12.599778675309938tps[39m
[1693633966304] [36m[OPENAI] Tokens per second: 3.0498881656020727tps[39m
[1693633966304] [32m[OPENAI] Chat completion created successfully.[39m
[1693633966477] {
  "id": "chatcmpl-7uDqoFjGkePHU55kfZ9aJs3a89TI6",
  "object": "chat.completion",
  "created": 1693633966,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633966477] {
  "role": "assistant",
  "content": "3"
}
[1693633966477] [36m[OPENAI] Chat completion took 455.07337498664856ms[39m
[1693633966477] [36m[OPENAI] Global tokens per second: 12.59315794199515tps[39m
[1693633966477] [36m[OPENAI] Tokens per second: 2.1974478292194948tps[39m
[1693633966477] [32m[OPENAI] Chat completion created successfully.[39m
[1693633966757] [33m[OPENAI] Creating embedding...[39m
[1693633966998] [32m[OPENAI] Embedding created successfully.[39m
[1693633967522] [33m[OPENAI] Creating embedding...[39m
[1693633967685] [32m[OPENAI] Embedding created successfully.[39m
[1693633968137] {
  "id": "chatcmpl-7uDqndXBbYrq27WeR5DWLFOG3uB22",
  "object": "chat.completion",
  "created": 1693633965,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.13,\n  \"y\": 26.69\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2031,
    "completion_tokens": 35,
    "total_tokens": 2066
  }
}
[1693633968137] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.13,\n  \"y\": 26.69\n}"
  }
}
[1693633968137] [36m[OPENAI] Chat completion took 2535.700250148773ms[39m
[1693633968144] [36m[OPENAI] Global tokens per second: 12.671529924604675tps[39m
[1693633968144] [36m[OPENAI] Tokens per second: 13.802893302529153tps[39m
[1693633968144] [32m[OPENAI] Chat completion created successfully.[39m
[1693633968150] --- Observations received -- 
[1693633968150] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 53.13, Y: 26.69.",
  "time": 171.733521
}
[1693633968150] [Character] Getting character: A4
[1693633968198] --- Observations received -- 
[1693633968199] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 53.13, Y: 26.69.",
  "time": 171.779938
}
[1693633968199] [Character] Getting character: A4
[1693633968203] [Character] Getting character: A4
[1693633968204] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633968205] [33m[OPENAI] Creating embedding...[39m
[1693633968227] [33m[OPENAI] Creating embedding...[39m
[1693633968228] [33m[OPENAI] Creating embedding...[39m
[1693633968262] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633968263] [33m[OPENAI] Creating embedding...[39m
[1693633968362] [32m[OPENAI] Embedding created successfully.[39m
[1693633968376] [32m[OPENAI] Embedding created successfully.[39m
[1693633968412] [32m[OPENAI] Embedding created successfully.[39m
[1693633968456] [32m[OPENAI] Embedding created successfully.[39m
[1693633968513] {
  "id": "chatcmpl-7uDqq8X94N8k6B6cIyhG9zeEzp71G",
  "object": "chat.completion",
  "created": 1693633968,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633968513] {
  "role": "assistant",
  "content": "1"
}
[1693633968513] [36m[OPENAI] Chat completion took 308.8732080459595ms[39m
[1693633968513] [36m[OPENAI] Global tokens per second: 12.65064251947533tps[39m
[1693633968513] [36m[OPENAI] Tokens per second: 3.237574428440562tps[39m
[1693633968513] [32m[OPENAI] Chat completion created successfully.[39m
[1693633968562] {
  "id": "chatcmpl-7uDqqCW0sJJzmmzT507WKWrhGyoXG",
  "object": "chat.completion",
  "created": 1693633968,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633968562] {
  "role": "assistant",
  "content": "3"
}
[1693633968562] [36m[OPENAI] Chat completion took 298.9757921695709ms[39m
[1693633968562] [36m[OPENAI] Global tokens per second: 12.652751044226386tps[39m
[1693633968562] [36m[OPENAI] Tokens per second: 3.344752405348013tps[39m
[1693633968562] [32m[OPENAI] Chat completion created successfully.[39m
[1693633968896] [33m[OPENAI] Creating embedding...[39m
[1693633968995] [33m[OPENAI] Creating embedding...[39m
[1693633969069] [32m[OPENAI] Embedding created successfully.[39m
[1693633969145] [32m[OPENAI] Embedding created successfully.[39m
[1693633969700] [33m[OPENAI] Creating embedding...[39m
[1693633969703] [33m[OPENAI] Creating embedding...[39m
[1693633969865] [32m[OPENAI] Embedding created successfully.[39m
[1693633969877] [32m[OPENAI] Embedding created successfully.[39m
[1693633970422] [33m[OPENAI] Creating embedding...[39m
[1693633970525] [33m[OPENAI] Creating embedding...[39m
[1693633970578] [32m[OPENAI] Embedding created successfully.[39m
[1693633970668] [32m[OPENAI] Embedding created successfully.[39m
[1693633971182] [33m[OPENAI] Creating embedding...[39m
[1693633971187] [33m[OPENAI] Creating embedding...[39m
[1693633971356] [32m[OPENAI] Embedding created successfully.[39m
[1693633971377] [32m[OPENAI] Embedding created successfully.[39m
[1693633971905] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633971910] [33m[OPENAI] Creating embedding...[39m
[1693633972087] [32m[OPENAI] Embedding created successfully.[39m
[1693633972456] [33m[OPENAI] Creating embedding...[39m
[1693633972605] [32m[OPENAI] Embedding created successfully.[39m
[1693633972940] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633974894] {
  "id": "chatcmpl-7uDquNVcNxQ69uq864AZZOFwQZVEv",
  "object": "chat.completion",
  "created": 1693633972,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.13,\n  \"y\": 26.69\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2031,
    "completion_tokens": 35,
    "total_tokens": 2066
  }
}
[1693633974894] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.13,\n  \"y\": 26.69\n}"
  }
}
[1693633974894] [36m[OPENAI] Chat completion took 2988.622458934784ms[39m
[1693633974894] [36m[OPENAI] Global tokens per second: 12.410976962525922tps[39m
[1693633974894] [36m[OPENAI] Tokens per second: 11.711081102052225tps[39m
[1693633974894] [32m[OPENAI] Chat completion created successfully.[39m
[1693633974899] --- Observations received -- 
[1693633974899] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 53.13, Y: 26.69.",
  "time": 178.481857
}
[1693633974899] [Character] Getting character: A4
[1693633974956] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633974957] [33m[OPENAI] Creating embedding...[39m
[1693633974963] --- Observations received -- 
[1693633974963] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 53.13, Y: 26.69.",
  "time": 178.539932
}
[1693633974963] [Character] Getting character: A4
[1693633974964] [Character] Getting character: A4
[1693633974995] [33m[OPENAI] Creating embedding...[39m
[1693633975025] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633975026] [33m[OPENAI] Creating embedding...[39m
[1693633975171] [32m[OPENAI] Embedding created successfully.[39m
[1693633975203] [32m[OPENAI] Embedding created successfully.[39m
[1693633975238] [32m[OPENAI] Embedding created successfully.[39m
[1693633975280] {
  "id": "chatcmpl-7uDqxgsYXnkTFEC2rUuz0wIuCwjiP",
  "object": "chat.completion",
  "created": 1693633975,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633975280] {
  "role": "assistant",
  "content": "5"
}
[1693633975280] [36m[OPENAI] Chat completion took 322.8073329925537ms[39m
[1693633975280] [36m[OPENAI] Global tokens per second: 12.390705633840478tps[39m
[1693633975280] [36m[OPENAI] Tokens per second: 3.097823059747739tps[39m
[1693633975280] [32m[OPENAI] Chat completion created successfully.[39m
[1693633975315] {
  "id": "chatcmpl-7uDqxyzteSshU2DusgOUYrc21gtwg",
  "object": "chat.completion",
  "created": 1693633975,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633975315] {
  "role": "assistant",
  "content": "2"
}
[1693633975315] [36m[OPENAI] Chat completion took 288.765625ms[39m
[1693633975315] [36m[OPENAI] Global tokens per second: 12.393733625621557tps[39m
[1693633975315] [36m[OPENAI] Tokens per second: 3.463016070558952tps[39m
[1693633975315] [32m[OPENAI] Chat completion created successfully.[39m
[1693633975694] [33m[OPENAI] Creating embedding...[39m
[1693633975806] {
  "id": "chatcmpl-7uDqvCthRlrdcBP3XyfA1ZAZ5oKK9",
  "object": "chat.completion",
  "created": 1693633973,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 62.25,\n  \"y\": 15.1\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2051,
    "completion_tokens": 35,
    "total_tokens": 2086
  }
}
[1693633975806] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 62.25,\n  \"y\": 15.1\n}"
  }
}
[1693633975806] [36m[OPENAI] Chat completion took 2865.881875038147ms[39m
[1693633975806] [36m[OPENAI] Global tokens per second: 12.54792796540121tps[39m
[1693633975806] [36m[OPENAI] Tokens per second: 12.212645714692663tps[39m
[1693633975806] [32m[OPENAI] Chat completion created successfully.[39m
[1693633975809] --- Observations received -- 
[1693633975809] {
  "observerId": "A2",
  "observation": "George Brown has started walking to 62.25, Y: 15.1.",
  "time": 179.392853
}
[1693633975809] [Character] Getting character: A2
[1693633975841] [32m[OPENAI] Embedding created successfully.[39m
[1693633975857] --- Observations received -- 
[1693633975857] {
  "observerId": "A2",
  "observation": "George Brown finished walking to 62.25, Y: 15.1.",
  "time": 179.439941
}
[1693633975857] [Character] Getting character: A2
[1693633975859] [Character] Getting character: A2
[1693633975873] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633975873] [33m[OPENAI] Creating embedding...[39m
[1693633975885] [33m[OPENAI] Creating embedding...[39m
[1693633975909] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633975910] [33m[OPENAI] Creating embedding...[39m
[1693633976015] [32m[OPENAI] Embedding created successfully.[39m
[1693633976060] [32m[OPENAI] Embedding created successfully.[39m
[1693633976084] [32m[OPENAI] Embedding created successfully.[39m
[1693633976179] {
  "id": "chatcmpl-7uDqxOnUW8qvEjMs3rktk6Gy8q1nc",
  "object": "chat.completion",
  "created": 1693633975,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 2,
    "total_tokens": 102
  }
}
[1693633976180] {
  "role": "assistant",
  "content": "2."
}
[1693633976180] [36m[OPENAI] Chat completion took 306.01166701316833ms[39m
[1693633976180] [36m[OPENAI] Global tokens per second: 12.53359589132228tps[39m
[1693633976180] [36m[OPENAI] Tokens per second: 6.535698522612001tps[39m
[1693633976180] [32m[OPENAI] Chat completion created successfully.[39m
[1693633976274] {
  "id": "chatcmpl-7uDqyMeVnY0MYCfshsEZWLzwRi0HQ",
  "object": "chat.completion",
  "created": 1693633976,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633976274] {
  "role": "assistant",
  "content": "3"
}
[1693633976274] [36m[OPENAI] Chat completion took 363.8197078704834ms[39m
[1693633976274] [36m[OPENAI] Global tokens per second: 12.532648186861996tps[39m
[1693633976274] [36m[OPENAI] Tokens per second: 2.7486141579663714tps[39m
[1693633976274] [32m[OPENAI] Chat completion created successfully.[39m
[1693633976366] [33m[OPENAI] Creating embedding...[39m
[1693633976524] [33m[OPENAI] Creating embedding...[39m
[1693633976552] [32m[OPENAI] Embedding created successfully.[39m
[1693633976662] [32m[OPENAI] Embedding created successfully.[39m
[1693633977109] [33m[OPENAI] Creating embedding...[39m
[1693633977176] [33m[OPENAI] Creating embedding...[39m
[1693633977349] [32m[OPENAI] Embedding created successfully.[39m
[1693633977373] [32m[OPENAI] Embedding created successfully.[39m
[1693633977920] [33m[OPENAI] Creating embedding...[39m
[1693633978010] [33m[OPENAI] Creating embedding...[39m
[1693633978075] [32m[OPENAI] Embedding created successfully.[39m
[1693633978177] [32m[OPENAI] Embedding created successfully.[39m
[1693633978689] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633978696] [33m[OPENAI] Creating embedding...[39m
[1693633978945] [32m[OPENAI] Embedding created successfully.[39m
[1693633979507] [33m[OPENAI] Creating embedding...[39m
[1693633979652] [32m[OPENAI] Embedding created successfully.[39m
[1693633980169] [33m[OPENAI] Creating embedding...[39m
[1693633980297] [32m[OPENAI] Embedding created successfully.[39m
[1693633980745] [33m[OPENAI] Creating embedding...[39m
[1693633980912] [32m[OPENAI] Embedding created successfully.[39m
[1693633981399] [33m[OPENAI] Creating embedding...[39m
[1693633981641] [32m[OPENAI] Embedding created successfully.[39m
[1693633981719] {
  "id": "chatcmpl-7uDr0FcpmJW2Tn9TG2LIKmxXP4q9e",
  "object": "chat.completion",
  "created": 1693633978,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.13,\n  \"y\": 26.69\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2031,
    "completion_tokens": 35,
    "total_tokens": 2066
  }
}
[1693633981720] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.13,\n  \"y\": 26.69\n}"
  }
}
[1693633981720] [36m[OPENAI] Chat completion took 3030.277374982834ms[39m
[1693633981720] [36m[OPENAI] Global tokens per second: 12.360741334298343tps[39m
[1693633981720] [36m[OPENAI] Tokens per second: 11.55009778608081tps[39m
[1693633981720] [32m[OPENAI] Chat completion created successfully.[39m
[1693633981727] --- Observations received -- 
[1693633981727] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 53.13, Y: 26.69.",
  "time": 185.309143
}
[1693633981727] [Character] Getting character: A4
[1693633981779] --- Observations received -- 
[1693633981779] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 53.13, Y: 26.69.",
  "time": 185.35994
}
[1693633981779] [Character] Getting character: A4
[1693633981782] [Character] Getting character: A4
[1693633981790] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633981791] [33m[OPENAI] Creating embedding...[39m
[1693633981816] [33m[OPENAI] Creating embedding...[39m
[1693633981846] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633981846] [33m[OPENAI] Creating embedding...[39m
[1693633982034] [32m[OPENAI] Embedding created successfully.[39m
[1693633982042] [32m[OPENAI] Embedding created successfully.[39m
[1693633982070] [32m[OPENAI] Embedding created successfully.[39m
[1693633982075] {
  "id": "chatcmpl-7uDr3YSHVujycOYD06JIlP6sEytFV",
  "object": "chat.completion",
  "created": 1693633981,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633982075] {
  "role": "assistant",
  "content": "3"
}
[1693633982075] [36m[OPENAI] Chat completion took 284.7376251220703ms[39m
[1693633982075] [36m[OPENAI] Global tokens per second: 12.34325816605604tps[39m
[1693633982075] [36m[OPENAI] Tokens per second: 3.5120051295338595tps[39m
[1693633982075] [32m[OPENAI] Chat completion created successfully.[39m
[1693633982101] [33m[OPENAI] Creating embedding...[39m
[1693633982253] {
  "id": "chatcmpl-7uDr4Km00BWgH2Zpt0pZlGHfAxbA4",
  "object": "chat.completion",
  "created": 1693633982,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633982253] {
  "role": "assistant",
  "content": "4"
}
[1693633982253] [36m[OPENAI] Chat completion took 405.53229212760925ms[39m
[1693633982253] [36m[OPENAI] Global tokens per second: 12.337086529736865tps[39m
[1693633982253] [36m[OPENAI] Tokens per second: 2.4658948730162504tps[39m
[1693633982253] [32m[OPENAI] Chat completion created successfully.[39m
[1693633982290] [32m[OPENAI] Embedding created successfully.[39m
[1693633982505] [33m[OPENAI] Creating embedding...[39m
[1693633982689] [32m[OPENAI] Embedding created successfully.[39m
[1693633982871] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633983167] [33m[OPENAI] Creating embedding...[39m
[1693633983341] [32m[OPENAI] Embedding created successfully.[39m
[1693633983793] [33m[CONVERSATION] Continuing conversation as player...[39m
[1693633983793] [33m[CONVERSATION] Continuing conversation...[39m
[1693633983793] [33m[CONVERSATION] Player: A1[39m
[1693633983793] [33m[CONVERSATION] Character: A5[39m
[1693633983898] [33m[OPENAI] Creating embedding...[39m
[1693633984055] [32m[OPENAI] Embedding created successfully.[39m
[1693633984592] [33m[OPENAI] Creating embedding...[39m
[1693633984755] [32m[OPENAI] Embedding created successfully.[39m
[1693633985288] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633986489] {
  "id": "chatcmpl-7uDr5Kqes0v4RPzVamt9MHPCh9Nx8",
  "object": "chat.completion",
  "created": 1693633983,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 65.22,\n  \"y\": 18.37\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2037,
    "completion_tokens": 35,
    "total_tokens": 2072
  }
}
[1693633986489] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 65.22,\n  \"y\": 18.37\n}"
  }
}
[1693633986489] [36m[OPENAI] Chat completion took 3618.2150840759277ms[39m
[1693633986489] [36m[OPENAI] Global tokens per second: 12.250005045306855tps[39m
[1693633986490] [36m[OPENAI] Tokens per second: 9.673277897170342tps[39m
[1693633986490] [32m[OPENAI] Chat completion created successfully.[39m
[1693633986496] --- Observations received -- 
[1693633986496] {
  "observerId": "A2",
  "observation": "George Brown has started walking to 65.22, Y: 18.37.",
  "time": 190.077164
}
[1693633986496] [Character] Getting character: A2
[1693633986555] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633986555] [33m[OPENAI] Creating embedding...[39m
[1693633986869] {
  "id": "chatcmpl-7uDr8DObmvdliSmrSHgGrZHpxZ9vT",
  "object": "chat.completion",
  "created": 1693633986,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633986869] {
  "role": "assistant",
  "content": "1"
}
[1693633986869] [36m[OPENAI] Chat completion took 313.94866704940796ms[39m
[1693633986869] [36m[OPENAI] Global tokens per second: 12.231599726060509tps[39m
[1693633986869] [36m[OPENAI] Tokens per second: 3.1852341002060194tps[39m
[1693633986870] [32m[OPENAI] Chat completion created successfully.[39m
[1693633986898] --- Observations received -- 
[1693633986899] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CoalOreMedium (1) at X: 57.27, Y: 17.32",
  "time": 190.481583
}
[1693633986899] [Character] Getting character: A2
[1693633986966] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633986966] [33m[OPENAI] Creating embedding...[39m
[1693633987018] --- Observations received -- 
[1693633987018] {
  "observerId": "A2",
  "observation": "George Brown sees Iron Ore Deposit (Medium) at X: 66.39, Y: 21.18.",
  "time": 190.600662
}
[1693633987018] [Character] Getting character: A2
[1693633987058] --- Observations received -- 
[1693633987058] {
  "observerId": "A2",
  "observation": "George Brown sees Iron Ore Deposit (Large) at X: 68.08, Y: 19.36.",
  "time": 190.64151
}
[1693633987058] [Character] Getting character: A2
[1693633987079] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633987079] [33m[OPENAI] Creating embedding...[39m
[1693633987097] [32m[OPENAI] Embedding created successfully.[39m
[1693633987142] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633987143] [33m[OPENAI] Creating embedding...[39m
[1693633987189] [32m[OPENAI] Embedding created successfully.[39m
[1693633987274] [32m[OPENAI] Embedding created successfully.[39m
[1693633987277] --- Observations received -- 
[1693633987277] {
  "observerId": "A2",
  "observation": "George Brown sees Iron Ore Deposit (Large) at X: 64.4, Y: 22.23.",
  "time": 190.860138
}
[1693633987277] [Character] Getting character: A2
[1693633987308] {
  "id": "chatcmpl-7uDr9SzaoWQuOpHMM3WeVb8lGFQFF",
  "object": "chat.completion",
  "created": 1693633987,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633987308] {
  "role": "assistant",
  "content": "3"
}
[1693633987308] [36m[OPENAI] Chat completion took 342.48074984550476ms[39m
[1693633987308] [36m[OPENAI] Global tokens per second: 12.209644111484602tps[39m
[1693633987308] [36m[OPENAI] Tokens per second: 2.919872140116215tps[39m
[1693633987308] [32m[OPENAI] Chat completion created successfully.[39m
[1693633987334] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633987334] [33m[OPENAI] Creating embedding...[39m
[1693633987385] {
  "id": "chatcmpl-7uDr9siWNghrgfHkQiT32gDKSeQoa",
  "object": "chat.completion",
  "created": 1693633987,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633987385] {
  "role": "assistant",
  "content": "2"
}
[1693633987385] [36m[OPENAI] Chat completion took 305.9792079925537ms[39m
[1693633987385] [36m[OPENAI] Global tokens per second: 12.209944751381215tps[39m
[1693633987385] [36m[OPENAI] Tokens per second: 3.268195922725363tps[39m
[1693633987385] [32m[OPENAI] Chat completion created successfully.[39m
[1693633987395] [32m[OPENAI] Embedding created successfully.[39m
[1693633987473] {
  "id": "chatcmpl-7uDr9ZmbylwIjvMB79RKGUatzWXHK",
  "object": "chat.completion",
  "created": 1693633987,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633987473] {
  "role": "assistant",
  "content": "2"
}
[1693633987473] [36m[OPENAI] Chat completion took 330.00650000572205ms[39m
[1693633987473] [36m[OPENAI] Global tokens per second: 12.209570857682191tps[39m
[1693633987473] [36m[OPENAI] Tokens per second: 3.030243343639173tps[39m
[1693633987473] [32m[OPENAI] Chat completion created successfully.[39m
[1693633987494] [32m[OPENAI] Embedding created successfully.[39m
[1693633987673] {
  "id": "chatcmpl-7uDr9tVJAMeJKZpWs7aGgk46N4KxX",
  "object": "chat.completion",
  "created": 1693633987,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633987673] {
  "role": "assistant",
  "content": "4"
}
[1693633987673] [36m[OPENAI] Chat completion took 338.84070801734924ms[39m
[1693633987673] [36m[OPENAI] Global tokens per second: 12.202339157822937tps[39m
[1693633987673] [36m[OPENAI] Tokens per second: 2.951239258857877tps[39m
[1693633987673] [32m[OPENAI] Chat completion created successfully.[39m
[1693633987697] --- Observations received -- 
[1693633987698] {
  "observerId": "A2",
  "observation": "George Brown sees Diamond Ore Deposit (Medium) at X: 60.84, Y: 22.05.",
  "time": 191.280243
}
[1693633987698] [Character] Getting character: A2
[1693633987758] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633987763] [33m[OPENAI] Creating embedding...[39m
[1693633987765] --- Observations received -- 
[1693633987765] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CoalOreSmall (2) at X: 59.32, Y: 14.11",
  "time": 191.340042
}
[1693633987765] [Character] Getting character: A2
[1693633987827] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633987828] [33m[OPENAI] Creating embedding...[39m
[1693633987900] [32m[OPENAI] Embedding created successfully.[39m
[1693633988023] [32m[OPENAI] Embedding created successfully.[39m
[1693633988031] {
  "id": "chatcmpl-7uDr9ak1KDzQJySYDQc38YJjWqKff",
  "object": "chat.completion",
  "created": 1693633987,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633988031] {
  "role": "assistant",
  "content": "2"
}
[1693633988031] [36m[OPENAI] Chat completion took 272.3404998779297ms[39m
[1693633988031] [36m[OPENAI] Global tokens per second: 12.18547555395352tps[39m
[1693633988031] [36m[OPENAI] Tokens per second: 3.6718739976177868tps[39m
[1693633988031] [32m[OPENAI] Chat completion created successfully.[39m
[1693633988129] {
  "id": "chatcmpl-7uDr9cu6XrSlVnVivQjLVeUl2cEa1",
  "object": "chat.completion",
  "created": 1693633987,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633988129] {
  "role": "assistant",
  "content": "2"
}
[1693633988129] [36m[OPENAI] Chat completion took 301.44079184532166ms[39m
[1693633988129] [36m[OPENAI] Global tokens per second: 12.18450391305218tps[39m
[1693633988129] [36m[OPENAI] Tokens per second: 3.3174010520551254tps[39m
[1693633988129] [32m[OPENAI] Chat completion created successfully.[39m
[1693633988338] --- Observations received -- 
[1693633988339] {
  "observerId": "A2",
  "observation": "George Brown sees Iron Ore Deposit (Large) at X: 65.92, Y: 23.75.",
  "time": 191.921219
}
[1693633988339] [Character] Getting character: A2
[1693633988400] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633988400] [33m[OPENAI] Creating embedding...[39m
[1693633988583] {
  "id": "chatcmpl-7uDr75Bxj3rYgVXsDBQozW8pZ1RmW",
  "object": "chat.completion",
  "created": 1693633985,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.13,\n  \"y\": 26.69\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2031,
    "completion_tokens": 35,
    "total_tokens": 2066
  }
}
[1693633988584] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 53.13,\n  \"y\": 26.69\n}"
  }
}
[1693633988584] [36m[OPENAI] Chat completion took 3294.608792066574ms[39m
[1693633988584] [36m[OPENAI] Global tokens per second: 12.331564311354525tps[39m
[1693633988585] [36m[OPENAI] Tokens per second: 10.623416074248354tps[39m
[1693633988585] [32m[OPENAI] Chat completion created successfully.[39m
[1693633988588] [32m[OPENAI] Embedding created successfully.[39m
[1693633988590] --- Observations received -- 
[1693633988590] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 53.13, Y: 26.69.",
  "time": 192.172943
}
[1693633988590] [Character] Getting character: A4
[1693633988639] --- Observations received -- 
[1693633988639] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 53.13, Y: 26.69.",
  "time": 192.219925
}
[1693633988639] [Character] Getting character: A4
[1693633988639] --- Observations received -- 
[1693633988639] {
  "observerId": "A2",
  "observation": "George Brown no longer sees CoalOreLarge (1) at X: 58.91, Y: 19.37",
  "time": 192.2218
}
[1693633988639] [Character] Getting character: A2
[1693633988641] [Character] Getting character: A4
[1693633988649] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633988649] [33m[OPENAI] Creating embedding...[39m
[1693633988670] [33m[OPENAI] Creating embedding...[39m
[1693633988678] {
  "id": "chatcmpl-7uDrAlieBE2iSoEfMTT23ktN45JmP",
  "object": "chat.completion",
  "created": 1693633988,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633988679] {
  "role": "assistant",
  "content": "2"
}
[1693633988679] [36m[OPENAI] Chat completion took 278.6858329772949ms[39m
[1693633988679] [36m[OPENAI] Global tokens per second: 12.330708504246633tps[39m
[1693633988679] [36m[OPENAI] Tokens per second: 3.5882699501322404tps[39m
[1693633988679] [32m[OPENAI] Chat completion created successfully.[39m
[1693633988696] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633988697] [33m[OPENAI] Creating embedding...[39m
[1693633988699] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633988706] [33m[OPENAI] Creating embedding...[39m
[1693633988763] --- Observations received -- 
[1693633988764] {
  "observerId": "A2",
  "observation": "George Brown sees Iron Ore Deposit (Large) at X: 69.37, Y: 22.11.",
  "time": 192.341171
}
[1693633988764] [Character] Getting character: A2
[1693633988764] --- Observations received -- 
[1693633988764] {
  "observerId": "A2",
  "observation": "George Brown sees Iron Ore Deposit (Large) at X: 69.37, Y: 22.11.",
  "time": 192.341171
}
[1693633988764] [Character] Getting character: A2
[1693633988778] --- Observations received -- 
[1693633988778] {
  "observerId": "A2",
  "observation": "George Brown finished walking to 65.22, Y: 18.37.",
  "time": 192.359924
}
[1693633988778] [Character] Getting character: A2
[1693633988783] [Character] Getting character: A2
[1693633988824] [33m[OPENAI] Creating embedding...[39m
[1693633988833] [32m[OPENAI] Embedding created successfully.[39m
[1693633988852] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633988852] [33m[OPENAI] Creating embedding...[39m
[1693633988853] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633988853] [33m[OPENAI] Creating embedding...[39m
[1693633988854] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633988854] [33m[OPENAI] Creating embedding...[39m
[1693633988855] [32m[OPENAI] Embedding created successfully.[39m
[1693633988873] [32m[OPENAI] Embedding created successfully.[39m
[1693633988889] [32m[OPENAI] Embedding created successfully.[39m
[1693633988926] {
  "id": "chatcmpl-7uDrAAoV1NfuvZ0nuS5SuYxc0sN9J",
  "object": "chat.completion",
  "created": 1693633988,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633988926] {
  "role": "assistant",
  "content": "1"
}
[1693633988926] [36m[OPENAI] Chat completion took 277.0132911205292ms[39m
[1693633988926] [36m[OPENAI] Global tokens per second: 12.320512756615049tps[39m
[1693633988926] [36m[OPENAI] Tokens per second: 3.6099350899552953tps[39m
[1693633988926] [32m[OPENAI] Chat completion created successfully.[39m
[1693633988975] {
  "id": "chatcmpl-7uDrAgP1msiTgm1CWo4kjwR4pqie6",
  "object": "chat.completion",
  "created": 1693633988,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633988975] {
  "role": "assistant",
  "content": "3"
}
[1693633988975] [36m[OPENAI] Chat completion took 278.55166697502136ms[39m
[1693633988975] [36m[OPENAI] Global tokens per second: 12.322487418406498tps[39m
[1693633988975] [36m[OPENAI] Tokens per second: 3.5899982608600696tps[39m
[1693633988975] [32m[OPENAI] Chat completion created successfully.[39m
[1693633988991] [32m[OPENAI] Embedding created successfully.[39m
[1693633989023] [32m[OPENAI] Embedding created successfully.[39m
[1693633989074] {
  "id": "chatcmpl-7uDrAKTaLD3jHVbhAKGsTs43OpHXj",
  "object": "chat.completion",
  "created": 1693633988,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6.5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 3,
    "total_tokens": 111
  }
}
[1693633989074] {
  "role": "assistant",
  "content": "6.5"
}
[1693633989074] [36m[OPENAI] Chat completion took 374.8119580745697ms[39m
[1693633989074] [36m[OPENAI] Global tokens per second: 12.331352813152115tps[39m
[1693633989074] [36m[OPENAI] Tokens per second: 8.004013573662832tps[39m
[1693633989074] [32m[OPENAI] Chat completion created successfully.[39m
[1693633989082] [32m[OPENAI] Embedding created successfully.[39m
[1693633989101] {
  "id": "chatcmpl-7uDrAkvuWeYyaRxxUldQI9KuZ2prv",
  "object": "chat.completion",
  "created": 1693633988,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633989101] {
  "role": "assistant",
  "content": "2"
}
[1693633989101] [36m[OPENAI] Chat completion took 248.90812492370605ms[39m
[1693633989101] [36m[OPENAI] Global tokens per second: 12.334674527926062tps[39m
[1693633989101] [36m[OPENAI] Tokens per second: 4.0175466361594845tps[39m
[1693633989101] [32m[OPENAI] Chat completion created successfully.[39m
[1693633989150] {
  "id": "chatcmpl-7uDrA2DaPOIXQQLCx7szHVoc99ZJm",
  "object": "chat.completion",
  "created": 1693633988,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633989151] {
  "role": "assistant",
  "content": "1"
}
[1693633989151] [36m[OPENAI] Chat completion took 296.56841683387756ms[39m
[1693633989151] [36m[OPENAI] Global tokens per second: 12.336582597353459tps[39m
[1693633989151] [36m[OPENAI] Tokens per second: 3.3719032211044535tps[39m
[1693633989151] [32m[OPENAI] Chat completion created successfully.[39m
[1693633989193] {
  "id": "chatcmpl-7uDrAnsXGM8rThouaa9Fb3uYuQSDn",
  "object": "chat.completion",
  "created": 1693633988,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633989193] {
  "role": "assistant",
  "content": "2"
}
[1693633989193] [36m[OPENAI] Chat completion took 340.3757908344269ms[39m
[1693633989193] [36m[OPENAI] Global tokens per second: 12.338981026141319tps[39m
[1693633989193] [36m[OPENAI] Tokens per second: 2.9379292738432214tps[39m
[1693633989193] [32m[OPENAI] Chat completion created successfully.[39m
[1693633989423] [33m[OPENAI] Creating embedding...[39m
[1693633989573] [32m[OPENAI] Embedding created successfully.[39m
[1693633989613] [33m[OPENAI] Creating embedding...[39m
[1693633989771] [32m[OPENAI] Embedding created successfully.[39m
[1693633990083] [33m[OPENAI] Creating embedding...[39m
[1693633990242] [32m[OPENAI] Embedding created successfully.[39m
[1693633990275] [32m[OPENAI] Embedding created successfully.[39m
[1693633990371] [33m[OPENAI] Creating embedding...[39m
[1693633990723] [33m[OPENAI] Creating embedding...[39m
[1693633990895] [32m[OPENAI] Embedding created successfully.[39m
[1693633991319] [32m[OPENAI] Embedding created successfully.[39m
[1693633991357] [33m[OPENAI] Creating embedding...[39m
[1693633991539] [32m[OPENAI] Embedding created successfully.[39m
[1693633991904] [33m[OPENAI] Creating embedding...[39m
[1693633992017] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633992060] [32m[OPENAI] Embedding created successfully.[39m
[1693633992665] [33m[OPENAI] Creating embedding...[39m
[1693633992870] [32m[OPENAI] Embedding created successfully.[39m
[1693633993432] [33m[OPENAI] Creating embedding...[39m
[1693633993665] [32m[OPENAI] Embedding created successfully.[39m
[1693633994182] [33m[OPENAI] Creating embedding...[39m
[1693633994515] [32m[OPENAI] Embedding created successfully.[39m
[1693633995053] [33m[OPENAI] Creating embedding...[39m
[1693633995195] [32m[OPENAI] Embedding created successfully.[39m
[1693633995676] [33m[OPENAI] Creating embedding...[39m
[1693633995926] [32m[OPENAI] Embedding created successfully.[39m
[1693633996056] {
  "id": "chatcmpl-7uDrEjZIIiLuPBLCAimbOnraFVZ9V",
  "object": "chat.completion",
  "created": 1693633992,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 54.06,\n  \"y\": 24.46\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2031,
    "completion_tokens": 35,
    "total_tokens": 2066
  }
}
[1693633996056] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 54.06,\n  \"y\": 24.46\n}"
  }
}
[1693633996056] [36m[OPENAI] Chat completion took 4038.830416917801ms[39m
[1693633996056] [36m[OPENAI] Global tokens per second: 12.099859941955327tps[39m
[1693633996056] [36m[OPENAI] Tokens per second: 8.665875114090568tps[39m
[1693633996056] [32m[OPENAI] Chat completion created successfully.[39m
[1693633996064] --- Observations received -- 
[1693633996064] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 54.06, Y: 24.46.",
  "time": 199.646667
}
[1693633996064] [Character] Getting character: A4
[1693633996147] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633996148] [33m[OPENAI] Creating embedding...[39m
[1693633996178] --- Observations received -- 
[1693633996178] {
  "observerId": "A4",
  "observation": "Lucy Wilde sees Diamond Ore Deposit (Small) at X: 58.32, Y: 22.87.",
  "time": 199.76091
}
[1693633996178] [Character] Getting character: A4
[1693633996253] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633996253] [33m[OPENAI] Creating embedding...[39m
[1693633996381] [33m[OPENAI] Creating embedding...[39m
[1693633996394] [32m[OPENAI] Embedding created successfully.[39m
[1693633996420] [32m[OPENAI] Embedding created successfully.[39m
[1693633996526] {
  "id": "chatcmpl-7uDrI1W3755CgZkV8uNEzYjhI43fb",
  "object": "chat.completion",
  "created": 1693633996,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633996527] {
  "role": "assistant",
  "content": "1"
}
[1693633996527] [36m[OPENAI] Chat completion took 378.8644998073578ms[39m
[1693633996527] [36m[OPENAI] Global tokens per second: 12.077294685990339tps[39m
[1693633996527] [36m[OPENAI] Tokens per second: 2.639466090141654tps[39m
[1693633996527] [32m[OPENAI] Chat completion created successfully.[39m
[1693633996565] [32m[OPENAI] Embedding created successfully.[39m
[1693633996759] --- Observations received -- 
[1693633996759] {
  "observerId": "A4",
  "observation": "Lucy Wilde no longer sees CopperOreLarge (1) at X: 49.04, Y: 28.68",
  "time": 200.340912
}
[1693633996759] [Character] Getting character: A4
[1693633996777] --- Observations received -- 
[1693633996777] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 54.06, Y: 24.46.",
  "time": 200.359924
}
[1693633996777] [Character] Getting character: A4
[1693633996779] [Character] Getting character: A4
[1693633996811] [33m[OPENAI] Creating embedding...[39m
[1693633996814] {
  "id": "chatcmpl-7uDrIv5ehVaYPNIFJvO7nz4H7fxzS",
  "object": "chat.completion",
  "created": 1693633996,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693633996814] {
  "role": "assistant",
  "content": "1"
}
[1693633996814] [36m[OPENAI] Chat completion took 560.8593339920044ms[39m
[1693633996814] [36m[OPENAI] Global tokens per second: 12.065468112348881tps[39m
[1693633996814] [36m[OPENAI] Tokens per second: 1.7829782610237455tps[39m
[1693633996814] [32m[OPENAI] Chat completion created successfully.[39m
[1693633996853] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633996853] [33m[OPENAI] Creating embedding...[39m
[1693633996854] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633996854] [33m[OPENAI] Creating embedding...[39m
[1693633996999] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693633997009] [32m[OPENAI] Embedding created successfully.[39m
[1693633997019] [32m[OPENAI] Embedding created successfully.[39m
[1693633997087] [32m[OPENAI] Embedding created successfully.[39m
[1693633997127] {
  "id": "chatcmpl-7uDrIbpMvAJTNc1osREg9hLZmqC4s",
  "object": "chat.completion",
  "created": 1693633996,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693633997127] {
  "role": "assistant",
  "content": "4"
}
[1693633997127] [36m[OPENAI] Chat completion took 273.7404170036316ms[39m
[1693633997127] [36m[OPENAI] Global tokens per second: 12.052173413393858tps[39m
[1693633997127] [36m[OPENAI] Tokens per second: 3.6530959181914793tps[39m
[1693633997127] [32m[OPENAI] Chat completion created successfully.[39m
[1693633997197] {
  "id": "chatcmpl-7uDrIMz4w7Lbpm4vtthQWbLuxM567",
  "object": "chat.completion",
  "created": 1693633996,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693633997197] {
  "role": "assistant",
  "content": "3"
}
[1693633997197] [36m[OPENAI] Chat completion took 343.4657919406891ms[39m
[1693633997197] [36m[OPENAI] Global tokens per second: 12.052921804396108tps[39m
[1693633997197] [36m[OPENAI] Tokens per second: 2.9114980981066187tps[39m
[1693633997197] [32m[OPENAI] Chat completion created successfully.[39m
[1693633997498] [33m[OPENAI] Creating embedding...[39m
[1693633997729] [32m[OPENAI] Embedding created successfully.[39m
[1693633998285] [33m[OPENAI] Creating embedding...[39m
[1693633998422] [32m[OPENAI] Embedding created successfully.[39m
[1693633998904] [33m[OPENAI] Creating embedding...[39m
[1693633999069] [32m[OPENAI] Embedding created successfully.[39m
[1693633999562] [33m[OPENAI] Creating embedding...[39m
[1693633999630] {
  "id": "chatcmpl-7uDrJAvIBPas6SR3sYmCORnGr6ABR",
  "object": "chat.completion",
  "created": 1693633997,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 62.25,\n  \"y\": 15.1\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2117,
    "completion_tokens": 35,
    "total_tokens": 2152
  }
}
[1693633999630] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A2\",\n  \"x\": 62.25,\n  \"y\": 15.1\n}"
  }
}
[1693633999630] [36m[OPENAI] Chat completion took 2631.013083934784ms[39m
[1693633999630] [36m[OPENAI] Global tokens per second: 12.07977477584045tps[39m
[1693633999630] [36m[OPENAI] Tokens per second: 13.302860488879105tps[39m
[1693633999630] [32m[OPENAI] Chat completion created successfully.[39m
[1693633999635] --- Observations received -- 
[1693633999635] {
  "observerId": "A2",
  "observation": "George Brown has started walking to 62.25, Y: 15.1.",
  "time": 203.218246
}
[1693633999635] [Character] Getting character: A2
[1693633999697] --- Observations received -- 
[1693633999697] {
  "observerId": "A2",
  "observation": "George Brown no longer sees IronOreSmall (4) at X: 69.37, Y: 22.11",
  "time": 203.280136
}
[1693633999697] [Character] Getting character: A2
[1693633999697] --- Observations received -- 
[1693633999697] {
  "observerId": "A2",
  "observation": "George Brown no longer sees IronOreSmall (2) at X: 69.37, Y: 22.11",
  "time": 203.280136
}
[1693633999697] [Character] Getting character: A2
[1693633999697] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633999697] [33m[OPENAI] Creating embedding...[39m
[1693633999721] [32m[OPENAI] Embedding created successfully.[39m
[1693633999756] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633999756] [33m[OPENAI] Creating embedding...[39m
[1693633999757] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633999758] [33m[OPENAI] Creating embedding...[39m
[1693633999797] --- Observations received -- 
[1693633999797] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Large) at X: 58.91, Y: 19.37.",
  "time": 203.380157
}
[1693633999797] [Character] Getting character: A2
[1693633999840] [32m[OPENAI] Embedding created successfully.[39m
[1693633999870] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693633999870] [33m[OPENAI] Creating embedding...[39m
[1693633999941] [32m[OPENAI] Embedding created successfully.[39m
[1693633999961] {
  "id": "chatcmpl-7uDrL9WaYEkh2qF0xRiggtskhGT8x",
  "object": "chat.completion",
  "created": 1693633999,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693633999961] {
  "role": "assistant",
  "content": "2"
}
[1693633999961] [36m[OPENAI] Chat completion took 263.61908411979675ms[39m
[1693633999961] [36m[OPENAI] Global tokens per second: 12.065609705398817tps[39m
[1693633999961] [36m[OPENAI] Tokens per second: 3.7933520759277384tps[39m
[1693633999961] [32m[OPENAI] Chat completion created successfully.[39m
[1693633999975] [32m[OPENAI] Embedding created successfully.[39m
[1693634000012] {
  "id": "chatcmpl-7uDrLKJLCJQRsOB0eGCofncXsQfU4",
  "object": "chat.completion",
  "created": 1693633999,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693634000013] {
  "role": "assistant",
  "content": "5"
}
[1693634000013] [36m[OPENAI] Chat completion took 255.46929097175598ms[39m
[1693634000013] [36m[OPENAI] Global tokens per second: 12.067369455150004tps[39m
[1693634000013] [36m[OPENAI] Tokens per second: 3.914364799762009tps[39m
[1693634000013] [32m[OPENAI] Chat completion created successfully.[39m
[1693634000087] [32m[OPENAI] Embedding created successfully.[39m
[1693634000097] {
  "id": "chatcmpl-7uDrLctgXhLpKE0bjCy5x4TRfT3Dl",
  "object": "chat.completion",
  "created": 1693633999,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693634000097] {
  "role": "assistant",
  "content": "2"
}
[1693634000098] [36m[OPENAI] Chat completion took 339.6776249408722ms[39m
[1693634000098] [36m[OPENAI] Global tokens per second: 12.067247997054006tps[39m
[1693634000098] [36m[OPENAI] Tokens per second: 2.94396782883203tps[39m
[1693634000098] [32m[OPENAI] Chat completion created successfully.[39m
[1693634000152] --- Observations received -- 
[1693634000153] {
  "observerId": "A2",
  "observation": "George Brown no longer sees IronOreLarge at X: 65.92, Y: 23.75",
  "time": 203.721237
}
[1693634000153] [Character] Getting character: A2
[1693634000210] {
  "id": "chatcmpl-7uDrLoheBkJkzRPXwFxI6kaXXSXs4",
  "object": "chat.completion",
  "created": 1693633999,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693634000210] {
  "role": "assistant",
  "content": "4"
}
[1693634000210] [36m[OPENAI] Chat completion took 339.50970792770386ms[39m
[1693634000210] [36m[OPENAI] Global tokens per second: 12.065589241476937tps[39m
[1693634000210] [36m[OPENAI] Tokens per second: 2.945423876400444tps[39m
[1693634000210] [32m[OPENAI] Chat completion created successfully.[39m
[1693634000214] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693634000214] [33m[OPENAI] Creating embedding...[39m
[1693634000331] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693634000370] [32m[OPENAI] Embedding created successfully.[39m
[1693634000538] --- Observations received -- 
[1693634000538] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Small) at X: 59.32, Y: 14.11.",
  "time": 204.119949
}
[1693634000538] [Character] Getting character: A2
[1693634000596] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693634000597] [33m[OPENAI] Creating embedding...[39m
[1693634000627] {
  "id": "chatcmpl-7uDrMjN5vfsauJHrY4q876PAX8NaM",
  "object": "chat.completion",
  "created": 1693634000,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693634000627] {
  "role": "assistant",
  "content": "2"
}
[1693634000627] [36m[OPENAI] Chat completion took 412.54904103279114ms[39m
[1693634000627] [36m[OPENAI] Global tokens per second: 12.046604063256444tps[39m
[1693634000627] [36m[OPENAI] Tokens per second: 2.4239542467401245tps[39m
[1693634000627] [32m[OPENAI] Chat completion created successfully.[39m
[1693634000826] [32m[OPENAI] Embedding created successfully.[39m
[1693634000966] {
  "id": "chatcmpl-7uDrMYahDbUsIsfAmvyydqB4kZxya",
  "object": "chat.completion",
  "created": 1693634000,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693634000966] {
  "role": "assistant",
  "content": "4"
}
[1693634000966] [36m[OPENAI] Chat completion took 369.20733284950256ms[39m
[1693634000966] [36m[OPENAI] Global tokens per second: 12.032104419294624tps[39m
[1693634000966] [36m[OPENAI] Tokens per second: 2.7085052517297186tps[39m
[1693634000966] [32m[OPENAI] Chat completion created successfully.[39m
[1693634001019] --- Observations received -- 
[1693634001020] {
  "observerId": "A2",
  "observation": "George Brown sees Coal Ore Deposit (Medium) at X: 57.27, Y: 17.32.",
  "time": 204.60144
}
[1693634001020] [Character] Getting character: A2
[1693634001082] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693634001082] [33m[OPENAI] Creating embedding...[39m
[1693634001140] --- Observations received -- 
[1693634001140] {
  "observerId": "A2",
  "observation": "George Brown no longer sees IronOreSmall (1) at X: 68.08, Y: 19.36",
  "time": 204.720215
}
[1693634001140] [Character] Getting character: A2
[1693634001197] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693634001197] [33m[OPENAI] Creating embedding...[39m
[1693634001268] [32m[OPENAI] Embedding created successfully.[39m
[1693634001337] --- Observations received -- 
[1693634001337] {
  "observerId": "A2",
  "observation": "George Brown no longer sees IronOreLarge (1) at X: 64.4, Y: 22.23",
  "time": 204.920425
}
[1693634001337] [Character] Getting character: A2
[1693634001350] [32m[OPENAI] Embedding created successfully.[39m
[1693634001358] --- Observations received -- 
[1693634001358] {
  "observerId": "A2",
  "observation": "George Brown no longer sees DiamondOreMedium at X: 60.84, Y: 22.05",
  "time": 204.94104
}
[1693634001358] [Character] Getting character: A2
[1693634001399] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693634001403] [33m[OPENAI] Creating embedding...[39m
[1693634001417] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693634001417] [33m[OPENAI] Creating embedding...[39m
[1693634001418] --- Observations received -- 
[1693634001418] {
  "observerId": "A2",
  "observation": "George Brown no longer sees IronOreMedium at X: 66.39, Y: 21.18",
  "time": 205.000183
}
[1693634001418] [Character] Getting character: A2
[1693634001452] {
  "id": "chatcmpl-7uDrNm1ySLSEMxDuGNVQmghBlXoQ6",
  "object": "chat.completion",
  "created": 1693634001,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693634001452] {
  "role": "assistant",
  "content": "4"
}
[1693634001452] [36m[OPENAI] Chat completion took 370.33783292770386ms[39m
[1693634001452] [36m[OPENAI] Global tokens per second: 12.009363550643393tps[39m
[1693634001452] [36m[OPENAI] Tokens per second: 2.7002372187969703tps[39m
[1693634001452] [32m[OPENAI] Chat completion created successfully.[39m
[1693634001479] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693634001479] [33m[OPENAI] Creating embedding...[39m
[1693634001567] {
  "id": "chatcmpl-7uDrNBQqkOn0YIyeq8Ze3VcM8B2LP",
  "object": "chat.completion",
  "created": 1693634001,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 2,
    "total_tokens": 110
  }
}
[1693634001567] {
  "role": "assistant",
  "content": "4."
}
[1693634001567] [36m[OPENAI] Chat completion took 369.55316710472107ms[39m
[1693634001567] [36m[OPENAI] Global tokens per second: 12.012265451374237tps[39m
[1693634001567] [36m[OPENAI] Tokens per second: 5.411941171196229tps[39m
[1693634001567] [32m[OPENAI] Chat completion created successfully.[39m
[1693634001572] [32m[OPENAI] Embedding created successfully.[39m
[1693634001633] [32m[OPENAI] Embedding created successfully.[39m
[1693634001652] {
  "id": "chatcmpl-7uDrNz4abJbyu2k8aFafBuOQU92aL",
  "object": "chat.completion",
  "created": 1693634001,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693634001652] {
  "role": "assistant",
  "content": "2"
}
[1693634001652] [36m[OPENAI] Chat completion took 251.82575011253357ms[39m
[1693634001652] [36m[OPENAI] Global tokens per second: 12.012166829922153tps[39m
[1693634001652] [36m[OPENAI] Tokens per second: 3.9709997867697377tps[39m
[1693634001652] [32m[OPENAI] Chat completion created successfully.[39m
[1693634001706] [32m[OPENAI] Embedding created successfully.[39m
[1693634001740] {
  "id": "chatcmpl-7uDrNNH2NdVKKUxMxjHdDVj0ySzSo",
  "object": "chat.completion",
  "created": 1693634001,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693634001740] {
  "role": "assistant",
  "content": "1"
}
[1693634001740] [36m[OPENAI] Chat completion took 322.5885000228882ms[39m
[1693634001740] [36m[OPENAI] Global tokens per second: 12.011899463587172tps[39m
[1693634001740] [36m[OPENAI] Tokens per second: 3.0999245166180702tps[39m
[1693634001740] [32m[OPENAI] Chat completion created successfully.[39m
[1693634001811] {
  "id": "chatcmpl-7uDrNimN5JQGTtboDRKLv0IwBe889",
  "object": "chat.completion",
  "created": 1693634001,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693634001811] {
  "role": "assistant",
  "content": "2"
}
[1693634001811] [36m[OPENAI] Chat completion took 332.22499990463257ms[39m
[1693634001811] [36m[OPENAI] Global tokens per second: 12.012588630892724tps[39m
[1693634001811] [36m[OPENAI] Tokens per second: 3.0100082783868065tps[39m
[1693634001811] [32m[OPENAI] Chat completion created successfully.[39m
[1693634001899] --- Observations received -- 
[1693634001899] {
  "observerId": "A2",
  "observation": "George Brown finished walking to 62.25, Y: 15.1.",
  "time": 205.479935
}
[1693634001899] [Character] Getting character: A2
[1693634001905] [Character] Getting character: A2
[1693634001937] [33m[OPENAI] Creating embedding...[39m
[1693634001961] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693634001961] [33m[OPENAI] Creating embedding...[39m
[1693634002119] [32m[OPENAI] Embedding created successfully.[39m
[1693634002226] [32m[OPENAI] Embedding created successfully.[39m
[1693634002510] {
  "id": "chatcmpl-7uDrOwe03PCNsMZ0qDnRdytXSg2GH",
  "object": "chat.completion",
  "created": 1693634002,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693634002510] {
  "role": "assistant",
  "content": "2"
}
[1693634002510] [36m[OPENAI] Chat completion took 548.8654999732971ms[39m
[1693634002510] [36m[OPENAI] Global tokens per second: 11.978060450460964tps[39m
[1693634002510] [36m[OPENAI] Tokens per second: 1.8219399835636436tps[39m
[1693634002510] [32m[OPENAI] Chat completion created successfully.[39m
[1693634002841] [33m[OPENAI] Creating embedding...[39m
[1693634003033] [32m[OPENAI] Embedding created successfully.[39m
[1693634003605] [33m[OPENAI] Creating embedding...[39m
[1693634003834] {
  "id": "chatcmpl-7uDrMb7um6FQffS9OYErIaXuPun26",
  "object": "chat.completion",
  "created": 1693634000,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 54.06,\n  \"y\": 24.46\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2078,
    "completion_tokens": 35,
    "total_tokens": 2113
  }
}
[1693634003834] {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "move_to",
    "arguments": "{\n  \"characterId\": \"A4\",\n  \"x\": 54.06,\n  \"y\": 24.46\n}"
  }
}
[1693634003834] [36m[OPENAI] Chat completion took 3502.42108297348ms[39m
[1693634003834] [36m[OPENAI] Global tokens per second: 12.066861827241137tps[39m
[1693634003834] [36m[OPENAI] Tokens per second: 9.993087401782585tps[39m
[1693634003834] [32m[OPENAI] Chat completion created successfully.[39m
[1693634003838] --- Observations received -- 
[1693634003838] {
  "observerId": "A4",
  "observation": "Lucy Wilde has started walking to 54.06, Y: 24.46.",
  "time": 207.421555
}
[1693634003838] [Character] Getting character: A4
[1693634003898] --- Observations received -- 
[1693634003898] {
  "observerId": "A4",
  "observation": "Lucy Wilde finished walking to 54.06, Y: 24.46.",
  "time": 207.479919
}
[1693634003898] [Character] Getting character: A4
[1693634003899] [Character] Getting character: A4
[1693634003906] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693634003906] [33m[OPENAI] Creating embedding...[39m
[1693634003928] [33m[OPENAI] Creating embedding...[39m
[1693634003961] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693634003961] [33m[OPENAI] Creating embedding...[39m
[1693634004020] [32m[OPENAI] Embedding created successfully.[39m
[1693634004066] [32m[OPENAI] Embedding created successfully.[39m
[1693634004087] [32m[OPENAI] Embedding created successfully.[39m
[1693634004114] [32m[OPENAI] Embedding created successfully.[39m
[1693634004263] [35m[CORTEX] Eli Green - New Goal: Find a way to fulfill Thomas Smith's request without causing unnecessary harm to the forest}[39m
[1693634004264] {
  "id": "chatcmpl-7uDrQtyWuORTAEygQvzKSGeyo0d5V",
  "object": "chat.completion",
  "created": 1693634004,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693634004264] {
  "role": "assistant",
  "content": "2"
}
[1693634004264] [36m[OPENAI] Chat completion took 302.8129999637604ms[39m
[1693634004264] [36m[OPENAI] Global tokens per second: 12.047467577866366tps[39m
[1693634004264] [36m[OPENAI] Tokens per second: 3.3023681285799373tps[39m
[1693634004264] [32m[OPENAI] Chat completion created successfully.[39m
[1693634004280] {
  "id": "chatcmpl-7uDrQI6NRxdmRmbuO3GMyKNfUO1uy",
  "object": "chat.completion",
  "created": 1693634004,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693634004280] {
  "role": "assistant",
  "content": "1"
}
[1693634004280] [36m[OPENAI] Chat completion took 373.75450015068054ms[39m
[1693634004280] [36m[OPENAI] Global tokens per second: 12.05120488900206tps[39m
[1693634004280] [36m[OPENAI] Tokens per second: 2.6755530691853773tps[39m
[1693634004280] [32m[OPENAI] Chat completion created successfully.[39m
[1693634004686] [33m[OPENAI] Creating embedding...[39m
[1693634004746] [33m[OPENAI] Creating embedding...[39m
[1693634004828] [32m[OPENAI] Embedding created successfully.[39m
[1693634004916] [32m[OPENAI] Embedding created successfully.[39m
[1693634005493] [33m[OPENAI] Creating embedding...[39m
[1693634005522] [33m[OPENAI] Creating embedding...[39m
[1693634005671] [32m[OPENAI] Embedding created successfully.[39m
[1693634005710] [32m[OPENAI] Embedding created successfully.[39m
[1693634006310] [33m[OPENAI] Creating embedding...[39m
[1693634006311] [33m[OPENAI] Creating embedding...[39m
[1693634006485] [32m[OPENAI] Embedding created successfully.[39m
[1693634006536] [32m[OPENAI] Embedding created successfully.[39m
