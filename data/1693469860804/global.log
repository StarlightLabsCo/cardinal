[1693469860810] [Character] Creating Thomas's logger
[1693469860811] [Character] Creating George's logger
[1693469860811] [Character] Creating Will's logger
[1693469860811] [Character] Creating Lucy's logger
[1693469860812] [Character] Creating Eli's logger
[1693469860814] [Main] WebSocket server listening on port 8082
[1693469861070] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861071] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: Today was my first day in the mines."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861071] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861072] [33m[OPENAI] Creating embedding...[39m
[1693469861072] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861072] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: George and Thomas have been really helpful."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861073] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861073] [33m[OPENAI] Creating embedding...[39m
[1693469861073] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861073] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: The depth and darkness of the mines can be intimidating."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861073] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861073] [33m[OPENAI] Creating embedding...[39m
[1693469861073] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861073] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I accidentally broke a pickaxe on my first day."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861074] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861074] [33m[OPENAI] Creating embedding...[39m
[1693469861074] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861074] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: The older miners have so many stories to tell."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861074] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861074] [33m[OPENAI] Creating embedding...[39m
[1693469861074] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861074] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I've always dreamed of being a miner like my father."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861074] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861074] [33m[OPENAI] Creating embedding...[39m
[1693469861074] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861074] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: The echo in the mines is fascinating."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861074] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861074] [33m[OPENAI] Creating embedding...[39m
[1693469861074] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861074] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I need to remember to wear my helmet at all times."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861074] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861074] [33m[OPENAI] Creating embedding...[39m
[1693469861074] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861075] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: The village has been supportive of my new journey."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861075] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861075] [33m[OPENAI] Creating embedding...[39m
[1693469861075] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861075] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I'm still learning the different routes in the mine."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861075] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861075] [33m[OPENAI] Creating embedding...[39m
[1693469861075] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861075] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I was startled by the sound of a mine cart today."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861075] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861075] [33m[OPENAI] Creating embedding...[39m
[1693469861075] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861075] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: It's tiring, but I'm determined to make everyone proud."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861075] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861075] [33m[OPENAI] Creating embedding...[39m
[1693469861075] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861075] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I hope to find a rare gem or mineral soon."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861075] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861075] [33m[OPENAI] Creating embedding...[39m
[1693469861075] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861075] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: The lanterns light up the mines in such a mysterious way."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861075] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861075] [33m[OPENAI] Creating embedding...[39m
[1693469861075] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861075] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I can't wait to tell my family about my adventures here."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861075] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861075] [33m[OPENAI] Creating embedding...[39m
[1693469861159] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861160] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I need to let Thomas know I'm going to explore. He's asked me in the past to let him know just in case I get hurt or lost."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861160] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861160] [33m[OPENAI] Creating embedding...[39m
[1693469861160] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861160] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I once found a secret clearing in the woods, it's my personal hideout now."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861160] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861160] [33m[OPENAI] Creating embedding...[39m
[1693469861160] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861160] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: The world feels so big and full of wonders, I want to see them all!"
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861160] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861160] [33m[OPENAI] Creating embedding...[39m
[1693469861160] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861160] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I saw a deer up close once, our eyes met and we just stared for a moment."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861160] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861160] [33m[OPENAI] Creating embedding...[39m
[1693469861160] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861160] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: Climbing trees is my favorite! The higher I go, the bigger the world looks."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861160] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861160] [33m[OPENAI] Creating embedding...[39m
[1693469861160] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861160] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: Lucy showed me how to listen to the forest, it's like it's telling stories."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861160] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861160] [33m[OPENAI] Creating embedding...[39m
[1693469861160] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861160] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: Every rock and leaf, every bird and bug, feels like a friend to me."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861160] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861160] [33m[OPENAI] Creating embedding...[39m
[1693469861160] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861160] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I once got lost, but the stars guided me home. They're like nature's map!"
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861160] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861160] [33m[OPENAI] Creating embedding...[39m
[1693469861160] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861160] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: George tells me tales of old, turning every tree and hill into an adventure."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861160] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861160] [33m[OPENAI] Creating embedding...[39m
[1693469861160] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861161] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I made a whistle out of a reed! Nature is full of surprises."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861161] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861161] [33m[OPENAI] Creating embedding...[39m
[1693469861161] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861161] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: The woods in autumn is my favorite. All those colors... like nature's painting!"
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861161] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861161] [33m[OPENAI] Creating embedding...[39m
[1693469861161] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861161] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I wish I could talk to animals. Imagine the stories they'd tell!"
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861161] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861161] [33m[OPENAI] Creating embedding...[39m
[1693469861161] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861161] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I've learned to move silently. That way, nature doesn’t hide from me."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861161] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861161] [33m[OPENAI] Creating embedding...[39m
[1693469861161] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861161] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: Lucy once said every tree has a story. I'm trying to learn them all."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861161] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861161] [33m[OPENAI] Creating embedding...[39m
[1693469861161] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861161] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: Rainy days? That's when the forest sings its loudest song!"
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861161] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861161] [33m[OPENAI] Creating embedding...[39m
[1693469861161] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861161] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I dreamt I could fly like a bird, seeing the world from above. Maybe one day..."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861161] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861161] [33m[OPENAI] Creating embedding...[39m
[1693469861169] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861169] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: Working in the mines is tough but rewarding."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861169] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861169] [33m[OPENAI] Creating embedding...[39m
[1693469861169] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861169] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I've been friends with Thomas for a long time."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861169] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861169] [33m[OPENAI] Creating embedding...[39m
[1693469861169] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861169] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: Safety in the mines is a top priority for me."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861169] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861169] [33m[OPENAI] Creating embedding...[39m
[1693469861169] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861169] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I've discovered some rare minerals during my time here."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861169] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861169] [33m[OPENAI] Creating embedding...[39m
[1693469861169] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861169] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I'm usually one of the first to arrive at the mine site."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861169] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861169] [33m[OPENAI] Creating embedding...[39m
[1693469861169] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861169] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: My family has been mining for generations."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861169] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861170] [33m[OPENAI] Creating embedding...[39m
[1693469861170] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861170] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I enjoy a cold beverage after a long day in the mines."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861170] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861170] [33m[OPENAI] Creating embedding...[39m
[1693469861170] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861170] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I've been taught traditional mining songs by the older miners."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861170] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861170] [33m[OPENAI] Creating embedding...[39m
[1693469861170] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861170] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I've saved up to buy a house near the village."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861170] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861170] [33m[OPENAI] Creating embedding...[39m
[1693469861170] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861170] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I know a secret tunnel in the mine that few know about."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861170] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861170] [33m[OPENAI] Creating embedding...[39m
[1693469861170] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861170] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: It's important to have the right tools for the job."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861170] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861170] [33m[OPENAI] Creating embedding...[39m
[1693469861170] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861170] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I take pride in my work and look after my equipment."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861170] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861170] [33m[OPENAI] Creating embedding...[39m
[1693469861170] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861170] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I sometimes join Thomas and others for a meal after work."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861170] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861170] [33m[OPENAI] Creating embedding...[39m
[1693469861170] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861170] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I've had a few close calls, but always came out safe."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861170] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861170] [33m[OPENAI] Creating embedding...[39m
[1693469861170] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861170] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: The village festivities are something I look forward to every year."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861170] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861170] [33m[OPENAI] Creating embedding...[39m
[1693469861177] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861177] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I should be asleep until 7am."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861177] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861177] [33m[OPENAI] Creating embedding...[39m
[1693469861177] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861177] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: It's my job to protect the village."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861177] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861177] [33m[OPENAI] Creating embedding...[39m
[1693469861177] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861177] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I need to make sure everyone is safe."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861177] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861177] [33m[OPENAI] Creating embedding...[39m
[1693469861177] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861177] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I do the work that no one else wants to do."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861177] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861177] [33m[OPENAI] Creating embedding...[39m
[1693469861177] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861177] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I try to be as honest as possible."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861177] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861177] [33m[OPENAI] Creating embedding...[39m
[1693469861177] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861177] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I'm not afraid of anything."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861177] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861177] [33m[OPENAI] Creating embedding...[39m
[1693469861178] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861178] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I go to bed at 10pm."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861178] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861178] [33m[OPENAI] Creating embedding...[39m
[1693469861178] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861178] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I like strawberries."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861178] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861178] [33m[OPENAI] Creating embedding...[39m
[1693469861178] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861178] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: The village location is 2, -58."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861178] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861178] [33m[OPENAI] Creating embedding...[39m
[1693469861178] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861178] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: The mine site is at 51, 17."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861178] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861178] [33m[OPENAI] Creating embedding...[39m
[1693469861178] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861178] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: The lumberyard is at 72, -55.1"
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861178] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861178] [33m[OPENAI] Creating embedding...[39m
[1693469861178] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861178] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: The campsite is at 7, -8.3"
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861178] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861178] [33m[OPENAI] Creating embedding...[39m
[1693469861178] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861178] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: The Nume River flows through the village."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861178] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861178] [33m[OPENAI] Creating embedding...[39m
[1693469861178] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861178] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: Nume Falls are north of the village, and west of the campsite."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861178] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861178] [33m[OPENAI] Creating embedding...[39m
[1693469861178] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861178] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: The area is surrounded by forested monutains, filled with wildlife, rivers, and lakes."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861178] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861178] [33m[OPENAI] Creating embedding...[39m
[1693469861207] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861207] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: The feel of the axe in my hand is like an extension of myself."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861207] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861207] [33m[OPENAI] Creating embedding...[39m
[1693469861207] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861207] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I remember the tallest tree I've ever felled, stood mighty for over a century."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861207] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861207] [33m[OPENAI] Creating embedding...[39m
[1693469861207] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861207] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: The forest whispers its secrets if you're patient enough to listen."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861207] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861207] [33m[OPENAI] Creating embedding...[39m
[1693469861208] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861208] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: The village depends on our timber, it's a responsibility I don't take lightly."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861208] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861208] [33m[OPENAI] Creating embedding...[39m
[1693469861208] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861208] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: Thomas once tried to chop wood, it was amusing to say the least."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861208] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861208] [33m[OPENAI] Creating embedding...[39m
[1693469861208] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861208] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: Nothing beats the smell of fresh-cut timber in the morning."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861208] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861208] [33m[OPENAI] Creating embedding...[39m
[1693469861208] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861208] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I've carved symbols on some trees, marking special moments of my life."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861208] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861208] [33m[OPENAI] Creating embedding...[39m
[1693469861208] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861208] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: Will reminds me of when I was young, eager to learn and prove myself."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861208] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861208] [33m[OPENAI] Creating embedding...[39m
[1693469861208] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861208] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I've saved more than a few animals stuck or hurt, the forest is their home."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861208] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861208] [33m[OPENAI] Creating embedding...[39m
[1693469861208] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861208] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: George and I have shared tales over campfires many nights."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861208] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861208] [33m[OPENAI] Creating embedding...[39m
[1693469861208] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861208] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: Rain or shine, the trees await and work must be done."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861208] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861208] [33m[OPENAI] Creating embedding...[39m
[1693469861208] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861208] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: I respect the forest, only taking what's necessary and planting twice as much."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861208] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861208] [33m[OPENAI] Creating embedding...[39m
[1693469861209] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861209] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: Every lumberjack has a favorite axe; mine's named 'Whisper'."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861209] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861209] [33m[OPENAI] Creating embedding...[39m
[1693469861209] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861209] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: The creaking sound a tree makes just before it falls is both eerie and beautiful."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861209] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861209] [33m[OPENAI] Creating embedding...[39m
[1693469861209] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693469861209] {
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "On the scale of 1 to 10, where 1 is purely mundane (e.g., waking up, making bed) and 10 is extremely poignant (e.g., a break up, a family death), rate the likely poignancy of the following piece of memory. Only return the number."
    },
    {
      "role": "user",
      "content": "Memory: At times, the forest feels alive, watching, and I'm just a small part of its vast story."
    },
    {
      "role": "assistant",
      "content": "Rating: "
    }
  ]
}
[1693469861209] {
  "X-Starlight-Tag": "getMemoryImportance",
  "X-Starlight-Run": "1693469860804"
}
[1693469861209] [33m[OPENAI] Creating embedding...[39m
[1693469861287] [32m[OPENAI] Embedding created successfully.[39m
[1693469861300] [32m[OPENAI] Embedding created successfully.[39m
[1693469861306] [32m[OPENAI] Embedding created successfully.[39m
[1693469861308] [32m[OPENAI] Embedding created successfully.[39m
[1693469861313] [32m[OPENAI] Embedding created successfully.[39m
[1693469861316] [32m[OPENAI] Embedding created successfully.[39m
[1693469861317] [32m[OPENAI] Embedding created successfully.[39m
[1693469861330] [32m[OPENAI] Embedding created successfully.[39m
[1693469861351] [32m[OPENAI] Embedding created successfully.[39m
[1693469861351] [32m[OPENAI] Embedding created successfully.[39m
[1693469861359] [32m[OPENAI] Embedding created successfully.[39m
[1693469861361] [32m[OPENAI] Embedding created successfully.[39m
[1693469861365] [32m[OPENAI] Embedding created successfully.[39m
[1693469861374] [32m[OPENAI] Embedding created successfully.[39m
[1693469861382] {
  "id": "chatcmpl-7tX9xMoA2OSFADdDMxyF3nn2RU1DF",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 92,
    "completion_tokens": 1,
    "total_tokens": 93
  }
}
[1693469861382] {
  "role": "assistant",
  "content": "5"
}
[1693469861382] [36m[OPENAI] Chat completion took 307.6742080450058ms[39m
[1693469861382] [36m[OPENAI] Tokens per second: 3.250191188771087tps[39m
[1693469861383] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861384] [32m[OPENAI] Embedding created successfully.[39m
[1693469861384] [32m[OPENAI] Embedding created successfully.[39m
[1693469861385] [32m[OPENAI] Embedding created successfully.[39m
[1693469861390] [32m[OPENAI] Embedding created successfully.[39m
[1693469861391] [32m[OPENAI] Embedding created successfully.[39m
[1693469861393] {
  "id": "chatcmpl-7tX9xlmR0rCTNPnOg297PLQuhRkOe",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 90,
    "completion_tokens": 1,
    "total_tokens": 91
  }
}
[1693469861393] {
  "role": "assistant",
  "content": "5"
}
[1693469861393] [36m[OPENAI] Chat completion took 320.3828749656677ms[39m
[1693469861393] [36m[OPENAI] Tokens per second: 3.121265454987755tps[39m
[1693469861393] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861394] {
  "id": "chatcmpl-7tX9xFNVDNZomW5RYWfGGQUf2vZin",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693469861394] {
  "role": "assistant",
  "content": "4"
}
[1693469861394] [36m[OPENAI] Chat completion took 319.90637505054474ms[39m
[1693469861394] [36m[OPENAI] Tokens per second: 3.125914573731147tps[39m
[1693469861394] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861396] [32m[OPENAI] Embedding created successfully.[39m
[1693469861401] {
  "id": "chatcmpl-7tX9xSB8b1mIFnKWmxN9RYWuRT2QR",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693469861401] {
  "role": "assistant",
  "content": "5"
}
[1693469861401] [36m[OPENAI] Chat completion took 325.35108411312103ms[39m
[1693469861401] [36m[OPENAI] Tokens per second: 3.0736027904314924tps[39m
[1693469861401] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861401] [32m[OPENAI] Embedding created successfully.[39m
[1693469861411] [32m[OPENAI] Embedding created successfully.[39m
[1693469861411] [32m[OPENAI] Embedding created successfully.[39m
[1693469861418] [32m[OPENAI] Embedding created successfully.[39m
[1693469861418] {
  "id": "chatcmpl-7tX9xbTjjTJqtYKv11ffPLh72RUpB",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693469861418] {
  "role": "assistant",
  "content": "3"
}
[1693469861418] [36m[OPENAI] Chat completion took 343.64804196357727ms[39m
[1693469861418] [36m[OPENAI] Tokens per second: 2.9099540165748663tps[39m
[1693469861418] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861419] {
  "id": "chatcmpl-7tX9xCOPy6rqIxkvoc8TibZrNZA7j",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693469861419] {
  "role": "assistant",
  "content": "3"
}
[1693469861419] [36m[OPENAI] Chat completion took 344.3228340148926ms[39m
[1693469861419] [36m[OPENAI] Tokens per second: 2.9042511887455835tps[39m
[1693469861419] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861419] [32m[OPENAI] Embedding created successfully.[39m
[1693469861420] [32m[OPENAI] Embedding created successfully.[39m
[1693469861420] [32m[OPENAI] Embedding created successfully.[39m
[1693469861423] {
  "id": "chatcmpl-7tX9xTjvVMaNXlsmWxeNpQvMJk3t6",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 90,
    "completion_tokens": 1,
    "total_tokens": 91
  }
}
[1693469861423] {
  "role": "assistant",
  "content": "5"
}
[1693469861423] [36m[OPENAI] Chat completion took 349.07274997234344ms[39m
[1693469861423] [36m[OPENAI] Tokens per second: 2.8647323518642707tps[39m
[1693469861423] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861424] [32m[OPENAI] Embedding created successfully.[39m
[1693469861425] [32m[OPENAI] Embedding created successfully.[39m
[1693469861426] [32m[OPENAI] Embedding created successfully.[39m
[1693469861427] [32m[OPENAI] Embedding created successfully.[39m
[1693469861430] {
  "id": "chatcmpl-7tX9xr7Uc4nL5YI97ISkVENSOGZYK",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693469861430] {
  "role": "assistant",
  "content": "3"
}
[1693469861430] [36m[OPENAI] Chat completion took 355.06991696357727ms[39m
[1693469861430] [36m[OPENAI] Tokens per second: 2.8163467312342854tps[39m
[1693469861430] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861435] {
  "id": "chatcmpl-7tX9xzybOC8Ew9pesOsR6gMLrKngC",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693469861435] {
  "role": "assistant",
  "content": "2"
}
[1693469861435] [36m[OPENAI] Chat completion took 363.2694580554962ms[39m
[1693469861435] [36m[OPENAI] Tokens per second: 2.7527775259521854tps[39m
[1693469861435] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861437] [32m[OPENAI] Embedding created successfully.[39m
[1693469861437] [32m[OPENAI] Embedding created successfully.[39m
[1693469861438] [32m[OPENAI] Embedding created successfully.[39m
[1693469861438] [32m[OPENAI] Embedding created successfully.[39m
[1693469861439] [32m[OPENAI] Embedding created successfully.[39m
[1693469861442] [32m[OPENAI] Embedding created successfully.[39m
[1693469861443] [32m[OPENAI] Embedding created successfully.[39m
[1693469861443] [32m[OPENAI] Embedding created successfully.[39m
[1693469861444] [32m[OPENAI] Embedding created successfully.[39m
[1693469861450] [32m[OPENAI] Embedding created successfully.[39m
[1693469861450] [32m[OPENAI] Embedding created successfully.[39m
[1693469861451] [32m[OPENAI] Embedding created successfully.[39m
[1693469861451] [32m[OPENAI] Embedding created successfully.[39m
[1693469861452] [32m[OPENAI] Embedding created successfully.[39m
[1693469861455] [32m[OPENAI] Embedding created successfully.[39m
[1693469861455] [32m[OPENAI] Embedding created successfully.[39m
[1693469861457] [32m[OPENAI] Embedding created successfully.[39m
[1693469861457] {
  "id": "chatcmpl-7tX9xBTYx9nS8ma6lGR10aMkhN7k0",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693469861457] {
  "role": "assistant",
  "content": "7"
}
[1693469861457] [36m[OPENAI] Chat completion took 296.9319999217987ms[39m
[1693469861457] [36m[OPENAI] Tokens per second: 3.3677744408260626tps[39m
[1693469861457] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861458] [32m[OPENAI] Embedding created successfully.[39m
[1693469861461] [32m[OPENAI] Embedding created successfully.[39m
[1693469861462] [32m[OPENAI] Embedding created successfully.[39m
[1693469861464] {
  "id": "chatcmpl-7tX9xIkyiL58cAnFDvQ0kPz6AJzj8",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "8"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693469861464] {
  "role": "assistant",
  "content": "8"
}
[1693469861464] [36m[OPENAI] Chat completion took 303.4577909708023ms[39m
[1693469861464] [36m[OPENAI] Tokens per second: 3.295351214417219tps[39m
[1693469861464] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861465] [32m[OPENAI] Embedding created successfully.[39m
[1693469861468] {
  "id": "chatcmpl-7tX9xhAVYXbQBkmyUnAzkzKusMD4Z",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 92,
    "completion_tokens": 1,
    "total_tokens": 93
  }
}
[1693469861468] {
  "role": "assistant",
  "content": "4"
}
[1693469861468] [36m[OPENAI] Chat completion took 394.50883293151855ms[39m
[1693469861468] [36m[OPENAI] Tokens per second: 2.534797491273374tps[39m
[1693469861468] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861470] [32m[OPENAI] Embedding created successfully.[39m
[1693469861470] {
  "id": "chatcmpl-7tX9xEcjQ7NjfiCURV4f5Qxnw76UP",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693469861470] {
  "role": "assistant",
  "content": "7"
}
[1693469861470] [36m[OPENAI] Chat completion took 309.871209025383ms[39m
[1693469861470] [36m[OPENAI] Tokens per second: 3.2271471852620075tps[39m
[1693469861470] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861472] {
  "id": "chatcmpl-7tX9xb695lULfnkG0MVSkQL6dzKfN",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1693469861472] {
  "role": "assistant",
  "content": "6"
}
[1693469861472] [36m[OPENAI] Chat completion took 311.7485829591751ms[39m
[1693469861472] [36m[OPENAI] Tokens per second: 3.207713056809482tps[39m
[1693469861472] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861474] {
  "id": "chatcmpl-7tX9x95jDEgyfC5xYODuObtStDUgy",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 96,
    "completion_tokens": 1,
    "total_tokens": 97
  }
}
[1693469861474] {
  "role": "assistant",
  "content": "5"
}
[1693469861474] [36m[OPENAI] Chat completion took 399.3976250886917ms[39m
[1693469861474] [36m[OPENAI] Tokens per second: 2.503770521364358tps[39m
[1693469861474] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861475] {
  "id": "chatcmpl-7tX9xWtZ4TrvUR7pQpf6CVomdyGiS",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1693469861475] {
  "role": "assistant",
  "content": "2"
}
[1693469861475] [36m[OPENAI] Chat completion took 297.00158309936523ms[39m
[1693469861475] [36m[OPENAI] Tokens per second: 3.366985419957976tps[39m
[1693469861475] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861478] {
  "id": "chatcmpl-7tX9xZo618U9IrRIBjdW9ReKCXdgW",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693469861478] {
  "role": "assistant",
  "content": "3"
}
[1693469861478] [36m[OPENAI] Chat completion took 317.1163750886917ms[39m
[1693469861478] [36m[OPENAI] Tokens per second: 3.153416469648778tps[39m
[1693469861478] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861478] {
  "id": "chatcmpl-7tX9xxrQeuTtg8vwcKtdRaS3wzSDm",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693469861478] {
  "role": "assistant",
  "content": "7"
}
[1693469861478] [36m[OPENAI] Chat completion took 316.66420900821686ms[39m
[1693469861478] [36m[OPENAI] Tokens per second: 3.157919245537635tps[39m
[1693469861478] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861479] {
  "id": "chatcmpl-7tX9xG6jTV9FbVcAeoggivJqiMUgc",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693469861479] {
  "role": "assistant",
  "content": "7"
}
[1693469861479] [36m[OPENAI] Chat completion took 318.4872920513153ms[39m
[1693469861479] [36m[OPENAI] Tokens per second: 3.1398427031709573tps[39m
[1693469861479] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861479] [32m[OPENAI] Embedding created successfully.[39m
[1693469861480] [32m[OPENAI] Embedding created successfully.[39m
[1693469861481] {
  "id": "chatcmpl-7tX9xU4Ngwd3CWgWshPtzmjdxnIaC",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693469861481] {
  "role": "assistant",
  "content": "3"
}
[1693469861481] [36m[OPENAI] Chat completion took 407.4591670036316ms[39m
[1693469861481] [36m[OPENAI] Tokens per second: 2.454233653285526tps[39m
[1693469861481] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861482] {
  "id": "chatcmpl-7tX9xT4rSUNivJZ0GEvFy2WKYgWBJ",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693469861482] {
  "role": "assistant",
  "content": "5"
}
[1693469861482] [36m[OPENAI] Chat completion took 320.7045829296112ms[39m
[1693469861482] [36m[OPENAI] Tokens per second: 3.118134424101703tps[39m
[1693469861482] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861483] [32m[OPENAI] Embedding created successfully.[39m
[1693469861485] {
  "id": "chatcmpl-7tX9xiVSVmnjNXfZmntcltC0qnu2L",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693469861485] {
  "role": "assistant",
  "content": "7"
}
[1693469861485] [36m[OPENAI] Chat completion took 324.7234160900116ms[39m
[1693469861485] [36m[OPENAI] Tokens per second: 3.079543853168893tps[39m
[1693469861485] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861486] [32m[OPENAI] Embedding created successfully.[39m
[1693469861489] {
  "id": "chatcmpl-7tX9xxZkFmCFtl8q0VUnzozt4Lzx6",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693469861489] {
  "role": "assistant",
  "content": "2"
}
[1693469861489] [36m[OPENAI] Chat completion took 319.13870799541473ms[39m
[1693469861489] [36m[OPENAI] Tokens per second: 3.1334337544988986tps[39m
[1693469861489] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861492] [32m[OPENAI] Embedding created successfully.[39m
[1693469861494] {
  "id": "chatcmpl-7tX9xfrA0XSyU616jZH5f1yFtw6ol",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693469861494] {
  "role": "assistant",
  "content": "5"
}
[1693469861494] [36m[OPENAI] Chat completion took 285.49325001239777ms[39m
[1693469861494] [36m[OPENAI] Tokens per second: 3.502709783704428tps[39m
[1693469861494] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861494] {
  "id": "chatcmpl-7tX9xztn2rjv75DArOl5p0DsKcHjq",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693469861494] {
  "role": "assistant",
  "content": "2"
}
[1693469861494] [36m[OPENAI] Chat completion took 333.421875ms[39m
[1693469861494] [36m[OPENAI] Tokens per second: 2.999203336613712tps[39m
[1693469861494] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861496] {
  "id": "chatcmpl-7tX9xExGhKHxLoGrQ941unNXmiEkQ",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 90,
    "completion_tokens": 1,
    "total_tokens": 91
  }
}
[1693469861496] {
  "role": "assistant",
  "content": "5"
}
[1693469861496] [36m[OPENAI] Chat completion took 326.4262499809265ms[39m
[1693469861496] [36m[OPENAI] Tokens per second: 3.0634791168247997tps[39m
[1693469861496] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861497] {
  "id": "chatcmpl-7tX9xWrF3644otWmFXVZNbimYCxaG",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693469861497] {
  "role": "assistant",
  "content": "3"
}
[1693469861497] [36m[OPENAI] Chat completion took 336.6753340959549ms[39m
[1693469861497] [36m[OPENAI] Tokens per second: 2.970220561851415tps[39m
[1693469861497] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861498] {
  "id": "chatcmpl-7tX9xB0CwB58ehdgzriQXEosFo3QP",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693469861498] {
  "role": "assistant",
  "content": "3"
}
[1693469861499] [36m[OPENAI] Chat completion took 320.5601669549942ms[39m
[1693469861499] [36m[OPENAI] Tokens per second: 3.119539178866217tps[39m
[1693469861499] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861500] {
  "id": "chatcmpl-7tX9x9Vc5HJOFHq1DVOm7uEQ2zZH8",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693469861500] {
  "role": "assistant",
  "content": "6"
}
[1693469861500] [36m[OPENAI] Chat completion took 329.7667499780655ms[39m
[1693469861500] [36m[OPENAI] Tokens per second: 3.032446418768767tps[39m
[1693469861500] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861500] {
  "id": "chatcmpl-7tX9xCuUV6ZYOFvTBzbRXlOY9hVPt",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693469861500] {
  "role": "assistant",
  "content": "2"
}
[1693469861500] [36m[OPENAI] Chat completion took 322.71020805835724ms[39m
[1693469861500] [36m[OPENAI] Tokens per second: 3.098755400446351tps[39m
[1693469861500] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861501] [32m[OPENAI] Embedding created successfully.[39m
[1693469861503] [32m[OPENAI] Embedding created successfully.[39m
[1693469861503] [32m[OPENAI] Embedding created successfully.[39m
[1693469861505] {
  "id": "chatcmpl-7tX9xKzw4wiOo5ZR6KR5shYOMbc3n",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "8"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693469861506] {
  "role": "assistant",
  "content": "8"
}
[1693469861506] [36m[OPENAI] Chat completion took 297.15720891952515ms[39m
[1693469861506] [36m[OPENAI] Tokens per second: 3.365222077687558tps[39m
[1693469861506] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861506] {
  "id": "chatcmpl-7tX9xygb5YGat6T3yoRL19sezkgJe",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 114,
    "completion_tokens": 1,
    "total_tokens": 115
  }
}
[1693469861506] {
  "role": "assistant",
  "content": "4"
}
[1693469861506] [36m[OPENAI] Chat completion took 345.98279190063477ms[39m
[1693469861506] [36m[OPENAI] Tokens per second: 2.8903171585689647tps[39m
[1693469861506] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861506] [32m[OPENAI] Embedding created successfully.[39m
[1693469861507] {
  "id": "chatcmpl-7tX9xB4qg3QZz96UAMT2noviYwnx9",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693469861507] {
  "role": "assistant",
  "content": "3"
}
[1693469861507] [36m[OPENAI] Chat completion took 346.42525005340576ms[39m
[1693469861507] [36m[OPENAI] Tokens per second: 2.8866256135943833tps[39m
[1693469861507] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861514] {
  "id": "chatcmpl-7tX9xxGKVklNamw5HaX0jkeFfbizM",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693469861514] {
  "role": "assistant",
  "content": "7"
}
[1693469861514] [36m[OPENAI] Chat completion took 352.6062910556793ms[39m
[1693469861514] [36m[OPENAI] Tokens per second: 2.8360242723011773tps[39m
[1693469861514] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861514] {
  "id": "chatcmpl-7tX9x7NST2iTh27N3r4ZoMCnplHeR",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693469861514] {
  "role": "assistant",
  "content": "1"
}
[1693469861514] [36m[OPENAI] Chat completion took 344.53949999809265ms[39m
[1693469861514] [36m[OPENAI] Tokens per second: 2.9024248308409804tps[39m
[1693469861514] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861516] {
  "id": "chatcmpl-7tX9xSuzCwpz9FDXpJCuB7K1kADLW",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693469861516] {
  "role": "assistant",
  "content": "4"
}
[1693469861516] [36m[OPENAI] Chat completion took 443.27649998664856ms[39m
[1693469861516] [36m[OPENAI] Tokens per second: 2.2559282976429382tps[39m
[1693469861516] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861517] {
  "id": "chatcmpl-7tX9xpGcjrQLcTl5fWD9RRMzkO2fS",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693469861517] {
  "role": "assistant",
  "content": "2"
}
[1693469861517] [36m[OPENAI] Chat completion took 339.2669999599457ms[39m
[1693469861517] [36m[OPENAI] Tokens per second: 2.947531001005289tps[39m
[1693469861517] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861517] {
  "id": "chatcmpl-7tX9x3SRJyWZubaFGlgnw1yimQpVg",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693469861517] {
  "role": "assistant",
  "content": "3"
}
[1693469861517] [36m[OPENAI] Chat completion took 442.737291932106ms[39m
[1693469861517] [36m[OPENAI] Tokens per second: 2.2586757840885707tps[39m
[1693469861517] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861518] {
  "id": "chatcmpl-7tX9x3gSdiwE7jE37BwjyS648DrMv",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693469861518] {
  "role": "assistant",
  "content": "3"
}
[1693469861518] [36m[OPENAI] Chat completion took 348.6672090291977ms[39m
[1693469861518] [36m[OPENAI] Tokens per second: 2.868064372283025tps[39m
[1693469861518] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861519] {
  "id": "chatcmpl-7tX9xdJizJ6wNYeAgnFcTDdIWUpMH",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693469861519] {
  "role": "assistant",
  "content": "5"
}
[1693469861519] [36m[OPENAI] Chat completion took 311.68070793151855ms[39m
[1693469861519] [36m[OPENAI] Tokens per second: 3.208411603774067tps[39m
[1693469861519] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861520] {
  "id": "chatcmpl-7tX9xUiSxtooS9jrpAXbaqVu1rO6b",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693469861520] {
  "role": "assistant",
  "content": "5"
}
[1693469861520] [36m[OPENAI] Chat completion took 312.9603340625763ms[39m
[1693469861520] [36m[OPENAI] Tokens per second: 3.1952931127688866tps[39m
[1693469861520] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861521] {
  "id": "chatcmpl-7tX9xMDTOjzPZWPbeKJZTYHlaqPXz",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693469861521] {
  "role": "assistant",
  "content": "4"
}
[1693469861521] [36m[OPENAI] Chat completion took 343.81433403491974ms[39m
[1693469861521] [36m[OPENAI] Tokens per second: 2.908546564258238tps[39m
[1693469861521] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861522] {
  "id": "chatcmpl-7tX9xE2NiePfRnwKfZW1l0D1jPy4s",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693469861522] {
  "role": "assistant",
  "content": "4"
}
[1693469861522] [36m[OPENAI] Chat completion took 352.81841695308685ms[39m
[1693469861522] [36m[OPENAI] Tokens per second: 2.8343191623496424tps[39m
[1693469861522] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861523] {
  "id": "chatcmpl-7tX9xezKSScRXRGEhhwm4gSixFcyf",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693469861523] {
  "role": "assistant",
  "content": "3"
}
[1693469861523] [36m[OPENAI] Chat completion took 314.7400840520859ms[39m
[1693469861523] [36m[OPENAI] Tokens per second: 3.1772247980797754tps[39m
[1693469861523] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861527] {
  "id": "chatcmpl-7tX9xUkJZi70Of1MP4MBufUryu3v7",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693469861527] {
  "role": "assistant",
  "content": "4"
}
[1693469861527] [36m[OPENAI] Chat completion took 357.48595798015594ms[39m
[1693469861528] [36m[OPENAI] Tokens per second: 2.7973126711050007tps[39m
[1693469861528] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861528] {
  "id": "chatcmpl-7tX9xkE8TjHUMvVDBVqDERoLw4eCw",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693469861528] {
  "role": "assistant",
  "content": "5"
}
[1693469861528] [36m[OPENAI] Chat completion took 350.32975006103516ms[39m
[1693469861528] [36m[OPENAI] Tokens per second: 2.8544535536184923tps[39m
[1693469861528] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861529] [32m[OPENAI] Embedding created successfully.[39m
[1693469861532] {
  "id": "chatcmpl-7tX9xFRlnFVN07lC3OMssrlGTvOLM",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 89,
    "completion_tokens": 1,
    "total_tokens": 90
  }
}
[1693469861532] {
  "role": "assistant",
  "content": "5"
}
[1693469861532] [36m[OPENAI] Chat completion took 354.06012511253357ms[39m
[1693469861532] [36m[OPENAI] Tokens per second: 2.824379050541663tps[39m
[1693469861532] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861532] {
  "id": "chatcmpl-7tX9x7nfn6KugqfRin8MT0ucyI1fz",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693469861532] {
  "role": "assistant",
  "content": "6"
}
[1693469861532] [36m[OPENAI] Chat completion took 362.06233298778534ms[39m
[1693469861532] [36m[OPENAI] Tokens per second: 2.761955356548333tps[39m
[1693469861532] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861533] {
  "id": "chatcmpl-7tX9xwiNRs3qUgsjQDI8mrzryzohj",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693469861533] {
  "role": "assistant",
  "content": "1"
}
[1693469861533] [36m[OPENAI] Chat completion took 355.4877499341965ms[39m
[1693469861533] [36m[OPENAI] Tokens per second: 2.813036455363392tps[39m
[1693469861533] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861534] {
  "id": "chatcmpl-7tX9xgkelglOKSaRcGF4TeiKLGEAz",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693469861534] {
  "role": "assistant",
  "content": "5"
}
[1693469861534] [36m[OPENAI] Chat completion took 373.69050002098083ms[39m
[1693469861534] [36m[OPENAI] Tokens per second: 2.676011297969456tps[39m
[1693469861534] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861535] [32m[OPENAI] Embedding created successfully.[39m
[1693469861536] [32m[OPENAI] Embedding created successfully.[39m
[1693469861536] [32m[OPENAI] Embedding created successfully.[39m
[1693469861539] {
  "id": "chatcmpl-7tX9xAimx5H1DMOxaRjNnZypw4v9g",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 96,
    "completion_tokens": 1,
    "total_tokens": 97
  }
}
[1693469861539] {
  "role": "assistant",
  "content": "4"
}
[1693469861539] [36m[OPENAI] Chat completion took 369.07970798015594ms[39m
[1693469861539] [36m[OPENAI] Tokens per second: 2.70944183161044tps[39m
[1693469861539] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861540] {
  "id": "chatcmpl-7tX9xATxtzSa5EEsWeLCSziTOs4KU",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 86,
    "completion_tokens": 1,
    "total_tokens": 87
  }
}
[1693469861540] {
  "role": "assistant",
  "content": "2"
}
[1693469861540] [36m[OPENAI] Chat completion took 362.30716705322266ms[39m
[1693469861540] [36m[OPENAI] Tokens per second: 2.760088927120508tps[39m
[1693469861540] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861540] [32m[OPENAI] Embedding created successfully.[39m
[1693469861541] [32m[OPENAI] Embedding created successfully.[39m
[1693469861541] {
  "id": "chatcmpl-7tX9xW8c2GHZNHYW7SLLQm4Xkvc1n",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7.5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 3,
    "total_tokens": 101
  }
}
[1693469861541] {
  "role": "assistant",
  "content": "7.5"
}
[1693469861541] [36m[OPENAI] Chat completion took 333.1655000448227ms[39m
[1693469861541] [36m[OPENAI] Tokens per second: 9.004533781548187tps[39m
[1693469861541] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861545] {
  "id": "chatcmpl-7tX9xZzlhL8IZEpkDVVUjybQMU96D",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 92,
    "completion_tokens": 1,
    "total_tokens": 93
  }
}
[1693469861545] {
  "role": "assistant",
  "content": "1"
}
[1693469861545] [36m[OPENAI] Chat completion took 367.1325000524521ms[39m
[1693469861545] [36m[OPENAI] Tokens per second: 2.7238122472326216tps[39m
[1693469861545] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861546] {
  "id": "chatcmpl-7tX9xUBgY0ecqe6IKjLOuz2FNsl8h",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1693469861546] {
  "role": "assistant",
  "content": "5"
}
[1693469861546] [36m[OPENAI] Chat completion took 337.06550002098083ms[39m
[1693469861546] [36m[OPENAI] Tokens per second: 2.9667824204427755tps[39m
[1693469861546] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861549] {
  "id": "chatcmpl-7tX9xjfvEjBV2ozClOUdU85f2dTkk",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693469861549] {
  "role": "assistant",
  "content": "7"
}
[1693469861549] [36m[OPENAI] Chat completion took 371.3211250305176ms[39m
[1693469861549] [36m[OPENAI] Tokens per second: 2.6930867451126397tps[39m
[1693469861549] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861555] {
  "id": "chatcmpl-7tX9xpp7Sglc04iK8glvhSOPp6Zvl",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693469861555] {
  "role": "assistant",
  "content": "5"
}
[1693469861555] [36m[OPENAI] Chat completion took 385.97037494182587ms[39m
[1693469861555] [36m[OPENAI] Tokens per second: 2.590872421622312tps[39m
[1693469861555] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861557] [32m[OPENAI] Embedding created successfully.[39m
[1693469861559] {
  "id": "chatcmpl-7tX9xJhHIi5s52UG1o1TRPkCOm2IU",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 96,
    "completion_tokens": 1,
    "total_tokens": 97
  }
}
[1693469861559] {
  "role": "assistant",
  "content": "1"
}
[1693469861559] [36m[OPENAI] Chat completion took 389.4137500524521ms[39m
[1693469861559] [36m[OPENAI] Tokens per second: 2.567962738514767tps[39m
[1693469861559] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861560] {
  "id": "chatcmpl-7tX9xzRf71wx9tVUV7F5eSLCybGfg",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693469861560] {
  "role": "assistant",
  "content": "6"
}
[1693469861560] [36m[OPENAI] Chat completion took 350.87162494659424ms[39m
[1693469861560] [36m[OPENAI] Tokens per second: 2.8500452270889927tps[39m
[1693469861560] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861561] {
  "id": "chatcmpl-7tX9xiRwDYtOGnnbDjsvfUPwnG3l4",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693469861561] {
  "role": "assistant",
  "content": "5"
}
[1693469861561] [36m[OPENAI] Chat completion took 383.62458300590515ms[39m
[1693469861561] [36m[OPENAI] Tokens per second: 2.6067151175882985tps[39m
[1693469861561] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861562] {
  "id": "chatcmpl-7tX9xisDeGQ9MdKWVSyfhrAy3CUOH",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693469861562] {
  "role": "assistant",
  "content": "5"
}
[1693469861562] [36m[OPENAI] Chat completion took 383.57770907878876ms[39m
[1693469861562] [36m[OPENAI] Tokens per second: 2.607033663143848tps[39m
[1693469861562] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861563] {
  "id": "chatcmpl-7tX9x48wFknw6EBNA0zxFrGCZFmAl",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693469861563] {
  "role": "assistant",
  "content": "4"
}
[1693469861563] [36m[OPENAI] Chat completion took 385.72783303260803ms[39m
[1693469861563] [36m[OPENAI] Tokens per second: 2.5925015369981446tps[39m
[1693469861563] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861565] {
  "id": "chatcmpl-7tX9xWYSOlcxyVgYAB79NaIh8X6IR",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 2,
    "total_tokens": 97
  }
}
[1693469861565] {
  "role": "assistant",
  "content": "4."
}
[1693469861565] [36m[OPENAI] Chat completion took 394.73274993896484ms[39m
[1693469861565] [36m[OPENAI] Tokens per second: 5.066719192439057tps[39m
[1693469861565] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861566] {
  "id": "chatcmpl-7tX9x9RhpaSQiQz43Z5xTHLX4G0pv",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693469861566] {
  "role": "assistant",
  "content": "5"
}
[1693469861566] [36m[OPENAI] Chat completion took 357.96979200839996ms[39m
[1693469861566] [36m[OPENAI] Tokens per second: 2.7935318072216955tps[39m
[1693469861566] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861569] {
  "id": "chatcmpl-7tX9xtwkddMuGBi5u7loBH6cpo9Am",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693469861569] {
  "role": "assistant",
  "content": "5"
}
[1693469861569] [36m[OPENAI] Chat completion took 398.94720804691315ms[39m
[1693469861569] [36m[OPENAI] Tokens per second: 2.506597313703741tps[39m
[1693469861569] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861573] {
  "id": "chatcmpl-7tX9xZa2zGVaAmvtJepve4RBnkvG5",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693469861573] {
  "role": "assistant",
  "content": "5"
}
[1693469861573] [36m[OPENAI] Chat completion took 364.8717919588089ms[39m
[1693469861573] [36m[OPENAI] Tokens per second: 2.7406887077554405tps[39m
[1693469861573] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861574] {
  "id": "chatcmpl-7tX9xvm6kclQFENRMTYa9RKJcg9KK",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693469861574] {
  "role": "assistant",
  "content": "4"
}
[1693469861574] [36m[OPENAI] Chat completion took 366.0370420217514ms[39m
[1693469861574] [36m[OPENAI] Tokens per second: 2.7319639413449743tps[39m
[1693469861574] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861574] {
  "id": "chatcmpl-7tX9xcy1Abw72n36xmhOh315OFgF6",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693469861574] {
  "role": "assistant",
  "content": "5"
}
[1693469861574] [36m[OPENAI] Chat completion took 365.5718330144882ms[39m
[1693469861574] [36m[OPENAI] Tokens per second: 2.7354405063268876tps[39m
[1693469861574] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861576] {
  "id": "chatcmpl-7tX9xcrGp1OV22no3nX6IPiVVgXUo",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693469861576] {
  "role": "assistant",
  "content": "3"
}
[1693469861577] [36m[OPENAI] Chat completion took 406.84879195690155ms[39m
[1693469861577] [36m[OPENAI] Tokens per second: 2.4579156182081827tps[39m
[1693469861577] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861577] [32m[OPENAI] Embedding created successfully.[39m
[1693469861578] [32m[OPENAI] Embedding created successfully.[39m
[1693469861584] [32m[OPENAI] Embedding created successfully.[39m
[1693469861586] {
  "id": "chatcmpl-7tX9xFhurbfFRxsP930BpI3y0njiB",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 2,
    "total_tokens": 106
  }
}
[1693469861586] {
  "role": "assistant",
  "content": "7."
}
[1693469861586] [36m[OPENAI] Chat completion took 376.9603750705719ms[39m
[1693469861586] [36m[OPENAI] Tokens per second: 5.30559743746428tps[39m
[1693469861586] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861589] [32m[OPENAI] Embedding created successfully.[39m
[1693469861603] [32m[OPENAI] Embedding created successfully.[39m
[1693469861635] {
  "id": "chatcmpl-7tX9xr46445cYsh521HudYRhBPTk4",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693469861635] {
  "role": "assistant",
  "content": "6"
}
[1693469861635] [36m[OPENAI] Chat completion took 427.6447499990463ms[39m
[1693469861635] [36m[OPENAI] Tokens per second: 2.3383895160696584tps[39m
[1693469861635] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861648] {
  "id": "chatcmpl-7tX9xRcRRjfez7vGOIWeLz76HlIyQ",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6.5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 3,
    "total_tokens": 100
  }
}
[1693469861648] {
  "role": "assistant",
  "content": "6.5"
}
[1693469861648] [36m[OPENAI] Chat completion took 439.9997090101242ms[39m
[1693469861648] [36m[OPENAI] Tokens per second: 6.818186327325438tps[39m
[1693469861648] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861657] {
  "id": "chatcmpl-7tX9x7fs8frYEhRQ84KTvUfgy7iTt",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 2,
    "total_tokens": 97
  }
}
[1693469861657] {
  "role": "assistant",
  "content": "6."
}
[1693469861657] [36m[OPENAI] Chat completion took 581.954332947731ms[39m
[1693469861657] [36m[OPENAI] Tokens per second: 3.4366957796663273tps[39m
[1693469861657] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861725] [32m[OPENAI] Embedding created successfully.[39m
[1693469861738] {
  "id": "chatcmpl-7tX9xpYghcVDIWuIzOiVRB1lrAggM",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1693469861738] {
  "role": "assistant",
  "content": "5"
}
[1693469861738] [36m[OPENAI] Chat completion took 577.4826658964157ms[39m
[1693469861738] [36m[OPENAI] Tokens per second: 1.731653708510399tps[39m
[1693469861738] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861746] {
  "id": "chatcmpl-7tX9xSqjymYdzVVUZ6FgKSbyursD8",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693469861746] {
  "role": "assistant",
  "content": "3"
}
[1693469861746] [36m[OPENAI] Chat completion took 575.7848749160767ms[39m
[1693469861746] [36m[OPENAI] Tokens per second: 1.7367597579664709tps[39m
[1693469861746] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861765] {
  "id": "chatcmpl-7tX9xfK3YD9gxs6QnIz6lE6jbRCjE",
  "object": "chat.completion",
  "created": 1693469861,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693469861765] {
  "role": "assistant",
  "content": "3"
}
[1693469861765] [36m[OPENAI] Chat completion took 586.6790829896927ms[39m
[1693469861765] [36m[OPENAI] Tokens per second: 1.7045093799902336tps[39m
[1693469861765] [32m[OPENAI] Chat completion created successfully.[39m
[1693469861790] [32m[OPENAI] Embedding created successfully.[39m
