[1692667127182] [Character] Creating Thomas's logger
[1692667127182] [Character] Creating George's logger
[1692667127182] [Character] Creating Will's logger
[1692667127182] [Character] Creating Lucy's logger
[1692667127183] [Character] Creating Eli's logger
[1692667127185] [Main] WebSocket server listening on port 8082
[1692667127606] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127620] [33m[OPENAI] No functions provided.[39m
[1692667127621] [33m[OPENAI] Creating embedding...[39m
[1692667127621] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127621] [33m[OPENAI] No functions provided.[39m
[1692667127621] [33m[OPENAI] Creating embedding...[39m
[1692667127621] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127621] [33m[OPENAI] No functions provided.[39m
[1692667127621] [33m[OPENAI] Creating embedding...[39m
[1692667127621] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127621] [33m[OPENAI] No functions provided.[39m
[1692667127622] [33m[OPENAI] Creating embedding...[39m
[1692667127622] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127622] [33m[OPENAI] No functions provided.[39m
[1692667127622] [33m[OPENAI] Creating embedding...[39m
[1692667127622] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127622] [33m[OPENAI] No functions provided.[39m
[1692667127622] [33m[OPENAI] Creating embedding...[39m
[1692667127622] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127622] [33m[OPENAI] No functions provided.[39m
[1692667127622] [33m[OPENAI] Creating embedding...[39m
[1692667127622] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127622] [33m[OPENAI] No functions provided.[39m
[1692667127622] [33m[OPENAI] Creating embedding...[39m
[1692667127622] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127622] [33m[OPENAI] No functions provided.[39m
[1692667127622] [33m[OPENAI] Creating embedding...[39m
[1692667127622] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127622] [33m[OPENAI] No functions provided.[39m
[1692667127623] [33m[OPENAI] Creating embedding...[39m
[1692667127623] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127624] [33m[OPENAI] No functions provided.[39m
[1692667127624] [33m[OPENAI] Creating embedding...[39m
[1692667127624] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127624] [33m[OPENAI] No functions provided.[39m
[1692667127624] [33m[OPENAI] Creating embedding...[39m
[1692667127624] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127624] [33m[OPENAI] No functions provided.[39m
[1692667127624] [33m[OPENAI] Creating embedding...[39m
[1692667127624] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127624] [33m[OPENAI] No functions provided.[39m
[1692667127624] [33m[OPENAI] Creating embedding...[39m
[1692667127624] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127624] [33m[OPENAI] No functions provided.[39m
[1692667127624] [33m[OPENAI] Creating embedding...[39m
[1692667127756] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127756] [33m[OPENAI] No functions provided.[39m
[1692667127756] [33m[OPENAI] Creating embedding...[39m
[1692667127756] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127756] [33m[OPENAI] No functions provided.[39m
[1692667127756] [33m[OPENAI] Creating embedding...[39m
[1692667127757] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127757] [33m[OPENAI] No functions provided.[39m
[1692667127757] [33m[OPENAI] Creating embedding...[39m
[1692667127757] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127757] [33m[OPENAI] No functions provided.[39m
[1692667127757] [33m[OPENAI] Creating embedding...[39m
[1692667127757] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127757] [33m[OPENAI] No functions provided.[39m
[1692667127757] [33m[OPENAI] Creating embedding...[39m
[1692667127757] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127757] [33m[OPENAI] No functions provided.[39m
[1692667127757] [33m[OPENAI] Creating embedding...[39m
[1692667127757] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127757] [33m[OPENAI] No functions provided.[39m
[1692667127757] [33m[OPENAI] Creating embedding...[39m
[1692667127757] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127757] [33m[OPENAI] No functions provided.[39m
[1692667127757] [33m[OPENAI] Creating embedding...[39m
[1692667127757] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127757] [33m[OPENAI] No functions provided.[39m
[1692667127757] [33m[OPENAI] Creating embedding...[39m
[1692667127757] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127757] [33m[OPENAI] No functions provided.[39m
[1692667127757] [33m[OPENAI] Creating embedding...[39m
[1692667127757] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127757] [33m[OPENAI] No functions provided.[39m
[1692667127757] [33m[OPENAI] Creating embedding...[39m
[1692667127757] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127757] [33m[OPENAI] No functions provided.[39m
[1692667127757] [33m[OPENAI] Creating embedding...[39m
[1692667127757] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127757] [33m[OPENAI] No functions provided.[39m
[1692667127757] [33m[OPENAI] Creating embedding...[39m
[1692667127757] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127757] [33m[OPENAI] No functions provided.[39m
[1692667127757] [33m[OPENAI] Creating embedding...[39m
[1692667127757] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127757] [33m[OPENAI] No functions provided.[39m
[1692667127757] [33m[OPENAI] Creating embedding...[39m
[1692667127770] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127770] [33m[OPENAI] No functions provided.[39m
[1692667127770] [33m[OPENAI] Creating embedding...[39m
[1692667127770] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127770] [33m[OPENAI] No functions provided.[39m
[1692667127770] [33m[OPENAI] Creating embedding...[39m
[1692667127770] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127770] [33m[OPENAI] No functions provided.[39m
[1692667127770] [33m[OPENAI] Creating embedding...[39m
[1692667127770] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127770] [33m[OPENAI] No functions provided.[39m
[1692667127770] [33m[OPENAI] Creating embedding...[39m
[1692667127770] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127770] [33m[OPENAI] No functions provided.[39m
[1692667127770] [33m[OPENAI] Creating embedding...[39m
[1692667127770] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127770] [33m[OPENAI] No functions provided.[39m
[1692667127770] [33m[OPENAI] Creating embedding...[39m
[1692667127770] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127770] [33m[OPENAI] No functions provided.[39m
[1692667127770] [33m[OPENAI] Creating embedding...[39m
[1692667127770] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127770] [33m[OPENAI] No functions provided.[39m
[1692667127770] [33m[OPENAI] Creating embedding...[39m
[1692667127770] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127770] [33m[OPENAI] No functions provided.[39m
[1692667127770] [33m[OPENAI] Creating embedding...[39m
[1692667127770] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127770] [33m[OPENAI] No functions provided.[39m
[1692667127770] [33m[OPENAI] Creating embedding...[39m
[1692667127770] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127770] [33m[OPENAI] No functions provided.[39m
[1692667127771] [33m[OPENAI] Creating embedding...[39m
[1692667127771] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127771] [33m[OPENAI] No functions provided.[39m
[1692667127771] [33m[OPENAI] Creating embedding...[39m
[1692667127771] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127771] [33m[OPENAI] No functions provided.[39m
[1692667127771] [33m[OPENAI] Creating embedding...[39m
[1692667127771] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127771] [33m[OPENAI] No functions provided.[39m
[1692667127771] [33m[OPENAI] Creating embedding...[39m
[1692667127771] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127771] [33m[OPENAI] No functions provided.[39m
[1692667127771] [33m[OPENAI] Creating embedding...[39m
[1692667127771] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127771] [33m[OPENAI] No functions provided.[39m
[1692667127771] [33m[OPENAI] Creating embedding...[39m
[1692667127818] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127818] [33m[OPENAI] No functions provided.[39m
[1692667127818] [33m[OPENAI] Creating embedding...[39m
[1692667127818] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127818] [33m[OPENAI] No functions provided.[39m
[1692667127818] [33m[OPENAI] Creating embedding...[39m
[1692667127818] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127818] [33m[OPENAI] No functions provided.[39m
[1692667127818] [33m[OPENAI] Creating embedding...[39m
[1692667127818] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127818] [33m[OPENAI] No functions provided.[39m
[1692667127818] [33m[OPENAI] Creating embedding...[39m
[1692667127818] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127818] [33m[OPENAI] No functions provided.[39m
[1692667127818] [33m[OPENAI] Creating embedding...[39m
[1692667127818] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127818] [33m[OPENAI] No functions provided.[39m
[1692667127818] [33m[OPENAI] Creating embedding...[39m
[1692667127818] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127818] [33m[OPENAI] No functions provided.[39m
[1692667127818] [33m[OPENAI] Creating embedding...[39m
[1692667127818] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127818] [33m[OPENAI] No functions provided.[39m
[1692667127818] [33m[OPENAI] Creating embedding...[39m
[1692667127818] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127818] [33m[OPENAI] No functions provided.[39m
[1692667127818] [33m[OPENAI] Creating embedding...[39m
[1692667127818] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127818] [33m[OPENAI] No functions provided.[39m
[1692667127818] [33m[OPENAI] Creating embedding...[39m
[1692667127818] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127818] [33m[OPENAI] No functions provided.[39m
[1692667127818] [33m[OPENAI] Creating embedding...[39m
[1692667127818] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127818] [33m[OPENAI] No functions provided.[39m
[1692667127819] [33m[OPENAI] Creating embedding...[39m
[1692667127819] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127819] [33m[OPENAI] No functions provided.[39m
[1692667127819] [33m[OPENAI] Creating embedding...[39m
[1692667127819] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127819] [33m[OPENAI] No functions provided.[39m
[1692667127819] [33m[OPENAI] Creating embedding...[39m
[1692667127819] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127819] [33m[OPENAI] No functions provided.[39m
[1692667127819] [33m[OPENAI] Creating embedding...[39m
[1692667127829] {
  "id": "chatcmpl-7olV7awQY0r1Z91TRQqy3X3sCOCtl",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1692667127829] [36m[OPENAI] Chat completion took 206.35112500190735ms[39m
[1692667127829] [36m[OPENAI] Tokens per second: 4.846108786616776tps[39m
[1692667127829] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127842] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127842] [33m[OPENAI] No functions provided.[39m
[1692667127842] [33m[OPENAI] Creating embedding...[39m
[1692667127842] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127842] [33m[OPENAI] No functions provided.[39m
[1692667127842] [33m[OPENAI] Creating embedding...[39m
[1692667127842] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127842] [33m[OPENAI] No functions provided.[39m
[1692667127842] [33m[OPENAI] Creating embedding...[39m
[1692667127842] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127842] [33m[OPENAI] No functions provided.[39m
[1692667127842] [33m[OPENAI] Creating embedding...[39m
[1692667127842] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127842] [33m[OPENAI] No functions provided.[39m
[1692667127842] [33m[OPENAI] Creating embedding...[39m
[1692667127842] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127842] [33m[OPENAI] No functions provided.[39m
[1692667127842] [33m[OPENAI] Creating embedding...[39m
[1692667127842] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127842] [33m[OPENAI] No functions provided.[39m
[1692667127842] [33m[OPENAI] Creating embedding...[39m
[1692667127842] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127842] [33m[OPENAI] No functions provided.[39m
[1692667127843] [33m[OPENAI] Creating embedding...[39m
[1692667127843] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127843] [33m[OPENAI] No functions provided.[39m
[1692667127843] [33m[OPENAI] Creating embedding...[39m
[1692667127843] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127843] [33m[OPENAI] No functions provided.[39m
[1692667127843] [33m[OPENAI] Creating embedding...[39m
[1692667127843] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127843] [33m[OPENAI] No functions provided.[39m
[1692667127843] [33m[OPENAI] Creating embedding...[39m
[1692667127843] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127843] [33m[OPENAI] No functions provided.[39m
[1692667127843] [33m[OPENAI] Creating embedding...[39m
[1692667127843] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127843] [33m[OPENAI] No functions provided.[39m
[1692667127843] [33m[OPENAI] Creating embedding...[39m
[1692667127843] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127843] [33m[OPENAI] No functions provided.[39m
[1692667127843] [33m[OPENAI] Creating embedding...[39m
[1692667127843] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667127843] [33m[OPENAI] No functions provided.[39m
[1692667127843] [33m[OPENAI] Creating embedding...[39m
[1692667127859] {
  "id": "chatcmpl-7olV8fN3fq9UpfWvSUTEp2NY38XF6",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1692667127859] [36m[OPENAI] Chat completion took 237.6199579834938ms[39m
[1692667127859] [36m[OPENAI] Tokens per second: 4.2084007104717385tps[39m
[1692667127859] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127859] {
  "id": "chatcmpl-7olV8kkS3FTnii4MmY8ia64SJ6LNI",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1692667127859] [36m[OPENAI] Chat completion took 236.91829201579094ms[39m
[1692667127859] [36m[OPENAI] Tokens per second: 4.220864465515177tps[39m
[1692667127859] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127867] {
  "id": "chatcmpl-7olV8am3kWnTxD3AdhAcKQ7sZFofT",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1692667127867] [36m[OPENAI] Chat completion took 245.57612499594688ms[39m
[1692667127867] [36m[OPENAI] Tokens per second: 4.072057086235498tps[39m
[1692667127867] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127870] {
  "id": "chatcmpl-7olV8aKTgfiVBW2NEZi4xnYtbzqXs",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "8"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1692667127870] [36m[OPENAI] Chat completion took 245.44762501120567ms[39m
[1692667127870] [36m[OPENAI] Tokens per second: 4.0741889433818965tps[39m
[1692667127870] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127870] {
  "id": "chatcmpl-7olV8Dz9sjPtUQKfjXwxRmXWT5R55",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1692667127870] [36m[OPENAI] Chat completion took 248.64987498521805ms[39m
[1692667127870] [36m[OPENAI] Tokens per second: 4.02171929529202tps[39m
[1692667127870] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127871] {
  "id": "chatcmpl-7omMfa2PRcUpPT5rniqV1aVs7hJcX",
  "object": "chat.completion",
  "created": 1692336669,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1692667127871] [36m[OPENAI] Chat completion took 249.3161659836769ms[39m
[1692667127871] [36m[OPENAI] Tokens per second: 4.0109713546031tps[39m
[1692667127871] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127871] {
  "id": "chatcmpl-7olV7APh60cRjJf0i5PmcQO8fTjfy",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1692667127871] [36m[OPENAI] Chat completion took 249.33050000667572ms[39m
[1692667127871] [36m[OPENAI] Tokens per second: 4.010740763657978tps[39m
[1692667127871] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127872] {
  "id": "chatcmpl-7olV8OlY5ASbWrYxYLt8a45Y4PR3r",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1692667127872] [36m[OPENAI] Chat completion took 247.92120802402496ms[39m
[1692667127872] [36m[OPENAI] Tokens per second: 4.033539558677426tps[39m
[1692667127872] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127872] {
  "id": "chatcmpl-7olV7j8jI4CsLNROmVW204qB21XOS",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "8"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1692667127872] [36m[OPENAI] Chat completion took 247.8474159836769ms[39m
[1692667127872] [36m[OPENAI] Tokens per second: 4.034740471394946tps[39m
[1692667127872] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127877] [32m[OPENAI] Embedding created successfully.[39m
[1692667127881] [32m[OPENAI] Embedding created successfully.[39m
[1692667127888] [32m[OPENAI] Embedding created successfully.[39m
[1692667127889] [32m[OPENAI] Embedding created successfully.[39m
[1692667127890] [32m[OPENAI] Embedding created successfully.[39m
[1692667127891] [32m[OPENAI] Embedding created successfully.[39m
[1692667127892] {
  "id": "chatcmpl-7olV7fvXbMZXKww0lwuV4saDZl6b0",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1692667127892] [36m[OPENAI] Chat completion took 268.05958300828934ms[39m
[1692667127892] [36m[OPENAI] Tokens per second: 3.730513898356234tps[39m
[1692667127892] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127893] [32m[OPENAI] Embedding created successfully.[39m
[1692667127897] {
  "id": "chatcmpl-7olV8zsVjzFPFnewm1LRc1ydBVcKx",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1692667127897] [36m[OPENAI] Chat completion took 277.75749999284744ms[39m
[1692667127897] [36m[OPENAI] Tokens per second: 3.6002628192785116tps[39m
[1692667127897] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127900] [32m[OPENAI] Embedding created successfully.[39m
[1692667127909] [32m[OPENAI] Embedding created successfully.[39m
[1692667127912] [32m[OPENAI] Embedding created successfully.[39m
[1692667127913] [32m[OPENAI] Embedding created successfully.[39m
[1692667127917] {
  "id": "chatcmpl-7omMf7ekcj16DBIUKnLgNQjV9DbEc",
  "object": "chat.completion",
  "created": 1692336669,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1692667127917] [36m[OPENAI] Chat completion took 160.6403750181198ms[39m
[1692667127917] [36m[OPENAI] Tokens per second: 6.225085068975982tps[39m
[1692667127917] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127922] {
  "id": "chatcmpl-7olV8Srn1MXRcNPWiwg97xq3mIAIQ",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 96,
    "completion_tokens": 1,
    "total_tokens": 97
  }
}
[1692667127922] [36m[OPENAI] Chat completion took 164.97141700983047ms[39m
[1692667127922] [36m[OPENAI] Tokens per second: 6.061656122771929tps[39m
[1692667127922] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127927] {
  "id": "chatcmpl-7olV8GJ1IBvPgWmgYv1XGPV02YStQ",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1692667127927] [36m[OPENAI] Chat completion took 302.9102919995785ms[39m
[1692667127927] [36m[OPENAI] Tokens per second: 3.301307437917598tps[39m
[1692667127927] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127927] {
  "id": "chatcmpl-7olV8KzYkm8v3MhXQPvCWFGD6v469",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1692667127927] [36m[OPENAI] Chat completion took 305.3417499959469ms[39m
[1692667127927] [36m[OPENAI] Tokens per second: 3.2750188928087103tps[39m
[1692667127927] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127930] {
  "id": "chatcmpl-7olV81tLnpWnlV0E87Dtv0VWIir0C",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1692667127930] [36m[OPENAI] Chat completion took 172.72404199838638ms[39m
[1692667127930] [36m[OPENAI] Tokens per second: 5.78958197382471tps[39m
[1692667127930] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127930] [32m[OPENAI] Embedding created successfully.[39m
[1692667127932] [32m[OPENAI] Embedding created successfully.[39m
[1692667127934] [32m[OPENAI] Embedding created successfully.[39m
[1692667127938] {
  "id": "chatcmpl-7olV71LhIbN48putDIQmSVZEBQfDN",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1692667127938] [36m[OPENAI] Chat completion took 180.6330830156803ms[39m
[1692667127938] [36m[OPENAI] Tokens per second: 5.536084438713768tps[39m
[1692667127938] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127945] {
  "id": "chatcmpl-7olV7xVky29QtP8jg94OIGF49l6Xh",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1692667127945] [36m[OPENAI] Chat completion took 188.41683399677277ms[39m
[1692667127945] [36m[OPENAI] Tokens per second: 5.307381398931309tps[39m
[1692667127945] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127953] {
  "id": "chatcmpl-7olV746E6rNKpkaXPf5MrQxZAwsO2",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1692667127953] [36m[OPENAI] Chat completion took 197.09650000929832ms[39m
[1692667127953] [36m[OPENAI] Tokens per second: 5.073656812540169tps[39m
[1692667127953] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127962] {
  "id": "chatcmpl-7olV7rSM98c3wrV6ENTUmLwnKbwbw",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1692667127962] [36m[OPENAI] Chat completion took 205.2199999988079ms[39m
[1692667127962] [36m[OPENAI] Tokens per second: 4.8728194133408484tps[39m
[1692667127962] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127969] {
  "id": "chatcmpl-7olV7qLYI7cHxKdREfvGldBQMhoMt",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 96,
    "completion_tokens": 1,
    "total_tokens": 97
  }
}
[1692667127969] [36m[OPENAI] Chat completion took 211.97995799779892ms[39m
[1692667127969] [36m[OPENAI] Tokens per second: 4.717427107002179tps[39m
[1692667127969] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127969] {
  "id": "chatcmpl-7olV77grwRXfmalZQgcsGh31003bs",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1692667127969] [36m[OPENAI] Chat completion took 212.2648750245571ms[39m
[1692667127969] [36m[OPENAI] Tokens per second: 4.71109504049744tps[39m
[1692667127969] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127969] {
  "id": "chatcmpl-7olV7IxMkWZqPJc7J4cneCp8IBC6C",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7.5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 3,
    "total_tokens": 103
  }
}
[1692667127969] [36m[OPENAI] Chat completion took 199.1541660130024ms[39m
[1692667127969] [36m[OPENAI] Tokens per second: 15.063706976655139tps[39m
[1692667127969] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127970] {
  "id": "chatcmpl-7olV8yLve7h6sPLF0O0oWRRj2jrxr",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 90,
    "completion_tokens": 1,
    "total_tokens": 91
  }
}
[1692667127970] [36m[OPENAI] Chat completion took 212.80245900154114ms[39m
[1692667127970] [36m[OPENAI] Tokens per second: 4.699193818962205tps[39m
[1692667127970] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127970] {
  "id": "chatcmpl-7olV7RaXQuNOvR7Ylu0WkrhMZoeSC",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 2,
    "total_tokens": 96
  }
}
[1692667127970] [36m[OPENAI] Chat completion took 212.3240829706192ms[39m
[1692667127970] [36m[OPENAI] Tokens per second: 9.41956264224984tps[39m
[1692667127970] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127970] [32m[OPENAI] Embedding created successfully.[39m
[1692667127978] {
  "id": "chatcmpl-7olVCzZk3HzXo2NQMOMd0GiNn5tcu",
  "object": "chat.completion",
  "created": 1692333354,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 2,
    "total_tokens": 102
  }
}
[1692667127978] [36m[OPENAI] Chat completion took 207.50070801377296ms[39m
[1692667127978] [36m[OPENAI] Tokens per second: 9.638521329128425tps[39m
[1692667127978] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127978] [32m[OPENAI] Embedding created successfully.[39m
[1692667127983] {
  "id": "chatcmpl-7olV757xzL4ZuTU41FmNrt2hWXJkz",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1692667127983] [36m[OPENAI] Chat completion took 212.5291250050068ms[39m
[1692667127983] [36m[OPENAI] Tokens per second: 4.705237458519823tps[39m
[1692667127983] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127983] [32m[OPENAI] Embedding created successfully.[39m
[1692667127984] [32m[OPENAI] Embedding created successfully.[39m
[1692667127987] {
  "id": "chatcmpl-7olV7HdNVZxJfRU21bECzegn2lNwi",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1692667127987] [36m[OPENAI] Chat completion took 230.04295900464058ms[39m
[1692667127987] [36m[OPENAI] Tokens per second: 4.347014159124198tps[39m
[1692667127987] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127992] {
  "id": "chatcmpl-7olV7vrDE6VNyHnI8foiB0wK9uXCn",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 90,
    "completion_tokens": 1,
    "total_tokens": 91
  }
}
[1692667127992] [36m[OPENAI] Chat completion took 173.54700002074242ms[39m
[1692667127992] [36m[OPENAI] Tokens per second: 5.762127837879534tps[39m
[1692667127992] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127997] {
  "id": "chatcmpl-7olV7XrJLdun8a9EZhgSUTTwxkfEv",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 2,
    "total_tokens": 101
  }
}
[1692667127997] [36m[OPENAI] Chat completion took 226.14058300852776ms[39m
[1692667127997] [36m[OPENAI] Tokens per second: 8.84405608844026tps[39m
[1692667127997] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127997] {
  "id": "chatcmpl-7olV85IQ0ZMhfMNYXgLMZ98Oqw7x9",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1692667127997] [36m[OPENAI] Chat completion took 374.9819999933243ms[39m
[1692667127997] [36m[OPENAI] Tokens per second: 2.666794672858438tps[39m
[1692667127997] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127998] {
  "id": "chatcmpl-7olV8Py9dUkaghVHNiYvwGjlihWx9",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1692667127998] [36m[OPENAI] Chat completion took 155.76479202508926ms[39m
[1692667127998] [36m[OPENAI] Tokens per second: 6.419936026614592tps[39m
[1692667127998] [32m[OPENAI] Chat completion created successfully.[39m
[1692667127999] {
  "id": "chatcmpl-7omMfKtOqiWZY1HULj9SxSxqtgvth",
  "object": "chat.completion",
  "created": 1692336669,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 114,
    "completion_tokens": 1,
    "total_tokens": 115
  }
}
[1692667127999] [36m[OPENAI] Chat completion took 229.42737498879433ms[39m
[1692667127999] [36m[OPENAI] Tokens per second: 4.358677773516966tps[39m
[1692667127999] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128005] {
  "id": "chatcmpl-7olV777mm4E117eWDlhnUXJv1akt3",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1692667128005] [36m[OPENAI] Chat completion took 186.11395800113678ms[39m
[1692667128005] [36m[OPENAI] Tokens per second: 5.373052138270532tps[39m
[1692667128005] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128005] {
  "id": "chatcmpl-7olV7ctuUV67Q1sfdu5KFIo2luWJB",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1692667128005] [36m[OPENAI] Chat completion took 186.83979201316833ms[39m
[1692667128005] [36m[OPENAI] Tokens per second: 5.352178940177373tps[39m
[1692667128005] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128005] {
  "id": "chatcmpl-7olV7FRwvXnqPU0zcwtBho0a9XM8N",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1692667128005] [36m[OPENAI] Chat completion took 187.08675000071526ms[39m
[1692667128005] [36m[OPENAI] Tokens per second: 5.345113964490681tps[39m
[1692667128006] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128006] [32m[OPENAI] Embedding created successfully.[39m
[1692667128006] [32m[OPENAI] Embedding created successfully.[39m
[1692667128007] [32m[OPENAI] Embedding created successfully.[39m
[1692667128009] {
  "id": "chatcmpl-7olV8zC3SlBJAGZ16CfxiW5ysM14X",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1692667128009] [36m[OPENAI] Chat completion took 191.01829200983047ms[39m
[1692667128009] [36m[OPENAI] Tokens per second: 5.2351007302930785tps[39m
[1692667128009] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128014] {
  "id": "chatcmpl-7olV7tu3HrQfLXa3gKYRIZRrlpt21",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1692667128014] [36m[OPENAI] Chat completion took 196.23500001430511ms[39m
[1692667128014] [36m[OPENAI] Tokens per second: 5.095930898805525tps[39m
[1692667128014] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128015] {
  "id": "chatcmpl-7olV8T9DG4pPIxUCGEYVdp1hITHfT",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1692667128015] [36m[OPENAI] Chat completion took 244.70533400774002ms[39m
[1692667128015] [36m[OPENAI] Tokens per second: 4.086547618812306tps[39m
[1692667128015] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128015] {
  "id": "chatcmpl-7olV8YtG6ysTRpfalhSZtYRhj6BFF",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1692667128015] [36m[OPENAI] Chat completion took 196.82479098439217ms[39m
[1692667128015] [36m[OPENAI] Tokens per second: 5.080660799885203tps[39m
[1692667128015] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128015] {
  "id": "chatcmpl-7olV8gGRRaflm8XIf2MXwKoEeVCsh",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1692667128015] [36m[OPENAI] Chat completion took 172.80812498927116ms[39m
[1692667128015] [36m[OPENAI] Tokens per second: 5.786764945583926tps[39m
[1692667128015] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128016] {
  "id": "chatcmpl-7olV7cqXYbdSPmsM1yjrwuEt0826y",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1692667128016] [36m[OPENAI] Chat completion took 259.73591700196266ms[39m
[1692667128016] [36m[OPENAI] Tokens per second: 3.8500643713146676tps[39m
[1692667128016] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128017] {
  "id": "chatcmpl-7olV7Br8PoxSOMCFkl0GY62STc2wu",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1692667128017] [36m[OPENAI] Chat completion took 246.43112498521805ms[39m
[1692667128017] [36m[OPENAI] Tokens per second: 4.0579289651823975tps[39m
[1692667128017] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128018] {
  "id": "chatcmpl-7olV8lZTqMoJn2eRn4eW5uL1SAakO",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1692667128018] [36m[OPENAI] Chat completion took 247.6559999883175ms[39m
[1692667128018] [36m[OPENAI] Tokens per second: 4.037858965852522tps[39m
[1692667128018] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128019] {
  "id": "chatcmpl-7olV7bXDGvpJQSwghwqyXcR08MqUR",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 92,
    "completion_tokens": 1,
    "total_tokens": 93
  }
}
[1692667128019] [36m[OPENAI] Chat completion took 176.75370800495148ms[39m
[1692667128019] [36m[OPENAI] Tokens per second: 5.65758993849219tps[39m
[1692667128019] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128019] {
  "id": "chatcmpl-7omMf1iH6S1cjaqDfWFBUxiipPCUG",
  "object": "chat.completion",
  "created": 1692336669,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1692667128019] [36m[OPENAI] Chat completion took 176.48841699957848ms[39m
[1692667128019] [36m[OPENAI] Tokens per second: 5.666094223069542tps[39m
[1692667128019] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128020] {
  "id": "chatcmpl-7olV8BoCj2TVoQKQaIkTdB8yJa75R",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1692667128020] [36m[OPENAI] Chat completion took 262.7999999821186ms[39m
[1692667128020] [36m[OPENAI] Tokens per second: 3.8051750383106615tps[39m
[1692667128020] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128020] {
  "id": "chatcmpl-7olV8NUOQZyQ8WoqNva8OKehDPmzu",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1692667128020] [36m[OPENAI] Chat completion took 177.5178339779377ms[39m
[1692667128020] [36m[OPENAI] Tokens per second: 5.633236828048962tps[39m
[1692667128020] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128020] {
  "id": "chatcmpl-7olV8FREfRx0ZWWp3SphTSzmx6xZ2",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 96,
    "completion_tokens": 1,
    "total_tokens": 97
  }
}
[1692667128020] [36m[OPENAI] Chat completion took 201.8652079999447ms[39m
[1692667128020] [36m[OPENAI] Tokens per second: 4.953800656922882tps[39m
[1692667128020] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128021] [32m[OPENAI] Embedding created successfully.[39m
[1692667128021] [32m[OPENAI] Embedding created successfully.[39m
[1692667128022] {
  "id": "chatcmpl-7olV7Ze1M8NgP8Lk7PYp1PhWSaIEf",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1692667128022] [36m[OPENAI] Chat completion took 179.39058297872543ms[39m
[1692667128022] [36m[OPENAI] Tokens per second: 5.574428620473315tps[39m
[1692667128022] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128023] {
  "id": "chatcmpl-7omMfBOgjTu7sXdHl9tvA7jxYHMKT",
  "object": "chat.completion",
  "created": 1692336669,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 90,
    "completion_tokens": 1,
    "total_tokens": 91
  }
}
[1692667128023] [36m[OPENAI] Chat completion took 205.29995799064636ms[39m
[1692667128023] [36m[OPENAI] Tokens per second: 4.870921600702718tps[39m
[1692667128023] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128024] [32m[OPENAI] Embedding created successfully.[39m
[1692667128025] [32m[OPENAI] Embedding created successfully.[39m
[1692667128026] [32m[OPENAI] Embedding created successfully.[39m
[1692667128028] {
  "id": "chatcmpl-7olV75Kg6LpizfVZoOUgYmChjg5d6",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1692667128028] [36m[OPENAI] Chat completion took 186.16374999284744ms[39m
[1692667128028] [36m[OPENAI] Tokens per second: 5.371615043414311tps[39m
[1692667128028] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128029] [32m[OPENAI] Embedding created successfully.[39m
[1692667128029] {
  "id": "chatcmpl-7olV8gA5LrpqgDUYedds92oLPqMCg",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 89,
    "completion_tokens": 1,
    "total_tokens": 90
  }
}
[1692667128030] [36m[OPENAI] Chat completion took 187.05979201197624ms[39m
[1692667128030] [36m[OPENAI] Tokens per second: 5.345884271783945tps[39m
[1692667128030] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128032] {
  "id": "chatcmpl-7olV778kF1nFpJ5zYXIDkaXF9tRXR",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1692667128032] [36m[OPENAI] Chat completion took 188.70158299803734ms[39m
[1692667128032] [36m[OPENAI] Tokens per second: 5.299372607862018tps[39m
[1692667128032] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128032] {
  "id": "chatcmpl-7olV8SQyMyfcS6uXzNc90h0LLuDY1",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1692667128032] [36m[OPENAI] Chat completion took 189.71387499570847ms[39m
[1692667128032] [36m[OPENAI] Tokens per second: 5.271095748914628tps[39m
[1692667128032] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128032] {
  "id": "chatcmpl-7olV83YLFQhCJTkBVDSmx47UrZkLN",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1692667128032] [36m[OPENAI] Chat completion took 213.3495829999447ms[39m
[1692667128032] [36m[OPENAI] Tokens per second: 4.687142978855784tps[39m
[1692667128032] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128032] {
  "id": "chatcmpl-7olV7zjV0jDIqYutwLfUmrgSVBifk",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1692667128032] [36m[OPENAI] Chat completion took 214.22716599702835ms[39m
[1692667128033] [36m[OPENAI] Tokens per second: 4.667942066758571tps[39m
[1692667128033] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128033] {
  "id": "chatcmpl-7olV8DoIHRPyAnFJQpub2WZmmGHFY",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1692667128033] [36m[OPENAI] Chat completion took 213.97441598773003ms[39m
[1692667128033] [36m[OPENAI] Tokens per second: 4.673455914735821tps[39m
[1692667128033] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128033] [32m[OPENAI] Embedding created successfully.[39m
[1692667128034] [32m[OPENAI] Embedding created successfully.[39m
[1692667128034] [32m[OPENAI] Embedding created successfully.[39m
[1692667128035] [32m[OPENAI] Embedding created successfully.[39m
[1692667128037] {
  "id": "chatcmpl-7olV8IiA12R5nF0Pmp4dfcjnLnWOn",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1692667128037] [36m[OPENAI] Chat completion took 267.20750001072884ms[39m
[1692667128037] [36m[OPENAI] Tokens per second: 3.7424099247208567tps[39m
[1692667128037] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128039] {
  "id": "chatcmpl-7olV7LWuqju0QGl6Hdki7b8wPcCqS",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1692667128039] [36m[OPENAI] Chat completion took 197.0474999845028ms[39m
[1692667128039] [36m[OPENAI] Tokens per second: 5.0749184845209765tps[39m
[1692667128039] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128040] {
  "id": "chatcmpl-7olV7PpiqlgvDunRGtioXg2g7NIPw",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1692667128040] [36m[OPENAI] Chat completion took 282.6024580001831ms[39m
[1692667128040] [36m[OPENAI] Tokens per second: 3.5385396400173983tps[39m
[1692667128040] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128044] [32m[OPENAI] Embedding created successfully.[39m
[1692667128045] [32m[OPENAI] Embedding created successfully.[39m
[1692667128049] [32m[OPENAI] Embedding created successfully.[39m
[1692667128051] {
  "id": "chatcmpl-7olV7Xwk3tvSdS5NEeiRvaWAx38sd",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1692667128051] [36m[OPENAI] Chat completion took 209.05158299207687ms[39m
[1692667128051] [36m[OPENAI] Tokens per second: 4.7835083843297195tps[39m
[1692667128051] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128052] [32m[OPENAI] Embedding created successfully.[39m
[1692667128053] [32m[OPENAI] Embedding created successfully.[39m
[1692667128055] {
  "id": "chatcmpl-7olV79ngfUn6SHKsI6M07wj1KL41H",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667128055] [36m[OPENAI] Chat completion took 285.21841701865196ms[39m
[1692667128055] [36m[OPENAI] Tokens per second: 3.5060849522021034tps[39m
[1692667128055] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128056] {
  "id": "chatcmpl-7olV7K7Q2Z1zQ4UQX0QjkzMFVYeI6",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "8"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1692667128056] [36m[OPENAI] Chat completion took 285.96287500858307ms[39m
[1692667128056] [36m[OPENAI] Tokens per second: 3.496957428372425tps[39m
[1692667128056] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128057] [32m[OPENAI] Embedding created successfully.[39m
[1692667128058] [32m[OPENAI] Embedding created successfully.[39m
[1692667128059] [32m[OPENAI] Embedding created successfully.[39m
[1692667128060] [32m[OPENAI] Embedding created successfully.[39m
[1692667128062] {
  "id": "chatcmpl-7olV7slmJcR3P7QDbSfQjf9qNly1R",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1692667128062] [36m[OPENAI] Chat completion took 291.9912499785423ms[39m
[1692667128063] [36m[OPENAI] Tokens per second: 3.424760160016738tps[39m
[1692667128063] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128063] [32m[OPENAI] Embedding created successfully.[39m
[1692667128063] [32m[OPENAI] Embedding created successfully.[39m
[1692667128064] [32m[OPENAI] Embedding created successfully.[39m
[1692667128065] [32m[OPENAI] Embedding created successfully.[39m
[1692667128066] [32m[OPENAI] Embedding created successfully.[39m
[1692667128067] [32m[OPENAI] Embedding created successfully.[39m
[1692667128068] [32m[OPENAI] Embedding created successfully.[39m
[1692667128072] {
  "id": "chatcmpl-7olV7noZMGrBR0G5IQC7H6xzCmDtX",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1692667128072] [36m[OPENAI] Chat completion took 229.62320798635483ms[39m
[1692667128072] [36m[OPENAI] Tokens per second: 4.354960497108917tps[39m
[1692667128072] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128072] [32m[OPENAI] Embedding created successfully.[39m
[1692667128077] {
  "id": "chatcmpl-7olV7POyU9BbIur1pbbjofBicYnQV",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667128077] [36m[OPENAI] Chat completion took 306.9419159889221ms[39m
[1692667128077] [36m[OPENAI] Tokens per second: 3.2579453893683623tps[39m
[1692667128077] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128078] {
  "id": "chatcmpl-7olV7mLd3CHurzeFeAcyiefLZ2bzR",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1692667128078] [36m[OPENAI] Chat completion took 306.90641701221466ms[39m
[1692667128078] [36m[OPENAI] Tokens per second: 3.2583222264792226tps[39m
[1692667128078] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128078] [32m[OPENAI] Embedding created successfully.[39m
[1692667128079] [32m[OPENAI] Embedding created successfully.[39m
[1692667128080] [32m[OPENAI] Embedding created successfully.[39m
[1692667128085] [32m[OPENAI] Embedding created successfully.[39m
[1692667128090] [32m[OPENAI] Embedding created successfully.[39m
[1692667128091] [32m[OPENAI] Embedding created successfully.[39m
[1692667128093] {
  "id": "chatcmpl-7olV7HleCtjDubqyAtoz4YCDoESYl",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1692667128093] [36m[OPENAI] Chat completion took 322.3401249945164ms[39m
[1692667128093] [36m[OPENAI] Tokens per second: 3.10231312349653tps[39m
[1692667128093] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128093] {
  "id": "chatcmpl-7olV8VNaWaURvwwCTSxpx87r0hDE0",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1692667128093] [36m[OPENAI] Chat completion took 322.21658301353455ms[39m
[1692667128093] [36m[OPENAI] Tokens per second: 3.103502590237559tps[39m
[1692667128093] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128096] {
  "id": "chatcmpl-7olV8mp16AEElDSWboZwenyFu445a",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 92,
    "completion_tokens": 1,
    "total_tokens": 93
  }
}
[1692667128096] [36m[OPENAI] Chat completion took 277.0804580152035ms[39m
[1692667128096] [36m[OPENAI] Tokens per second: 3.6090600079242314tps[39m
[1692667128096] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128097] [32m[OPENAI] Embedding created successfully.[39m
[1692667128098] [32m[OPENAI] Embedding created successfully.[39m
[1692667128099] [32m[OPENAI] Embedding created successfully.[39m
[1692667128099] {
  "id": "chatcmpl-7olV79SDWiud3CmckuSMAaCArje53",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 92,
    "completion_tokens": 1,
    "total_tokens": 93
  }
}
[1692667128099] [36m[OPENAI] Chat completion took 281.04050001502037ms[39m
[1692667128099] [36m[OPENAI] Tokens per second: 3.5582060234968074tps[39m
[1692667128099] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128100] [32m[OPENAI] Embedding created successfully.[39m
[1692667128101] [32m[OPENAI] Embedding created successfully.[39m
[1692667128108] [32m[OPENAI] Embedding created successfully.[39m
[1692667128110] {
  "id": "chatcmpl-7olV8kYnE1YMoyPDjABIJHD9Uvpff",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1692667128111] [36m[OPENAI] Chat completion took 267.6929579973221ms[39m
[1692667128111] [36m[OPENAI] Tokens per second: 3.735623108957553tps[39m
[1692667128111] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128113] [32m[OPENAI] Embedding created successfully.[39m
[1692667128113] [32m[OPENAI] Embedding created successfully.[39m
[1692667128114] [32m[OPENAI] Embedding created successfully.[39m
[1692667128115] [32m[OPENAI] Embedding created successfully.[39m
[1692667128116] [32m[OPENAI] Embedding created successfully.[39m
[1692667128116] {
  "id": "chatcmpl-7olV80dOsfHeL7YoM65UTcnGud0LK",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 2,
    "total_tokens": 97
  }
}
[1692667128116] [36m[OPENAI] Chat completion took 297.648707985878ms[39m
[1692667128116] [36m[OPENAI] Tokens per second: 6.719330359380866tps[39m
[1692667128116] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128117] [32m[OPENAI] Embedding created successfully.[39m
[1692667128118] [32m[OPENAI] Embedding created successfully.[39m
[1692667128119] [32m[OPENAI] Embedding created successfully.[39m
[1692667128120] [32m[OPENAI] Embedding created successfully.[39m
[1692667128121] [32m[OPENAI] Embedding created successfully.[39m
[1692667128122] {
  "id": "chatcmpl-7olV8KlbcvkCbGYfuCV5ccMLKBvt2",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 86,
    "completion_tokens": 1,
    "total_tokens": 87
  }
}
[1692667128122] [36m[OPENAI] Chat completion took 278.94449999928474ms[39m
[1692667128122] [36m[OPENAI] Tokens per second: 3.58494252441817tps[39m
[1692667128122] [32m[OPENAI] Chat completion created successfully.[39m
[1692667128128] [32m[OPENAI] Embedding created successfully.[39m
[1692667128164] [32m[OPENAI] Embedding created successfully.[39m
[1692667128168] [32m[OPENAI] Embedding created successfully.[39m
[1692667128173] [32m[OPENAI] Embedding created successfully.[39m
[1692667128201] [32m[OPENAI] Embedding created successfully.[39m
[1692667128245] [32m[OPENAI] Embedding created successfully.[39m
[1692667148538] [Main] WebSocket connection established
[1692667148560] [Character] Getting character: A5
[1692667148590] --- Observations received -- 
[1692667148590] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Small) at X: 41.33658, Y: 13.99647.",
  "time": 0
}
[1692667148590] [Character] Getting character: A5
[1692667148590] --- Observations received -- 
[1692667148590] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 42.12, Y: 5.77.",
  "time": 0
}
[1692667148590] [Character] Getting character: A5
[1692667148591] [Character] Getting character: A1
[1692667148591] --- Observations received -- 
[1692667148591] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 47.72001, Y: 10.21.",
  "time": 0
}
[1692667148591] [Character] Getting character: A1
[1692667148591] --- Observations received -- 
[1692667148591] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Chest at X: 50.52, Y: 14.5.",
  "time": 0
}
[1692667148591] [Character] Getting character: A1
[1692667148591] --- Observations received -- 
[1692667148591] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Stone Ore Deposit (Small) at X: 45.73, Y: 15.31.",
  "time": 0
}
[1692667148591] [Character] Getting character: A1
[1692667148591] --- Observations received -- 
[1692667148591] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 52.41, Y: 11.03.",
  "time": 0
}
[1692667148591] [Character] Getting character: A1
[1692667148591] --- Observations received -- 
[1692667148591] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 45.24001, Y: 10.2.",
  "time": 0
}
[1692667148591] [Character] Getting character: A1
[1692667148591] --- Observations received -- 
[1692667148591] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 50.77, Y: 9.22.",
  "time": 0
}
[1692667148591] [Character] Getting character: A1
[1692667148592] --- Observations received -- 
[1692667148592] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Stone Ore Deposit (Medium) at X: 46.05, Y: 17.85.",
  "time": 0
}
[1692667148592] [Character] Getting character: A1
[1692667148688] [33m[OPENAI] Creating embedding...[39m
[1692667148751] [33m[OPENAI] Creating embedding...[39m
[1692667148853] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667148853] [33m[OPENAI] No functions provided.[39m
[1692667148853] [33m[OPENAI] Creating embedding...[39m
[1692667148853] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667148853] [33m[OPENAI] No functions provided.[39m
[1692667148854] [33m[OPENAI] Creating embedding...[39m
[1692667148854] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667148854] [33m[OPENAI] No functions provided.[39m
[1692667148854] [33m[OPENAI] Creating embedding...[39m
[1692667148854] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667148854] [33m[OPENAI] No functions provided.[39m
[1692667148854] [33m[OPENAI] Creating embedding...[39m
[1692667148854] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667148854] [33m[OPENAI] No functions provided.[39m
[1692667148854] [33m[OPENAI] Creating embedding...[39m
[1692667148854] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667148854] [33m[OPENAI] No functions provided.[39m
[1692667148854] [33m[OPENAI] Creating embedding...[39m
[1692667148854] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667148854] [33m[OPENAI] No functions provided.[39m
[1692667148854] [33m[OPENAI] Creating embedding...[39m
[1692667148854] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667148854] [33m[OPENAI] No functions provided.[39m
[1692667148854] [33m[OPENAI] Creating embedding...[39m
[1692667148854] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667148854] [33m[OPENAI] No functions provided.[39m
[1692667148855] [33m[OPENAI] Creating embedding...[39m
[1692667148977] [32m[OPENAI] Embedding created successfully.[39m
[1692667149029] {
  "id": "chatcmpl-7olYVK3ubcflhZofq80hFwcKqzbWN",
  "object": "chat.completion",
  "created": 1692333559,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667149030] [36m[OPENAI] Chat completion took 174.82308301329613ms[39m
[1692667149030] [36m[OPENAI] Tokens per second: 5.720068441556687tps[39m
[1692667149030] [32m[OPENAI] Chat completion created successfully.[39m
[1692667149030] {
  "id": "chatcmpl-7olZFcOED2ldUw4M9Rg9y1NUOOc8o",
  "object": "chat.completion",
  "created": 1692333605,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1692667149030] [36m[OPENAI] Chat completion took 176.27862498164177ms[39m
[1692667149030] [36m[OPENAI] Tokens per second: 5.672837532651184tps[39m
[1692667149030] [32m[OPENAI] Chat completion created successfully.[39m
[1692667149042] {
  "id": "chatcmpl-7omSvZYm5TmWnrVrXwRvtB0Z021Ud",
  "object": "chat.completion",
  "created": 1692337057,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1692667149042] [36m[OPENAI] Chat completion took 188.77691599726677ms[39m
[1692667149042] [36m[OPENAI] Tokens per second: 5.2972578491243tps[39m
[1692667149042] [32m[OPENAI] Chat completion created successfully.[39m
[1692667149046] {
  "id": "chatcmpl-7olYVPZO2hJ85fnP0AXelCHaux4jx",
  "object": "chat.completion",
  "created": 1692333559,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1692667149046] [36m[OPENAI] Chat completion took 191.74858298897743ms[39m
[1692667149046] [36m[OPENAI] Tokens per second: 5.215162398657645tps[39m
[1692667149046] [32m[OPENAI] Chat completion created successfully.[39m
[1692667149051] {
  "id": "chatcmpl-7olYVT6GzRUKaYf3QTh5Q0qrIhfvi",
  "object": "chat.completion",
  "created": 1692333559,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667149052] [36m[OPENAI] Chat completion took 197.3592500090599ms[39m
[1692667149052] [36m[OPENAI] Tokens per second: 5.066902108485386tps[39m
[1692667149052] [32m[OPENAI] Chat completion created successfully.[39m
[1692667149053] {
  "id": "chatcmpl-7olYVTuEhtnoU81vyRAZAiSxNxkT3",
  "object": "chat.completion",
  "created": 1692333559,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1692667149053] [36m[OPENAI] Chat completion took 198.7807500064373ms[39m
[1692667149053] [36m[OPENAI] Tokens per second: 5.030668210918894tps[39m
[1692667149053] [32m[OPENAI] Chat completion created successfully.[39m
[1692667149061] {
  "id": "chatcmpl-7olYxD42manfyujIaUwmUKUVV7thF",
  "object": "chat.completion",
  "created": 1692333587,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667149061] [36m[OPENAI] Chat completion took 207.56975001096725ms[39m
[1692667149061] [36m[OPENAI] Tokens per second: 4.817657678670247tps[39m
[1692667149061] [32m[OPENAI] Chat completion created successfully.[39m
[1692667149081] [32m[OPENAI] Embedding created successfully.[39m
[1692667149102] {
  "id": "chatcmpl-7olYVI3RVsgz8WaPuEEOUclMtbGzx",
  "object": "chat.completion",
  "created": 1692333559,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1692667149102] [36m[OPENAI] Chat completion took 247.2332910001278ms[39m
[1692667149102] [36m[OPENAI] Tokens per second: 4.04476272574264tps[39m
[1692667149102] [32m[OPENAI] Chat completion created successfully.[39m
[1692667149103] [32m[OPENAI] Embedding created successfully.[39m
[1692667149104] [32m[OPENAI] Embedding created successfully.[39m
[1692667149105] [32m[OPENAI] Embedding created successfully.[39m
[1692667149107] [32m[OPENAI] Embedding created successfully.[39m
[1692667149127] {
  "id": "chatcmpl-7olYVWXT6KrquvJUsdoiU5pSZNMhm",
  "object": "chat.completion",
  "created": 1692333559,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667149127] [36m[OPENAI] Chat completion took 273.19370901584625ms[39m
[1692667149127] [36m[OPENAI] Tokens per second: 3.660406396627516tps[39m
[1692667149127] [32m[OPENAI] Chat completion created successfully.[39m
[1692667149136] [32m[OPENAI] Embedding created successfully.[39m
[1692667149139] [32m[OPENAI] Embedding created successfully.[39m
[1692667149152] [32m[OPENAI] Embedding created successfully.[39m
[1692667149154] [32m[OPENAI] Embedding created successfully.[39m
[1692667149527] [32m[OPENAI] Embedding created successfully.[39m
[1692667149791] [33m[OPENAI] Creating embedding...[39m
[1692667149991] [32m[OPENAI] Embedding created successfully.[39m
[1692667150232] [33m[OPENAI] Creating embedding...[39m
[1692667150268] [32m[OPENAI] Embedding created successfully.[39m
[1692667150685] [33m[OPENAI] Creating embedding...[39m
[1692667150875] [32m[OPENAI] Embedding created successfully.[39m
[1692667150882] [33m[OPENAI] Creating embedding...[39m
[1692667150920] [32m[OPENAI] Embedding created successfully.[39m
[1692667151372] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1692667151372] [33m[OPENAI] No functions provided.[39m
[1692667151461] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1692667151461] [33m[OPENAI] No functions provided.[39m
[1692667164356] {
  "id": "chatcmpl-7qAL134Jum5Qet4h3ZngZdjW34dL8",
  "object": "chat.completion",
  "created": 1692667151,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "[\n  {\n    \"task\": \"Eat the berries from your inventory\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Chop a tree to gather some wood\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Mine a small stone ore deposit\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Explore the surrounding area\",\n    \"priority\": 4\n  },\n  {\n    \"task\": \"Interact with the villagers\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Maintain a healthy lifestyle\",\n    \"priority\": 6\n  },\n  {\n    \"task\": \"Identify new possible areas for exploration\",\n    \"priority\": 7\n  }\n]"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 963,
    "completion_tokens": 162,
    "total_tokens": 1125
  }
}
[1692667164356] [36m[OPENAI] Chat completion took 12894.749458998442ms[39m
[1692667164356] [36m[OPENAI] Tokens per second: 12.563253013570597tps[39m
[1692667164356] [32m[OPENAI] Chat completion created successfully.[39m
[1692667164358] [Character] Getting character: A5
[1692667164494] [33m[OPENAI] Creating embedding...[39m
[1692667164714] [32m[OPENAI] Embedding created successfully.[39m
[1692667165398] [33m[OPENAI] Creating embedding...[39m
[1692667165619] [32m[OPENAI] Embedding created successfully.[39m
[1692667166184] [33m[OPENAI] Creating embedding...[39m
[1692667166473] [32m[OPENAI] Embedding created successfully.[39m
[1692667167011] [33m[OPENAI] Creating embedding...[39m
[1692667167286] [32m[OPENAI] Embedding created successfully.[39m
[1692667167769] [33m[OPENAI] Creating embedding...[39m
[1692667167990] [32m[OPENAI] Embedding created successfully.[39m
[1692667168518] [33m[OPENAI] Creating embedding...[39m
[1692667168739] [32m[OPENAI] Embedding created successfully.[39m
[1692667169222] [33m[OPENAI] Creating embedding...[39m
[1692667169451] [32m[OPENAI] Embedding created successfully.[39m
[1692667169914] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1692667169914] [33m[OPENAI] Using 6 functions.[39m
[1692667172571] {
  "id": "chatcmpl-7qAL1ynSN4VE9kYifgmF0wMbjiOet",
  "object": "chat.completion",
  "created": 1692667151,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "[\n  {\n    \"task\": \"Sleep until 7am\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Move to the village location (2, -58) to carry out regular duties\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Ensure safety measures in the village\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Catch up with other villagers\",\n    \"priority\": 4\n  },\n  {\n    \"task\": \"Gather resources from trees and ore deposits around\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Eat a meal to maintain a healthy lifestyle\",\n    \"priority\": 6\n  },\n  {\n    \"task\": \"Earn rest and sleep by 10pm\",\n    \"priority\": 7\n  }\n]"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 1247,
    "completion_tokens": 178,
    "total_tokens": 1425
  }
}
[1692667172571] [36m[OPENAI] Chat completion took 21198.59200000763ms[39m
[1692667172571] [36m[OPENAI] Tokens per second: 8.396784088298691tps[39m
[1692667172572] [32m[OPENAI] Chat completion created successfully.[39m
[1692667172572] [Character] Getting character: A1
[1692667172668] [33m[OPENAI] Creating embedding...[39m
[1692667173031] [32m[OPENAI] Embedding created successfully.[39m
[1692667173253] {
  "id": "chatcmpl-7qALK6bEMM7aTrkT4pcrs9kPMrlPc",
  "object": "chat.completion",
  "created": 1692667170,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "eat",
          "arguments": "{\n  \"characterId\": \"A5\",\n  \"foodId\": \"berries\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1334,
    "completion_tokens": 25,
    "total_tokens": 1359
  }
}
[1692667173253] [36m[OPENAI] Chat completion took 3338.565458983183ms[39m
[1692667173253] [36m[OPENAI] Tokens per second: 7.488246166547885tps[39m
[1692667173253] [32m[OPENAI] Chat completion created successfully.[39m
[1692667173261] [Character] Getting character: A1
[1692667173341] [33m[OPENAI] Creating embedding...[39m
[1692667173548] [33m[OPENAI] Creating embedding...[39m
[1692667173559] [32m[OPENAI] Embedding created successfully.[39m
[1692667173732] [32m[OPENAI] Embedding created successfully.[39m
[1692667174056] [33m[OPENAI] Creating embedding...[39m
[1692667174097] [32m[OPENAI] Embedding created successfully.[39m
[1692667174306] [33m[OPENAI] Creating embedding...[39m
[1692667174521] [32m[OPENAI] Embedding created successfully.[39m
[1692667174585] [33m[OPENAI] Creating embedding...[39m
[1692667174747] [32m[OPENAI] Embedding created successfully.[39m
[1692667175012] [33m[OPENAI] Creating embedding...[39m
[1692667175088] [32m[OPENAI] Embedding created successfully.[39m
[1692667175356] [33m[OPENAI] Creating embedding...[39m
[1692667175397] [32m[OPENAI] Embedding created successfully.[39m
[1692667175592] [33m[OPENAI] Creating embedding...[39m
[1692667175760] [32m[OPENAI] Embedding created successfully.[39m
[1692667175802] [33m[OPENAI] Creating embedding...[39m
[1692667175995] [32m[OPENAI] Embedding created successfully.[39m
[1692667176186] [33m[OPENAI] Creating embedding...[39m
[1692667176350] [32m[OPENAI] Embedding created successfully.[39m
[1692667176414] [33m[OPENAI] Creating embedding...[39m
[1692667176560] [32m[OPENAI] Embedding created successfully.[39m
[1692667176783] [33m[OPENAI] Creating embedding...[39m
[1692667176926] [32m[OPENAI] Embedding created successfully.[39m
[1692667176998] [33m[OPENAI] Creating embedding...[39m
[1692667177204] [32m[OPENAI] Embedding created successfully.[39m
[1692667177322] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1692667177322] [33m[OPENAI] Using 6 functions.[39m
[1692667177571] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1692667177571] [33m[OPENAI] Using 6 functions.[39m
[1692667180018] {
  "id": "chatcmpl-7qALR6AtJ2uHahkSfwouMHlXW6jqy",
  "object": "chat.completion",
  "created": 1692667177,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A1\",\n  \"x\": 2,\n  \"y\": -58\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1592,
    "completion_tokens": 31,
    "total_tokens": 1623
  }
}
[1692667180018] [36m[OPENAI] Chat completion took 2696.0502920150757ms[39m
[1692667180018] [36m[OPENAI] Tokens per second: 11.49830182760799tps[39m
[1692667180018] [32m[OPENAI] Chat completion created successfully.[39m
[1692667180042] --- Observations received -- 
[1692667180042] {
  "observerId": "A1",
  "observation": "Thomas Smith has started walking to 2, Y: -58.",
  "time": 30.9097481
}
[1692667180042] [Character] Getting character: A1
[1692667180182] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667180182] [33m[OPENAI] No functions provided.[39m
[1692667180182] [33m[OPENAI] Creating embedding...[39m
[1692667180409] [32m[OPENAI] Embedding created successfully.[39m
[1692667180545] {
  "id": "chatcmpl-7qALUtwvNjpyl5221HctrCwxq7OgS",
  "object": "chat.completion",
  "created": 1692667180,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 96,
    "completion_tokens": 1,
    "total_tokens": 97
  }
}
[1692667180545] [36m[OPENAI] Chat completion took 362.7619169950485ms[39m
[1692667180545] [36m[OPENAI] Tokens per second: 2.756628943532817tps[39m
[1692667180545] [32m[OPENAI] Chat completion created successfully.[39m
[1692667181474] --- Observations received -- 
[1692667181475] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (486) at X: 52.41, Y: 11.03",
  "time": 32.3611069
}
[1692667181475] [Character] Getting character: A1
[1692667181512] --- Observations received -- 
[1692667181512] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Stone Ore Deposit (Small) at X: 41.33658, Y: 13.99647.",
  "time": 32.4000969
}
[1692667181512] [Character] Getting character: A1
[1692667181655] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667181655] [33m[OPENAI] No functions provided.[39m
[1692667181656] [33m[OPENAI] Creating embedding...[39m
[1692667181750] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667181750] [33m[OPENAI] No functions provided.[39m
[1692667181750] [33m[OPENAI] Creating embedding...[39m
[1692667181834] --- Observations received -- 
[1692667181834] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Stone Ore Deposit (Medium) at X: 42.53862, Y: 17.00157.",
  "time": 32.7208138
}
[1692667181834] [Character] Getting character: A1
[1692667181853] {
  "id": "chatcmpl-7olaBvqT73Ne4ufjEwv7PbawlaoWS",
  "object": "chat.completion",
  "created": 1692333663,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1692667181853] [36m[OPENAI] Chat completion took 197.37875002622604ms[39m
[1692667181853] [36m[OPENAI] Tokens per second: 5.066401524313678tps[39m
[1692667181853] [32m[OPENAI] Chat completion created successfully.[39m
[1692667181896] [32m[OPENAI] Embedding created successfully.[39m
[1692667181927] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667181927] [33m[OPENAI] No functions provided.[39m
[1692667181927] [33m[OPENAI] Creating embedding...[39m
[1692667181935] --- Observations received -- 
[1692667181935] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (484) at X: 50.77, Y: 9.22",
  "time": 32.8202362
}
[1692667181935] [Character] Getting character: A1
[1692667181983] {
  "id": "chatcmpl-7olaB86EhZpWqRFg29vv0FJEsFotz",
  "object": "chat.completion",
  "created": 1692333663,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1692667181983] [36m[OPENAI] Chat completion took 233.19512498378754ms[39m
[1692667181983] [36m[OPENAI] Tokens per second: 4.288254310931771tps[39m
[1692667181983] [32m[OPENAI] Chat completion created successfully.[39m
[1692667182006] [32m[OPENAI] Embedding created successfully.[39m
[1692667182115] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667182115] [33m[OPENAI] No functions provided.[39m
[1692667182116] [33m[OPENAI] Creating embedding...[39m
[1692667182128] {
  "id": "chatcmpl-7qALRTrf56mqHe2nJafiIm1J9owWK",
  "object": "chat.completion",
  "created": 1692667177,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A1\",\n  \"x\": 2,\n  \"y\": -58\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1602,
    "completion_tokens": 31,
    "total_tokens": 1633
  }
}
[1692667182128] [36m[OPENAI] Chat completion took 4555.7333329916ms[39m
[1692667182128] [36m[OPENAI] Tokens per second: 6.804612503437141tps[39m
[1692667182128] [32m[OPENAI] Chat completion created successfully.[39m
[1692667182132] {
  "id": "chatcmpl-7olaCbtjSRJ1TDumOWJIE3eBWZoOp",
  "object": "chat.completion",
  "created": 1692333664,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1692667182132] [36m[OPENAI] Chat completion took 204.82316699624062ms[39m
[1692667182132] [36m[OPENAI] Tokens per second: 4.882260218241593tps[39m
[1692667182132] [32m[OPENAI] Chat completion created successfully.[39m
[1692667182132] [32m[OPENAI] Embedding created successfully.[39m
[1692667182264] {
  "id": "chatcmpl-7olZ0MzGvSytQom91j2vFoVNL1rQU",
  "object": "chat.completion",
  "created": 1692333590,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1692667182264] [36m[OPENAI] Chat completion took 148.72316700220108ms[39m
[1692667182265] [36m[OPENAI] Tokens per second: 6.723901999647439tps[39m
[1692667182265] [32m[OPENAI] Chat completion created successfully.[39m
[1692667182351] --- Observations received -- 
[1692667182351] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Chest (1) at X: 50.52, Y: 14.5",
  "time": 33.22092
}
[1692667182351] [Character] Getting character: A1
[1692667182353] [32m[OPENAI] Embedding created successfully.[39m
[1692667182446] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667182446] [33m[OPENAI] No functions provided.[39m
[1692667182446] [33m[OPENAI] Creating embedding...[39m
[1692667182640] {
  "id": "chatcmpl-7olZqYlYJ7XABAbbSnDbyWuhoI6f3",
  "object": "chat.completion",
  "created": 1692333642,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1692667182640] [36m[OPENAI] Chat completion took 193.9895830154419ms[39m
[1692667182640] [36m[OPENAI] Tokens per second: 5.154915972577756tps[39m
[1692667182640] [32m[OPENAI] Chat completion created successfully.[39m
[1692667182641] [32m[OPENAI] Embedding created successfully.[39m
[1692667182872] --- Observations received -- 
[1692667182873] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees StoneOreMedium (1) at X: 46.05, Y: 17.85",
  "time": 33.76089
}
[1692667182873] [Character] Getting character: A1
[1692667182994] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667182994] [33m[OPENAI] No functions provided.[39m
[1692667182994] [33m[OPENAI] Creating embedding...[39m
[1692667183073] --- Observations received -- 
[1692667183073] {
  "observerId": "A5",
  "observation": "Eli Green sees Thomas Smith at X: 43.99609, Y: 12.25.",
  "time": 33.9604225
}
[1692667183073] [Character] Getting character: A5
[1692667183158] {
  "id": "chatcmpl-7olZFxI4uk8V230Sf6vE5gxpsZif7",
  "object": "chat.completion",
  "created": 1692333605,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1692667183158] [36m[OPENAI] Chat completion took 163.34650000929832ms[39m
[1692667183158] [36m[OPENAI] Tokens per second: 6.1219554746693445tps[39m
[1692667183158] [32m[OPENAI] Chat completion created successfully.[39m
[1692667183199] [32m[OPENAI] Embedding created successfully.[39m
[1692667183233] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667183233] [33m[OPENAI] No functions provided.[39m
[1692667183233] [33m[OPENAI] Creating embedding...[39m
[1692667183321] --- Observations received -- 
[1692667183323] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Eli Green at X: 39.08, Y: 10.",
  "time": 34.20056
}
[1692667183323] [Character] Getting character: A1
[1692667183364] [32m[OPENAI] Embedding created successfully.[39m
[1692667183406] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667183406] [33m[OPENAI] No functions provided.[39m
[1692667183406] [33m[OPENAI] Creating embedding...[39m
[1692667183450] {
  "id": "chatcmpl-7qALXgKtdgNz3IL2sKGs2BxBCS9zx",
  "object": "chat.completion",
  "created": 1692667183,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 2,
    "total_tokens": 105
  }
}
[1692667183450] [36m[OPENAI] Chat completion took 216.44470900297165ms[39m
[1692667183450] [36m[OPENAI] Tokens per second: 9.240235112296237tps[39m
[1692667183450] [32m[OPENAI] Chat completion created successfully.[39m
[1692667183688] {
  "id": "chatcmpl-7qALXEakCFSbGCAakxxU8jTnt99hT",
  "object": "chat.completion",
  "created": 1692667183,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1692667183688] [36m[OPENAI] Chat completion took 281.96616700291634ms[39m
[1692667183688] [36m[OPENAI] Tokens per second: 3.546524785683444tps[39m
[1692667183688] [32m[OPENAI] Chat completion created successfully.[39m
[1692667183689] [32m[OPENAI] Embedding created successfully.[39m
[1692667184253] --- Observations received -- 
[1692667184253] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees StoneOreMedium at X: 42.53862, Y: 17.00157",
  "time": 35.1412659
}
[1692667184253] [Character] Getting character: A1
[1692667184342] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667184342] [33m[OPENAI] No functions provided.[39m
[1692667184342] [33m[OPENAI] Creating embedding...[39m
[1692667184452] --- Observations received -- 
[1692667184452] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (481) at X: 47.72001, Y: 10.21",
  "time": 35.34064
}
[1692667184453] [Character] Getting character: A1
[1692667184486] {
  "id": "chatcmpl-7olaEdwZoQoTwDOPDf7oxnCVg2s3k",
  "object": "chat.completion",
  "created": 1692333666,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 107,
    "completion_tokens": 1,
    "total_tokens": 108
  }
}
[1692667184486] [36m[OPENAI] Chat completion took 143.65404200553894ms[39m
[1692667184486] [36m[OPENAI] Tokens per second: 6.961168554947048tps[39m
[1692667184486] [32m[OPENAI] Chat completion created successfully.[39m
[1692667184539] [32m[OPENAI] Embedding created successfully.[39m
[1692667184541] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667184541] [33m[OPENAI] No functions provided.[39m
[1692667184541] [33m[OPENAI] Creating embedding...[39m
[1692667184592] --- Observations received -- 
[1692667184592] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees StoneOreSmall (4) at X: 45.73, Y: 15.31",
  "time": 35.48007
}
[1692667184592] [Character] Getting character: A1
[1692667184614] --- Observations received -- 
[1692667184614] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 42.12, Y: 5.77.",
  "time": 35.50022
}
[1692667184614] [Character] Getting character: A1
[1692667184737] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667184737] [33m[OPENAI] No functions provided.[39m
[1692667184737] [33m[OPENAI] Creating embedding...[39m
[1692667184741] {
  "id": "chatcmpl-7olZ1yP4bsQojjuSfETP7pN2Nge08",
  "object": "chat.completion",
  "created": 1692333591,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1692667184741] [36m[OPENAI] Chat completion took 199.41637498140335ms[39m
[1692667184741] [36m[OPENAI] Tokens per second: 5.014633327344634tps[39m
[1692667184741] [32m[OPENAI] Chat completion created successfully.[39m
[1692667184771] [32m[OPENAI] Embedding created successfully.[39m
[1692667184785] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667184785] [33m[OPENAI] No functions provided.[39m
[1692667184786] [33m[OPENAI] Creating embedding...[39m
[1692667184917] {
  "id": "chatcmpl-7olZFfCJV4xzX0bc3BWKu9HvdsjlD",
  "object": "chat.completion",
  "created": 1692333605,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1692667184917] [36m[OPENAI] Chat completion took 179.41237500309944ms[39m
[1692667184917] [36m[OPENAI] Tokens per second: 5.573751531814483tps[39m
[1692667184917] [32m[OPENAI] Chat completion created successfully.[39m
[1692667184929] [32m[OPENAI] Embedding created successfully.[39m
[1692667184969] {
  "id": "chatcmpl-7olaEDg0YhYdcndjGAaNNVX6T6rg9",
  "object": "chat.completion",
  "created": 1692333666,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667184969] [36m[OPENAI] Chat completion took 183.29941701889038ms[39m
[1692667184969] [36m[OPENAI] Tokens per second: 5.455554721687644tps[39m
[1692667184969] [32m[OPENAI] Chat completion created successfully.[39m
[1692667185048] [32m[OPENAI] Embedding created successfully.[39m
[1692667186433] --- Observations received -- 
[1692667186433] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (479) at X: 45.24001, Y: 10.2",
  "time": 37.3207359
}
[1692667186433] [Character] Getting character: A1
[1692667186533] --- Observations received -- 
[1692667186533] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees StoneOreSmall (3) at X: 41.33658, Y: 13.99647",
  "time": 37.4206734
}
[1692667186534] [Character] Getting character: A1
[1692667186536] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667186536] [33m[OPENAI] No functions provided.[39m
[1692667186536] [33m[OPENAI] Creating embedding...[39m
[1692667186625] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667186625] [33m[OPENAI] No functions provided.[39m
[1692667186625] [33m[OPENAI] Creating embedding...[39m
[1692667186684] {
  "id": "chatcmpl-7olaKrfvWqUsCOsI8esX0VNRg9j9R",
  "object": "chat.completion",
  "created": 1692333672,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1692667186684] [36m[OPENAI] Chat completion took 147.639250010252ms[39m
[1692667186684] [36m[OPENAI] Tokens per second: 6.7732665936094945tps[39m
[1692667186684] [32m[OPENAI] Chat completion created successfully.[39m
[1692667186712] [32m[OPENAI] Embedding created successfully.[39m
[1692667186834] {
  "id": "chatcmpl-7olaG4cXpdsQir5A7aevxeSRMc8dc",
  "object": "chat.completion",
  "created": 1692333668,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 110,
    "completion_tokens": 1,
    "total_tokens": 111
  }
}
[1692667186834] [36m[OPENAI] Chat completion took 207.77650001645088ms[39m
[1692667186834] [36m[OPENAI] Tokens per second: 4.812863822043514tps[39m
[1692667186834] [32m[OPENAI] Chat completion created successfully.[39m
[1692667186900] [32m[OPENAI] Embedding created successfully.[39m
[1692667187553] --- Observations received -- 
[1692667187553] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree Stump at X: 34.56, Y: 3.07.",
  "time": 38.4411545
}
[1692667187553] [Character] Getting character: A1
[1692667187651] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667187651] [33m[OPENAI] No functions provided.[39m
[1692667187652] [33m[OPENAI] Creating embedding...[39m
[1692667187812] --- Observations received -- 
[1692667187813] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 33.51, Y: 4.43.",
  "time": 38.700737
}
[1692667187813] [Character] Getting character: A1
[1692667187842] [32m[OPENAI] Embedding created successfully.[39m
[1692667187884] {
  "id": "chatcmpl-7qALbT5nZnjoYi8gaajFyyyoiUk7T",
  "object": "chat.completion",
  "created": 1692667187,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1692667187884] [36m[OPENAI] Chat completion took 232.88683301210403ms[39m
[1692667187884] [36m[OPENAI] Tokens per second: 4.29393103537127tps[39m
[1692667187884] [32m[OPENAI] Chat completion created successfully.[39m
[1692667187901] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667187901] [33m[OPENAI] No functions provided.[39m
[1692667187901] [33m[OPENAI] Creating embedding...[39m
[1692667188074] --- Observations received -- 
[1692667188074] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 42.32, Y: 1.859999.",
  "time": 38.961338
}
[1692667188074] [Character] Getting character: A1
[1692667188105] {
  "id": "chatcmpl-7qALbuEcyuJ0zCR3nKBaKTcxdat6R",
  "object": "chat.completion",
  "created": 1692667187,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667188105] [36m[OPENAI] Chat completion took 204.09645900130272ms[39m
[1692667188105] [36m[OPENAI] Tokens per second: 4.899644045238517tps[39m
[1692667188105] [32m[OPENAI] Chat completion created successfully.[39m
[1692667188161] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667188161] [33m[OPENAI] No functions provided.[39m
[1692667188161] [33m[OPENAI] Creating embedding...[39m
[1692667188210] [32m[OPENAI] Embedding created successfully.[39m
[1692667188376] [32m[OPENAI] Embedding created successfully.[39m
[1692667188384] {
  "id": "chatcmpl-7qALcBG1Z62FaeGoU8Fh5WE6Lxmhv",
  "object": "chat.completion",
  "created": 1692667188,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1692667188384] [36m[OPENAI] Chat completion took 223.06016701459885ms[39m
[1692667188384] [36m[OPENAI] Tokens per second: 4.483095361147793tps[39m
[1692667188385] [32m[OPENAI] Chat completion created successfully.[39m
[1692667188474] --- Observations received -- 
[1692667188474] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees Human at X: 38.75007, Y: 5.336733",
  "time": 39.3604546
}
[1692667188474] [Character] Getting character: A5
[1692667188550] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667188550] [33m[OPENAI] No functions provided.[39m
[1692667188550] [33m[OPENAI] Creating embedding...[39m
[1692667188713] --- Observations received -- 
[1692667188714] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 34.32, Y: 1.549999.",
  "time": 39.60051
}
[1692667188714] [Character] Getting character: A1
[1692667188719] [32m[OPENAI] Embedding created successfully.[39m
[1692667188799] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667188799] [33m[OPENAI] No functions provided.[39m
[1692667188799] [33m[OPENAI] Creating embedding...[39m
[1692667188807] {
  "id": "chatcmpl-7qALc4VCIKjdeAjbzNKYgsxps1Jow",
  "object": "chat.completion",
  "created": 1692667188,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1692667188810] [36m[OPENAI] Chat completion took 256.9735830128193ms[39m
[1692667188810] [36m[OPENAI] Tokens per second: 3.891450585214879tps[39m
[1692667188810] [32m[OPENAI] Chat completion created successfully.[39m
[1692667188933] --- Observations received -- 
[1692667188933] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Human (4) at X: 39.08, Y: 10",
  "time": 39.8203926
}
[1692667188933] [Character] Getting character: A1
[1692667189010] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667189010] [33m[OPENAI] No functions provided.[39m
[1692667189010] [33m[OPENAI] Creating embedding...[39m
[1692667189015] {
  "id": "chatcmpl-7qALcydYfM1J9LWCXJdv7HVmNAhP8",
  "object": "chat.completion",
  "created": 1692667188,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1692667189015] [36m[OPENAI] Chat completion took 215.0303750038147ms[39m
[1692667189015] [36m[OPENAI] Tokens per second: 4.650505771485818tps[39m
[1692667189015] [32m[OPENAI] Chat completion created successfully.[39m
[1692667189045] [32m[OPENAI] Embedding created successfully.[39m
[1692667189216] --- Observations received -- 
[1692667189216] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 42, Y: -0.3199997.",
  "time": 40.1000328
}
[1692667189216] [Character] Getting character: A1
[1692667189218] [32m[OPENAI] Embedding created successfully.[39m
[1692667189304] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667189304] [33m[OPENAI] No functions provided.[39m
[1692667189305] [33m[OPENAI] Creating embedding...[39m
[1692667189456] {
  "id": "chatcmpl-7qALdhx0nytoEqlGjFAZgLuuFVL0G",
  "object": "chat.completion",
  "created": 1692667189,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1692667189456] [36m[OPENAI] Chat completion took 445.4637080132961ms[39m
[1692667189456] [36m[OPENAI] Tokens per second: 2.24485178480612tps[39m
[1692667189456] [32m[OPENAI] Chat completion created successfully.[39m
[1692667189470] [32m[OPENAI] Embedding created successfully.[39m
[1692667189509] {
  "id": "chatcmpl-7qALdSzCplpTch6bYdzYwEcLrl8xc",
  "object": "chat.completion",
  "created": 1692667189,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667189509] [36m[OPENAI] Chat completion took 204.28566700220108ms[39m
[1692667189509] [36m[OPENAI] Tokens per second: 4.895106028115157tps[39m
[1692667189509] [32m[OPENAI] Chat completion created successfully.[39m
[1692667190552] --- Observations received -- 
[1692667190552] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (209) at X: 33.51, Y: 4.43",
  "time": 41.4403725
}
[1692667190553] [Character] Getting character: A1
[1692667190642] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667190643] [33m[OPENAI] No functions provided.[39m
[1692667190643] [33m[OPENAI] Creating embedding...[39m
[1692667190809] [32m[OPENAI] Embedding created successfully.[39m
[1692667191072] {
  "id": "chatcmpl-7qALe09Ul3L6Hv7MN9Bcz6dS3DzQP",
  "object": "chat.completion",
  "created": 1692667190,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1692667191072] [36m[OPENAI] Chat completion took 429.0692919790745ms[39m
[1692667191072] [36m[OPENAI] Tokens per second: 2.3306258888570603tps[39m
[1692667191072] [32m[OPENAI] Chat completion created successfully.[39m
[1692667191076] --- Observations received -- 
[1692667191076] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (205) at X: 42.12, Y: 5.77",
  "time": 41.96085
}
[1692667191076] [Character] Getting character: A1
[1692667191156] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667191157] [33m[OPENAI] No functions provided.[39m
[1692667191157] [33m[OPENAI] Creating embedding...[39m
[1692667191333] {
  "id": "chatcmpl-7olaJllV94ozWJ3YROGLbxDT8mxaf",
  "object": "chat.completion",
  "created": 1692333671,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1692667191333] [36m[OPENAI] Chat completion took 175.51891601085663ms[39m
[1692667191333] [36m[OPENAI] Tokens per second: 5.697391612982305tps[39m
[1692667191333] [32m[OPENAI] Chat completion created successfully.[39m
[1692667191393] [32m[OPENAI] Embedding created successfully.[39m
[1692667191612] --- Observations received -- 
[1692667191612] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 33.75, Y: -2.73.",
  "time": 42.50013
}
[1692667191612] [Character] Getting character: A1
[1692667191694] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667191694] [33m[OPENAI] No functions provided.[39m
[1692667191694] [33m[OPENAI] Creating embedding...[39m
[1692667191907] [32m[OPENAI] Embedding created successfully.[39m
[1692667191994] --- Observations received -- 
[1692667191994] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Stump (20) at X: 34.56, Y: 3.07",
  "time": 42.8812065
}
[1692667191994] [Character] Getting character: A1
[1692667192078] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667192078] [33m[OPENAI] No functions provided.[39m
[1692667192078] [33m[OPENAI] Creating embedding...[39m
[1692667192177] {
  "id": "chatcmpl-7qALfHk0oB0dRkBGT12ugIBVuVIQx",
  "object": "chat.completion",
  "created": 1692667191,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667192178] [36m[OPENAI] Chat completion took 483.43062499165535ms[39m
[1692667192178] [36m[OPENAI] Tokens per second: 2.0685491326025556tps[39m
[1692667192178] [32m[OPENAI] Chat completion created successfully.[39m
[1692667192298] {
  "id": "chatcmpl-7qALgJdqE2LwkkpgBBk68ZD2Tf9OM",
  "object": "chat.completion",
  "created": 1692667192,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1692667192299] [36m[OPENAI] Chat completion took 220.0659999847412ms[39m
[1692667192299] [36m[OPENAI] Tokens per second: 4.544091318374202tps[39m
[1692667192299] [32m[OPENAI] Chat completion created successfully.[39m
[1692667192438] [32m[OPENAI] Embedding created successfully.[39m
[1692667192933] --- Observations received -- 
[1692667192933] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (208) at X: 34.32, Y: 1.549999",
  "time": 43.82
}
[1692667192933] [Character] Getting character: A1
[1692667193018] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667193018] [33m[OPENAI] No functions provided.[39m
[1692667193018] [33m[OPENAI] Creating embedding...[39m
[1692667193185] [32m[OPENAI] Embedding created successfully.[39m
[1692667193232] --- Observations received -- 
[1692667193239] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (214) at X: 42.32, Y: 1.859999",
  "time": 44.12021
}
[1692667193239] [Character] Getting character: A1
[1692667193253] --- Observations received -- 
[1692667193253] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 33.43, Y: -4.91.",
  "time": 44.1410637
}
[1692667193253] [Character] Getting character: A1
[1692667193272] {
  "id": "chatcmpl-7qALhfqIgCaGMSEqv7MHyvnYcODf4",
  "object": "chat.completion",
  "created": 1692667193,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1692667193272] [36m[OPENAI] Chat completion took 254.26508298516273ms[39m
[1692667193272] [36m[OPENAI] Tokens per second: 3.932903363134424tps[39m
[1692667193272] [32m[OPENAI] Chat completion created successfully.[39m
[1692667193320] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667193320] [33m[OPENAI] No functions provided.[39m
[1692667193320] [33m[OPENAI] Creating embedding...[39m
[1692667193339] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667193339] [33m[OPENAI] No functions provided.[39m
[1692667193339] [33m[OPENAI] Creating embedding...[39m
[1692667193453] --- Observations received -- 
[1692667193455] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 36.24, Y: -8.09.",
  "time": 44.3406754
}
[1692667193455] [Character] Getting character: A1
[1692667193553] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667193553] [33m[OPENAI] No functions provided.[39m
[1692667193553] [33m[OPENAI] Creating embedding...[39m
[1692667193555] {
  "id": "chatcmpl-7qALhPd6qh3YgaZsCEoRxLwg2uaZg",
  "object": "chat.completion",
  "created": 1692667193,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1692667193555] [36m[OPENAI] Chat completion took 234.6482079923153ms[39m
[1692667193555] [36m[OPENAI] Tokens per second: 4.2616988578610835tps[39m
[1692667193555] [32m[OPENAI] Chat completion created successfully.[39m
[1692667193555] {
  "id": "chatcmpl-7qALhkyVERLRnhozla878zKNh6TMD",
  "object": "chat.completion",
  "created": 1692667193,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667193555] [36m[OPENAI] Chat completion took 215.7664999961853ms[39m
[1692667193555] [36m[OPENAI] Tokens per second: 4.634639761119913tps[39m
[1692667193555] [32m[OPENAI] Chat completion created successfully.[39m
[1692667193583] [32m[OPENAI] Embedding created successfully.[39m
[1692667193586] [32m[OPENAI] Embedding created successfully.[39m
[1692667193755] [32m[OPENAI] Embedding created successfully.[39m
[1692667193773] --- Observations received -- 
[1692667193773] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 38.75, Y: -9.01.",
  "time": 44.66103
}
[1692667193773] [Character] Getting character: A1
[1692667193782] {
  "id": "chatcmpl-7qALhvHrPwEu1mebwKVVnxXNrKlUu",
  "object": "chat.completion",
  "created": 1692667193,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667193782] [36m[OPENAI] Chat completion took 228.31733298301697ms[39m
[1692667193782] [36m[OPENAI] Tokens per second: 4.379868961041094tps[39m
[1692667193782] [32m[OPENAI] Chat completion created successfully.[39m
[1692667193792] --- Observations received -- 
[1692667193792] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 33.78, Y: -6.57.",
  "time": 44.68013
}
[1692667193792] [Character] Getting character: A1
[1692667193873] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667193873] [33m[OPENAI] No functions provided.[39m
[1692667193874] [33m[OPENAI] Creating embedding...[39m
[1692667194047] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667194048] [33m[OPENAI] No functions provided.[39m
[1692667194048] [33m[OPENAI] Creating embedding...[39m
[1692667194096] {
  "id": "chatcmpl-7qALhylBA4uo1yY9aeuPCGPe2W7o6",
  "object": "chat.completion",
  "created": 1692667193,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667194096] [36m[OPENAI] Chat completion took 222.38549998402596ms[39m
[1692667194096] [36m[OPENAI] Tokens per second: 4.49669605289837tps[39m
[1692667194096] [32m[OPENAI] Chat completion created successfully.[39m
[1692667194096] [32m[OPENAI] Embedding created successfully.[39m
[1692667194296] {
  "id": "chatcmpl-7qALiKvh61GGMdCtxdN5maA8ShbZk",
  "object": "chat.completion",
  "created": 1692667194,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667194296] [36m[OPENAI] Chat completion took 248.44224998354912ms[39m
[1692667194296] [36m[OPENAI] Tokens per second: 4.025080275461264tps[39m
[1692667194296] [32m[OPENAI] Chat completion created successfully.[39m
[1692667194344] [32m[OPENAI] Embedding created successfully.[39m
[1692667194492] --- Observations received -- 
[1692667194492] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (218) at X: 33.43, Y: -4.91",
  "time": 45.38009
}
[1692667194492] [Character] Getting character: A1
[1692667194516] --- Observations received -- 
[1692667194516] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (220) at X: 33.75, Y: -2.73",
  "time": 45.4009743
}
[1692667194516] [Character] Getting character: A1
[1692667194581] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667194581] [33m[OPENAI] No functions provided.[39m
[1692667194582] [33m[OPENAI] Creating embedding...[39m
[1692667194604] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667194604] [33m[OPENAI] No functions provided.[39m
[1692667194604] [33m[OPENAI] Creating embedding...[39m
[1692667194653] --- Observations received -- 
[1692667194653] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (193) at X: 33.78, Y: -6.57",
  "time": 45.54088
}
[1692667194653] [Character] Getting character: A1
[1692667194743] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667194744] [33m[OPENAI] No functions provided.[39m
[1692667194744] [33m[OPENAI] Creating embedding...[39m
[1692667194767] [32m[OPENAI] Embedding created successfully.[39m
[1692667194790] [32m[OPENAI] Embedding created successfully.[39m
[1692667194809] {
  "id": "chatcmpl-7qALivV4SCM796ra83DzaJFzxUgf9",
  "object": "chat.completion",
  "created": 1692667194,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1692667194809] [36m[OPENAI] Chat completion took 227.87691700458527ms[39m
[1692667194810] [36m[OPENAI] Tokens per second: 4.388333900356737tps[39m
[1692667194810] [32m[OPENAI] Chat completion created successfully.[39m
[1692667194832] {
  "id": "chatcmpl-7qAListz6rU5UjVPEybrYEk8FtVvY",
  "object": "chat.completion",
  "created": 1692667194,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1692667194832] [36m[OPENAI] Chat completion took 227.59620797634125ms[39m
[1692667194832] [36m[OPENAI] Tokens per second: 4.393746314542949tps[39m
[1692667194832] [32m[OPENAI] Chat completion created successfully.[39m
[1692667195004] {
  "id": "chatcmpl-7qALiDSKcwRxj2mbBTg5CHt0EqAAH",
  "object": "chat.completion",
  "created": 1692667194,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1692667195004] [36m[OPENAI] Chat completion took 260.2569580078125ms[39m
[1692667195004] [36m[OPENAI] Tokens per second: 3.8423564451636354tps[39m
[1692667195004] [32m[OPENAI] Chat completion created successfully.[39m
[1692667195005] [32m[OPENAI] Embedding created successfully.[39m
[1692667195093] --- Observations received -- 
[1692667195093] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (213) at X: 42, Y: -0.3199997",
  "time": 45.9814072
}
[1692667195093] [Character] Getting character: A1
[1692667195173] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667195173] [33m[OPENAI] No functions provided.[39m
[1692667195173] [33m[OPENAI] Creating embedding...[39m
[1692667195302] [32m[OPENAI] Embedding created successfully.[39m
[1692667195604] {
  "id": "chatcmpl-7qALjt5qujHGHtLJ9jexNjGqObAD0",
  "object": "chat.completion",
  "created": 1692667195,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1692667195604] [36m[OPENAI] Chat completion took 430.6980420053005ms[39m
[1692667195604] [36m[OPENAI] Tokens per second: 2.321812273267063tps[39m
[1692667195604] [32m[OPENAI] Chat completion created successfully.[39m
[1692667195734] --- Observations received -- 
[1692667195734] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 41.03, Y: -11.7.",
  "time": 46.6221237
}
[1692667195734] [Character] Getting character: A1
[1692667195811] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667195811] [33m[OPENAI] No functions provided.[39m
[1692667195811] [33m[OPENAI] Creating embedding...[39m
[1692667195872] --- Observations received -- 
[1692667195873] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 38.63, Y: -11.64.",
  "time": 46.7606277
}
[1692667195873] [Character] Getting character: A1
[1692667195947] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667195947] [33m[OPENAI] No functions provided.[39m
[1692667195947] [33m[OPENAI] Creating embedding...[39m
[1692667195991] [32m[OPENAI] Embedding created successfully.[39m
[1692667196064] [32m[OPENAI] Embedding created successfully.[39m
[1692667196092] {
  "id": "chatcmpl-7qALjZfTKhrJDnrdV7hxh1rNm7isG",
  "object": "chat.completion",
  "created": 1692667195,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667196092] [36m[OPENAI] Chat completion took 281.2380000054836ms[39m
[1692667196092] [36m[OPENAI] Tokens per second: 3.5557072656628974tps[39m
[1692667196092] [32m[OPENAI] Chat completion created successfully.[39m
[1692667196180] {
  "id": "chatcmpl-7qALkodi4MGtWhm6EoPeEA2KTSkcr",
  "object": "chat.completion",
  "created": 1692667196,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667196180] [36m[OPENAI] Chat completion took 233.17737498879433ms[39m
[1692667196180] [36m[OPENAI] Tokens per second: 4.288580742655913tps[39m
[1692667196180] [32m[OPENAI] Chat completion created successfully.[39m
[1692667196752] --- Observations received -- 
[1692667196752] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 42.72, Y: -12.97.",
  "time": 47.64
}
[1692667196752] [Character] Getting character: A1
[1692667196775] --- Observations received -- 
[1692667196776] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (198) at X: 36.24, Y: -8.09",
  "time": 47.6606026
}
[1692667196776] [Character] Getting character: A1
[1692667196841] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667196841] [33m[OPENAI] No functions provided.[39m
[1692667196841] [33m[OPENAI] Creating embedding...[39m
[1692667196853] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667196853] [33m[OPENAI] No functions provided.[39m
[1692667196853] [33m[OPENAI] Creating embedding...[39m
[1692667197051] [32m[OPENAI] Embedding created successfully.[39m
[1692667197071] {
  "id": "chatcmpl-7qALkPfBhZOBPQC7NjwXSmirNp3mM",
  "object": "chat.completion",
  "created": 1692667196,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1692667197071] [36m[OPENAI] Chat completion took 217.94104200601578ms[39m
[1692667197071] [36m[OPENAI] Tokens per second: 4.58839689301108tps[39m
[1692667197071] [32m[OPENAI] Chat completion created successfully.[39m
[1692667197079] {
  "id": "chatcmpl-7qALkyskgGi1amB45IFZ4jupuubyA",
  "object": "chat.completion",
  "created": 1692667196,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667197079] [36m[OPENAI] Chat completion took 237.20670899748802ms[39m
[1692667197079] [36m[OPENAI] Tokens per second: 4.215732363668474tps[39m
[1692667197079] [32m[OPENAI] Chat completion created successfully.[39m
[1692667197314] [32m[OPENAI] Embedding created successfully.[39m
[1692667197674] --- Observations received -- 
[1692667197674] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 44.48, Y: -14.04.",
  "time": 48.5607452
}
[1692667197674] [Character] Getting character: A1
[1692667197751] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667197751] [33m[OPENAI] No functions provided.[39m
[1692667197751] [33m[OPENAI] Creating embedding...[39m
[1692667197912] --- Observations received -- 
[1692667197913] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 48.84, Y: -7.200001.",
  "time": 48.80011
}
[1692667197913] [Character] Getting character: A1
[1692667197953] {
  "id": "chatcmpl-7qALlbfRJxLbtl3E8AP6UHPJXGq0j",
  "object": "chat.completion",
  "created": 1692667197,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667197953] [36m[OPENAI] Chat completion took 202.52674999833107ms[39m
[1692667197953] [36m[OPENAI] Tokens per second: 4.937619351558451tps[39m
[1692667197953] [32m[OPENAI] Chat completion created successfully.[39m
[1692667197989] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667197989] [33m[OPENAI] No functions provided.[39m
[1692667197989] [33m[OPENAI] Creating embedding...[39m
[1692667198031] [32m[OPENAI] Embedding created successfully.[39m
[1692667198133] --- Observations received -- 
[1692667198134] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 40.96, Y: -14.27.",
  "time": 49.0207977
}
[1692667198134] [Character] Getting character: A1
[1692667198212] [32m[OPENAI] Embedding created successfully.[39m
[1692667198219] {
  "id": "chatcmpl-7qALmrsQJ4MWusvgrxKsM2wh7nVMY",
  "object": "chat.completion",
  "created": 1692667198,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1692667198219] [36m[OPENAI] Chat completion took 230.38525000214577ms[39m
[1692667198219] [36m[OPENAI] Tokens per second: 4.340555656191905tps[39m
[1692667198219] [32m[OPENAI] Chat completion created successfully.[39m
[1692667198271] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667198271] [33m[OPENAI] No functions provided.[39m
[1692667198281] [33m[OPENAI] Creating embedding...[39m
[1692667198292] --- Observations received -- 
[1692667198292] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 49.51, Y: -10.13.",
  "time": 49.18036
}
[1692667198292] [Character] Getting character: A1
[1692667198389] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667198390] [33m[OPENAI] No functions provided.[39m
[1692667198390] [33m[OPENAI] Creating embedding...[39m
[1692667198469] [32m[OPENAI] Embedding created successfully.[39m
[1692667198475] {
  "id": "chatcmpl-7qALmJsLHHQs7887PAzANjrKkTzbl",
  "object": "chat.completion",
  "created": 1692667198,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667198475] [36m[OPENAI] Chat completion took 203.8331670165062ms[39m
[1692667198475] [36m[OPENAI] Tokens per second: 4.905972931868448tps[39m
[1692667198475] [32m[OPENAI] Chat completion created successfully.[39m
[1692667198513] --- Observations received -- 
[1692667198513] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (94) at X: 38.63, Y: -11.64",
  "time": 49.401062
}
[1692667198513] [Character] Getting character: A1
[1692667198603] [32m[OPENAI] Embedding created successfully.[39m
[1692667198605] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667198606] [33m[OPENAI] No functions provided.[39m
[1692667198606] [33m[OPENAI] Creating embedding...[39m
[1692667198772] --- Observations received -- 
[1692667198772] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (285) at X: 38.75, Y: -9.01",
  "time": 49.6599922
}
[1692667198772] [Character] Getting character: A1
[1692667198777] [32m[OPENAI] Embedding created successfully.[39m
[1692667198852] {
  "id": "chatcmpl-7qALmxSYongRqdVgVlEHOTw81stF9",
  "object": "chat.completion",
  "created": 1692667198,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667198853] [36m[OPENAI] Chat completion took 462.60008400678635ms[39m
[1692667198853] [36m[OPENAI] Tokens per second: 2.16169437614138tps[39m
[1692667198853] [32m[OPENAI] Chat completion created successfully.[39m
[1692667198863] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667198863] [33m[OPENAI] No functions provided.[39m
[1692667198863] [33m[OPENAI] Creating embedding...[39m
[1692667198893] {
  "id": "chatcmpl-7qALmGnSKjN6Szln4d9Ov92QXjja0",
  "object": "chat.completion",
  "created": 1692667198,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1692667198893] [36m[OPENAI] Chat completion took 287.84545800089836ms[39m
[1692667198893] [36m[OPENAI] Tokens per second: 3.4740864314658704tps[39m
[1692667198893] [32m[OPENAI] Chat completion created successfully.[39m
[1692667199025] [32m[OPENAI] Embedding created successfully.[39m
[1692667199113] {
  "id": "chatcmpl-7qALmZmggLeuPb8AMabL6wj4v01Xb",
  "object": "chat.completion",
  "created": 1692667198,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1692667199113] [36m[OPENAI] Chat completion took 249.5806249976158ms[39m
[1692667199113] [36m[OPENAI] Tokens per second: 4.006721274976985tps[39m
[1692667199113] [32m[OPENAI] Chat completion created successfully.[39m
[1692667199153] --- Observations received -- 
[1692667199153] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 45.66, Y: -15.94.",
  "time": 50.0414734
}
[1692667199153] [Character] Getting character: A1
[1692667199242] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667199242] [33m[OPENAI] No functions provided.[39m
[1692667199243] [33m[OPENAI] Creating embedding...[39m
[1692667199458] [32m[OPENAI] Embedding created successfully.[39m
[1692667199473] --- Observations received -- 
[1692667199473] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 47.86, Y: -15.94.",
  "time": 50.36093
}
[1692667199473] [Character] Getting character: A1
[1692667199556] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667199556] [33m[OPENAI] No functions provided.[39m
[1692667199556] [33m[OPENAI] Creating embedding...[39m
[1692667199708] {
  "id": "chatcmpl-7qALnNTkYhxsf3BBzo0q0fLiyReMI",
  "object": "chat.completion",
  "created": 1692667199,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667199708] [36m[OPENAI] Chat completion took 465.430458009243ms[39m
[1692667199708] [36m[OPENAI] Tokens per second: 2.148548688191225tps[39m
[1692667199708] [32m[OPENAI] Chat completion created successfully.[39m
[1692667199752] --- Observations received -- 
[1692667199753] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 43.22001, Y: -16.37.",
  "time": 50.6405525
}
[1692667199753] [Character] Getting character: A1
[1692667199773] [32m[OPENAI] Embedding created successfully.[39m
[1692667199826] {
  "id": "chatcmpl-7qALnhmoPeQXeVNipG8mumqOs6Bs4",
  "object": "chat.completion",
  "created": 1692667199,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667199826] [36m[OPENAI] Chat completion took 269.318499982357ms[39m
[1692667199826] [36m[OPENAI] Tokens per second: 3.7130757822634157tps[39m
[1692667199826] [32m[OPENAI] Chat completion created successfully.[39m
[1692667199843] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667199843] [33m[OPENAI] No functions provided.[39m
[1692667199843] [33m[OPENAI] Creating embedding...[39m
[1692667200012] --- Observations received -- 
[1692667200012] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 51.52, Y: -10.15.",
  "time": 50.90038
}
[1692667200012] [Character] Getting character: A1
[1692667200029] {
  "id": "chatcmpl-7qALn1Dap4Md2yPQ1ACfmHHyV4sjQ",
  "object": "chat.completion",
  "created": 1692667199,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1692667200029] [36m[OPENAI] Chat completion took 186.16312500834465ms[39m
[1692667200029] [36m[OPENAI] Tokens per second: 5.371633076932801tps[39m
[1692667200029] [32m[OPENAI] Chat completion created successfully.[39m
[1692667200090] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667200090] [33m[OPENAI] No functions provided.[39m
[1692667200090] [33m[OPENAI] Creating embedding...[39m
[1692667200121] [32m[OPENAI] Embedding created successfully.[39m
[1692667200272] --- Observations received -- 
[1692667200272] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (284) at X: 40.96, Y: -14.27",
  "time": 51.1602669
}
[1692667200272] [Character] Getting character: A1
[1692667200278] [32m[OPENAI] Embedding created successfully.[39m
[1692667200332] --- Observations received -- 
[1692667200332] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 52.03, Y: -12.2.",
  "time": 51.2203178
}
[1692667200332] [Character] Getting character: A1
[1692667200334] {
  "id": "chatcmpl-7qALoHBUrE5oaUTKFAWCPS7FMY7Hu",
  "object": "chat.completion",
  "created": 1692667200,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667200334] [36m[OPENAI] Chat completion took 243.87045899033546ms[39m
[1692667200334] [36m[OPENAI] Tokens per second: 4.100537654868767tps[39m
[1692667200334] [32m[OPENAI] Chat completion created successfully.[39m
[1692667200349] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667200349] [33m[OPENAI] No functions provided.[39m
[1692667200349] [33m[OPENAI] Creating embedding...[39m
[1692667200420] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667200420] [33m[OPENAI] No functions provided.[39m
[1692667200420] [33m[OPENAI] Creating embedding...[39m
[1692667200533] {
  "id": "chatcmpl-7qALoVciKb2LkH5pBfCQuLdL0LdOm",
  "object": "chat.completion",
  "created": 1692667200,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1692667200533] [36m[OPENAI] Chat completion took 183.1199579834938ms[39m
[1692667200533] [36m[OPENAI] Tokens per second: 5.460901209305316tps[39m
[1692667200533] [32m[OPENAI] Chat completion created successfully.[39m
[1692667200577] [32m[OPENAI] Embedding created successfully.[39m
[1692667200586] [32m[OPENAI] Embedding created successfully.[39m
[1692667200632] --- Observations received -- 
[1692667200634] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (281) at X: 41.03, Y: -11.7",
  "time": 51.5203972
}
[1692667200634] [Character] Getting character: A1
[1692667200637] {
  "id": "chatcmpl-7qALoin3DFTDE6XvkUI6bzLzUwNDD",
  "object": "chat.completion",
  "created": 1692667200,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667200637] [36m[OPENAI] Chat completion took 217.498625010252ms[39m
[1692667200637] [36m[OPENAI] Tokens per second: 4.597730215319127tps[39m
[1692667200637] [32m[OPENAI] Chat completion created successfully.[39m
[1692667200653] --- Observations received -- 
[1692667200653] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (430) at X: 48.84, Y: -7.200001",
  "time": 51.54137
}
[1692667200653] [Character] Getting character: A1
[1692667200724] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667200724] [33m[OPENAI] No functions provided.[39m
[1692667200724] [33m[OPENAI] Creating embedding...[39m
[1692667200729] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667200729] [33m[OPENAI] No functions provided.[39m
[1692667200729] [33m[OPENAI] Creating embedding...[39m
[1692667200864] [32m[OPENAI] Embedding created successfully.[39m
[1692667200894] [32m[OPENAI] Embedding created successfully.[39m
[1692667200934] --- Observations received -- 
[1692667200934] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 46.7, Y: -18.14.",
  "time": 51.8212357
}
[1692667200934] [Character] Getting character: A1
[1692667200935] {
  "id": "chatcmpl-7qALoPURs1701CSLgqNFFPswCRK4A",
  "object": "chat.completion",
  "created": 1692667200,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1692667200935] [36m[OPENAI] Chat completion took 210.70808300375938ms[39m
[1692667200935] [36m[OPENAI] Tokens per second: 4.745902415059029tps[39m
[1692667200935] [32m[OPENAI] Chat completion created successfully.[39m
[1692667200943] {
  "id": "chatcmpl-7qALosR7gGfP1eHq0uXz2v08mXnsy",
  "object": "chat.completion",
  "created": 1692667200,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1692667200943] [36m[OPENAI] Chat completion took 213.84829199314117ms[39m
[1692667200943] [36m[OPENAI] Tokens per second: 4.676212237561725tps[39m
[1692667200943] [32m[OPENAI] Chat completion created successfully.[39m
[1692667201009] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667201009] [33m[OPENAI] No functions provided.[39m
[1692667201009] [33m[OPENAI] Creating embedding...[39m
[1692667201224] [32m[OPENAI] Embedding created successfully.[39m
[1692667201231] {
  "id": "chatcmpl-7qALpdZjRmljti1EKzzzuXUo2nnox",
  "object": "chat.completion",
  "created": 1692667201,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667201231] [36m[OPENAI] Chat completion took 221.58658301830292ms[39m
[1692667201231] [36m[OPENAI] Tokens per second: 4.512908617384116tps[39m
[1692667201231] [32m[OPENAI] Chat completion created successfully.[39m
[1692667201895] --- Observations received -- 
[1692667201895] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 52.91, Y: -17.4.",
  "time": 52.7807922
}
[1692667201895] [Character] Getting character: A1
[1692667201973] --- Observations received -- 
[1692667201973] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (283) at X: 42.72, Y: -12.97",
  "time": 52.8606873
}
[1692667201973] [Character] Getting character: A1
[1692667201983] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667201983] [33m[OPENAI] No functions provided.[39m
[1692667201984] [33m[OPENAI] Creating embedding...[39m
[1692667202032] --- Observations received -- 
[1692667202032] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 54.01, Y: -15.6.",
  "time": 52.9205856
}
[1692667202032] [Character] Getting character: A1
[1692667202066] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667202067] [33m[OPENAI] No functions provided.[39m
[1692667202067] [33m[OPENAI] Creating embedding...[39m
[1692667202116] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667202116] [33m[OPENAI] No functions provided.[39m
[1692667202116] [33m[OPENAI] Creating embedding...[39m
[1692667202173] --- Observations received -- 
[1692667202176] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (184) at X: 43.22001, Y: -16.37",
  "time": 53.0610733
}
[1692667202176] [Character] Getting character: A1
[1692667202201] {
  "id": "chatcmpl-7qALqSSYHajRjQ4bNjZYes832pX44",
  "object": "chat.completion",
  "created": 1692667202,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667202201] [36m[OPENAI] Chat completion took 217.18245801329613ms[39m
[1692667202201] [36m[OPENAI] Tokens per second: 4.604423438005195tps[39m
[1692667202201] [32m[OPENAI] Chat completion created successfully.[39m
[1692667202202] [32m[OPENAI] Embedding created successfully.[39m
[1692667202249] [32m[OPENAI] Embedding created successfully.[39m
[1692667202256] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667202256] [33m[OPENAI] No functions provided.[39m
[1692667202256] [33m[OPENAI] Creating embedding...[39m
[1692667202281] {
  "id": "chatcmpl-7qALqgZ5lHlmOmCzWncnb1yVVI5MZ",
  "object": "chat.completion",
  "created": 1692667202,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1692667202282] [36m[OPENAI] Chat completion took 214.50129199028015ms[39m
[1692667202282] [36m[OPENAI] Tokens per second: 4.661976581685642tps[39m
[1692667202282] [32m[OPENAI] Chat completion created successfully.[39m
[1692667202328] [32m[OPENAI] Embedding created successfully.[39m
[1692667202443] {
  "id": "chatcmpl-7qALqTcatQhmRyc4NUfVDWjEafb6h",
  "object": "chat.completion",
  "created": 1692667202,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667202443] [36m[OPENAI] Chat completion took 327.0144160091877ms[39m
[1692667202444] [36m[OPENAI] Tokens per second: 3.057969162961624tps[39m
[1692667202444] [32m[OPENAI] Chat completion created successfully.[39m
[1692667202496] [32m[OPENAI] Embedding created successfully.[39m
[1692667202612] --- Observations received -- 
[1692667202612] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 54.59, Y: -12.8.",
  "time": 53.49998
}
[1692667202612] [Character] Getting character: A1
[1692667202632] --- Observations received -- 
[1692667202633] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (419) at X: 54.59, Y: -12.8",
  "time": 53.52056
}
[1692667202633] [Character] Getting character: A1
[1692667202714] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667202714] [33m[OPENAI] No functions provided.[39m
[1692667202714] [33m[OPENAI] Creating embedding...[39m
[1692667202716] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667202716] [33m[OPENAI] No functions provided.[39m
[1692667202716] [33m[OPENAI] Creating embedding...[39m
[1692667202832] --- Observations received -- 
[1692667202832] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 44.34, Y: -18.3.",
  "time": 53.72023
}
[1692667202832] [Character] Getting character: A1
[1692667202888] [32m[OPENAI] Embedding created successfully.[39m
[1692667202895] --- Observations received -- 
[1692667202896] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (423) at X: 51.52, Y: -10.15",
  "time": 53.7807121
}
[1692667202896] [Character] Getting character: A1
[1692667202910] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667202910] [33m[OPENAI] No functions provided.[39m
[1692667202910] [33m[OPENAI] Creating embedding...[39m
[1692667202936] --- Observations received -- 
[1692667202936] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree Stump at X: 52.4, Y: -20.42.",
  "time": 53.8213959
}
[1692667202936] [Character] Getting character: A1
[1692667202938] {
  "id": "chatcmpl-7qALqNkPrXYjxuWV2fqF9zxq43iuF",
  "object": "chat.completion",
  "created": 1692667202,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1692667202938] [36m[OPENAI] Chat completion took 221.97991701960564ms[39m
[1692667202938] [36m[OPENAI] Tokens per second: 4.504912036306772tps[39m
[1692667202938] [32m[OPENAI] Chat completion created successfully.[39m
[1692667202977] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667202977] [33m[OPENAI] No functions provided.[39m
[1692667202977] [33m[OPENAI] Creating embedding...[39m
[1692667203014] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667203014] [33m[OPENAI] No functions provided.[39m
[1692667203014] [33m[OPENAI] Creating embedding...[39m
[1692667203034] --- Observations received -- 
[1692667203034] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (421) at X: 49.51, Y: -10.13",
  "time": 53.92085
}
[1692667203035] [Character] Getting character: A1
[1692667203120] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667203120] [33m[OPENAI] No functions provided.[39m
[1692667203120] [33m[OPENAI] Creating embedding...[39m
[1692667203176] [32m[OPENAI] Embedding created successfully.[39m
[1692667203248] [32m[OPENAI] Embedding created successfully.[39m
[1692667203265] [32m[OPENAI] Embedding created successfully.[39m
[1692667203267] [32m[OPENAI] Embedding created successfully.[39m
[1692667203412] --- Observations received -- 
[1692667203412] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 54.2, Y: -19.25.",
  "time": 54.3001
}
[1692667203412] [Character] Getting character: A1
[1692667203431] [32m[OPENAI] Embedding created successfully.[39m
[1692667203493] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667203493] [33m[OPENAI] No functions provided.[39m
[1692667203494] [33m[OPENAI] Creating embedding...[39m
[1692667203702] [32m[OPENAI] Embedding created successfully.[39m
[1692667203895] --- Observations received -- 
[1692667203895] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 45.95, Y: -21.7.",
  "time": 54.78115
}
[1692667203895] [Character] Getting character: A1
[1692667203956] --- Observations received -- 
[1692667203957] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (424) at X: 52.03, Y: -12.2",
  "time": 54.8408127
}
[1692667203957] [Character] Getting character: A1
[1692667203973] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667203974] [33m[OPENAI] No functions provided.[39m
[1692667203974] [33m[OPENAI] Creating embedding...[39m
[1692667204033] --- Observations received -- 
[1692667204033] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (282) at X: 44.48, Y: -14.04",
  "time": 54.92064
}
[1692667204033] [Character] Getting character: A1
[1692667204037] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667204037] [33m[OPENAI] No functions provided.[39m
[1692667204037] [33m[OPENAI] Creating embedding...[39m
[1692667204093] --- Observations received -- 
[1692667204093] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 44.3, Y: -20.42.",
  "time": 54.9813347
}
[1692667204093] [Character] Getting character: A1
[1692667204109] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667204109] [33m[OPENAI] No functions provided.[39m
[1692667204109] [33m[OPENAI] Creating embedding...[39m
[1692667204133] --- Observations received -- 
[1692667204136] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 44.48, Y: -14.04.",
  "time": 55.0203667
}
[1692667204136] [Character] Getting character: A1
[1692667204180] [32m[OPENAI] Embedding created successfully.[39m
[1692667204197] [32m[OPENAI] Embedding created successfully.[39m
[1692667204206] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667204206] [33m[OPENAI] No functions provided.[39m
[1692667204207] [33m[OPENAI] Creating embedding...[39m
[1692667204211] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667204212] [33m[OPENAI] No functions provided.[39m
[1692667204212] [33m[OPENAI] Creating embedding...[39m
[1692667204293] --- Observations received -- 
[1692667204293] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (282) at X: 44.48, Y: -14.04",
  "time": 55.1804924
}
[1692667204293] [Character] Getting character: A1
[1692667204364] [32m[OPENAI] Embedding created successfully.[39m
[1692667204372] {
  "id": "chatcmpl-7qALlbfRJxLbtl3E8AP6UHPJXGq0j",
  "object": "chat.completion",
  "created": 1692667197,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667204372] [36m[OPENAI] Chat completion took 160.39487498998642ms[39m
[1692667204372] [36m[OPENAI] Tokens per second: 6.234613169918496tps[39m
[1692667204372] [32m[OPENAI] Chat completion created successfully.[39m
[1692667204377] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667204377] [33m[OPENAI] No functions provided.[39m
[1692667204377] [33m[OPENAI] Creating embedding...[39m
[1692667204394] [32m[OPENAI] Embedding created successfully.[39m
[1692667204492] --- Observations received -- 
[1692667204492] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 43.22001, Y: -16.37.",
  "time": 55.3802834
}
[1692667204493] [Character] Getting character: A1
[1692667204498] [32m[OPENAI] Embedding created successfully.[39m
[1692667204508] [32m[OPENAI] Embedding created successfully.[39m
[1692667204572] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1692667204572] [33m[OPENAI] No functions provided.[39m
[1692667204572] [33m[OPENAI] Creating embedding...[39m
[1692667204597] [Main] connection (id = 915a22ee-b602-4e6e-a4f5-b23bd4ea32f8) closed
[1692667204612] {
  "id": "chatcmpl-7qALn1Dap4Md2yPQ1ACfmHHyV4sjQ",
  "object": "chat.completion",
  "created": 1692667199,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1692667204612] [36m[OPENAI] Chat completion took 39.92054200172424ms[39m
[1692667204612] [36m[OPENAI] Tokens per second: 25.04976009486064tps[39m
[1692667204612] [32m[OPENAI] Chat completion created successfully.[39m
[1692667204746] [32m[OPENAI] Embedding created successfully.[39m
[1692667205398] {
  "id": "chatcmpl-7qALtHYEuvdKRWMzdZCEZLlrFvyZ6",
  "object": "chat.completion",
  "created": 1692667205,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1692667205398] [36m[OPENAI] Chat completion took 1360.684541016817ms[39m
[1692667205398] [36m[OPENAI] Tokens per second: 0.7349242016468538tps[39m
[1692667205398] [32m[OPENAI] Chat completion created successfully.[39m
[1692667205456] {
  "id": "chatcmpl-7qALtWgLYU7TIi8WgwsYcONxti3hm",
  "object": "chat.completion",
  "created": 1692667205,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1692667205456] [36m[OPENAI] Chat completion took 3198.4313749969006ms[39m
[1692667205456] [36m[OPENAI] Tokens per second: 0.31265326116336295tps[39m
[1692667205456] [32m[OPENAI] Chat completion created successfully.[39m
[1692667205672] {
  "id": "chatcmpl-7qALtFiTzAp9fzWyOwdio26MbyxCN",
  "object": "chat.completion",
  "created": 1692667205,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667205672] [36m[OPENAI] Chat completion took 2178.5831249952316ms[39m
[1692667205672] [36m[OPENAI] Tokens per second: 0.4590139290655658tps[39m
[1692667205672] [32m[OPENAI] Chat completion created successfully.[39m
[1692667205693] {
  "id": "chatcmpl-7qALtordZdMUi7CgeIrvYfn9EtNwF",
  "object": "chat.completion",
  "created": 1692667205,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667205693] [36m[OPENAI] Chat completion took 2979.349292010069ms[39m
[1692667205693] [36m[OPENAI] Tokens per second: 0.33564376042841654tps[39m
[1692667205693] [32m[OPENAI] Chat completion created successfully.[39m
[1692667205699] {
  "id": "chatcmpl-7qALtZfBPtLMu2ityMoUWZhR4Dem4",
  "object": "chat.completion",
  "created": 1692667205,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1692667205699] [36m[OPENAI] Chat completion took 2721.6268749833107ms[39m
[1692667205699] [36m[OPENAI] Tokens per second: 0.3674272947521993tps[39m
[1692667205699] [32m[OPENAI] Chat completion created successfully.[39m
[1692667205805] {
  "id": "chatcmpl-7qALtGD30bbkB4laEjb9ecRTipTm7",
  "object": "chat.completion",
  "created": 1692667205,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667205806] [36m[OPENAI] Chat completion took 1831.220833003521ms[39m
[1692667205806] [36m[OPENAI] Tokens per second: 0.5460837830027446tps[39m
[1692667205806] [32m[OPENAI] Chat completion created successfully.[39m
[1692667205832] {
  "id": "chatcmpl-7qALtuHEquZ1BM6iTySLZr57CaL5k",
  "object": "chat.completion",
  "created": 1692667205,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667205832] [36m[OPENAI] Chat completion took 1625.1692499816418ms[39m
[1692667205832] [36m[OPENAI] Tokens per second: 0.6153205273920216tps[39m
[1692667205832] [32m[OPENAI] Chat completion created successfully.[39m
[1692667206015] {
  "id": "chatcmpl-7qALtP9lVwk2wrKzKNuT5uOHqCvBX",
  "object": "chat.completion",
  "created": 1692667205,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1692667206015] [36m[OPENAI] Chat completion took 1906.0422919988632ms[39m
[1692667206015] [36m[OPENAI] Tokens per second: 0.5246473303335267tps[39m
[1692667206015] [32m[OPENAI] Chat completion created successfully.[39m
[1692667206016] {
  "id": "chatcmpl-7qALtwR2VNLxlFfTdAVXu9SQ8CP5f",
  "object": "chat.completion",
  "created": 1692667205,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1692667206016] [36m[OPENAI] Chat completion took 1639.2645410001278ms[39m
[1692667206016] [36m[OPENAI] Tokens per second: 0.6100296657364969tps[39m
[1692667206016] [32m[OPENAI] Chat completion created successfully.[39m
[1692667206017] {
  "id": "chatcmpl-7qALtd4fHjZaaDiQBc1Rp9XJSTC2N",
  "object": "chat.completion",
  "created": 1692667205,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1692667206017] [36m[OPENAI] Chat completion took 3106.7823329865932ms[39m
[1692667206017] [36m[OPENAI] Tokens per second: 0.32187642802728506tps[39m
[1692667206017] [32m[OPENAI] Chat completion created successfully.[39m
[1692667206020] {
  "id": "chatcmpl-7qALtG6WHQbvo32pOhQRa12CpEkS1",
  "object": "chat.completion",
  "created": 1692667205,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1692667206020] [36m[OPENAI] Chat completion took 2899.5593750178814ms[39m
[1692667206020] [36m[OPENAI] Tokens per second: 0.34487998715109364tps[39m
[1692667206020] [32m[OPENAI] Chat completion created successfully.[39m
[1692667206371] {
  "id": "chatcmpl-7qALuMG1NhPw1AYOftSMw75VcwhgK",
  "object": "chat.completion",
  "created": 1692667206,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1692667206371] [36m[OPENAI] Chat completion took 3357.092916995287ms[39m
[1692667206371] [36m[OPENAI] Tokens per second: 0.29787677157742604tps[39m
[1692667206371] [32m[OPENAI] Chat completion created successfully.[39m
