[1693026224680] [Character] Creating Thomas's logger
[1693026224681] [Character] Creating George's logger
[1693026224681] [Character] Creating Will's logger
[1693026224681] [Character] Creating Lucy's logger
[1693026224682] [Character] Creating Eli's logger
[1693026224684] [Main] WebSocket server listening on port 8082
[1693026224918] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026224920] [33m[OPENAI] No functions provided.[39m
[1693026224920] [33m[OPENAI] Creating embedding...[39m
[1693026224921] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026224921] [33m[OPENAI] No functions provided.[39m
[1693026224921] [33m[OPENAI] Creating embedding...[39m
[1693026224921] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026224921] [33m[OPENAI] No functions provided.[39m
[1693026224921] [33m[OPENAI] Creating embedding...[39m
[1693026224921] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026224921] [33m[OPENAI] No functions provided.[39m
[1693026224921] [33m[OPENAI] Creating embedding...[39m
[1693026224921] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026224921] [33m[OPENAI] No functions provided.[39m
[1693026224921] [33m[OPENAI] Creating embedding...[39m
[1693026224921] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026224921] [33m[OPENAI] No functions provided.[39m
[1693026224921] [33m[OPENAI] Creating embedding...[39m
[1693026224922] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026224922] [33m[OPENAI] No functions provided.[39m
[1693026224922] [33m[OPENAI] Creating embedding...[39m
[1693026224922] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026224922] [33m[OPENAI] No functions provided.[39m
[1693026224922] [33m[OPENAI] Creating embedding...[39m
[1693026224922] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026224922] [33m[OPENAI] No functions provided.[39m
[1693026224922] [33m[OPENAI] Creating embedding...[39m
[1693026224922] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026224922] [33m[OPENAI] No functions provided.[39m
[1693026224922] [33m[OPENAI] Creating embedding...[39m
[1693026224922] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026224922] [33m[OPENAI] No functions provided.[39m
[1693026224923] [33m[OPENAI] Creating embedding...[39m
[1693026224923] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026224923] [33m[OPENAI] No functions provided.[39m
[1693026224923] [33m[OPENAI] Creating embedding...[39m
[1693026224923] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026224923] [33m[OPENAI] No functions provided.[39m
[1693026224923] [33m[OPENAI] Creating embedding...[39m
[1693026224923] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026224923] [33m[OPENAI] No functions provided.[39m
[1693026224923] [33m[OPENAI] Creating embedding...[39m
[1693026224923] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026224923] [33m[OPENAI] No functions provided.[39m
[1693026224923] [33m[OPENAI] Creating embedding...[39m
[1693026225024] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225024] [33m[OPENAI] No functions provided.[39m
[1693026225025] [33m[OPENAI] Creating embedding...[39m
[1693026225025] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225025] [33m[OPENAI] No functions provided.[39m
[1693026225025] [33m[OPENAI] Creating embedding...[39m
[1693026225025] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225025] [33m[OPENAI] No functions provided.[39m
[1693026225025] [33m[OPENAI] Creating embedding...[39m
[1693026225025] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225025] [33m[OPENAI] No functions provided.[39m
[1693026225025] [33m[OPENAI] Creating embedding...[39m
[1693026225025] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225025] [33m[OPENAI] No functions provided.[39m
[1693026225025] [33m[OPENAI] Creating embedding...[39m
[1693026225025] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225025] [33m[OPENAI] No functions provided.[39m
[1693026225025] [33m[OPENAI] Creating embedding...[39m
[1693026225025] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225025] [33m[OPENAI] No functions provided.[39m
[1693026225025] [33m[OPENAI] Creating embedding...[39m
[1693026225025] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225025] [33m[OPENAI] No functions provided.[39m
[1693026225025] [33m[OPENAI] Creating embedding...[39m
[1693026225025] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225025] [33m[OPENAI] No functions provided.[39m
[1693026225025] [33m[OPENAI] Creating embedding...[39m
[1693026225025] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225025] [33m[OPENAI] No functions provided.[39m
[1693026225025] [33m[OPENAI] Creating embedding...[39m
[1693026225025] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225025] [33m[OPENAI] No functions provided.[39m
[1693026225025] [33m[OPENAI] Creating embedding...[39m
[1693026225025] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225025] [33m[OPENAI] No functions provided.[39m
[1693026225025] [33m[OPENAI] Creating embedding...[39m
[1693026225025] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225025] [33m[OPENAI] No functions provided.[39m
[1693026225025] [33m[OPENAI] Creating embedding...[39m
[1693026225026] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225026] [33m[OPENAI] No functions provided.[39m
[1693026225026] [33m[OPENAI] Creating embedding...[39m
[1693026225026] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225026] [33m[OPENAI] No functions provided.[39m
[1693026225026] [33m[OPENAI] Creating embedding...[39m
[1693026225078] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225078] [33m[OPENAI] No functions provided.[39m
[1693026225079] [33m[OPENAI] Creating embedding...[39m
[1693026225079] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225079] [33m[OPENAI] No functions provided.[39m
[1693026225079] [33m[OPENAI] Creating embedding...[39m
[1693026225079] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225079] [33m[OPENAI] No functions provided.[39m
[1693026225079] [33m[OPENAI] Creating embedding...[39m
[1693026225079] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225079] [33m[OPENAI] No functions provided.[39m
[1693026225079] [33m[OPENAI] Creating embedding...[39m
[1693026225079] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225079] [33m[OPENAI] No functions provided.[39m
[1693026225079] [33m[OPENAI] Creating embedding...[39m
[1693026225079] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225079] [33m[OPENAI] No functions provided.[39m
[1693026225079] [33m[OPENAI] Creating embedding...[39m
[1693026225079] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225079] [33m[OPENAI] No functions provided.[39m
[1693026225079] [33m[OPENAI] Creating embedding...[39m
[1693026225079] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225079] [33m[OPENAI] No functions provided.[39m
[1693026225079] [33m[OPENAI] Creating embedding...[39m
[1693026225079] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225079] [33m[OPENAI] No functions provided.[39m
[1693026225079] [33m[OPENAI] Creating embedding...[39m
[1693026225079] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225079] [33m[OPENAI] No functions provided.[39m
[1693026225079] [33m[OPENAI] Creating embedding...[39m
[1693026225079] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225079] [33m[OPENAI] No functions provided.[39m
[1693026225079] [33m[OPENAI] Creating embedding...[39m
[1693026225079] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225079] [33m[OPENAI] No functions provided.[39m
[1693026225079] [33m[OPENAI] Creating embedding...[39m
[1693026225079] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225079] [33m[OPENAI] No functions provided.[39m
[1693026225079] [33m[OPENAI] Creating embedding...[39m
[1693026225079] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225079] [33m[OPENAI] No functions provided.[39m
[1693026225079] [33m[OPENAI] Creating embedding...[39m
[1693026225079] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225079] [33m[OPENAI] No functions provided.[39m
[1693026225079] [33m[OPENAI] Creating embedding...[39m
[1693026225079] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225079] [33m[OPENAI] No functions provided.[39m
[1693026225079] [33m[OPENAI] Creating embedding...[39m
[1693026225119] {
  "id": "chatcmpl-7olV7vrDE6VNyHnI8foiB0wK9uXCn",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 90,
    "completion_tokens": 1,
    "total_tokens": 91
  }
}
[1693026225120] [36m[OPENAI] Chat completion took 196.79633402824402ms[39m
[1693026225120] [36m[OPENAI] Tokens per second: 5.081395468761532tps[39m
[1693026225120] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225133] {
  "id": "chatcmpl-7olV7ctuUV67Q1sfdu5KFIo2luWJB",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693026225133] [36m[OPENAI] Chat completion took 213.45020800828934ms[39m
[1693026225133] [36m[OPENAI] Tokens per second: 4.68493335907719tps[39m
[1693026225133] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225133] {
  "id": "chatcmpl-7olV7FRwvXnqPU0zcwtBho0a9XM8N",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693026225133] [36m[OPENAI] Chat completion took 211.4575830101967ms[39m
[1693026225133] [36m[OPENAI] Tokens per second: 4.729080819730068tps[39m
[1693026225133] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225136] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225136] [33m[OPENAI] No functions provided.[39m
[1693026225137] [33m[OPENAI] Creating embedding...[39m
[1693026225137] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225137] [33m[OPENAI] No functions provided.[39m
[1693026225137] [33m[OPENAI] Creating embedding...[39m
[1693026225137] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225137] [33m[OPENAI] No functions provided.[39m
[1693026225137] [33m[OPENAI] Creating embedding...[39m
[1693026225137] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225137] [33m[OPENAI] No functions provided.[39m
[1693026225137] [33m[OPENAI] Creating embedding...[39m
[1693026225137] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225137] [33m[OPENAI] No functions provided.[39m
[1693026225137] [33m[OPENAI] Creating embedding...[39m
[1693026225137] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225137] [33m[OPENAI] No functions provided.[39m
[1693026225137] [33m[OPENAI] Creating embedding...[39m
[1693026225137] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225137] [33m[OPENAI] No functions provided.[39m
[1693026225137] [33m[OPENAI] Creating embedding...[39m
[1693026225137] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225137] [33m[OPENAI] No functions provided.[39m
[1693026225137] [33m[OPENAI] Creating embedding...[39m
[1693026225137] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225137] [33m[OPENAI] No functions provided.[39m
[1693026225137] [33m[OPENAI] Creating embedding...[39m
[1693026225137] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225137] [33m[OPENAI] No functions provided.[39m
[1693026225137] [33m[OPENAI] Creating embedding...[39m
[1693026225137] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225137] [33m[OPENAI] No functions provided.[39m
[1693026225137] [33m[OPENAI] Creating embedding...[39m
[1693026225137] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225137] [33m[OPENAI] No functions provided.[39m
[1693026225137] [33m[OPENAI] Creating embedding...[39m
[1693026225137] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225137] [33m[OPENAI] No functions provided.[39m
[1693026225137] [33m[OPENAI] Creating embedding...[39m
[1693026225137] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225137] [33m[OPENAI] No functions provided.[39m
[1693026225137] [33m[OPENAI] Creating embedding...[39m
[1693026225137] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225137] [33m[OPENAI] No functions provided.[39m
[1693026225137] [33m[OPENAI] Creating embedding...[39m
[1693026225144] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225144] [33m[OPENAI] No functions provided.[39m
[1693026225144] [33m[OPENAI] Creating embedding...[39m
[1693026225144] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225144] [33m[OPENAI] No functions provided.[39m
[1693026225144] [33m[OPENAI] Creating embedding...[39m
[1693026225144] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225144] [33m[OPENAI] No functions provided.[39m
[1693026225144] [33m[OPENAI] Creating embedding...[39m
[1693026225144] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225144] [33m[OPENAI] No functions provided.[39m
[1693026225144] [33m[OPENAI] Creating embedding...[39m
[1693026225144] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225144] [33m[OPENAI] No functions provided.[39m
[1693026225144] [33m[OPENAI] Creating embedding...[39m
[1693026225144] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225144] [33m[OPENAI] No functions provided.[39m
[1693026225144] [33m[OPENAI] Creating embedding...[39m
[1693026225144] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225144] [33m[OPENAI] No functions provided.[39m
[1693026225144] [33m[OPENAI] Creating embedding...[39m
[1693026225144] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225144] [33m[OPENAI] No functions provided.[39m
[1693026225144] [33m[OPENAI] Creating embedding...[39m
[1693026225144] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225144] [33m[OPENAI] No functions provided.[39m
[1693026225144] [33m[OPENAI] Creating embedding...[39m
[1693026225145] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225145] [33m[OPENAI] No functions provided.[39m
[1693026225145] [33m[OPENAI] Creating embedding...[39m
[1693026225145] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225145] [33m[OPENAI] No functions provided.[39m
[1693026225145] [33m[OPENAI] Creating embedding...[39m
[1693026225145] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225145] [33m[OPENAI] No functions provided.[39m
[1693026225145] [33m[OPENAI] Creating embedding...[39m
[1693026225145] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225145] [33m[OPENAI] No functions provided.[39m
[1693026225145] [33m[OPENAI] Creating embedding...[39m
[1693026225145] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225145] [33m[OPENAI] No functions provided.[39m
[1693026225145] [33m[OPENAI] Creating embedding...[39m
[1693026225145] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026225145] [33m[OPENAI] No functions provided.[39m
[1693026225145] [33m[OPENAI] Creating embedding...[39m
[1693026225152] {
  "id": "chatcmpl-7olV7tu3HrQfLXa3gKYRIZRrlpt21",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693026225152] [36m[OPENAI] Chat completion took 230.34512501955032ms[39m
[1693026225152] [36m[OPENAI] Tokens per second: 4.3413117595396296tps[39m
[1693026225152] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225155] {
  "id": "chatcmpl-7omMfBOgjTu7sXdHl9tvA7jxYHMKT",
  "object": "chat.completion",
  "created": 1692336669,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 90,
    "completion_tokens": 1,
    "total_tokens": 91
  }
}
[1693026225155] [36m[OPENAI] Chat completion took 234.28925001621246ms[39m
[1693026225155] [36m[OPENAI] Tokens per second: 4.268228268820706tps[39m
[1693026225155] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225155] {
  "id": "chatcmpl-7olV79SDWiud3CmckuSMAaCArje53",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 92,
    "completion_tokens": 1,
    "total_tokens": 93
  }
}
[1693026225155] [36m[OPENAI] Chat completion took 234.0296249985695ms[39m
[1693026225155] [36m[OPENAI] Tokens per second: 4.272963305419613tps[39m
[1693026225155] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225155] {
  "id": "chatcmpl-7olV8DoIHRPyAnFJQpub2WZmmGHFY",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693026225155] [36m[OPENAI] Chat completion took 232.35129100084305ms[39m
[1693026225155] [36m[OPENAI] Tokens per second: 4.3038280342344715tps[39m
[1693026225155] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225155] {
  "id": "chatcmpl-7olV777mm4E117eWDlhnUXJv1akt3",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693026225155] [36m[OPENAI] Chat completion took 232.95333296060562ms[39m
[1693026225155] [36m[OPENAI] Tokens per second: 4.292705269725025tps[39m
[1693026225155] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225156] {
  "id": "chatcmpl-7olV8FREfRx0ZWWp3SphTSzmx6xZ2",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 96,
    "completion_tokens": 1,
    "total_tokens": 97
  }
}
[1693026225156] [36m[OPENAI] Chat completion took 232.84245800971985ms[39m
[1693026225156] [36m[OPENAI] Tokens per second: 4.294749370659263tps[39m
[1693026225156] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225156] [32m[OPENAI] Embedding created successfully.[39m
[1693026225158] [32m[OPENAI] Embedding created successfully.[39m
[1693026225160] {
  "id": "chatcmpl-7olV8zC3SlBJAGZ16CfxiW5ysM14X",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693026225160] [36m[OPENAI] Chat completion took 239.0097079873085ms[39m
[1693026225160] [36m[OPENAI] Tokens per second: 4.183930470527583tps[39m
[1693026225160] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225160] {
  "id": "chatcmpl-7olV8mp16AEElDSWboZwenyFu445a",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 92,
    "completion_tokens": 1,
    "total_tokens": 93
  }
}
[1693026225160] [36m[OPENAI] Chat completion took 238.36983400583267ms[39m
[1693026225160] [36m[OPENAI] Tokens per second: 4.195161708152765tps[39m
[1693026225160] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225160] {
  "id": "chatcmpl-7olV80dOsfHeL7YoM65UTcnGud0LK",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 2,
    "total_tokens": 97
  }
}
[1693026225160] [36m[OPENAI] Chat completion took 237.37670797109604ms[39m
[1693026225160] [36m[OPENAI] Tokens per second: 8.425426475471756tps[39m
[1693026225160] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225161] {
  "id": "chatcmpl-7olV8YtG6ysTRpfalhSZtYRhj6BFF",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693026225161] [36m[OPENAI] Chat completion took 237.89729100465775ms[39m
[1693026225161] [36m[OPENAI] Tokens per second: 4.203494692087188tps[39m
[1693026225161] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225161] [32m[OPENAI] Embedding created successfully.[39m
[1693026225164] {
  "id": "chatcmpl-7olV83YLFQhCJTkBVDSmx47UrZkLN",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693026225164] [36m[OPENAI] Chat completion took 242.1215000152588ms[39m
[1693026225164] [36m[OPENAI] Tokens per second: 4.130157792418182tps[39m
[1693026225164] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225164] {
  "id": "chatcmpl-7olV7zjV0jDIqYutwLfUmrgSVBifk",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693026225164] [36m[OPENAI] Chat completion took 242.71724998950958ms[39m
[1693026225164] [36m[OPENAI] Tokens per second: 4.120020311878207tps[39m
[1693026225164] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225165] [32m[OPENAI] Embedding created successfully.[39m
[1693026225179] {
  "id": "chatcmpl-7olV778kF1nFpJ5zYXIDkaXF9tRXR",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1693026225179] [36m[OPENAI] Chat completion took 153.38212502002716ms[39m
[1693026225179] [36m[OPENAI] Tokens per second: 6.5196645298103tps[39m
[1693026225179] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225181] {
  "id": "chatcmpl-7olV8SQyMyfcS6uXzNc90h0LLuDY1",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693026225181] [36m[OPENAI] Chat completion took 155.96287500858307ms[39m
[1693026225181] [36m[OPENAI] Tokens per second: 6.411782290785337tps[39m
[1693026225181] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225181] [32m[OPENAI] Embedding created successfully.[39m
[1693026225182] [32m[OPENAI] Embedding created successfully.[39m
[1693026225187] {
  "id": "chatcmpl-7olV8KlbcvkCbGYfuCV5ccMLKBvt2",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 86,
    "completion_tokens": 1,
    "total_tokens": 87
  }
}
[1693026225187] [36m[OPENAI] Chat completion took 161.42762500047684ms[39m
[1693026225187] [36m[OPENAI] Tokens per second: 6.194726584108799tps[39m
[1693026225187] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225187] [32m[OPENAI] Embedding created successfully.[39m
[1693026225190] {
  "id": "chatcmpl-7olV8Py9dUkaghVHNiYvwGjlihWx9",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693026225190] [36m[OPENAI] Chat completion took 165.08262503147125ms[39m
[1693026225190] [36m[OPENAI] Tokens per second: 6.057572684038436tps[39m
[1693026225190] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225194] {
  "id": "chatcmpl-7olV8gA5LrpqgDUYedds92oLPqMCg",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 89,
    "completion_tokens": 1,
    "total_tokens": 90
  }
}
[1693026225194] [36m[OPENAI] Chat completion took 168.66595804691315ms[39m
[1693026225194] [36m[OPENAI] Tokens per second: 5.928878663955756tps[39m
[1693026225194] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225194] [32m[OPENAI] Embedding created successfully.[39m
[1693026225196] [32m[OPENAI] Embedding created successfully.[39m
[1693026225197] {
  "id": "chatcmpl-7olV7LWuqju0QGl6Hdki7b8wPcCqS",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693026225197] [36m[OPENAI] Chat completion took 171.64179199934006ms[39m
[1693026225197] [36m[OPENAI] Tokens per second: 5.826086924120699tps[39m
[1693026225197] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225197] [32m[OPENAI] Embedding created successfully.[39m
[1693026225198] [32m[OPENAI] Embedding created successfully.[39m
[1693026225199] {
  "id": "chatcmpl-7olV7Xwk3tvSdS5NEeiRvaWAx38sd",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693026225199] [36m[OPENAI] Chat completion took 173.75520795583725ms[39m
[1693026225199] [36m[OPENAI] Tokens per second: 5.755223177276888tps[39m
[1693026225199] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225203] {
  "id": "chatcmpl-7olV7Ze1M8NgP8Lk7PYp1PhWSaIEf",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693026225203] [36m[OPENAI] Chat completion took 177.29058295488358ms[39m
[1693026225203] [36m[OPENAI] Tokens per second: 5.640457509547912tps[39m
[1693026225203] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225204] [32m[OPENAI] Embedding created successfully.[39m
[1693026225205] [32m[OPENAI] Embedding created successfully.[39m
[1693026225209] {
  "id": "chatcmpl-7olV8kYnE1YMoyPDjABIJHD9Uvpff",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693026225209] [36m[OPENAI] Chat completion took 183.5782499909401ms[39m
[1693026225209] [36m[OPENAI] Tokens per second: 5.447268399439213tps[39m
[1693026225209] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225209] [32m[OPENAI] Embedding created successfully.[39m
[1693026225210] {
  "id": "chatcmpl-7olV7bXDGvpJQSwghwqyXcR08MqUR",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 92,
    "completion_tokens": 1,
    "total_tokens": 93
  }
}
[1693026225210] [36m[OPENAI] Chat completion took 185.25108301639557ms[39m
[1693026225211] [36m[OPENAI] Tokens per second: 5.3980791027898904tps[39m
[1693026225211] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225213] {
  "id": "chatcmpl-7olV75Kg6LpizfVZoOUgYmChjg5d6",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693026225213] [36m[OPENAI] Chat completion took 188.162790954113ms[39m
[1693026225213] [36m[OPENAI] Tokens per second: 5.314547020318531tps[39m
[1693026225213] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225213] {
  "id": "chatcmpl-7olV8NUOQZyQ8WoqNva8OKehDPmzu",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693026225213] [36m[OPENAI] Chat completion took 187.87420797348022ms[39m
[1693026225213] [36m[OPENAI] Tokens per second: 5.322710396422042tps[39m
[1693026225213] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225213] [32m[OPENAI] Embedding created successfully.[39m
[1693026225220] {
  "id": "chatcmpl-7olV7noZMGrBR0G5IQC7H6xzCmDtX",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693026225220] [36m[OPENAI] Chat completion took 194.99424999952316ms[39m
[1693026225220] [36m[OPENAI] Tokens per second: 5.128356348981805tps[39m
[1693026225220] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225223] [32m[OPENAI] Embedding created successfully.[39m
[1693026225224] {
  "id": "chatcmpl-7olV8gGRRaflm8XIf2MXwKoEeVCsh",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693026225224] [36m[OPENAI] Chat completion took 198.6289170384407ms[39m
[1693026225224] [36m[OPENAI] Tokens per second: 5.034513679629385tps[39m
[1693026225224] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225228] {
  "id": "chatcmpl-7olV79ngfUn6SHKsI6M07wj1KL41H",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693026225228] [36m[OPENAI] Chat completion took 149.5356249809265ms[39m
[1693026225228] [36m[OPENAI] Tokens per second: 6.687369649389913tps[39m
[1693026225228] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225232] {
  "id": "chatcmpl-7olV7K7Q2Z1zQ4UQX0QjkzMFVYeI6",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "8"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693026225232] [36m[OPENAI] Chat completion took 153.3628749847412ms[39m
[1693026225232] [36m[OPENAI] Tokens per second: 6.520482875008014tps[39m
[1693026225232] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225232] [32m[OPENAI] Embedding created successfully.[39m
[1693026225234] {
  "id": "chatcmpl-7olV8IiA12R5nF0Pmp4dfcjnLnWOn",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693026225234] [36m[OPENAI] Chat completion took 155.59691697359085ms[39m
[1693026225234] [36m[OPENAI] Tokens per second: 6.426862559042401tps[39m
[1693026225234] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225234] {
  "id": "chatcmpl-7omMfKtOqiWZY1HULj9SxSxqtgvth",
  "object": "chat.completion",
  "created": 1692336669,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 114,
    "completion_tokens": 1,
    "total_tokens": 115
  }
}
[1693026225234] [36m[OPENAI] Chat completion took 155.83166700601578ms[39m
[1693026225234] [36m[OPENAI] Tokens per second: 6.417180918441922tps[39m
[1693026225234] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225235] {
  "id": "chatcmpl-7omMf1iH6S1cjaqDfWFBUxiipPCUG",
  "object": "chat.completion",
  "created": 1692336669,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693026225235] [36m[OPENAI] Chat completion took 209.57370901107788ms[39m
[1693026225235] [36m[OPENAI] Tokens per second: 4.771590886656211tps[39m
[1693026225235] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225235] [32m[OPENAI] Embedding created successfully.[39m
[1693026225236] [32m[OPENAI] Embedding created successfully.[39m
[1693026225237] [32m[OPENAI] Embedding created successfully.[39m
[1693026225238] [32m[OPENAI] Embedding created successfully.[39m
[1693026225241] {
  "id": "chatcmpl-7olV7IxMkWZqPJc7J4cneCp8IBC6C",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7.5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 3,
    "total_tokens": 103
  }
}
[1693026225241] [36m[OPENAI] Chat completion took 161.96366596221924ms[39m
[1693026225241] [36m[OPENAI] Tokens per second: 18.522672861083553tps[39m
[1693026225241] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225241] [32m[OPENAI] Embedding created successfully.[39m
[1693026225245] [32m[OPENAI] Embedding created successfully.[39m
[1693026225247] {
  "id": "chatcmpl-7olV7HleCtjDubqyAtoz4YCDoESYl",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1693026225247] [36m[OPENAI] Chat completion took 167.3641249537468ms[39m
[1693026225247] [36m[OPENAI] Tokens per second: 5.9749961365756405tps[39m
[1693026225247] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225247] [32m[OPENAI] Embedding created successfully.[39m
[1693026225248] [32m[OPENAI] Embedding created successfully.[39m
[1693026225249] {
  "id": "chatcmpl-7olV8VNaWaURvwwCTSxpx87r0hDE0",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693026225249] [36m[OPENAI] Chat completion took 169.22591596841812ms[39m
[1693026225249] [36m[OPENAI] Tokens per second: 5.909260377037199tps[39m
[1693026225249] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225250] {
  "id": "chatcmpl-7olV7mLd3CHurzeFeAcyiefLZ2bzR",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693026225250] [36m[OPENAI] Chat completion took 170.5341249704361ms[39m
[1693026225250] [36m[OPENAI] Tokens per second: 5.86392899470039tps[39m
[1693026225250] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225250] {
  "id": "chatcmpl-7olV7XrJLdun8a9EZhgSUTTwxkfEv",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 2,
    "total_tokens": 101
  }
}
[1693026225250] [36m[OPENAI] Chat completion took 170.70162498950958ms[39m
[1693026225250] [36m[OPENAI] Tokens per second: 11.716350094048076tps[39m
[1693026225250] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225250] [32m[OPENAI] Embedding created successfully.[39m
[1693026225255] {
  "id": "chatcmpl-7olVCzZk3HzXo2NQMOMd0GiNn5tcu",
  "object": "chat.completion",
  "created": 1692333354,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 2,
    "total_tokens": 102
  }
}
[1693026225255] [36m[OPENAI] Chat completion took 176.25458401441574ms[39m
[1693026225255] [36m[OPENAI] Tokens per second: 11.347222605208506tps[39m
[1693026225255] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225255] [32m[OPENAI] Embedding created successfully.[39m
[1693026225257] {
  "id": "chatcmpl-7olV8lZTqMoJn2eRn4eW5uL1SAakO",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693026225257] [36m[OPENAI] Chat completion took 178.17599999904633ms[39m
[1693026225257] [36m[OPENAI] Tokens per second: 5.61242816094958tps[39m
[1693026225257] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225258] {
  "id": "chatcmpl-7olV757xzL4ZuTU41FmNrt2hWXJkz",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693026225258] [36m[OPENAI] Chat completion took 178.49320805072784ms[39m
[1693026225258] [36m[OPENAI] Tokens per second: 5.602454070497739tps[39m
[1693026225258] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225258] [32m[OPENAI] Embedding created successfully.[39m
[1693026225261] [32m[OPENAI] Embedding created successfully.[39m
[1693026225263] {
  "id": "chatcmpl-7olV746E6rNKpkaXPf5MrQxZAwsO2",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 91,
    "completion_tokens": 1,
    "total_tokens": 92
  }
}
[1693026225263] [36m[OPENAI] Chat completion took 126.1286249756813ms[39m
[1693026225263] [36m[OPENAI] Tokens per second: 7.928414348390849tps[39m
[1693026225263] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225263] [32m[OPENAI] Embedding created successfully.[39m
[1693026225264] [32m[OPENAI] Embedding created successfully.[39m
[1693026225266] [32m[OPENAI] Embedding created successfully.[39m
[1693026225269] {
  "id": "chatcmpl-7olV7POyU9BbIur1pbbjofBicYnQV",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693026225269] [36m[OPENAI] Chat completion took 189.49008303880692ms[39m
[1693026225269] [36m[OPENAI] Tokens per second: 5.277321028959618tps[39m
[1693026225269] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225270] {
  "id": "chatcmpl-7omMf7ekcj16DBIUKnLgNQjV9DbEc",
  "object": "chat.completion",
  "created": 1692336669,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693026225270] [36m[OPENAI] Chat completion took 133.2420830130577ms[39m
[1693026225270] [36m[OPENAI] Tokens per second: 7.50513634571444tps[39m
[1693026225270] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225270] [32m[OPENAI] Embedding created successfully.[39m
[1693026225272] {
  "id": "chatcmpl-7olV7Br8PoxSOMCFkl0GY62STc2wu",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693026225272] [36m[OPENAI] Chat completion took 192.73125004768372ms[39m
[1693026225272] [36m[OPENAI] Tokens per second: 5.188572168512318tps[39m
[1693026225272] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225276] [32m[OPENAI] Embedding created successfully.[39m
[1693026225279] {
  "id": "chatcmpl-7olV7slmJcR3P7QDbSfQjf9qNly1R",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1693026225279] [36m[OPENAI] Chat completion took 199.59962499141693ms[39m
[1693026225279] [36m[OPENAI] Tokens per second: 5.010029452926084tps[39m
[1693026225279] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225280] {
  "id": "chatcmpl-7olV7HdNVZxJfRU21bECzegn2lNwi",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693026225280] [36m[OPENAI] Chat completion took 143.3777909874916ms[39m
[1693026225280] [36m[OPENAI] Tokens per second: 6.9745808825248305tps[39m
[1693026225280] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225281] [32m[OPENAI] Embedding created successfully.[39m
[1693026225286] [32m[OPENAI] Embedding created successfully.[39m
[1693026225288] [32m[OPENAI] Embedding created successfully.[39m
[1693026225289] [32m[OPENAI] Embedding created successfully.[39m
[1693026225291] [32m[OPENAI] Embedding created successfully.[39m
[1693026225291] [32m[OPENAI] Embedding created successfully.[39m
[1693026225293] [32m[OPENAI] Embedding created successfully.[39m
[1693026225294] {
  "id": "chatcmpl-7olV8yLve7h6sPLF0O0oWRRj2jrxr",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 90,
    "completion_tokens": 1,
    "total_tokens": 91
  }
}
[1693026225294] [36m[OPENAI] Chat completion took 157.11516696214676ms[39m
[1693026225294] [36m[OPENAI] Tokens per second: 6.364757899158945tps[39m
[1693026225294] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225297] [32m[OPENAI] Embedding created successfully.[39m
[1693026225298] {
  "id": "chatcmpl-7olV8Srn1MXRcNPWiwg97xq3mIAIQ",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 96,
    "completion_tokens": 1,
    "total_tokens": 97
  }
}
[1693026225298] [36m[OPENAI] Chat completion took 161.28883302211761ms[39m
[1693026225298] [36m[OPENAI] Tokens per second: 6.200057259158602tps[39m
[1693026225298] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225304] [32m[OPENAI] Embedding created successfully.[39m
[1693026225307] [32m[OPENAI] Embedding created successfully.[39m
[1693026225308] {
  "id": "chatcmpl-7olV8BoCj2TVoQKQaIkTdB8yJa75R",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693026225308] [36m[OPENAI] Chat completion took 171.31983304023743ms[39m
[1693026225308] [36m[OPENAI] Tokens per second: 5.837035807553774tps[39m
[1693026225308] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225308] [32m[OPENAI] Embedding created successfully.[39m
[1693026225311] {
  "id": "chatcmpl-7olV71LhIbN48putDIQmSVZEBQfDN",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693026225311] [36m[OPENAI] Chat completion took 173.3214579820633ms[39m
[1693026225311] [36m[OPENAI] Tokens per second: 5.7696260557852455tps[39m
[1693026225311] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225312] [32m[OPENAI] Embedding created successfully.[39m
[1693026225315] [32m[OPENAI] Embedding created successfully.[39m
[1693026225316] {
  "id": "chatcmpl-7olV7RaXQuNOvR7Ylu0WkrhMZoeSC",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 2,
    "total_tokens": 96
  }
}
[1693026225316] [36m[OPENAI] Chat completion took 178.2655839920044ms[39m
[1693026225316] [36m[OPENAI] Tokens per second: 11.21921548294877tps[39m
[1693026225316] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225316] [32m[OPENAI] Embedding created successfully.[39m
[1693026225317] {
  "id": "chatcmpl-7olV8Dz9sjPtUQKfjXwxRmXWT5R55",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693026225317] [36m[OPENAI] Chat completion took 172.99958300590515ms[39m
[1693026225317] [36m[OPENAI] Tokens per second: 5.780360753620234tps[39m
[1693026225317] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225317] [32m[OPENAI] Embedding created successfully.[39m
[1693026225318] [32m[OPENAI] Embedding created successfully.[39m
[1693026225318] {
  "id": "chatcmpl-7olV7fvXbMZXKww0lwuV4saDZl6b0",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693026225318] [36m[OPENAI] Chat completion took 173.62299996614456ms[39m
[1693026225318] [36m[OPENAI] Tokens per second: 5.759605583332819tps[39m
[1693026225318] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225318] {
  "id": "chatcmpl-7olV81tLnpWnlV0E87Dtv0VWIir0C",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693026225319] [36m[OPENAI] Chat completion took 181.3479170203209ms[39m
[1693026225319] [36m[OPENAI] Tokens per second: 5.514262399208839tps[39m
[1693026225319] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225319] [32m[OPENAI] Embedding created successfully.[39m
[1693026225321] {
  "id": "chatcmpl-7olV77grwRXfmalZQgcsGh31003bs",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693026225321] [36m[OPENAI] Chat completion took 183.5201659798622ms[39m
[1693026225321] [36m[OPENAI] Tokens per second: 5.4489924562826015tps[39m
[1693026225321] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225322] {
  "id": "chatcmpl-7olV8KzYkm8v3MhXQPvCWFGD6v469",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693026225322] [36m[OPENAI] Chat completion took 177.35050004720688ms[39m
[1693026225322] [36m[OPENAI] Tokens per second: 5.638551905598358tps[39m
[1693026225322] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225322] {
  "id": "chatcmpl-7olV7cqXYbdSPmsM1yjrwuEt0826y",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693026225322] [36m[OPENAI] Chat completion took 185.04162496328354ms[39m
[1693026225322] [36m[OPENAI] Tokens per second: 5.404189463848594tps[39m
[1693026225322] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225325] {
  "id": "chatcmpl-7olV7PpiqlgvDunRGtioXg2g7NIPw",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693026225325] [36m[OPENAI] Chat completion took 187.59062498807907ms[39m
[1693026225325] [36m[OPENAI] Tokens per second: 5.330756801218332tps[39m
[1693026225325] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225325] {
  "id": "chatcmpl-7olV8aKTgfiVBW2NEZi4xnYtbzqXs",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "8"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 104,
    "completion_tokens": 1,
    "total_tokens": 105
  }
}
[1693026225325] [36m[OPENAI] Chat completion took 180.67066603899002ms[39m
[1693026225325] [36m[OPENAI] Tokens per second: 5.534932825144913tps[39m
[1693026225325] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225326] {
  "id": "chatcmpl-7olV8am3kWnTxD3AdhAcKQ7sZFofT",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693026225326] [36m[OPENAI] Chat completion took 181.21937501430511ms[39m
[1693026225326] [36m[OPENAI] Tokens per second: 5.518173759958403tps[39m
[1693026225326] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225326] {
  "id": "chatcmpl-7olV8zsVjzFPFnewm1LRc1ydBVcKx",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693026225326] [36m[OPENAI] Chat completion took 181.55508399009705ms[39m
[1693026225326] [36m[OPENAI] Tokens per second: 5.507970242543829tps[39m
[1693026225326] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225326] {
  "id": "chatcmpl-7olV7rSM98c3wrV6ENTUmLwnKbwbw",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 93,
    "completion_tokens": 1,
    "total_tokens": 94
  }
}
[1693026225326] [36m[OPENAI] Chat completion took 189.10320901870728ms[39m
[1693026225326] [36m[OPENAI] Tokens per second: 5.2881175586030045tps[39m
[1693026225326] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225326] {
  "id": "chatcmpl-7olV7awQY0r1Z91TRQqy3X3sCOCtl",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693026225326] [36m[OPENAI] Chat completion took 181.79770803451538ms[39m
[1693026225326] [36m[OPENAI] Tokens per second: 5.50061940170414tps[39m
[1693026225326] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225327] [32m[OPENAI] Embedding created successfully.[39m
[1693026225327] {
  "id": "chatcmpl-7olV7j8jI4CsLNROmVW204qB21XOS",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "8"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693026225327] [36m[OPENAI] Chat completion took 182.45795899629593ms[39m
[1693026225327] [36m[OPENAI] Tokens per second: 5.480714601330715tps[39m
[1693026225327] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225327] {
  "id": "chatcmpl-7olV8kkS3FTnii4MmY8ia64SJ6LNI",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693026225327] [36m[OPENAI] Chat completion took 182.77754199504852ms[39m
[1693026225327] [36m[OPENAI] Tokens per second: 5.471131677802572tps[39m
[1693026225327] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225329] {
  "id": "chatcmpl-7olV8OlY5ASbWrYxYLt8a45Y4PR3r",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693026225329] [36m[OPENAI] Chat completion took 184.64416599273682ms[39m
[1693026225329] [36m[OPENAI] Tokens per second: 5.415822344689386tps[39m
[1693026225329] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225330] {
  "id": "chatcmpl-7olV8GJ1IBvPgWmgYv1XGPV02YStQ",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1693026225330] [36m[OPENAI] Chat completion took 185.80916702747345ms[39m
[1693026225330] [36m[OPENAI] Tokens per second: 5.381865792725618tps[39m
[1693026225330] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225331] {
  "id": "chatcmpl-7omMfa2PRcUpPT5rniqV1aVs7hJcX",
  "object": "chat.completion",
  "created": 1692336669,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693026225331] [36m[OPENAI] Chat completion took 186.28795897960663ms[39m
[1693026225331] [36m[OPENAI] Tokens per second: 5.368033476116792tps[39m
[1693026225331] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225332] {
  "id": "chatcmpl-7olV8fN3fq9UpfWvSUTEp2NY38XF6",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 1,
    "total_tokens": 96
  }
}
[1693026225332] [36m[OPENAI] Chat completion took 187.25933402776718ms[39m
[1693026225332] [36m[OPENAI] Tokens per second: 5.340187741198086tps[39m
[1693026225332] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225332] [32m[OPENAI] Embedding created successfully.[39m
[1693026225336] [32m[OPENAI] Embedding created successfully.[39m
[1693026225337] [32m[OPENAI] Embedding created successfully.[39m
[1693026225338] [32m[OPENAI] Embedding created successfully.[39m
[1693026225339] [32m[OPENAI] Embedding created successfully.[39m
[1693026225341] {
  "id": "chatcmpl-7olV7xVky29QtP8jg94OIGF49l6Xh",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "6"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 94,
    "completion_tokens": 1,
    "total_tokens": 95
  }
}
[1693026225341] [36m[OPENAI] Chat completion took 204.20504200458527ms[39m
[1693026225341] [36m[OPENAI] Tokens per second: 4.897038732165809tps[39m
[1693026225341] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225344] [32m[OPENAI] Embedding created successfully.[39m
[1693026225345] {
  "id": "chatcmpl-7olV7APh60cRjJf0i5PmcQO8fTjfy",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 98,
    "completion_tokens": 1,
    "total_tokens": 99
  }
}
[1693026225345] [36m[OPENAI] Chat completion took 200.78270798921585ms[39m
[1693026225345] [36m[OPENAI] Tokens per second: 4.980508580717571tps[39m
[1693026225345] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225346] [32m[OPENAI] Embedding created successfully.[39m
[1693026225348] {
  "id": "chatcmpl-7olV7qLYI7cHxKdREfvGldBQMhoMt",
  "object": "chat.completion",
  "created": 1692333349,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 96,
    "completion_tokens": 1,
    "total_tokens": 97
  }
}
[1693026225348] [36m[OPENAI] Chat completion took 210.79308396577835ms[39m
[1693026225348] [36m[OPENAI] Tokens per second: 4.743988660284258tps[39m
[1693026225348] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225348] [32m[OPENAI] Embedding created successfully.[39m
[1693026225349] [32m[OPENAI] Embedding created successfully.[39m
[1693026225353] [32m[OPENAI] Embedding created successfully.[39m
[1693026225354] [32m[OPENAI] Embedding created successfully.[39m
[1693026225355] {
  "id": "chatcmpl-7olV85IQ0ZMhfMNYXgLMZ98Oqw7x9",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "7"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693026225355] [36m[OPENAI] Chat completion took 210.77995800971985ms[39m
[1693026225355] [36m[OPENAI] Tokens per second: 4.744284083944481tps[39m
[1693026225355] [32m[OPENAI] Chat completion created successfully.[39m
[1693026225356] [32m[OPENAI] Embedding created successfully.[39m
[1693026225358] [32m[OPENAI] Embedding created successfully.[39m
[1693026225358] [32m[OPENAI] Embedding created successfully.[39m
[1693026225359] [32m[OPENAI] Embedding created successfully.[39m
[1693026225360] [32m[OPENAI] Embedding created successfully.[39m
[1693026225365] [32m[OPENAI] Embedding created successfully.[39m
[1693026225373] [32m[OPENAI] Embedding created successfully.[39m
[1693026225378] [32m[OPENAI] Embedding created successfully.[39m
[1693026225380] [32m[OPENAI] Embedding created successfully.[39m
[1693026225381] [32m[OPENAI] Embedding created successfully.[39m
[1693026225390] [32m[OPENAI] Embedding created successfully.[39m
[1693026225398] [32m[OPENAI] Embedding created successfully.[39m
[1693026225421] [32m[OPENAI] Embedding created successfully.[39m
[1693026226176] {
  "id": "chatcmpl-7olV8T9DG4pPIxUCGEYVdp1hITHfT",
  "object": "chat.completion",
  "created": 1692333350,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 97,
    "completion_tokens": 1,
    "total_tokens": 98
  }
}
[1693026226176] [36m[OPENAI] Chat completion took 1096.6913340091705ms[39m
[1693026226177] [36m[OPENAI] Tokens per second: 0.9118335934545079tps[39m
[1693026226177] [32m[OPENAI] Chat completion created successfully.[39m
[1693026243503] [Main] WebSocket connection established
[1693026243776] [Character] Getting character: A5
[1693026243777] --- Observations received -- 
[1693026243778] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 42.12, Y: 5.77.",
  "time": 0.0199999921
}
[1693026243778] [Character] Getting character: A5
[1693026243778] --- Observations received -- 
[1693026243778] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Small) at X: 41.33658, Y: 13.99647.",
  "time": 0.0199999921
}
[1693026243778] [Character] Getting character: A5
[1693026243778] [Character] Getting character: A1
[1693026243779] --- Observations received -- 
[1693026243779] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 52.41, Y: 11.03.",
  "time": 0.0199999921
}
[1693026243779] [Character] Getting character: A1
[1693026243779] --- Observations received -- 
[1693026243779] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Chest at X: 50.52, Y: 14.5.",
  "time": 0.0199999921
}
[1693026243779] [Character] Getting character: A1
[1693026243779] --- Observations received -- 
[1693026243780] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 50.77, Y: 9.22.",
  "time": 0.0199999921
}
[1693026243780] [Character] Getting character: A1
[1693026243780] --- Observations received -- 
[1693026243780] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 47.72001, Y: 10.21.",
  "time": 0.0199999921
}
[1693026243780] [Character] Getting character: A1
[1693026243780] --- Observations received -- 
[1693026243780] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Stone Ore Deposit (Small) at X: 45.73, Y: 15.31.",
  "time": 0.0199999921
}
[1693026243780] [Character] Getting character: A1
[1693026243781] --- Observations received -- 
[1693026243781] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 45.24001, Y: 10.2.",
  "time": 0.0199999921
}
[1693026243781] [Character] Getting character: A1
[1693026243781] --- Observations received -- 
[1693026243781] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Stone Ore Deposit (Medium) at X: 46.05, Y: 17.85.",
  "time": 0.0199999921
}
[1693026243781] [Character] Getting character: A1
[1693026243851] [33m[OPENAI] Creating embedding...[39m
[1693026243881] [33m[OPENAI] Creating embedding...[39m
[1693026243907] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026243907] [33m[OPENAI] No functions provided.[39m
[1693026243907] [33m[OPENAI] Creating embedding...[39m
[1693026243907] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026243907] [33m[OPENAI] No functions provided.[39m
[1693026243907] [33m[OPENAI] Creating embedding...[39m
[1693026243913] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026243913] [33m[OPENAI] No functions provided.[39m
[1693026243914] [33m[OPENAI] Creating embedding...[39m
[1693026243914] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026243914] [33m[OPENAI] No functions provided.[39m
[1693026243914] [33m[OPENAI] Creating embedding...[39m
[1693026243916] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026243916] [33m[OPENAI] No functions provided.[39m
[1693026243916] [33m[OPENAI] Creating embedding...[39m
[1693026243917] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026243917] [33m[OPENAI] No functions provided.[39m
[1693026243917] [33m[OPENAI] Creating embedding...[39m
[1693026243919] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026243919] [33m[OPENAI] No functions provided.[39m
[1693026243919] [33m[OPENAI] Creating embedding...[39m
[1693026243942] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026243942] [33m[OPENAI] No functions provided.[39m
[1693026243942] [33m[OPENAI] Creating embedding...[39m
[1693026243942] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026243942] [33m[OPENAI] No functions provided.[39m
[1693026243942] [33m[OPENAI] Creating embedding...[39m
[1693026244058] {
  "id": "chatcmpl-7olYVPZO2hJ85fnP0AXelCHaux4jx",
  "object": "chat.completion",
  "created": 1692333559,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693026244059] [36m[OPENAI] Chat completion took 150.9813750386238ms[39m
[1693026244059] [36m[OPENAI] Tokens per second: 6.623333505501468tps[39m
[1693026244059] [32m[OPENAI] Chat completion created successfully.[39m
[1693026244071] {
  "id": "chatcmpl-7olZFcOED2ldUw4M9Rg9y1NUOOc8o",
  "object": "chat.completion",
  "created": 1692333605,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693026244071] [36m[OPENAI] Chat completion took 163.18412500619888ms[39m
[1693026244071] [36m[OPENAI] Tokens per second: 6.128047075424848tps[39m
[1693026244071] [32m[OPENAI] Chat completion created successfully.[39m
[1693026244075] {
  "id": "chatcmpl-7olYxD42manfyujIaUwmUKUVV7thF",
  "object": "chat.completion",
  "created": 1692333587,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693026244076] [36m[OPENAI] Chat completion took 158.315249979496ms[39m
[1693026244077] [36m[OPENAI] Tokens per second: 6.316510886535022tps[39m
[1693026244077] [32m[OPENAI] Chat completion created successfully.[39m
[1693026244080] {
  "id": "chatcmpl-7olYVT6GzRUKaYf3QTh5Q0qrIhfvi",
  "object": "chat.completion",
  "created": 1692333559,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693026244080] [36m[OPENAI] Chat completion took 164.29066598415375ms[39m
[1693026244080] [36m[OPENAI] Tokens per second: 6.0867730616933065tps[39m
[1693026244080] [32m[OPENAI] Chat completion created successfully.[39m
[1693026244081] [32m[OPENAI] Embedding created successfully.[39m
[1693026244084] [32m[OPENAI] Embedding created successfully.[39m
[1693026244103] {
  "id": "chatcmpl-7omSvZYm5TmWnrVrXwRvtB0Z021Ud",
  "object": "chat.completion",
  "created": 1692337057,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693026244104] [36m[OPENAI] Chat completion took 189.69379204511642ms[39m
[1693026244104] [36m[OPENAI] Tokens per second: 5.2716538017341215tps[39m
[1693026244104] [32m[OPENAI] Chat completion created successfully.[39m
[1693026244105] [32m[OPENAI] Embedding created successfully.[39m
[1693026244110] {
  "id": "chatcmpl-7olYVWXT6KrquvJUsdoiU5pSZNMhm",
  "object": "chat.completion",
  "created": 1692333559,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693026244110] [36m[OPENAI] Chat completion took 167.97949999570847ms[39m
[1693026244110] [36m[OPENAI] Tokens per second: 5.953107373373227tps[39m
[1693026244110] [32m[OPENAI] Chat completion created successfully.[39m
[1693026244114] [32m[OPENAI] Embedding created successfully.[39m
[1693026244117] [32m[OPENAI] Embedding created successfully.[39m
[1693026244119] {
  "id": "chatcmpl-7olYVK3ubcflhZofq80hFwcKqzbWN",
  "object": "chat.completion",
  "created": 1692333559,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693026244119] [36m[OPENAI] Chat completion took 176.6780419945717ms[39m
[1693026244119] [36m[OPENAI] Tokens per second: 5.660012917908182tps[39m
[1693026244119] [32m[OPENAI] Chat completion created successfully.[39m
[1693026244119] [32m[OPENAI] Embedding created successfully.[39m
[1693026244121] {
  "id": "chatcmpl-7olYVI3RVsgz8WaPuEEOUclMtbGzx",
  "object": "chat.completion",
  "created": 1692333559,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693026244121] [36m[OPENAI] Chat completion took 201.93670803308487ms[39m
[1693026244121] [36m[OPENAI] Tokens per second: 4.952046657293048tps[39m
[1693026244121] [32m[OPENAI] Chat completion created successfully.[39m
[1693026244126] [32m[OPENAI] Embedding created successfully.[39m
[1693026244128] [32m[OPENAI] Embedding created successfully.[39m
[1693026244138] {
  "id": "chatcmpl-7olYVTuEhtnoU81vyRAZAiSxNxkT3",
  "object": "chat.completion",
  "created": 1692333559,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693026244138] [36m[OPENAI] Chat completion took 220.15154099464417ms[39m
[1693026244138] [36m[OPENAI] Tokens per second: 4.542325688396285tps[39m
[1693026244138] [32m[OPENAI] Chat completion created successfully.[39m
[1693026244139] [32m[OPENAI] Embedding created successfully.[39m
[1693026244153] [32m[OPENAI] Embedding created successfully.[39m
[1693026244167] [32m[OPENAI] Embedding created successfully.[39m
[1693026244598] [33m[OPENAI] Creating embedding...[39m
[1693026244721] [33m[OPENAI] Creating embedding...[39m
[1693026244789] [32m[OPENAI] Embedding created successfully.[39m
[1693026244916] [32m[OPENAI] Embedding created successfully.[39m
[1693026245221] [33m[OPENAI] Creating embedding...[39m
[1693026245353] [32m[OPENAI] Embedding created successfully.[39m
[1693026245386] [33m[OPENAI] Creating embedding...[39m
[1693026245433] [32m[OPENAI] Embedding created successfully.[39m
[1693026245678] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026245678] [33m[OPENAI] No functions provided.[39m
[1693026245844] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026245844] [33m[OPENAI] No functions provided.[39m
[1693026255706] {
  "id": "chatcmpl-7rfkrcgRjrl3SWaEJd6f4q5ynZbUV",
  "object": "chat.completion",
  "created": 1693026245,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "[\n  {\n    \"task\": \"Eat the berries\",\n    \"priority\": 1\n  },\n  {\n    \"task\": \"Collect wood and stone resources using axe and pickaxe\",\n    \"priority\": 2\n  },\n  {\n    \"task\": \"Explore the surrounding area\",\n    \"priority\": 3\n  },\n  {\n    \"task\": \"Maintain a healthy lifestyle\",\n    \"priority\": 4\n  },\n  {\n    \"task\": \"Catch up with other villagers\",\n    \"priority\": 5\n  },\n  {\n    \"task\": \"Visit the secret clearing in the woods\",\n    \"priority\": 6\n  }\n]"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 968,
    "completion_tokens": 138,
    "total_tokens": 1106
  }
}
[1693026255706] [36m[OPENAI] Chat completion took 10027.400833010674ms[39m
[1693026255706] [36m[OPENAI] Tokens per second: 13.762290178497455tps[39m
[1693026255706] [32m[OPENAI] Chat completion created successfully.[39m
[1693026255708] [Character] Getting character: A5
[1693026255774] [33m[OPENAI] Creating embedding...[39m
[1693026255975] [32m[OPENAI] Embedding created successfully.[39m
[1693026256472] [33m[OPENAI] Creating embedding...[39m
[1693026256819] [32m[OPENAI] Embedding created successfully.[39m
[1693026257234] [33m[OPENAI] Creating embedding...[39m
[1693026257428] [32m[OPENAI] Embedding created successfully.[39m
[1693026257768] [33m[OPENAI] Creating embedding...[39m
[1693026257810] [32m[OPENAI] Embedding created successfully.[39m
[1693026258183] [33m[OPENAI] Creating embedding...[39m
[1693026258218] [32m[OPENAI] Embedding created successfully.[39m
[1693026258574] [33m[OPENAI] Creating embedding...[39m
[1693026258767] [32m[OPENAI] Embedding created successfully.[39m
[1693026259182] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026259183] [33m[OPENAI] Using 6 functions.[39m
[1693026261415] {
  "id": "chatcmpl-7rfl5FdWW391dCYicvnvWNUFYxbJv",
  "object": "chat.completion",
  "created": 1693026259,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "eat",
          "arguments": "{\n  \"characterId\": \"A5\",\n  \"foodId\": \"berries\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1321,
    "completion_tokens": 25,
    "total_tokens": 1346
  }
}
[1693026261415] [36m[OPENAI] Chat completion took 2232.3598330020905ms[39m
[1693026261415] [36m[OPENAI] Tokens per second: 11.198911407745522tps[39m
[1693026261415] [32m[OPENAI] Chat completion created successfully.[39m
[1693026261482] [Character] Getting character: A5
[1693026261556] [33m[OPENAI] Creating embedding...[39m
[1693026261600] [32m[OPENAI] Embedding created successfully.[39m
[1693026262028] [33m[OPENAI] Creating embedding...[39m
[1693026262066] [32m[OPENAI] Embedding created successfully.[39m
[1693026262434] [33m[OPENAI] Creating embedding...[39m
[1693026262479] [32m[OPENAI] Embedding created successfully.[39m
[1693026262792] [33m[OPENAI] Creating embedding...[39m
[1693026262848] [32m[OPENAI] Embedding created successfully.[39m
[1693026263158] [33m[OPENAI] Creating embedding...[39m
[1693026263199] [32m[OPENAI] Embedding created successfully.[39m
[1693026263516] [33m[OPENAI] Creating embedding...[39m
[1693026263554] [32m[OPENAI] Embedding created successfully.[39m
[1693026263817] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026263817] [33m[OPENAI] Using 4 functions.[39m
[1693026264296] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026264297] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026264297] [31mFailed to create chat completion. Retrying...[39m
[1693026264297] [33m[OPENAI] No functions provided.[39m
[1693026264354] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026264354] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026264354] [31mFailed to create chat completion. Retrying...[39m
[1693026264354] [33m[OPENAI] No functions provided.[39m
[1693026264385] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026264385] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026264385] [31mFailed to create chat completion. Retrying...[39m
[1693026264385] [33m[OPENAI] No functions provided.[39m
[1693026264443] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026264445] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026264445] [31mFailed to create chat completion. Retrying...[39m
[1693026264445] [33m[OPENAI] No functions provided.[39m
[1693026264490] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026264490] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026264490] [31mFailed to create chat completion. Retrying...[39m
[1693026264496] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026264496] [33m[OPENAI] No functions provided.[39m
[1693026264529] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026264529] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026264529] [31mFailed to create chat completion. Retrying...[39m
[1693026264530] [33m[OPENAI] No functions provided.[39m
[1693026264567] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026264568] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026264568] [31mFailed to create chat completion. Retrying...[39m
[1693026264568] [33m[OPENAI] No functions provided.[39m
[1693026264606] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026264606] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026264606] [31mFailed to create chat completion. Retrying...[39m
[1693026264606] [33m[OPENAI] No functions provided.[39m
[1693026264643] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026264643] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026264643] [31mFailed to create chat completion. Retrying...[39m
[1693026264643] [33m[OPENAI] No functions provided.[39m
[1693026264688] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026264689] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026264689] [31mFailed to create chat completion. Retrying...[39m
[1693026264690] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026264690] [33m[OPENAI] No functions provided.[39m
[1693026264726] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026264726] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026264726] [31mFailed to create chat completion. Retrying...[39m
[1693026264726] [33m[OPENAI] No functions provided.[39m
[1693026264767] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026264767] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026264767] [31mFailed to create chat completion. Retrying...[39m
[1693026264767] [33m[OPENAI] No functions provided.[39m
[1693026264809] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026264809] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026264809] [31mFailed to create chat completion. Retrying...[39m
[1693026264809] [33m[OPENAI] No functions provided.[39m
[1693026264848] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026264849] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026264849] [31mFailed to create chat completion. Retrying...[39m
[1693026264849] [33m[OPENAI] No functions provided.[39m
[1693026264890] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026264890] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026264890] [31mFailed to create chat completion. Retrying...[39m
[1693026264891] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026264891] [33m[OPENAI] No functions provided.[39m
[1693026264924] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026264924] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026264924] [31mFailed to create chat completion. Retrying...[39m
[1693026264924] [33m[OPENAI] No functions provided.[39m
[1693026264955] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026264956] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026264956] [31mFailed to create chat completion. Retrying...[39m
[1693026264956] [33m[OPENAI] No functions provided.[39m
[1693026264994] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026264994] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026264995] [31mFailed to create chat completion. Retrying...[39m
[1693026264995] [33m[OPENAI] No functions provided.[39m
[1693026265030] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265030] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265033] [31mFailed to create chat completion. Retrying...[39m
[1693026265033] [33m[OPENAI] No functions provided.[39m
[1693026265070] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265070] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265070] [31mFailed to create chat completion. Retrying...[39m
[1693026265072] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026265072] [33m[OPENAI] No functions provided.[39m
[1693026265119] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265120] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265120] [31mFailed to create chat completion. Retrying...[39m
[1693026265120] [33m[OPENAI] No functions provided.[39m
[1693026265153] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265153] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265153] [31mFailed to create chat completion. Retrying...[39m
[1693026265153] [33m[OPENAI] No functions provided.[39m
[1693026265185] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265186] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265186] [31mFailed to create chat completion. Retrying...[39m
[1693026265186] [33m[OPENAI] No functions provided.[39m
[1693026265223] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265224] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265224] [31mFailed to create chat completion. Retrying...[39m
[1693026265224] [33m[OPENAI] No functions provided.[39m
[1693026265256] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265256] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265256] [31mFailed to create chat completion. Retrying...[39m
[1693026265256] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026265256] [33m[OPENAI] No functions provided.[39m
[1693026265292] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265292] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265292] [31mFailed to create chat completion. Retrying...[39m
[1693026265292] [33m[OPENAI] No functions provided.[39m
[1693026265325] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265325] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265325] [31mFailed to create chat completion. Retrying...[39m
[1693026265325] [33m[OPENAI] No functions provided.[39m
[1693026265365] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265365] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265365] [31mFailed to create chat completion. Retrying...[39m
[1693026265365] [33m[OPENAI] No functions provided.[39m
[1693026265399] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265399] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265400] [31mFailed to create chat completion. Retrying...[39m
[1693026265400] [33m[OPENAI] No functions provided.[39m
[1693026265462] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265462] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265462] [31mFailed to create chat completion. Retrying...[39m
[1693026265464] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026265464] [33m[OPENAI] No functions provided.[39m
[1693026265495] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265496] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265496] [31mFailed to create chat completion. Retrying...[39m
[1693026265496] [33m[OPENAI] No functions provided.[39m
[1693026265529] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265530] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265530] [31mFailed to create chat completion. Retrying...[39m
[1693026265530] [33m[OPENAI] No functions provided.[39m
[1693026265562] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265563] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265563] [31mFailed to create chat completion. Retrying...[39m
[1693026265563] [33m[OPENAI] No functions provided.[39m
[1693026265606] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265607] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265607] [31mFailed to create chat completion. Retrying...[39m
[1693026265608] [33m[OPENAI] No functions provided.[39m
[1693026265643] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265643] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265643] [31mFailed to create chat completion. Retrying...[39m
[1693026265653] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026265653] [33m[OPENAI] No functions provided.[39m
[1693026265689] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265696] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265697] [31mFailed to create chat completion. Retrying...[39m
[1693026265697] [33m[OPENAI] No functions provided.[39m
[1693026265729] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265729] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265729] [31mFailed to create chat completion. Retrying...[39m
[1693026265730] [33m[OPENAI] No functions provided.[39m
[1693026265764] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265765] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265765] [31mFailed to create chat completion. Retrying...[39m
[1693026265765] [33m[OPENAI] No functions provided.[39m
[1693026265800] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265800] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265800] [31mFailed to create chat completion. Retrying...[39m
[1693026265800] [33m[OPENAI] No functions provided.[39m
[1693026265834] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265835] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265835] [31mFailed to create chat completion. Retrying...[39m
[1693026265836] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026265836] [33m[OPENAI] No functions provided.[39m
[1693026265884] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265885] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265885] [31mFailed to create chat completion. Retrying...[39m
[1693026265885] [33m[OPENAI] No functions provided.[39m
[1693026265931] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265932] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265932] [31mFailed to create chat completion. Retrying...[39m
[1693026265932] [33m[OPENAI] No functions provided.[39m
[1693026265962] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265962] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265962] [31mFailed to create chat completion. Retrying...[39m
[1693026265962] [33m[OPENAI] No functions provided.[39m
[1693026265993] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026265993] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026265993] [31mFailed to create chat completion. Retrying...[39m
[1693026265993] [33m[OPENAI] No functions provided.[39m
[1693026266024] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026266025] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026266025] [31mFailed to create chat completion. Retrying...[39m
[1693026266026] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026266026] [33m[OPENAI] No functions provided.[39m
[1693026266056] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026266056] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026266056] [31mFailed to create chat completion. Retrying...[39m
[1693026266056] [33m[OPENAI] No functions provided.[39m
[1693026266087] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026266089] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026266089] [31mFailed to create chat completion. Retrying...[39m
[1693026266089] [33m[OPENAI] No functions provided.[39m
[1693026266125] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026266126] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026266126] [31mFailed to create chat completion. Retrying...[39m
[1693026266126] [33m[OPENAI] No functions provided.[39m
[1693026266159] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026266159] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026266159] [31mFailed to create chat completion. Retrying...[39m
[1693026266159] [33m[OPENAI] No functions provided.[39m
[1693026266199] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1",
  "type": "invalid-json"
}
[1693026266200] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected non-whitespace character after JSON at position 1[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:58:28)[39m
[31m    at async updateTaskList (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:136:30)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:175:9)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026266200] [31mFailed to create chat completion. Retrying...[39m
[1693026266201] [Character] Getting character: A1
[1693026266265] [33m[OPENAI] Creating embedding...[39m
[1693026266300] [32m[OPENAI] Embedding created successfully.[39m
[1693026266680] [33m[OPENAI] Creating embedding...[39m
[1693026266720] [32m[OPENAI] Embedding created successfully.[39m
[1693026267103] [33m[OPENAI] Creating embedding...[39m
[1693026267139] [32m[OPENAI] Embedding created successfully.[39m
[1693026267425] {
  "id": "chatcmpl-7rfl9bP4TlghB53PQD0Zm4bMObJxg",
  "object": "chat.completion",
  "created": 1693026263,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 41.33658,\n  \"y\": 13.99647\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1223,
    "completion_tokens": 37,
    "total_tokens": 1260
  }
}
[1693026267425] [36m[OPENAI] Chat completion took 3608.2981249690056ms[39m
[1693026267425] [36m[OPENAI] Tokens per second: 10.254141625372993tps[39m
[1693026267425] [32m[OPENAI] Chat completion created successfully.[39m
[1693026267452] --- Observations received -- 
[1693026267452] {
  "observerId": "A5",
  "observation": "Eli Green has started walking to 41.33658, Y: 13.99647.",
  "time": 23.7191849
}
[1693026267452] [Character] Getting character: A5
[1693026267482] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026267482] [33m[OPENAI] Using 6 functions.[39m
[1693026267548] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026267548] [33m[OPENAI] No functions provided.[39m
[1693026267548] [33m[OPENAI] Creating embedding...[39m
[1693026267665] --- Observations received -- 
[1693026267666] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Small) at X: 38.24, Y: 15.93.",
  "time": 23.9407883
}
[1693026267666] [Character] Getting character: A5
[1693026267739] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026267739] [33m[OPENAI] No functions provided.[39m
[1693026267739] [33m[OPENAI] Creating embedding...[39m
[1693026267788] [32m[OPENAI] Embedding created successfully.[39m
[1693026267805] {
  "id": "chatcmpl-7on2evystqnriuxaBN3cCOCey3Ndc",
  "object": "chat.completion",
  "created": 1692339272,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693026267805] [36m[OPENAI] Chat completion took 256.77837496995926ms[39m
[1693026267805] [36m[OPENAI] Tokens per second: 3.8944089435763076tps[39m
[1693026267805] [32m[OPENAI] Chat completion created successfully.[39m
[1693026267849] --- Observations received -- 
[1693026267850] {
  "observerId": "A5",
  "observation": "Eli Green sees Tree at X: 45.24001, Y: 10.2.",
  "time": 24.1247749
}
[1693026267850] [Character] Getting character: A5
[1693026267851] --- Observations received -- 
[1693026267851] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees Tree (205) at X: 42.12, Y: 5.77",
  "time": 24.1247749
}
[1693026267851] [Character] Getting character: A5
[1693026267918] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026267918] [33m[OPENAI] No functions provided.[39m
[1693026267918] [33m[OPENAI] Creating embedding...[39m
[1693026267931] {
  "id": "chatcmpl-7on2h1jUrrcqLkZw9D3AW6HlZOeAK",
  "object": "chat.completion",
  "created": 1692339275,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693026267931] [36m[OPENAI] Chat completion took 191.57520800828934ms[39m
[1693026267931] [36m[OPENAI] Tokens per second: 5.219882104769687tps[39m
[1693026267931] [32m[OPENAI] Chat completion created successfully.[39m
[1693026267942] [32m[OPENAI] Embedding created successfully.[39m
[1693026267948] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026267948] [33m[OPENAI] No functions provided.[39m
[1693026267948] [33m[OPENAI] Creating embedding...[39m
[1693026268099] {
  "id": "chatcmpl-7omS1GiIXh2zBhSl8lisOT4Hv8UzZ",
  "object": "chat.completion",
  "created": 1692337001,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693026268099] [36m[OPENAI] Chat completion took 181.34329199790955ms[39m
[1693026268099] [36m[OPENAI] Tokens per second: 5.51440303626741tps[39m
[1693026268099] [32m[OPENAI] Chat completion created successfully.[39m
[1693026268114] {
  "id": "chatcmpl-7olYyEUNGIv9pM6OPK8j5Dz1admz6",
  "object": "chat.completion",
  "created": 1692333588,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693026268114] [36m[OPENAI] Chat completion took 165.6586670279503ms[39m
[1693026268114] [36m[OPENAI] Tokens per second: 6.036508792089205tps[39m
[1693026268114] [32m[OPENAI] Chat completion created successfully.[39m
[1693026268115] [32m[OPENAI] Embedding created successfully.[39m
[1693026268135] [32m[OPENAI] Embedding created successfully.[39m
[1693026268606] --- Observations received -- 
[1693026268606] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Medium) at X: 42.53862, Y: 17.00157.",
  "time": 24.88097
}
[1693026268606] [Character] Getting character: A5
[1693026268669] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026268669] [33m[OPENAI] No functions provided.[39m
[1693026268669] [33m[OPENAI] Creating embedding...[39m
[1693026268832] {
  "id": "chatcmpl-7omSxVO1Sj1YPeEhz2gtTZh1zWGM7",
  "object": "chat.completion",
  "created": 1692337059,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693026268833] [36m[OPENAI] Chat completion took 145.70762503147125ms[39m
[1693026268833] [36m[OPENAI] Tokens per second: 6.863058812358042tps[39m
[1693026268833] [32m[OPENAI] Chat completion created successfully.[39m
[1693026268836] [32m[OPENAI] Embedding created successfully.[39m
[1693026269345] --- Observations received -- 
[1693026269345] {
  "observerId": "A5",
  "observation": "Eli Green no longer sees Tree (479) at X: 45.24001, Y: 10.2",
  "time": 25.6203346
}
[1693026269345] [Character] Getting character: A5
[1693026269410] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026269410] [33m[OPENAI] No functions provided.[39m
[1693026269410] [33m[OPENAI] Creating embedding...[39m
[1693026269556] {
  "id": "chatcmpl-7omSS4n5sqmhXJdvxH1P3zLO00w5J",
  "object": "chat.completion",
  "created": 1692337028,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693026269557] [36m[OPENAI] Chat completion took 146.16412496566772ms[39m
[1693026269557] [36m[OPENAI] Tokens per second: 6.841624100543745tps[39m
[1693026269557] [32m[OPENAI] Chat completion created successfully.[39m
[1693026269586] --- Observations received -- 
[1693026269586] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Medium) at X: 38.03, Y: 18.78.",
  "time": 25.8606548
}
[1693026269586] [Character] Getting character: A5
[1693026269609] [32m[OPENAI] Embedding created successfully.[39m
[1693026269651] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026269651] [33m[OPENAI] No functions provided.[39m
[1693026269651] [33m[OPENAI] Creating embedding...[39m
[1693026269728] {
  "id": "chatcmpl-7rflDvmh8gIjMBoR27EAVOgGc1hKY",
  "object": "chat.completion",
  "created": 1693026267,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "eat",
          "arguments": "{\n  \"characterId\": \"A1\",\n  \"foodId\": \"berries\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1497,
    "completion_tokens": 25,
    "total_tokens": 1522
  }
}
[1693026269728] [36m[OPENAI] Chat completion took 2245.4413329958916ms[39m
[1693026269728] [36m[OPENAI] Tokens per second: 11.133668750385358tps[39m
[1693026269728] [32m[OPENAI] Chat completion created successfully.[39m
[1693026269750] [Character] Getting character: A1
[1693026269784] [33m[OPENAI] Creating embedding...[39m
[1693026269793] {
  "id": "chatcmpl-7on2j8uwH2aW7sCO2uSGCJXnN334P",
  "object": "chat.completion",
  "created": 1692339277,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693026269793] [36m[OPENAI] Chat completion took 141.50112503767014ms[39m
[1693026269793] [36m[OPENAI] Tokens per second: 7.067081620261197tps[39m
[1693026269793] [32m[OPENAI] Chat completion created successfully.[39m
[1693026269817] [32m[OPENAI] Embedding created successfully.[39m
[1693026269818] [32m[OPENAI] Embedding created successfully.[39m
[1693026269967] --- Observations received -- 
[1693026269967] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Small) at X: 45.73, Y: 15.31.",
  "time": 26.2416821
}
[1693026269967] [Character] Getting character: A5
[1693026269969] --- Observations received -- 
[1693026269969] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Large) at X: 40.75, Y: 19.74.",
  "time": 26.2416821
}
[1693026269969] [Character] Getting character: A5
[1693026270051] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026270051] [33m[OPENAI] No functions provided.[39m
[1693026270051] [33m[OPENAI] Creating embedding...[39m
[1693026270079] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026270079] [33m[OPENAI] No functions provided.[39m
[1693026270079] [33m[OPENAI] Creating embedding...[39m
[1693026270188] [33m[OPENAI] Creating embedding...[39m
[1693026270201] {
  "id": "chatcmpl-7omSx4Y4AaHV98EAI198ik0d3LtIF",
  "object": "chat.completion",
  "created": 1692337059,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693026270201] [36m[OPENAI] Chat completion took 150.2281669974327ms[39m
[1693026270201] [36m[OPENAI] Tokens per second: 6.6565413130354525tps[39m
[1693026270201] [32m[OPENAI] Chat completion created successfully.[39m
[1693026270235] {
  "id": "chatcmpl-7on2jSx97vTlRg0CtQd8Gm154sfJx",
  "object": "chat.completion",
  "created": 1692339277,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693026270235] [36m[OPENAI] Chat completion took 153.35191702842712ms[39m
[1693026270235] [36m[OPENAI] Tokens per second: 6.520948804406718tps[39m
[1693026270236] [32m[OPENAI] Chat completion created successfully.[39m
[1693026270240] [32m[OPENAI] Embedding created successfully.[39m
[1693026270241] [32m[OPENAI] Embedding created successfully.[39m
[1693026270269] [32m[OPENAI] Embedding created successfully.[39m
[1693026270603] [33m[OPENAI] Creating embedding...[39m
[1693026270668] --- Observations received -- 
[1693026270669] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Medium) at X: 46.05, Y: 17.85.",
  "time": 26.939991
}
[1693026270669] [Character] Getting character: A5
[1693026270769] --- Observations received -- 
[1693026270770] {
  "observerId": "A5",
  "observation": "Eli Green finished walking to 41.33658, Y: 13.99647.",
  "time": 27.01999
}
[1693026270770] [Character] Getting character: A5
[1693026270770] [Character] Getting character: A5
[1693026270770] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026270770] [33m[OPENAI] No functions provided.[39m
[1693026270770] [33m[OPENAI] Creating embedding...[39m
[1693026270771] [32m[OPENAI] Embedding created successfully.[39m
[1693026270840] [33m[OPENAI] Creating embedding...[39m
[1693026270877] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026270877] [33m[OPENAI] No functions provided.[39m
[1693026270877] [33m[OPENAI] Creating embedding...[39m
[1693026270880] [32m[OPENAI] Embedding created successfully.[39m
[1693026270932] {
  "id": "chatcmpl-7omSzs7AJfRvbjeCFQOaZ3nAsowKH",
  "object": "chat.completion",
  "created": 1692337061,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693026270932] [36m[OPENAI] Chat completion took 161.79237496852875ms[39m
[1693026270932] [36m[OPENAI] Tokens per second: 6.180760991947341tps[39m
[1693026270932] [32m[OPENAI] Chat completion created successfully.[39m
[1693026270970] [32m[OPENAI] Embedding created successfully.[39m
[1693026271084] [32m[OPENAI] Embedding created successfully.[39m
[1693026271112] {
  "id": "chatcmpl-7on2jSRWHdDW8n4fghcYXkqV3VMbc",
  "object": "chat.completion",
  "created": 1692339277,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693026271112] [36m[OPENAI] Chat completion took 235.4897499680519ms[39m
[1693026271113] [36m[OPENAI] Tokens per second: 4.246469326735735tps[39m
[1693026271113] [32m[OPENAI] Chat completion created successfully.[39m
[1693026271144] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026271145] [33m[OPENAI] Using 4 functions.[39m
[1693026271284] [33m[OPENAI] Creating embedding...[39m
[1693026271460] [32m[OPENAI] Embedding created successfully.[39m
[1693026271802] [33m[OPENAI] Creating embedding...[39m
[1693026272004] [32m[OPENAI] Embedding created successfully.[39m
[1693026272353] [33m[OPENAI] Creating embedding...[39m
[1693026272490] [32m[OPENAI] Embedding created successfully.[39m
[1693026272855] [33m[OPENAI] Creating embedding...[39m
[1693026272993] [32m[OPENAI] Embedding created successfully.[39m
[1693026273359] [33m[OPENAI] Creating embedding...[39m
[1693026273526] [32m[OPENAI] Embedding created successfully.[39m
[1693026273856] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026273856] [33m[OPENAI] Using 7 functions.[39m
[1693026274141] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!�\b\u0000 J���Q\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026274142] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!�  J���Q"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026274142] [31mFailed to create chat completion. Retrying...[39m
[1693026274142] [33m[OPENAI] Using 4 functions.[39m
[1693026275904] {
  "id": "chatcmpl-7rflJguvea7pVdgGo7Yah7bMlj1gU",
  "object": "chat.completion",
  "created": 1693026273,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_pickaxe",
          "arguments": "{\n  \"characterId\": \"A5\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1567,
    "completion_tokens": 18,
    "total_tokens": 1585
  }
}
[1693026275904] [36m[OPENAI] Chat completion took 2047.4888749718666ms[39m
[1693026275904] [36m[OPENAI] Tokens per second: 8.7912565582303tps[39m
[1693026275904] [32m[OPENAI] Chat completion created successfully.[39m
[1693026276535] --- Observations received -- 
[1693026276536] {
  "observerId": "A5",
  "observation": "Eli Green picked up Stone at X: 41.20406, Y: 14.52373",
  "time": 32.8102875
}
[1693026276536] [Character] Getting character: A5
[1693026276612] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026276612] [33m[OPENAI] No functions provided.[39m
[1693026276613] [33m[OPENAI] Creating embedding...[39m
[1693026276742] {
  "id": "chatcmpl-7pqzJ32NF63KdXjNplqfoO7yR0L5x",
  "object": "chat.completion",
  "created": 1692592769,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693026276742] [36m[OPENAI] Chat completion took 128.4567499756813ms[39m
[1693026276742] [36m[OPENAI] Tokens per second: 7.784721318181523tps[39m
[1693026276742] [32m[OPENAI] Chat completion created successfully.[39m
[1693026276849] [32m[OPENAI] Embedding created successfully.[39m
[1693026276925] [Character] Getting character: A5
[1693026276987] [33m[OPENAI] Creating embedding...[39m
[1693026277215] [32m[OPENAI] Embedding created successfully.[39m
[1693026277283] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!�\b\u0000 FΕ�Q;\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026277284] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!�  FΕ�Q;"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026277284] [31mFailed to create chat completion. Retrying...[39m
[1693026277284] [33m[OPENAI] Using 4 functions.[39m
[1693026277330] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!�\b\u0000 J���Q\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026277331] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!�  J���Q"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026277331] [31mFailed to create chat completion. Retrying...[39m
[1693026277332] [33m[OPENAI] Using 4 functions.[39m
[1693026277376] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!�\b\u0000 J���Q\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026277377] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!�  J���Q"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026277377] [31mFailed to create chat completion. Retrying...[39m
[1693026277384] [33m[OPENAI] Using 4 functions.[39m
[1693026277430] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!�\b\u0000 FΕ�Q;\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026277434] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!�  FΕ�Q;"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026277436] [31mFailed to create chat completion. Retrying...[39m
[1693026277448] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026277448] [33m[OPENAI] Using 4 functions.[39m
[1693026277661] [33m[OPENAI] Creating embedding...[39m
[1693026277805] [32m[OPENAI] Embedding created successfully.[39m
[1693026278202] [33m[OPENAI] Creating embedding...[39m
[1693026278389] [32m[OPENAI] Embedding created successfully.[39m
[1693026278778] [33m[OPENAI] Creating embedding...[39m
[1693026278911] [32m[OPENAI] Embedding created successfully.[39m
[1693026279252] [33m[OPENAI] Creating embedding...[39m
[1693026279434] [32m[OPENAI] Embedding created successfully.[39m
[1693026279785] [33m[OPENAI] Creating embedding...[39m
[1693026279948] [32m[OPENAI] Embedding created successfully.[39m
[1693026280251] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!�\b\u0000 F�V��\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026280251] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!�  F�V��"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026280251] [31mFailed to create chat completion. Retrying...[39m
[1693026280254] [33m[OPENAI] Using 4 functions.[39m
[1693026280283] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026280292] [33m[OPENAI] Using 5 functions.[39m
[1693026282622] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!�\b\u0000 J���Q\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026282622] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!�  J���Q"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026282623] [31mFailed to create chat completion. Retrying...[39m
[1693026282623] [33m[OPENAI] Using 4 functions.[39m
[1693026282683] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!�\b\u0000 F�V��\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026282683] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!�  F�V��"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026282683] [31mFailed to create chat completion. Retrying...[39m
[1693026282684] [33m[OPENAI] Using 4 functions.[39m
[1693026282716] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!�\b\u0000 F�V��\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026282724] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!�  F�V��"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026282724] [31mFailed to create chat completion. Retrying...[39m
[1693026282724] [33m[OPENAI] Using 4 functions.[39m
[1693026282769] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!�\b\u0000 F�V��\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026282771] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!�  F�V��"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026282771] [31mFailed to create chat completion. Retrying...[39m
[1693026282776] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026282776] [33m[OPENAI] Using 4 functions.[39m
[1693026283082] {
  "id": "chatcmpl-7rflQiAPNCXcLrTksNz2RFkSqTmCI",
  "object": "chat.completion",
  "created": 1693026280,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A5\",\n  \"x\": 42.53862,\n  \"y\": 17.00157\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1521,
    "completion_tokens": 37,
    "total_tokens": 1558
  }
}
[1693026283082] [36m[OPENAI] Chat completion took 2799.167083978653ms[39m
[1693026283082] [36m[OPENAI] Tokens per second: 13.218217737616897tps[39m
[1693026283082] [32m[OPENAI] Chat completion created successfully.[39m
[1693026283094] --- Observations received -- 
[1693026283094] {
  "observerId": "A5",
  "observation": "Eli Green has started walking to 42.53862, Y: 17.00157.",
  "time": 39.3688354
}
[1693026283094] [Character] Getting character: A5
[1693026283160] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026283160] [33m[OPENAI] No functions provided.[39m
[1693026283160] [33m[OPENAI] Creating embedding...[39m
[1693026283314] {
  "id": "chatcmpl-7on37ED1xKeFXl9cjjgYCUPcWZNG0",
  "object": "chat.completion",
  "created": 1692339301,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693026283314] [36m[OPENAI] Chat completion took 154.71504199504852ms[39m
[1693026283314] [36m[OPENAI] Tokens per second: 6.463495644024088tps[39m
[1693026283314] [32m[OPENAI] Chat completion created successfully.[39m
[1693026283398] [32m[OPENAI] Embedding created successfully.[39m
[1693026283487] --- Observations received -- 
[1693026283488] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Large) at X: 44.3, Y: 20.36.",
  "time": 39.7628937
}
[1693026283488] [Character] Getting character: A5
[1693026283551] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026283554] [33m[OPENAI] No functions provided.[39m
[1693026283555] [33m[OPENAI] Creating embedding...[39m
[1693026283738] {
  "id": "chatcmpl-7on4TYnOWeWZSIdlCun5ySDJhMvFr",
  "object": "chat.completion",
  "created": 1692339385,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693026283739] [36m[OPENAI] Chat completion took 186.14633303880692ms[39m
[1693026283739] [36m[OPENAI] Tokens per second: 5.372117643550489tps[39m
[1693026283739] [32m[OPENAI] Chat completion created successfully.[39m
[1693026283815] [32m[OPENAI] Embedding created successfully.[39m
[1693026284388] --- Observations received -- 
[1693026284389] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Large) at X: 41.29, Y: 22.52.",
  "time": 40.66227
}
[1693026284389] [Character] Getting character: A5
[1693026284457] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026284461] [33m[OPENAI] No functions provided.[39m
[1693026284461] [33m[OPENAI] Creating embedding...[39m
[1693026284658] {
  "id": "chatcmpl-7on38VicHhsuetR0XOf5iYaC26qUU",
  "object": "chat.completion",
  "created": 1692339302,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693026284658] [36m[OPENAI] Chat completion took 200.85512501001358ms[39m
[1693026284658] [36m[OPENAI] Tokens per second: 4.978712890448502tps[39m
[1693026284658] [32m[OPENAI] Chat completion created successfully.[39m
[1693026284660] [32m[OPENAI] Embedding created successfully.[39m
[1693026285246] --- Observations received -- 
[1693026285246] {
  "observerId": "A5",
  "observation": "Eli Green sees Stone Ore Deposit (Small) at X: 47.58, Y: 19.17.",
  "time": 41.5212479
}
[1693026285246] [Character] Getting character: A5
[1693026285373] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026285373] [33m[OPENAI] No functions provided.[39m
[1693026285373] [33m[OPENAI] Creating embedding...[39m
[1693026285388] --- Observations received -- 
[1693026285388] {
  "observerId": "A5",
  "observation": "Eli Green finished walking to 42.53862, Y: 17.00157.",
  "time": 41.6599846
}
[1693026285388] [Character] Getting character: A5
[1693026285404] [Character] Getting character: A5
[1693026285435] [33m[OPENAI] Creating embedding...[39m
[1693026285451] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026285451] [33m[OPENAI] No functions provided.[39m
[1693026285452] [33m[OPENAI] Creating embedding...[39m
[1693026285512] [32m[OPENAI] Embedding created successfully.[39m
[1693026285518] {
  "id": "chatcmpl-7omT1RhEmeDvpxj8AaAwyEEsfAIRE",
  "object": "chat.completion",
  "created": 1692337063,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693026285518] [36m[OPENAI] Chat completion took 144.79179203510284ms[39m
[1693026285518] [36m[OPENAI] Tokens per second: 6.906468840150575tps[39m
[1693026285518] [32m[OPENAI] Chat completion created successfully.[39m
[1693026285564] [32m[OPENAI] Embedding created successfully.[39m
[1693026285634] {
  "id": "chatcmpl-7on39Pzzmfv2AbytFTs8ylh1LbPTU",
  "object": "chat.completion",
  "created": 1692339303,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 2,
    "total_tokens": 103
  }
}
[1693026285634] [36m[OPENAI] Chat completion took 182.3774589896202ms[39m
[1693026285634] [36m[OPENAI] Tokens per second: 10.966267493143588tps[39m
[1693026285634] [32m[OPENAI] Chat completion created successfully.[39m
[1693026285738] [32m[OPENAI] Embedding created successfully.[39m
[1693026285932] [33m[OPENAI] Creating embedding...[39m
[1693026286133] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!�\b\u0000 F���Q\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026286134] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!�  F���Q"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026286134] [31mFailed to create chat completion. Retrying...[39m
[1693026286134] [33m[OPENAI] Using 4 functions.[39m
[1693026286142] [32m[OPENAI] Embedding created successfully.[39m
[1693026286606] [33m[OPENAI] Creating embedding...[39m
[1693026286644] [32m[OPENAI] Embedding created successfully.[39m
[1693026287007] [33m[OPENAI] Creating embedding...[39m
[1693026287042] [32m[OPENAI] Embedding created successfully.[39m
[1693026287421] [33m[OPENAI] Creating embedding...[39m
[1693026287465] [32m[OPENAI] Embedding created successfully.[39m
[1693026287870] [33m[OPENAI] Creating embedding...[39m
[1693026287919] [32m[OPENAI] Embedding created successfully.[39m
[1693026288344] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026288344] [33m[OPENAI] Using 8 functions.[39m
[1693026288836] {
  "id": "chatcmpl-7rflW0oLeB8eeWKBvYPIwZdXdDtgT",
  "object": "chat.completion",
  "created": 1693026286,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A1\",\n  \"x\": 50.52,\n  \"y\": 14.5\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1399,
    "completion_tokens": 35,
    "total_tokens": 1434
  }
}
[1693026288836] [36m[OPENAI] Chat completion took 2702.055624961853ms[39m
[1693026288836] [36m[OPENAI] Tokens per second: 12.953101215484459tps[39m
[1693026288836] [32m[OPENAI] Chat completion created successfully.[39m
[1693026288844] --- Observations received -- 
[1693026288844] {
  "observerId": "A1",
  "observation": "Thomas Smith has started walking to 50.52, Y: 14.5.",
  "time": 45.031723
}
[1693026288844] [Character] Getting character: A1
[1693026288930] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026288930] [33m[OPENAI] No functions provided.[39m
[1693026288930] [33m[OPENAI] Creating embedding...[39m
[1693026288976] --- Observations received -- 
[1693026288976] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Stone Ore Deposit (Small) at X: 47.58, Y: 19.17.",
  "time": 45.16092
}
[1693026288976] [Character] Getting character: A1
[1693026289031] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026289032] [33m[OPENAI] No functions provided.[39m
[1693026289032] [33m[OPENAI] Creating embedding...[39m
[1693026289087] {
  "id": "chatcmpl-7olYz0rVKqE4VyVZYijh3tnaouu00",
  "object": "chat.completion",
  "created": 1692333589,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693026289087] [36m[OPENAI] Chat completion took 157.2157500386238ms[39m
[1693026289087] [36m[OPENAI] Tokens per second: 6.360685871195004tps[39m
[1693026289087] [32m[OPENAI] Chat completion created successfully.[39m
[1693026289153] [32m[OPENAI] Embedding created successfully.[39m
[1693026289234] {
  "id": "chatcmpl-7olYzzHOWkhROkE4Kihk6zsnVnk6Q",
  "object": "chat.completion",
  "created": 1692333589,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693026289234] [36m[OPENAI] Chat completion took 201.5089169740677ms[39m
[1693026289234] [36m[OPENAI] Tokens per second: 4.9625595483136395tps[39m
[1693026289234] [32m[OPENAI] Chat completion created successfully.[39m
[1693026289253] [32m[OPENAI] Embedding created successfully.[39m
[1693026289311] --- Observations received -- 
[1693026289311] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (479) at X: 45.24001, Y: 10.2",
  "time": 45.5015335
}
[1693026289312] [Character] Getting character: A1
[1693026289383] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026289383] [33m[OPENAI] No functions provided.[39m
[1693026289384] [33m[OPENAI] Creating embedding...[39m
[1693026289459] --- Observations received -- 
[1693026289459] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Coal Ore Deposit (Small) at X: 54.64, Y: 16.97.",
  "time": 45.64843
}
[1693026289459] [Character] Getting character: A1
[1693026289546] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026289547] [33m[OPENAI] No functions provided.[39m
[1693026289547] [33m[OPENAI] Creating embedding...[39m
[1693026289557] [32m[OPENAI] Embedding created successfully.[39m
[1693026289612] --- Observations received -- 
[1693026289612] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (484) at X: 50.77, Y: 9.22",
  "time": 45.80225
}
[1693026289612] [Character] Getting character: A1
[1693026289673] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026289673] [33m[OPENAI] No functions provided.[39m
[1693026289673] [33m[OPENAI] Creating embedding...[39m
[1693026289689] {
  "id": "chatcmpl-7olaKrfvWqUsCOsI8esX0VNRg9j9R",
  "object": "chat.completion",
  "created": 1692333672,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693026289689] [36m[OPENAI] Chat completion took 305.4022919535637ms[39m
[1693026289689] [36m[OPENAI] Tokens per second: 3.27436966370917tps[39m
[1693026289689] [32m[OPENAI] Chat completion created successfully.[39m
[1693026289711] {
  "id": "chatcmpl-7olZ0T8O9CCrq9EEPfKU0azLDZq33",
  "object": "chat.completion",
  "created": 1692333590,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693026289711] [36m[OPENAI] Chat completion took 164.35970902442932ms[39m
[1693026289711] [36m[OPENAI] Tokens per second: 6.08421617399777tps[39m
[1693026289711] [32m[OPENAI] Chat completion created successfully.[39m
[1693026289745] [32m[OPENAI] Embedding created successfully.[39m
[1693026289903] {
  "id": "chatcmpl-7olZ0MzGvSytQom91j2vFoVNL1rQU",
  "object": "chat.completion",
  "created": 1692333590,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693026289903] [36m[OPENAI] Chat completion took 230.42325001955032ms[39m
[1693026289904] [36m[OPENAI] Tokens per second: 4.339839837842556tps[39m
[1693026289904] [32m[OPENAI] Chat completion created successfully.[39m
[1693026289906] [32m[OPENAI] Embedding created successfully.[39m
[1693026290142] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 �;��\u0018\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026290143] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  �;��"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026290143] [31mFailed to create chat completion. Retrying...[39m
[1693026290143] [33m[OPENAI] Using 8 functions.[39m
[1693026290170] --- Observations received -- 
[1693026290171] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (481) at X: 47.72001, Y: 10.21",
  "time": 46.3601227
}
[1693026290171] [Character] Getting character: A1
[1693026290227] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026290227] [33m[OPENAI] No functions provided.[39m
[1693026290228] [33m[OPENAI] Creating embedding...[39m
[1693026290235] --- Observations received -- 
[1693026290235] {
  "observerId": "A1",
  "observation": "Thomas Smith finished walking to 50.52, Y: 14.5.",
  "time": 46.4199829
}
[1693026290235] [Character] Getting character: A1
[1693026290239] [Character] Getting character: A1
[1693026290282] [33m[OPENAI] Creating embedding...[39m
[1693026290311] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026290311] [33m[OPENAI] No functions provided.[39m
[1693026290311] [33m[OPENAI] Creating embedding...[39m
[1693026290354] {
  "id": "chatcmpl-7olZ1yP4bsQojjuSfETP7pN2Nge08",
  "object": "chat.completion",
  "created": 1692333591,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "4"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693026290354] [36m[OPENAI] Chat completion took 126.51266700029373ms[39m
[1693026290354] [36m[OPENAI] Tokens per second: 7.904346842974058tps[39m
[1693026290354] [32m[OPENAI] Chat completion created successfully.[39m
[1693026290470] {
  "id": "chatcmpl-7olZ14kauh9VqvPIrPGlltRU20plh",
  "object": "chat.completion",
  "created": 1692333591,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693026290470] [36m[OPENAI] Chat completion took 158.95870798826218ms[39m
[1693026290470] [36m[OPENAI] Tokens per second: 6.290941922312567tps[39m
[1693026290470] [32m[OPENAI] Chat completion created successfully.[39m
[1693026290473] [32m[OPENAI] Embedding created successfully.[39m
[1693026290481] [32m[OPENAI] Embedding created successfully.[39m
[1693026290529] [32m[OPENAI] Embedding created successfully.[39m
[1693026290860] [33m[OPENAI] Creating embedding...[39m
[1693026290908] [32m[OPENAI] Embedding created successfully.[39m
[1693026291289] [33m[OPENAI] Creating embedding...[39m
[1693026291329] [32m[OPENAI] Embedding created successfully.[39m
[1693026291559] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 J͕�Q�\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026291561] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  J͕�Q�"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026291561] [31mFailed to create chat completion. Retrying...[39m
[1693026291561] [33m[OPENAI] Using 8 functions.[39m
[1693026291600] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 �;��\u0018\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026291600] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  �;��"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026291600] [31mFailed to create chat completion. Retrying...[39m
[1693026291600] [33m[OPENAI] Using 8 functions.[39m
[1693026291633] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 �;��\u0018\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026291633] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  �;��"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026291633] [31mFailed to create chat completion. Retrying...[39m
[1693026291633] [33m[OPENAI] Using 8 functions.[39m
[1693026291667] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 �;��\u0018\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026291669] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  �;��"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026291669] [31mFailed to create chat completion. Retrying...[39m
[1693026291673] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026291673] [33m[OPENAI] Using 8 functions.[39m
[1693026291691] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026291691] [33m[OPENAI] Using 10 functions.[39m
[1693026293167] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 F���Q\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026293167] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  F���Q"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026293167] [31mFailed to create chat completion. Retrying...[39m
[1693026293167] [33m[OPENAI] Using 8 functions.[39m
[1693026296013] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 �;��\u0018\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026296014] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  �;��"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026296014] [31mFailed to create chat completion. Retrying...[39m
[1693026296014] [33m[OPENAI] Using 8 functions.[39m
[1693026296052] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 F���Q\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026296052] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  F���Q"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026296052] [31mFailed to create chat completion. Retrying...[39m
[1693026296052] [33m[OPENAI] Using 8 functions.[39m
[1693026296087] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 F���Q\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026296088] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  F���Q"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026296088] [31mFailed to create chat completion. Retrying...[39m
[1693026296089] [33m[OPENAI] Using 8 functions.[39m
[1693026296118] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 F���Q\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026296118] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  F���Q"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026296118] [31mFailed to create chat completion. Retrying...[39m
[1693026296119] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026296119] [33m[OPENAI] Using 8 functions.[39m
[1693026296472] {
  "id": "chatcmpl-7rflbsVgx5NxV3lPBxRnJndlRNC6B",
  "object": "chat.completion",
  "created": 1693026291,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A1\",\n  \"x\": 52.41,\n  \"y\": 11.03\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1942,
    "completion_tokens": 35,
    "total_tokens": 1977
  }
}
[1693026296472] [36m[OPENAI] Chat completion took 4780.550583958626ms[39m
[1693026296472] [36m[OPENAI] Tokens per second: 7.32133242506506tps[39m
[1693026296472] [32m[OPENAI] Chat completion created successfully.[39m
[1693026296476] --- Observations received -- 
[1693026296476] {
  "observerId": "A1",
  "observation": "Thomas Smith has started walking to 52.41, Y: 11.03.",
  "time": 52.6662178
}
[1693026296476] [Character] Getting character: A1
[1693026296531] --- Observations received -- 
[1693026296531] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Copper Ore Deposit (Small) at X: 50.43, Y: 20.71.",
  "time": 52.7221642
}
[1693026296531] [Character] Getting character: A1
[1693026296556] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026296556] [33m[OPENAI] No functions provided.[39m
[1693026296556] [33m[OPENAI] Creating embedding...[39m
[1693026296569] --- Observations received -- 
[1693026296569] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Copper Ore Deposit (Small) at X: 53.88, Y: 19.83.",
  "time": 52.7600327
}
[1693026296569] [Character] Getting character: A1
[1693026296613] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026296613] [33m[OPENAI] No functions provided.[39m
[1693026296613] [33m[OPENAI] Creating embedding...[39m
[1693026296623] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026296623] [33m[OPENAI] No functions provided.[39m
[1693026296623] [33m[OPENAI] Creating embedding...[39m
[1693026296700] {
  "id": "chatcmpl-7olZEItXNzcrRu7ZPMwBc1ztqYMR4",
  "object": "chat.completion",
  "created": 1692333604,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693026296700] [36m[OPENAI] Chat completion took 143.90979200601578ms[39m
[1693026296700] [36m[OPENAI] Tokens per second: 6.948797479730897tps[39m
[1693026296700] [32m[OPENAI] Chat completion created successfully.[39m
[1693026296777] [32m[OPENAI] Embedding created successfully.[39m
[1693026296795] {
  "id": "chatcmpl-7olZEhqLJkFuxEwi4kc7kaLB8Vkij",
  "object": "chat.completion",
  "created": 1692333604,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693026296795] [36m[OPENAI] Chat completion took 171.7051249742508ms[39m
[1693026296795] [36m[OPENAI] Tokens per second: 5.823937987581685tps[39m
[1693026296795] [32m[OPENAI] Chat completion created successfully.[39m
[1693026296818] {
  "id": "chatcmpl-7olZEHsvMpmzBkEItH0XPRoCXQR9h",
  "object": "chat.completion",
  "created": 1692333604,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693026296819] [36m[OPENAI] Chat completion took 205.65454196929932ms[39m
[1693026296819] [36m[OPENAI] Tokens per second: 4.8625232899027475tps[39m
[1693026296819] [32m[OPENAI] Chat completion created successfully.[39m
[1693026296835] --- Observations received -- 
[1693026296835] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees CopperOreSmall (2) at X: 50.43, Y: 20.71",
  "time": 53.0216446
}
[1693026296835] [Character] Getting character: A1
[1693026296870] [32m[OPENAI] Embedding created successfully.[39m
[1693026296878] [32m[OPENAI] Embedding created successfully.[39m
[1693026296894] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026296894] [33m[OPENAI] No functions provided.[39m
[1693026296894] [33m[OPENAI] Creating embedding...[39m
[1693026297054] {
  "id": "chatcmpl-7olZFVyBHlXcLmQvFEDaQVfU5rDmB",
  "object": "chat.completion",
  "created": 1692333605,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693026297054] [36m[OPENAI] Chat completion took 159.6742080450058ms[39m
[1693026297054] [36m[OPENAI] Tokens per second: 6.262752214297127tps[39m
[1693026297054] [32m[OPENAI] Chat completion created successfully.[39m
[1693026297076] --- Observations received -- 
[1693026297076] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees StoneOreMedium (1) at X: 46.05, Y: 17.85",
  "time": 53.2637367
}
[1693026297076] [Character] Getting character: A1
[1693026297103] [32m[OPENAI] Embedding created successfully.[39m
[1693026297130] --- Observations received -- 
[1693026297131] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Coal Ore Deposit (Small) at X: 56.74, Y: 14.81.",
  "time": 53.32085
}
[1693026297131] [Character] Getting character: A1
[1693026297132] --- Observations received -- 
[1693026297132] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees CopperOreSmall (3) at X: 53.88, Y: 19.83",
  "time": 53.32085
}
[1693026297132] [Character] Getting character: A1
[1693026297139] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026297139] [33m[OPENAI] No functions provided.[39m
[1693026297139] [33m[OPENAI] Creating embedding...[39m
[1693026297193] --- Observations received -- 
[1693026297194] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees StoneOreSmall (5) at X: 47.58, Y: 19.17",
  "time": 53.38352
}
[1693026297194] [Character] Getting character: A1
[1693026297194] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026297194] [33m[OPENAI] No functions provided.[39m
[1693026297194] [33m[OPENAI] Creating embedding...[39m
[1693026297198] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026297198] [33m[OPENAI] No functions provided.[39m
[1693026297198] [33m[OPENAI] Creating embedding...[39m
[1693026297253] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026297253] [33m[OPENAI] No functions provided.[39m
[1693026297253] [33m[OPENAI] Creating embedding...[39m
[1693026297276] --- Observations received -- 
[1693026297276] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 47.72001, Y: 10.21.",
  "time": 53.46161
}
[1693026297276] [Character] Getting character: A1
[1693026297294] [32m[OPENAI] Embedding created successfully.[39m
[1693026297301] {
  "id": "chatcmpl-7olZFxI4uk8V230Sf6vE5gxpsZif7",
  "object": "chat.completion",
  "created": 1692333605,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693026297301] [36m[OPENAI] Chat completion took 162.00529199838638ms[39m
[1693026297301] [36m[OPENAI] Tokens per second: 6.1726378667306765tps[39m
[1693026297301] [32m[OPENAI] Chat completion created successfully.[39m
[1693026297332] --- Observations received -- 
[1693026297333] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 50.77, Y: 9.22.",
  "time": 53.5204773
}
[1693026297333] [Character] Getting character: A1
[1693026297337] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026297337] [33m[OPENAI] No functions provided.[39m
[1693026297337] [33m[OPENAI] Creating embedding...[39m
[1693026297349] {
  "id": "chatcmpl-7omQd6A5XlnL9M5rjRgFp0BaD70vR",
  "object": "chat.completion",
  "created": 1692336915,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693026297349] [36m[OPENAI] Chat completion took 150.72966700792313ms[39m
[1693026297349] [36m[OPENAI] Tokens per second: 6.634394010486568tps[39m
[1693026297349] [32m[OPENAI] Chat completion created successfully.[39m
[1693026297351] {
  "id": "chatcmpl-7olZFqXpO5kvxAmpyje5MwyyxJEe8",
  "object": "chat.completion",
  "created": 1692333605,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693026297351] [36m[OPENAI] Chat completion took 156.6329579949379ms[39m
[1693026297351] [36m[OPENAI] Tokens per second: 6.3843523917381315tps[39m
[1693026297351] [32m[OPENAI] Chat completion created successfully.[39m
[1693026297354] [32m[OPENAI] Embedding created successfully.[39m
[1693026297379] [32m[OPENAI] Embedding created successfully.[39m
[1693026297390] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026297390] [33m[OPENAI] No functions provided.[39m
[1693026297390] [33m[OPENAI] Creating embedding...[39m
[1693026297413] {
  "id": "chatcmpl-7olZFpPHyRUpQFR0WwKFTHJa1EXVF",
  "object": "chat.completion",
  "created": 1692333605,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693026297413] [36m[OPENAI] Chat completion took 159.8629999756813ms[39m
[1693026297413] [36m[OPENAI] Tokens per second: 6.255356149653905tps[39m
[1693026297413] [32m[OPENAI] Chat completion created successfully.[39m
[1693026297428] [32m[OPENAI] Embedding created successfully.[39m
[1693026297457] [32m[OPENAI] Embedding created successfully.[39m
[1693026297468] {
  "id": "chatcmpl-7olZFcOED2ldUw4M9Rg9y1NUOOc8o",
  "object": "chat.completion",
  "created": 1692333605,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693026297468] [36m[OPENAI] Chat completion took 131.10137498378754ms[39m
[1693026297468] [36m[OPENAI] Tokens per second: 7.627685065268488tps[39m
[1693026297468] [32m[OPENAI] Chat completion created successfully.[39m
[1693026297502] [32m[OPENAI] Embedding created successfully.[39m
[1693026297510] {
  "id": "chatcmpl-7olYVK3ubcflhZofq80hFwcKqzbWN",
  "object": "chat.completion",
  "created": 1692333559,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693026297510] [36m[OPENAI] Chat completion took 120.29616695642471ms[39m
[1693026297510] [36m[OPENAI] Tokens per second: 8.312816819527038tps[39m
[1693026297510] [32m[OPENAI] Chat completion created successfully.[39m
[1693026297558] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 V���Q\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026297558] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  V���Q"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026297558] [31mFailed to create chat completion. Retrying...[39m
[1693026297559] [33m[OPENAI] Using 8 functions.[39m
[1693026297567] --- Observations received -- 
[1693026297570] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees StoneOreSmall (4) at X: 45.73, Y: 15.31",
  "time": 53.75733
}
[1693026297570] [Character] Getting character: A1
[1693026297629] --- Observations received -- 
[1693026297631] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 53.93, Y: 9.11.",
  "time": 53.8201942
}
[1693026297631] [Character] Getting character: A1
[1693026297637] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026297637] [33m[OPENAI] No functions provided.[39m
[1693026297637] [33m[OPENAI] Creating embedding...[39m
[1693026297710] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026297710] [33m[OPENAI] No functions provided.[39m
[1693026297710] [33m[OPENAI] Creating embedding...[39m
[1693026297769] {
  "id": "chatcmpl-7olZFfCJV4xzX0bc3BWKu9HvdsjlD",
  "object": "chat.completion",
  "created": 1692333605,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 1,
    "total_tokens": 109
  }
}
[1693026297769] [36m[OPENAI] Chat completion took 132.1091250181198ms[39m
[1693026297769] [36m[OPENAI] Tokens per second: 7.569499834798256tps[39m
[1693026297769] [32m[OPENAI] Chat completion created successfully.[39m
[1693026297822] [32m[OPENAI] Embedding created successfully.[39m
[1693026297844] {
  "id": "chatcmpl-7olZFXZGaFBslxr8QeIyLVveM2Ywp",
  "object": "chat.completion",
  "created": 1692333605,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 101,
    "completion_tokens": 1,
    "total_tokens": 102
  }
}
[1693026297844] [36m[OPENAI] Chat completion took 133.97699999809265ms[39m
[1693026297844] [36m[OPENAI] Tokens per second: 7.463967696054072tps[39m
[1693026297844] [32m[OPENAI] Chat completion created successfully.[39m
[1693026297928] [32m[OPENAI] Embedding created successfully.[39m
[1693026298790] --- Observations received -- 
[1693026298790] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree at X: 57.55001, Y: 10.45.",
  "time": 54.9803467
}
[1693026298790] [Character] Getting character: A1
[1693026298853] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026298853] [33m[OPENAI] No functions provided.[39m
[1693026298853] [33m[OPENAI] Creating embedding...[39m
[1693026298998] {
  "id": "chatcmpl-7olZGcXlT4ATJ6jqciw9ANlzWLAw7",
  "object": "chat.completion",
  "created": 1692333606,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 102,
    "completion_tokens": 1,
    "total_tokens": 103
  }
}
[1693026298998] [36m[OPENAI] Chat completion took 144.49787497520447ms[39m
[1693026298998] [36m[OPENAI] Tokens per second: 6.920516998409823tps[39m
[1693026298998] [32m[OPENAI] Chat completion created successfully.[39m
[1693026299052] [32m[OPENAI] Embedding created successfully.[39m
[1693026299133] --- Observations received -- 
[1693026299134] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees CoalOreSmall (1) at X: 54.64, Y: 16.97",
  "time": 55.32167
}
[1693026299134] [Character] Getting character: A1
[1693026299195] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026299195] [33m[OPENAI] No functions provided.[39m
[1693026299195] [33m[OPENAI] Creating embedding...[39m
[1693026299310] --- Observations received -- 
[1693026299310] {
  "observerId": "A1",
  "observation": "Thomas Smith finished walking to 52.41, Y: 11.03.",
  "time": 55.49998
}
[1693026299310] [Character] Getting character: A1
[1693026299317] [Character] Getting character: A1
[1693026299337] {
  "id": "chatcmpl-7olZHikuf073X1j49oWXsuSi6yhD7",
  "object": "chat.completion",
  "created": 1692333607,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 108,
    "completion_tokens": 2,
    "total_tokens": 110
  }
}
[1693026299337] [36m[OPENAI] Chat completion took 141.72874999046326ms[39m
[1693026299337] [36m[OPENAI] Tokens per second: 14.111462918670894tps[39m
[1693026299337] [32m[OPENAI] Chat completion created successfully.[39m
[1693026299344] [33m[OPENAI] Creating embedding...[39m
[1693026299369] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026299369] [33m[OPENAI] No functions provided.[39m
[1693026299369] [33m[OPENAI] Creating embedding...[39m
[1693026299377] [32m[OPENAI] Embedding created successfully.[39m
[1693026299511] [32m[OPENAI] Embedding created successfully.[39m
[1693026299576] [32m[OPENAI] Embedding created successfully.[39m
[1693026299578] {
  "id": "chatcmpl-7olZHeE3UnWFAbhXiPACT6GJkO4KL",
  "object": "chat.completion",
  "created": 1692333607,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "5"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693026299578] [36m[OPENAI] Chat completion took 208.602333009243ms[39m
[1693026299578] [36m[OPENAI] Tokens per second: 4.793810239675942tps[39m
[1693026299578] [32m[OPENAI] Chat completion created successfully.[39m
[1693026299721] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 F�V��\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026299724] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  F�V��"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026299725] [31mFailed to create chat completion. Retrying...[39m
[1693026299725] [33m[OPENAI] Using 8 functions.[39m
[1693026299760] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 V���Q\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026299760] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  V���Q"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026299760] [31mFailed to create chat completion. Retrying...[39m
[1693026299760] [33m[OPENAI] Using 8 functions.[39m
[1693026299827] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 V���Q\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026299827] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  V���Q"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026299827] [31mFailed to create chat completion. Retrying...[39m
[1693026299827] [33m[OPENAI] Using 8 functions.[39m
[1693026299869] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 F�V��\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026299869] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  F�V��"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026299869] [31mFailed to create chat completion. Retrying...[39m
[1693026299876] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026299876] [33m[OPENAI] Using 8 functions.[39m
[1693026300019] [33m[OPENAI] Creating embedding...[39m
[1693026300182] [32m[OPENAI] Embedding created successfully.[39m
[1693026300615] [33m[OPENAI] Creating embedding...[39m
[1693026300782] [32m[OPENAI] Embedding created successfully.[39m
[1693026301167] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 >����\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026301168] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  >����"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026301168] [31mFailed to create chat completion. Retrying...[39m
[1693026301168] [33m[OPENAI] Using 8 functions.[39m
[1693026301226] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026301226] [33m[OPENAI] Using 7 functions.[39m
[1693026302561] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 �;��\u0018\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026302572] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  �;��"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026302572] [31mFailed to create chat completion. Retrying...[39m
[1693026302572] [33m[OPENAI] Using 8 functions.[39m
[1693026302609] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 >����\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026302609] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  >����"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026302609] [31mFailed to create chat completion. Retrying...[39m
[1693026302610] [33m[OPENAI] Using 8 functions.[39m
[1693026302643] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 >����\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026302643] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  >����"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026302643] [31mFailed to create chat completion. Retrying...[39m
[1693026302643] [33m[OPENAI] Using 8 functions.[39m
[1693026302678] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 �;��\u0018\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026302678] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  �;��"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026302678] [31mFailed to create chat completion. Retrying...[39m
[1693026302685] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026302685] [33m[OPENAI] Using 8 functions.[39m
[1693026302785] {
  "id": "chatcmpl-7rfllYaOZAcqdb4EE0tpAMV4mVRVg",
  "object": "chat.completion",
  "created": 1693026301,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_axe",
          "arguments": "{\"characterId\": \"A1\"}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1612,
    "completion_tokens": 15,
    "total_tokens": 1627
  }
}
[1693026302785] [36m[OPENAI] Chat completion took 1558.7279170155525ms[39m
[1693026302785] [36m[OPENAI] Tokens per second: 9.623231762423316tps[39m
[1693026302785] [32m[OPENAI] Chat completion created successfully.[39m
[1693026303795] [Character] Getting character: A1
[1693026303835] [33m[OPENAI] Creating embedding...[39m
[1693026303869] [32m[OPENAI] Embedding created successfully.[39m
[1693026304348] [33m[OPENAI] Creating embedding...[39m
[1693026304394] [32m[OPENAI] Embedding created successfully.[39m
[1693026304611] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 FΕ�Q;\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026304611] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  FΕ�Q;"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026304611] [31mFailed to create chat completion. Retrying...[39m
[1693026304611] [33m[OPENAI] Using 8 functions.[39m
[1693026304800] [33m[OPENAI] Creating embedding...[39m
[1693026304844] [32m[OPENAI] Embedding created successfully.[39m
[1693026305269] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026305269] [33m[OPENAI] Using 7 functions.[39m
[1693026306824] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 F���Q\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026306824] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  F���Q"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026306824] [31mFailed to create chat completion. Retrying...[39m
[1693026306824] [33m[OPENAI] Using 8 functions.[39m
[1693026306869] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 FΕ�Q;\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026306870] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  FΕ�Q;"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026306870] [31mFailed to create chat completion. Retrying...[39m
[1693026306870] [33m[OPENAI] Using 8 functions.[39m
[1693026306906] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 FΕ�Q;\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026306906] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  FΕ�Q;"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026306906] [31mFailed to create chat completion. Retrying...[39m
[1693026306907] [33m[OPENAI] Using 8 functions.[39m
[1693026306942] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 F���Q\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026306942] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  F���Q"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026306942] [31mFailed to create chat completion. Retrying...[39m
[1693026306949] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026306949] [33m[OPENAI] Using 8 functions.[39m
[1693026307841] {
  "id": "chatcmpl-7rflp9bkCYUcGYzEo7GWf8VoXetlM",
  "object": "chat.completion",
  "created": 1693026305,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "swing_axe",
          "arguments": "{\n  \"characterId\": \"A1\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1643,
    "completion_tokens": 18,
    "total_tokens": 1661
  }
}
[1693026307841] [36m[OPENAI] Chat completion took 2572.5507499575615ms[39m
[1693026307841] [36m[OPENAI] Tokens per second: 6.996946513221144tps[39m
[1693026307842] [32m[OPENAI] Chat completion created successfully.[39m
[1693026308459] --- Observations received -- 
[1693026308459] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Tree Stump at X: 52.41, Y: 11.03.",
  "time": 64.64898
}
[1693026308459] [Character] Getting character: A1
[1693026308459] --- Observations received -- 
[1693026308459] {
  "observerId": "A1",
  "observation": "Thomas Smith picked up Wood at X: 52.36464, Y: 11.17588",
  "time": 64.64898
}
[1693026308459] [Character] Getting character: A1
[1693026308559] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026308559] [33m[OPENAI] No functions provided.[39m
[1693026308559] [33m[OPENAI] Creating embedding...[39m
[1693026308559] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026308559] [33m[OPENAI] No functions provided.[39m
[1693026308559] [33m[OPENAI] Creating embedding...[39m
[1693026308698] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 J��_�\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026308699] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  J��_�"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026308699] [31mFailed to create chat completion. Retrying...[39m
[1693026308699] [33m[OPENAI] Using 8 functions.[39m
[1693026308736] [32m[OPENAI] Embedding created successfully.[39m
[1693026308736] {
  "id": "chatcmpl-7q3pDf9Y1FNfuyEiRFI9N34wneROX",
  "object": "chat.completion",
  "created": 1692642115,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693026308736] [36m[OPENAI] Chat completion took 177.19174998998642ms[39m
[1693026308736] [36m[OPENAI] Tokens per second: 5.643603610532165tps[39m
[1693026308736] [32m[OPENAI] Chat completion created successfully.[39m
[1693026308778] [32m[OPENAI] Embedding created successfully.[39m
[1693026308850] [Character] Getting character: A1
[1693026308878] [33m[OPENAI] Creating embedding...[39m
[1693026308899] {
  "id": "chatcmpl-7rflslReXAm35kwnyIOVJQk4ajllk",
  "object": "chat.completion",
  "created": 1693026308,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 103,
    "completion_tokens": 1,
    "total_tokens": 104
  }
}
[1693026308899] [36m[OPENAI] Chat completion took 339.9954580068588ms[39m
[1693026308899] [36m[OPENAI] Tokens per second: 2.941215761711225tps[39m
[1693026308899] [32m[OPENAI] Chat completion created successfully.[39m
[1693026308913] [32m[OPENAI] Embedding created successfully.[39m
[1693026309338] [33m[OPENAI] Creating embedding...[39m
[1693026309377] [32m[OPENAI] Embedding created successfully.[39m
[1693026309824] [33m[OPENAI] Creating embedding...[39m
[1693026309865] [32m[OPENAI] Embedding created successfully.[39m
[1693026310072] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 F͙?�v\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026310072] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  F͙?�v"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026310072] [31mFailed to create chat completion. Retrying...[39m
[1693026310072] [33m[OPENAI] Using 8 functions.[39m
[1693026310105] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 J��_�\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026310105] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  J��_�"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026310105] [31mFailed to create chat completion. Retrying...[39m
[1693026310105] [33m[OPENAI] Using 8 functions.[39m
[1693026310147] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 J��_�\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026310148] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  J��_�"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026310148] [31mFailed to create chat completion. Retrying...[39m
[1693026310149] [33m[OPENAI] Using 8 functions.[39m
[1693026310185] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 F͙?�v\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026310186] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  F͙?�v"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026310186] [31mFailed to create chat completion. Retrying...[39m
[1693026310188] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026310188] [33m[OPENAI] Using 8 functions.[39m
[1693026310263] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026310263] [33m[OPENAI] Using 5 functions.[39m
[1693026311724] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 FΕ�Q;\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026311724] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  FΕ�Q;"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026311724] [31mFailed to create chat completion. Retrying...[39m
[1693026311724] [33m[OPENAI] Using 8 functions.[39m
[1693026312759] {
  "id": "chatcmpl-7rfluTHQHdOcXm7DohCEroFSLmv3L",
  "object": "chat.completion",
  "created": 1693026310,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "move_to",
          "arguments": "{\n  \"characterId\": \"A1\",\n  \"x\": 50.52,\n  \"y\": 14.5\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 1666,
    "completion_tokens": 35,
    "total_tokens": 1701
  }
}
[1693026312759] [36m[OPENAI] Chat completion took 2495.4329159855843ms[39m
[1693026312759] [36m[OPENAI] Tokens per second: 14.025622478485488tps[39m
[1693026312759] [32m[OPENAI] Chat completion created successfully.[39m
[1693026312772] --- Observations received -- 
[1693026312772] {
  "observerId": "A1",
  "observation": "Thomas Smith has started walking to 50.52, Y: 14.5.",
  "time": 68.9574
}
[1693026312772] [Character] Getting character: A1
[1693026312831] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026312831] [33m[OPENAI] No functions provided.[39m
[1693026312831] [33m[OPENAI] Creating embedding...[39m
[1693026312949] --- Observations received -- 
[1693026312950] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Coal Ore Deposit (Small) at X: 54.64, Y: 16.97.",
  "time": 69.14022
}
[1693026312950] [Character] Getting character: A1
[1693026312976] {
  "id": "chatcmpl-7olYz0rVKqE4VyVZYijh3tnaouu00",
  "object": "chat.completion",
  "created": 1692333589,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 1,
    "total_tokens": 101
  }
}
[1693026312976] [36m[OPENAI] Chat completion took 144.37087500095367ms[39m
[1693026312976] [36m[OPENAI] Tokens per second: 6.926604829356298tps[39m
[1693026312976] [32m[OPENAI] Chat completion created successfully.[39m
[1693026313007] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026313007] [33m[OPENAI] No functions provided.[39m
[1693026313008] [33m[OPENAI] Creating embedding...[39m
[1693026313043] [32m[OPENAI] Embedding created successfully.[39m
[1693026313076] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 �O���\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026313076] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  �O���"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026313077] [31mFailed to create chat completion. Retrying...[39m
[1693026313077] [33m[OPENAI] Using 8 functions.[39m
[1693026313113] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 FΕ�Q;\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026313113] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  FΕ�Q;"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026313113] [31mFailed to create chat completion. Retrying...[39m
[1693026313113] [33m[OPENAI] Using 8 functions.[39m
[1693026313148] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 FΕ�Q;\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026313152] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  FΕ�Q;"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026313153] [31mFailed to create chat completion. Retrying...[39m
[1693026313153] [33m[OPENAI] Using 8 functions.[39m
[1693026313173] {
  "id": "chatcmpl-7olZ0T8O9CCrq9EEPfKU0azLDZq33",
  "object": "chat.completion",
  "created": 1692333590,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693026313174] [36m[OPENAI] Chat completion took 165.8375000357628ms[39m
[1693026313174] [36m[OPENAI] Tokens per second: 6.029999244949727tps[39m
[1693026313174] [32m[OPENAI] Chat completion created successfully.[39m
[1693026313198] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 FΕ�Q;\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026313198] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  FΕ�Q;"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026313198] [31mFailed to create chat completion. Retrying...[39m
[1693026313209] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026313209] [33m[OPENAI] Using 8 functions.[39m
[1693026313220] [32m[OPENAI] Embedding created successfully.[39m
[1693026313273] --- Observations received -- 
[1693026313273] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (483) at X: 57.55001, Y: 10.45",
  "time": 69.46073
}
[1693026313274] [Character] Getting character: A1
[1693026313340] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026313341] [33m[OPENAI] No functions provided.[39m
[1693026313344] [33m[OPENAI] Creating embedding...[39m
[1693026313509] [32m[OPENAI] Embedding created successfully.[39m
[1693026313514] {
  "id": "chatcmpl-7ola8TFJfEZ7WPK3o6frrBhgDvlNs",
  "object": "chat.completion",
  "created": 1692333660,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693026313514] [36m[OPENAI] Chat completion took 172.68483299016953ms[39m
[1693026313514] [36m[OPENAI] Tokens per second: 5.7908965291522tps[39m
[1693026313514] [32m[OPENAI] Chat completion created successfully.[39m
[1693026314469] --- Observations received -- 
[1693026314470] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (485) at X: 53.93, Y: 9.11",
  "time": 70.66007
}
[1693026314470] [Character] Getting character: A1
[1693026314512] --- Observations received -- 
[1693026314520] {
  "observerId": "A1",
  "observation": "Thomas Smith sees Stone Ore Deposit (Small) at X: 45.73, Y: 15.31.",
  "time": 70.70253
}
[1693026314520] [Character] Getting character: A1
[1693026314529] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026314530] [33m[OPENAI] No functions provided.[39m
[1693026314530] [33m[OPENAI] Creating embedding...[39m
[1693026314570] --- Observations received -- 
[1693026314570] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees CoalOreSmall at X: 56.74, Y: 14.81",
  "time": 70.7609253
}
[1693026314570] [Character] Getting character: A1
[1693026314579] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026314579] [33m[OPENAI] No functions provided.[39m
[1693026314579] [33m[OPENAI] Creating embedding...[39m
[1693026314627] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026314627] [33m[OPENAI] No functions provided.[39m
[1693026314627] [33m[OPENAI] Creating embedding...[39m
[1693026314659] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 �;��\u0018\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026314659] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  �;��"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026314659] [31mFailed to create chat completion. Retrying...[39m
[1693026314659] [33m[OPENAI] Using 8 functions.[39m
[1693026314715] {
  "id": "chatcmpl-7olaArXcvcbOQxeztCmBPZD62WGiJ",
  "object": "chat.completion",
  "created": 1692333662,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "2"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693026314715] [36m[OPENAI] Chat completion took 185.1753339767456ms[39m
[1693026314715] [36m[OPENAI] Tokens per second: 5.400287276520211tps[39m
[1693026314715] [32m[OPENAI] Chat completion created successfully.[39m
[1693026314716] {
  "id": "chatcmpl-7olYVPZO2hJ85fnP0AXelCHaux4jx",
  "object": "chat.completion",
  "created": 1692333559,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 106,
    "completion_tokens": 1,
    "total_tokens": 107
  }
}
[1693026314716] [36m[OPENAI] Chat completion took 136.62479096651077ms[39m
[1693026314716] [36m[OPENAI] Tokens per second: 7.319315864462095tps[39m
[1693026314716] [32m[OPENAI] Chat completion created successfully.[39m
[1693026314716] [32m[OPENAI] Embedding created successfully.[39m
[1693026314770] --- Observations received -- 
[1693026314771] {
  "observerId": "A1",
  "observation": "Thomas Smith no longer sees Tree (484) at X: 50.77, Y: 9.22",
  "time": 70.96084
}
[1693026314771] [Character] Getting character: A1
[1693026314796] [32m[OPENAI] Embedding created successfully.[39m
[1693026314811] --- Observations received -- 
[1693026314811] {
  "observerId": "A1",
  "observation": "Thomas Smith finished walking to 50.52, Y: 14.5.",
  "time": 70.99998
}
[1693026314811] [Character] Getting character: A1
[1693026314812] {
  "id": "chatcmpl-7olZWuSxu2n8nl1sGEhMXJRAq2baE",
  "object": "chat.completion",
  "created": 1692333622,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "1"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693026314812] [36m[OPENAI] Chat completion took 184.3209170103073ms[39m
[1693026314812] [36m[OPENAI] Tokens per second: 5.425320230715212tps[39m
[1693026314812] [32m[OPENAI] Chat completion created successfully.[39m
[1693026314813] [Character] Getting character: A1
[1693026314857] [32m[OPENAI] Embedding created successfully.[39m
[1693026314866] [33m[OPENAI] Creating embedding...[39m
[1693026314875] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026314875] [33m[OPENAI] No functions provided.[39m
[1693026314875] [33m[OPENAI] Creating embedding...[39m
[1693026314907] [32m[OPENAI] Embedding created successfully.[39m
[1693026314922] [33m[OPENAI][gpt-3.5-turbo] Creating chat completion...[39m
[1693026314922] [33m[OPENAI] No functions provided.[39m
[1693026314922] [33m[OPENAI] Creating embedding...[39m
[1693026314923] [32m[OPENAI] Embedding created successfully.[39m
[1693026315004] {
  "id": "chatcmpl-7olZ0MzGvSytQom91j2vFoVNL1rQU",
  "object": "chat.completion",
  "created": 1692333590,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 105,
    "completion_tokens": 1,
    "total_tokens": 106
  }
}
[1693026315004] [36m[OPENAI] Chat completion took 128.92829203605652ms[39m
[1693026315004] [36m[OPENAI] Tokens per second: 7.756249495031987tps[39m
[1693026315005] [32m[OPENAI] Chat completion created successfully.[39m
[1693026315072] [32m[OPENAI] Embedding created successfully.[39m
[1693026315094] {
  "id": "chatcmpl-7olZ14kauh9VqvPIrPGlltRU20plh",
  "object": "chat.completion",
  "created": 1692333591,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "3"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 99,
    "completion_tokens": 1,
    "total_tokens": 100
  }
}
[1693026315094] [36m[OPENAI] Chat completion took 172.0945839881897ms[39m
[1693026315094] [36m[OPENAI] Tokens per second: 5.810758112344935tps[39m
[1693026315094] [32m[OPENAI] Chat completion created successfully.[39m
[1693026315521] [33m[OPENAI] Creating embedding...[39m
[1693026315568] [32m[OPENAI] Embedding created successfully.[39m
[1693026316015] [33m[OPENAI] Creating embedding...[39m
[1693026316055] [32m[OPENAI] Embedding created successfully.[39m
[1693026316443] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 Ƨ���T\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026316444] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  Ƨ���T"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026316444] [31mFailed to create chat completion. Retrying...[39m
[1693026316444] [33m[OPENAI] Using 8 functions.[39m
[1693026316481] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 �;��\u0018\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026316481] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  �;��"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026316481] [31mFailed to create chat completion. Retrying...[39m
[1693026316481] [33m[OPENAI] Using 8 functions.[39m
[1693026316514] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 �;��\u0018\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026316515] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  �;��"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026316515] [31mFailed to create chat completion. Retrying...[39m
[1693026316515] [33m[OPENAI] Using 8 functions.[39m
[1693026316548] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 �;��\u0018\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026316548] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  �;��"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026316548] [31mFailed to create chat completion. Retrying...[39m
[1693026316565] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026316565] [33m[OPENAI] Using 8 functions.[39m
[1693026316710] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026316711] [33m[OPENAI] Using 12 functions.[39m
[1693026318178] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 �g���\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026318179] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  �g���"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026318179] [31mFailed to create chat completion. Retrying...[39m
[1693026318179] [33m[OPENAI] Using 8 functions.[39m
[1693026319271] [Main] connection (id = b7afae2e-9e83-4cfd-8a40-53493cf7fecb) closed
[1693026319595] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 J͕�Q�\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026319596] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  J͕�Q�"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026319596] [31mFailed to create chat completion. Retrying...[39m
[1693026319597] [33m[OPENAI] Using 8 functions.[39m
[1693026319632] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 �g���\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026319633] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  �g���"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026319633] [31mFailed to create chat completion. Retrying...[39m
[1693026319634] [33m[OPENAI] Using 8 functions.[39m
[1693026319674] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 J͕�Q�\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026319674] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  J͕�Q�"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026319674] [31mFailed to create chat completion. Retrying...[39m
[1693026319674] [33m[OPENAI] Using 8 functions.[39m
[1693026319689] {
  "id": "chatcmpl-7rfm0qDbIw0pazYX8VNQUJpbznhLT",
  "object": "chat.completion",
  "created": 1693026316,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "add_wood_to_chest",
          "arguments": "{\n  \"characterId\": \"A1\",\n  \"chestId\": \"chest_(50.52,14.5)\",\n  \"itemId\": \"wood\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ],
  "usage": {
    "prompt_tokens": 2186,
    "completion_tokens": 44,
    "total_tokens": 2230
  }
}
[1693026319689] [36m[OPENAI] Chat completion took 2978.3192499876022ms[39m
[1693026319689] [36m[OPENAI] Tokens per second: 14.773433036160633tps[39m
[1693026319689] [32m[OPENAI] Chat completion created successfully.[39m
[1693026319709] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 J͕�Q�\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026319710] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  J͕�Q�"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026319710] [31mFailed to create chat completion. Retrying...[39m
[1693026319718] [33m[OPENAI][gpt-4] Creating chat completion...[39m
[1693026319719] [33m[OPENAI] Using 8 functions.[39m
[1693026321440] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 J���Q\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026321440] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  J���Q"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026321440] [31mFailed to create chat completion. Retrying...[39m
[1693026321440] [33m[OPENAI] Using 8 functions.[39m
[1693026322967] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 �;��\u0018\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026322967] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  �;��"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026322967] [31mFailed to create chat completion. Retrying...[39m
[1693026322968] [33m[OPENAI] Using 8 functions.[39m
[1693026323024] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 J���Q\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026323024] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  J���Q"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026323024] [31mFailed to create chat completion. Retrying...[39m
[1693026323024] [33m[OPENAI] Using 8 functions.[39m
[1693026323060] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 �;��\u0018\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026323060] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  �;��"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026323060] [31mFailed to create chat completion. Retrying...[39m
[1693026323060] [33m[OPENAI] Using 8 functions.[39m
[1693026323097] {
  "message": "invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', \"!P\b\u0000 �;��\u0018\"... is not valid JSON",
  "type": "invalid-json"
}
[1693026323097] [31mFetchError: invalid json response body at https://llm_cache.harrishr.workers.dev/chat/completions reason: Unexpected token '!', "!P  �;��"... is not valid JSON[39m
[31m    at /Users/harris/src/starlightshire-server/node_modules/node-fetch/lib/index.js:273:32[39m
[31m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)[39m
[31m    at async OpenAI.request (file:///Users/harris/src/starlightshire-server/node_modules/openai/core.mjs:222:20)[39m
[31m    at async createChatCompletion (file:///Users/harris/src/starlightshire-server/dist/src/ai/openai.js:49:28)[39m
[31m    at async Object.getAction [as GetAction] (file:///Users/harris/src/starlightshire-server/dist/src/ai/agent.js:298:30)[39m
[31m    at async WebSocket.<anonymous> (file:///Users/harris/src/starlightshire-server/dist/src/index.js:70:13) {[39m
[31m  type: 'invalid-json'[39m
[31m}[39m
[1693026323097] [31mFailed to create chat completion. Retrying...[39m
